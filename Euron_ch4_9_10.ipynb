{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "meGh4eGwQY88",
        "jQ29KFY5UnoL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **09**"
      ],
      "metadata": {
        "id": "ApafcjrVhrdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "\n",
        "cust_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Datasets/santander-customer-satisfaction/train_santander.csv\", encoding='latin-1')\n",
        "print('dataset shape:', cust_df.shape)\n",
        "cust_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QXjYeIDMn4yd",
        "outputId": "d52d49c2-e527-4b1f-d347-60c170c4dbf4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset shape: (76020, 371)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
              "0   1     2     23                 0.0                      0.0   \n",
              "1   3     2     34                 0.0                      0.0   \n",
              "2   4     2     23                 0.0                      0.0   \n",
              "\n",
              "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
              "0                      0.0                      0.0                      0.0   \n",
              "1                      0.0                      0.0                      0.0   \n",
              "2                      0.0                      0.0                      0.0   \n",
              "\n",
              "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
              "0                      0.0                      0.0  ...   \n",
              "1                      0.0                      0.0  ...   \n",
              "2                      0.0                      0.0  ...   \n",
              "\n",
              "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
              "0                      0.0                      0.0                     0.0   \n",
              "1                      0.0                      0.0                     0.0   \n",
              "2                      0.0                      0.0                     0.0   \n",
              "\n",
              "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
              "0                     0.0                      0.0                      0.0   \n",
              "1                     0.0                      0.0                      0.0   \n",
              "2                     0.0                      0.0                      0.0   \n",
              "\n",
              "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
              "0                     0.0                     0.0  39205.17       0  \n",
              "1                     0.0                     0.0  49278.03       0  \n",
              "2                     0.0                     0.0  67333.77       0  \n",
              "\n",
              "[3 rows x 371 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-79c0a074-de2e-4d04-b902-432aca0b31a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>39205.17</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49278.03</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>67333.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 371 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79c0a074-de2e-4d04-b902-432aca0b31a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-79c0a074-de2e-4d04-b902-432aca0b31a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-79c0a074-de2e-4d04-b902-432aca0b31a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-26776e94-cdfd-428a-b517-88ca6b8ef4e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-26776e94-cdfd-428a-b517-88ca6b8ef4e2')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-26776e94-cdfd-428a-b517-88ca6b8ef4e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cust_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyJmYqtOoEuy",
        "outputId": "79cfc35f-89e4-4f8b-b581-0864ea74520a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76020 entries, 0 to 76019\n",
            "Columns: 371 entries, ID to TARGET\n",
            "dtypes: float64(111), int64(260)\n",
            "memory usage: 215.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cust_df['TARGET'].value_counts())\n",
        "unsatisfied_cnt = cust_df[cust_df['TARGET']==1].TARGET.count()\n",
        "total_cnt = cust_df.TARGET.count()\n",
        "print('unsatisfied : {0:.2f}'.format((unsatisfied_cnt/total_cnt)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMNFFPhcodXr",
        "outputId": "1a47892f-069d-4229-ac63-6fa65f363d60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    73012\n",
            "1     3008\n",
            "Name: TARGET, dtype: int64\n",
            "unsatisfied : 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cust_df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "7fdM579xoj1S",
        "outputId": "77527e15-5349-47fc-d137-db19c35aff93"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
              "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
              "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
              "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
              "min         1.000000 -999999.000000      5.000000            0.000000   \n",
              "25%     38104.750000       2.000000     23.000000            0.000000   \n",
              "50%     76043.000000       2.000000     28.000000            0.000000   \n",
              "75%    113748.750000       2.000000     40.000000            0.000000   \n",
              "max    151838.000000     238.000000    105.000000       210000.000000   \n",
              "\n",
              "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                 72.363067               119.529632   \n",
              "std                 339.315831               546.266294   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max               12888.030000             21024.810000   \n",
              "\n",
              "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                  3.559130                 6.472698   \n",
              "std                  93.155749               153.737066   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max                8237.820000             11073.570000   \n",
              "\n",
              "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
              "count             76020.000000             76020.000000  ...   \n",
              "mean                  0.412946                 0.567352  ...   \n",
              "std                  30.604864                36.513513  ...   \n",
              "min                   0.000000                 0.000000  ...   \n",
              "25%                   0.000000                 0.000000  ...   \n",
              "50%                   0.000000                 0.000000  ...   \n",
              "75%                   0.000000                 0.000000  ...   \n",
              "max                6600.000000              6600.000000  ...   \n",
              "\n",
              "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                  7.935824                 1.365146   \n",
              "std                 455.887218               113.959637   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max               50003.880000             20385.720000   \n",
              "\n",
              "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
              "count            76020.000000            76020.000000   \n",
              "mean                12.215580                8.784074   \n",
              "std                783.207399              538.439211   \n",
              "min                  0.000000                0.000000   \n",
              "25%                  0.000000                0.000000   \n",
              "50%                  0.000000                0.000000   \n",
              "75%                  0.000000                0.000000   \n",
              "max             138831.630000            91778.730000   \n",
              "\n",
              "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
              "count             76020.000000             76020.000000   \n",
              "mean                 31.505324                 1.858575   \n",
              "std                2013.125393               147.786584   \n",
              "min                   0.000000                 0.000000   \n",
              "25%                   0.000000                 0.000000   \n",
              "50%                   0.000000                 0.000000   \n",
              "75%                   0.000000                 0.000000   \n",
              "max              438329.220000             24650.010000   \n",
              "\n",
              "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
              "count            76020.000000            76020.000000  7.602000e+04   \n",
              "mean                76.026165               56.614351  1.172358e+05   \n",
              "std               4040.337842             2852.579397  1.826646e+05   \n",
              "min                  0.000000                0.000000  5.163750e+03   \n",
              "25%                  0.000000                0.000000  6.787061e+04   \n",
              "50%                  0.000000                0.000000  1.064092e+05   \n",
              "75%                  0.000000                0.000000  1.187563e+05   \n",
              "max             681462.900000           397884.300000  2.203474e+07   \n",
              "\n",
              "             TARGET  \n",
              "count  76020.000000  \n",
              "mean       0.039569  \n",
              "std        0.194945  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        1.000000  \n",
              "\n",
              "[8 rows x 371 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d48452e-3795-46f3-918d-2c090d8f719d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>var3</th>\n",
              "      <th>var15</th>\n",
              "      <th>imp_ent_var16_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult1</th>\n",
              "      <th>imp_op_var39_comer_ult3</th>\n",
              "      <th>imp_op_var40_comer_ult1</th>\n",
              "      <th>imp_op_var40_comer_ult3</th>\n",
              "      <th>imp_op_var40_efect_ult1</th>\n",
              "      <th>imp_op_var40_efect_ult3</th>\n",
              "      <th>...</th>\n",
              "      <th>saldo_medio_var33_hace2</th>\n",
              "      <th>saldo_medio_var33_hace3</th>\n",
              "      <th>saldo_medio_var33_ult1</th>\n",
              "      <th>saldo_medio_var33_ult3</th>\n",
              "      <th>saldo_medio_var44_hace2</th>\n",
              "      <th>saldo_medio_var44_hace3</th>\n",
              "      <th>saldo_medio_var44_ult1</th>\n",
              "      <th>saldo_medio_var44_ult3</th>\n",
              "      <th>var38</th>\n",
              "      <th>TARGET</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>76020.000000</td>\n",
              "      <td>7.602000e+04</td>\n",
              "      <td>76020.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>75964.050723</td>\n",
              "      <td>-1523.199277</td>\n",
              "      <td>33.212865</td>\n",
              "      <td>86.208265</td>\n",
              "      <td>72.363067</td>\n",
              "      <td>119.529632</td>\n",
              "      <td>3.559130</td>\n",
              "      <td>6.472698</td>\n",
              "      <td>0.412946</td>\n",
              "      <td>0.567352</td>\n",
              "      <td>...</td>\n",
              "      <td>7.935824</td>\n",
              "      <td>1.365146</td>\n",
              "      <td>12.215580</td>\n",
              "      <td>8.784074</td>\n",
              "      <td>31.505324</td>\n",
              "      <td>1.858575</td>\n",
              "      <td>76.026165</td>\n",
              "      <td>56.614351</td>\n",
              "      <td>1.172358e+05</td>\n",
              "      <td>0.039569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>43781.947379</td>\n",
              "      <td>39033.462364</td>\n",
              "      <td>12.956486</td>\n",
              "      <td>1614.757313</td>\n",
              "      <td>339.315831</td>\n",
              "      <td>546.266294</td>\n",
              "      <td>93.155749</td>\n",
              "      <td>153.737066</td>\n",
              "      <td>30.604864</td>\n",
              "      <td>36.513513</td>\n",
              "      <td>...</td>\n",
              "      <td>455.887218</td>\n",
              "      <td>113.959637</td>\n",
              "      <td>783.207399</td>\n",
              "      <td>538.439211</td>\n",
              "      <td>2013.125393</td>\n",
              "      <td>147.786584</td>\n",
              "      <td>4040.337842</td>\n",
              "      <td>2852.579397</td>\n",
              "      <td>1.826646e+05</td>\n",
              "      <td>0.194945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-999999.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.163750e+03</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>38104.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.787061e+04</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>76043.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.064092e+05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>113748.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.187563e+05</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>151838.000000</td>\n",
              "      <td>238.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>210000.000000</td>\n",
              "      <td>12888.030000</td>\n",
              "      <td>21024.810000</td>\n",
              "      <td>8237.820000</td>\n",
              "      <td>11073.570000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>6600.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>50003.880000</td>\n",
              "      <td>20385.720000</td>\n",
              "      <td>138831.630000</td>\n",
              "      <td>91778.730000</td>\n",
              "      <td>438329.220000</td>\n",
              "      <td>24650.010000</td>\n",
              "      <td>681462.900000</td>\n",
              "      <td>397884.300000</td>\n",
              "      <td>2.203474e+07</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 371 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d48452e-3795-46f3-918d-2c090d8f719d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2d48452e-3795-46f3-918d-2c090d8f719d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2d48452e-3795-46f3-918d-2c090d8f719d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9af8eea0-21dc-4313-bc7b-cba50ef9ec73\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9af8eea0-21dc-4313-bc7b-cba50ef9ec73')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9af8eea0-21dc-4313-bc7b-cba50ef9ec73 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cust_df['var3'].replace(-999999, 2, inplace=True)\n",
        "cust_df.drop('ID', axis=1, inplace=True)\n",
        "\n",
        "X_features = cust_df.iloc[:,:-1]\n",
        "y_labels = cust_df.iloc[:,-1]\n",
        "\n",
        "print('피처 데이터 shape:{0}'.format(X_features.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2lrifKJonMK",
        "outputId": "06eee6f3-d747-44ae-92ca-6afee1f958ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "피처 데이터 shape:(76020, 369)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels,\n",
        "                                                    test_size=0.2, random_state=0)\n",
        "\n",
        "train_cnt = y_train.count()\n",
        "test_cnt = y_test.count()\n",
        "print('train set, shape:{0}, test set, shape:{1}'.format(X_train.shape, X_test.shape))\n",
        "\n",
        "print('학습 세트 레이블 값 분포 비율')\n",
        "print(y_train.value_counts()/train_cnt)\n",
        "print('\\n테스트 세트 레이블 값 분포 비율')\n",
        "print(y_test.value_counts()/test_cnt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7NLXI9-onnq",
        "outputId": "52d1ee79-bbf5-43af-b31f-c6311fd958fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set, shape:(60816, 369), test set, shape:(15204, 369)\n",
            "학습 세트 레이블 값 분포 비율\n",
            "0    0.960964\n",
            "1    0.039036\n",
            "Name: TARGET, dtype: float64\n",
            "\n",
            "테스트 세트 레이블 값 분포 비율\n",
            "0    0.9583\n",
            "1    0.0417\n",
            "Name: TARGET, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "faJmUTrDL-fN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "xgb_clf = XGBClassifier(n_estimator=500, random_state=156)\n",
        "xgb_clf.fit(X_train, y_train, early_stopping_rounds=100,\n",
        "            eval_metric=\"auc\", eval_set=[(X_train, y_train), (X_test, y_test)], verbose=0)\n",
        "\n",
        "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1], average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-MK3VhGopvA",
        "outputId": "9b8161ce-425a-4d61-fdb8-28c24b829d06"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[03:44:33] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_estimator\" } are not used.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import hp\n",
        "\n",
        "xgb_search_space = {\n",
        "    'max_depth': hp.quniform(\"max_depth\", 5,15,1),\n",
        "    'min_child_weight': hp.quniform(\"min_child_weight\", 1,6,1),\n",
        "    'colsample_bytree': hp.uniform(\"colsample_bytree\", 0.5,0.95),\n",
        "    'learning_rate': hp.uniform(\"learning_rate\", 0.01,0.2),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "02G7A1oTpPid"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def objective_func(xgb_search_space):\n",
        "    xgb_clf = XGBClassifier(n_estimators = 800,\n",
        "\n",
        "                            # int type 필요\n",
        "                            max_depth = int(xgb_search_space['max_depth']),\n",
        "                            min_child_weight = int(xgb_search_space['min_child_weight']),\n",
        "                            learning_rate = xgb_search_space['learning_rate'],\n",
        "                            colsample_bytree = xgb_search_space['colsample_bytree'])\n",
        "\n",
        "    roc_auc_list = []\n",
        "\n",
        "    kf = KFold(n_splits=3)\n",
        "\n",
        "    for tr_index, val_index in kf.split(X_train):\n",
        "      X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
        "      X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
        "\n",
        "      xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n",
        "                  eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "      score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:,1])\n",
        "      roc_auc_list.append(score)\n",
        "\n",
        "\n",
        "    return -1 * np.mean(roc_auc_list)"
      ],
      "metadata": {
        "id": "bNBp9HSmD_2w"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, Trials\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn = objective_func,\n",
        "            space = xgb_search_space,\n",
        "            algo = tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials = trials,\n",
        "            rstate = np.random.default_rng(seed = 30))\n",
        "print('best:', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FEaxVM1LFygl",
        "outputId": "b2ab4ad5-deee-4d84-88c1-e7e2904e8f37"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82172\tvalidation_1-auc:0.79884\n",
            "[1]\tvalidation_0-auc:0.81786\tvalidation_1-auc:0.79065\n",
            "[2]\tvalidation_0-auc:0.83199\tvalidation_1-auc:0.80639\n",
            "[3]\tvalidation_0-auc:0.83262\tvalidation_1-auc:0.80859\n",
            "[4]\tvalidation_0-auc:0.83830\tvalidation_1-auc:0.81264\n",
            "[5]\tvalidation_0-auc:0.84130\tvalidation_1-auc:0.81562\n",
            "[6]\tvalidation_0-auc:0.84344\tvalidation_1-auc:0.81736\n",
            "[7]\tvalidation_0-auc:0.84457\tvalidation_1-auc:0.81739\n",
            "[8]\tvalidation_0-auc:0.84520\tvalidation_1-auc:0.81817\n",
            "[9]\tvalidation_0-auc:0.84586\tvalidation_1-auc:0.81742\n",
            "[10]\tvalidation_0-auc:0.84650\tvalidation_1-auc:0.81681\n",
            "[11]\tvalidation_0-auc:0.84763\tvalidation_1-auc:0.81716\n",
            "[12]\tvalidation_0-auc:0.84835\tvalidation_1-auc:0.81818\n",
            "[13]\tvalidation_0-auc:0.84903\tvalidation_1-auc:0.81854\n",
            "[14]\tvalidation_0-auc:0.85096\tvalidation_1-auc:0.82041\n",
            "[15]\tvalidation_0-auc:0.85222\tvalidation_1-auc:0.82126\n",
            "[16]\tvalidation_0-auc:0.85296\tvalidation_1-auc:0.82089\n",
            "[17]\tvalidation_0-auc:0.85455\tvalidation_1-auc:0.82230\n",
            "[18]\tvalidation_0-auc:0.85622\tvalidation_1-auc:0.82288\n",
            "[19]\tvalidation_0-auc:0.85684\tvalidation_1-auc:0.82305\n",
            "[20]\tvalidation_0-auc:0.85848\tvalidation_1-auc:0.82435\n",
            "[21]\tvalidation_0-auc:0.85946\tvalidation_1-auc:0.82582\n",
            "[22]\tvalidation_0-auc:0.86063\tvalidation_1-auc:0.82670\n",
            "[23]\tvalidation_0-auc:0.86166\tvalidation_1-auc:0.82764\n",
            "[24]\tvalidation_0-auc:0.86304\tvalidation_1-auc:0.82784\n",
            "[25]\tvalidation_0-auc:0.86442\tvalidation_1-auc:0.82796\n",
            "[26]\tvalidation_0-auc:0.86530\tvalidation_1-auc:0.82801\n",
            "[27]\tvalidation_0-auc:0.86649\tvalidation_1-auc:0.82878\n",
            "[28]\tvalidation_0-auc:0.86751\tvalidation_1-auc:0.82864\n",
            "[29]\tvalidation_0-auc:0.86817\tvalidation_1-auc:0.82858\n",
            "[30]\tvalidation_0-auc:0.86899\tvalidation_1-auc:0.82876\n",
            "[31]\tvalidation_0-auc:0.86936\tvalidation_1-auc:0.82903\n",
            "[32]\tvalidation_0-auc:0.87032\tvalidation_1-auc:0.82980\n",
            "[33]\tvalidation_0-auc:0.87055\tvalidation_1-auc:0.83064\n",
            "[34]\tvalidation_0-auc:0.87107\tvalidation_1-auc:0.83086\n",
            "[35]\tvalidation_0-auc:0.87213\tvalidation_1-auc:0.83173\n",
            "[36]\tvalidation_0-auc:0.87281\tvalidation_1-auc:0.83149\n",
            "[37]\tvalidation_0-auc:0.87332\tvalidation_1-auc:0.83176\n",
            "[38]\tvalidation_0-auc:0.87493\tvalidation_1-auc:0.83215\n",
            "[39]\tvalidation_0-auc:0.87582\tvalidation_1-auc:0.83241\n",
            "[40]\tvalidation_0-auc:0.87712\tvalidation_1-auc:0.83213\n",
            "[41]\tvalidation_0-auc:0.87773\tvalidation_1-auc:0.83245\n",
            "[42]\tvalidation_0-auc:0.87824\tvalidation_1-auc:0.83158\n",
            "[43]\tvalidation_0-auc:0.87899\tvalidation_1-auc:0.83155\n",
            "[44]\tvalidation_0-auc:0.87987\tvalidation_1-auc:0.83123\n",
            "[45]\tvalidation_0-auc:0.88041\tvalidation_1-auc:0.83135\n",
            "[46]\tvalidation_0-auc:0.88118\tvalidation_1-auc:0.83182\n",
            "[47]\tvalidation_0-auc:0.88162\tvalidation_1-auc:0.83165\n",
            "[48]\tvalidation_0-auc:0.88223\tvalidation_1-auc:0.83186\n",
            "[49]\tvalidation_0-auc:0.88297\tvalidation_1-auc:0.83209\n",
            "[50]\tvalidation_0-auc:0.88386\tvalidation_1-auc:0.83212\n",
            "[51]\tvalidation_0-auc:0.88479\tvalidation_1-auc:0.83226\n",
            "[52]\tvalidation_0-auc:0.88530\tvalidation_1-auc:0.83275\n",
            "[53]\tvalidation_0-auc:0.88610\tvalidation_1-auc:0.83253\n",
            "[54]\tvalidation_0-auc:0.88655\tvalidation_1-auc:0.83231\n",
            "[55]\tvalidation_0-auc:0.88709\tvalidation_1-auc:0.83262\n",
            "[56]\tvalidation_0-auc:0.88765\tvalidation_1-auc:0.83237\n",
            "[57]\tvalidation_0-auc:0.88802\tvalidation_1-auc:0.83231\n",
            "[58]\tvalidation_0-auc:0.88860\tvalidation_1-auc:0.83223\n",
            "[59]\tvalidation_0-auc:0.88888\tvalidation_1-auc:0.83218\n",
            "[60]\tvalidation_0-auc:0.88939\tvalidation_1-auc:0.83220\n",
            "[61]\tvalidation_0-auc:0.88976\tvalidation_1-auc:0.83224\n",
            "[62]\tvalidation_0-auc:0.89017\tvalidation_1-auc:0.83220\n",
            "[63]\tvalidation_0-auc:0.89064\tvalidation_1-auc:0.83225\n",
            "[64]\tvalidation_0-auc:0.89091\tvalidation_1-auc:0.83218\n",
            "[65]\tvalidation_0-auc:0.89137\tvalidation_1-auc:0.83215\n",
            "[66]\tvalidation_0-auc:0.89202\tvalidation_1-auc:0.83226\n",
            "[67]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.83238\n",
            "[68]\tvalidation_0-auc:0.89268\tvalidation_1-auc:0.83251\n",
            "[69]\tvalidation_0-auc:0.89296\tvalidation_1-auc:0.83280\n",
            "[70]\tvalidation_0-auc:0.89314\tvalidation_1-auc:0.83249\n",
            "[71]\tvalidation_0-auc:0.89330\tvalidation_1-auc:0.83252\n",
            "[72]\tvalidation_0-auc:0.89354\tvalidation_1-auc:0.83253\n",
            "[73]\tvalidation_0-auc:0.89366\tvalidation_1-auc:0.83251\n",
            "[74]\tvalidation_0-auc:0.89399\tvalidation_1-auc:0.83272\n",
            "[75]\tvalidation_0-auc:0.89429\tvalidation_1-auc:0.83284\n",
            "[76]\tvalidation_0-auc:0.89442\tvalidation_1-auc:0.83278\n",
            "[77]\tvalidation_0-auc:0.89458\tvalidation_1-auc:0.83278\n",
            "[78]\tvalidation_0-auc:0.89489\tvalidation_1-auc:0.83277\n",
            "[79]\tvalidation_0-auc:0.89510\tvalidation_1-auc:0.83262\n",
            "[80]\tvalidation_0-auc:0.89528\tvalidation_1-auc:0.83267\n",
            "[81]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.83260\n",
            "[82]\tvalidation_0-auc:0.89572\tvalidation_1-auc:0.83244\n",
            "[83]\tvalidation_0-auc:0.89584\tvalidation_1-auc:0.83231\n",
            "[84]\tvalidation_0-auc:0.89609\tvalidation_1-auc:0.83238\n",
            "[85]\tvalidation_0-auc:0.89671\tvalidation_1-auc:0.83239\n",
            "[86]\tvalidation_0-auc:0.89694\tvalidation_1-auc:0.83248\n",
            "[87]\tvalidation_0-auc:0.89771\tvalidation_1-auc:0.83246\n",
            "[88]\tvalidation_0-auc:0.89777\tvalidation_1-auc:0.83259\n",
            "[89]\tvalidation_0-auc:0.89805\tvalidation_1-auc:0.83244\n",
            "[90]\tvalidation_0-auc:0.89859\tvalidation_1-auc:0.83220\n",
            "[91]\tvalidation_0-auc:0.89870\tvalidation_1-auc:0.83205\n",
            "[92]\tvalidation_0-auc:0.89880\tvalidation_1-auc:0.83192\n",
            "[93]\tvalidation_0-auc:0.89899\tvalidation_1-auc:0.83205\n",
            "[94]\tvalidation_0-auc:0.89904\tvalidation_1-auc:0.83207\n",
            "[95]\tvalidation_0-auc:0.89914\tvalidation_1-auc:0.83193\n",
            "[96]\tvalidation_0-auc:0.89925\tvalidation_1-auc:0.83191\n",
            "[97]\tvalidation_0-auc:0.89953\tvalidation_1-auc:0.83200\n",
            "[98]\tvalidation_0-auc:0.89995\tvalidation_1-auc:0.83177\n",
            "[99]\tvalidation_0-auc:0.89998\tvalidation_1-auc:0.83175\n",
            "[100]\tvalidation_0-auc:0.90009\tvalidation_1-auc:0.83174\n",
            "[101]\tvalidation_0-auc:0.90019\tvalidation_1-auc:0.83155\n",
            "[102]\tvalidation_0-auc:0.90048\tvalidation_1-auc:0.83145\n",
            "[103]\tvalidation_0-auc:0.90057\tvalidation_1-auc:0.83139\n",
            "[104]\tvalidation_0-auc:0.90061\tvalidation_1-auc:0.83135\n",
            "  0%|          | 0/50 [01:01<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.81645\tvalidation_1-auc:0.80537\n",
            "[1]\tvalidation_0-auc:0.80841\tvalidation_1-auc:0.79421\n",
            "[2]\tvalidation_0-auc:0.82421\tvalidation_1-auc:0.81059\n",
            "[3]\tvalidation_0-auc:0.83509\tvalidation_1-auc:0.81859\n",
            "[4]\tvalidation_0-auc:0.84064\tvalidation_1-auc:0.82326\n",
            "[5]\tvalidation_0-auc:0.84302\tvalidation_1-auc:0.82613\n",
            "[6]\tvalidation_0-auc:0.84507\tvalidation_1-auc:0.82768\n",
            "[7]\tvalidation_0-auc:0.84576\tvalidation_1-auc:0.82752\n",
            "[8]\tvalidation_0-auc:0.84711\tvalidation_1-auc:0.82856\n",
            "[9]\tvalidation_0-auc:0.84767\tvalidation_1-auc:0.82857\n",
            "[10]\tvalidation_0-auc:0.84926\tvalidation_1-auc:0.82868\n",
            "[11]\tvalidation_0-auc:0.85043\tvalidation_1-auc:0.83004\n",
            "[12]\tvalidation_0-auc:0.85111\tvalidation_1-auc:0.82965\n",
            "[13]\tvalidation_0-auc:0.85329\tvalidation_1-auc:0.83065\n",
            "[14]\tvalidation_0-auc:0.85445\tvalidation_1-auc:0.83078\n",
            "[15]\tvalidation_0-auc:0.85656\tvalidation_1-auc:0.83118\n",
            "[16]\tvalidation_0-auc:0.85793\tvalidation_1-auc:0.83102\n",
            "[17]\tvalidation_0-auc:0.85877\tvalidation_1-auc:0.83094\n",
            "[18]\tvalidation_0-auc:0.86007\tvalidation_1-auc:0.83076\n",
            "[19]\tvalidation_0-auc:0.86181\tvalidation_1-auc:0.83164\n",
            "[20]\tvalidation_0-auc:0.86247\tvalidation_1-auc:0.83178\n",
            "[21]\tvalidation_0-auc:0.86362\tvalidation_1-auc:0.83225\n",
            "[22]\tvalidation_0-auc:0.86460\tvalidation_1-auc:0.83240\n",
            "[23]\tvalidation_0-auc:0.86532\tvalidation_1-auc:0.83242\n",
            "[24]\tvalidation_0-auc:0.86581\tvalidation_1-auc:0.83245\n",
            "[25]\tvalidation_0-auc:0.86684\tvalidation_1-auc:0.83222\n",
            "[26]\tvalidation_0-auc:0.86742\tvalidation_1-auc:0.83215\n",
            "[27]\tvalidation_0-auc:0.86868\tvalidation_1-auc:0.83198\n",
            "[28]\tvalidation_0-auc:0.86982\tvalidation_1-auc:0.83290\n",
            "[29]\tvalidation_0-auc:0.87041\tvalidation_1-auc:0.83411\n",
            "[30]\tvalidation_0-auc:0.87087\tvalidation_1-auc:0.83409\n",
            "[31]\tvalidation_0-auc:0.87148\tvalidation_1-auc:0.83419\n",
            "[32]\tvalidation_0-auc:0.87207\tvalidation_1-auc:0.83381\n",
            "[33]\tvalidation_0-auc:0.87286\tvalidation_1-auc:0.83403\n",
            "[34]\tvalidation_0-auc:0.87358\tvalidation_1-auc:0.83424\n",
            "[35]\tvalidation_0-auc:0.87485\tvalidation_1-auc:0.83407\n",
            "[36]\tvalidation_0-auc:0.87534\tvalidation_1-auc:0.83437\n",
            "[37]\tvalidation_0-auc:0.87563\tvalidation_1-auc:0.83455\n",
            "[38]\tvalidation_0-auc:0.87629\tvalidation_1-auc:0.83447\n",
            "[39]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83467\n",
            "[40]\tvalidation_0-auc:0.87778\tvalidation_1-auc:0.83541\n",
            "[41]\tvalidation_0-auc:0.87873\tvalidation_1-auc:0.83567\n",
            "[42]\tvalidation_0-auc:0.87908\tvalidation_1-auc:0.83615\n",
            "[43]\tvalidation_0-auc:0.87978\tvalidation_1-auc:0.83653\n",
            "[44]\tvalidation_0-auc:0.88076\tvalidation_1-auc:0.83637\n",
            "[45]\tvalidation_0-auc:0.88191\tvalidation_1-auc:0.83653\n",
            "[46]\tvalidation_0-auc:0.88301\tvalidation_1-auc:0.83619\n",
            "[47]\tvalidation_0-auc:0.88385\tvalidation_1-auc:0.83652\n",
            "[48]\tvalidation_0-auc:0.88438\tvalidation_1-auc:0.83662\n",
            "[49]\tvalidation_0-auc:0.88498\tvalidation_1-auc:0.83696\n",
            "[50]\tvalidation_0-auc:0.88597\tvalidation_1-auc:0.83648\n",
            "[51]\tvalidation_0-auc:0.88648\tvalidation_1-auc:0.83670\n",
            "[52]\tvalidation_0-auc:0.88703\tvalidation_1-auc:0.83700\n",
            "[53]\tvalidation_0-auc:0.88722\tvalidation_1-auc:0.83677\n",
            "[54]\tvalidation_0-auc:0.88748\tvalidation_1-auc:0.83688\n",
            "[55]\tvalidation_0-auc:0.88805\tvalidation_1-auc:0.83688\n",
            "[56]\tvalidation_0-auc:0.88884\tvalidation_1-auc:0.83675\n",
            "[57]\tvalidation_0-auc:0.88931\tvalidation_1-auc:0.83680\n",
            "[58]\tvalidation_0-auc:0.88980\tvalidation_1-auc:0.83719\n",
            "[59]\tvalidation_0-auc:0.89012\tvalidation_1-auc:0.83726\n",
            "[60]\tvalidation_0-auc:0.89058\tvalidation_1-auc:0.83749\n",
            "[61]\tvalidation_0-auc:0.89137\tvalidation_1-auc:0.83754\n",
            "[62]\tvalidation_0-auc:0.89161\tvalidation_1-auc:0.83735\n",
            "[63]\tvalidation_0-auc:0.89228\tvalidation_1-auc:0.83730\n",
            "[64]\tvalidation_0-auc:0.89276\tvalidation_1-auc:0.83713\n",
            "[65]\tvalidation_0-auc:0.89325\tvalidation_1-auc:0.83690\n",
            "[66]\tvalidation_0-auc:0.89383\tvalidation_1-auc:0.83674\n",
            "[67]\tvalidation_0-auc:0.89419\tvalidation_1-auc:0.83681\n",
            "[68]\tvalidation_0-auc:0.89436\tvalidation_1-auc:0.83690\n",
            "[69]\tvalidation_0-auc:0.89473\tvalidation_1-auc:0.83692\n",
            "[70]\tvalidation_0-auc:0.89504\tvalidation_1-auc:0.83678\n",
            "[71]\tvalidation_0-auc:0.89525\tvalidation_1-auc:0.83681\n",
            "[72]\tvalidation_0-auc:0.89576\tvalidation_1-auc:0.83672\n",
            "[73]\tvalidation_0-auc:0.89612\tvalidation_1-auc:0.83654\n",
            "[74]\tvalidation_0-auc:0.89629\tvalidation_1-auc:0.83664\n",
            "[75]\tvalidation_0-auc:0.89668\tvalidation_1-auc:0.83648\n",
            "[76]\tvalidation_0-auc:0.89704\tvalidation_1-auc:0.83642\n",
            "[77]\tvalidation_0-auc:0.89744\tvalidation_1-auc:0.83647\n",
            "[78]\tvalidation_0-auc:0.89762\tvalidation_1-auc:0.83653\n",
            "[79]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.83634\n",
            "[80]\tvalidation_0-auc:0.89850\tvalidation_1-auc:0.83616\n",
            "[81]\tvalidation_0-auc:0.89905\tvalidation_1-auc:0.83612\n",
            "[82]\tvalidation_0-auc:0.89919\tvalidation_1-auc:0.83615\n",
            "[83]\tvalidation_0-auc:0.89941\tvalidation_1-auc:0.83605\n",
            "[84]\tvalidation_0-auc:0.89957\tvalidation_1-auc:0.83597\n",
            "[85]\tvalidation_0-auc:0.89985\tvalidation_1-auc:0.83590\n",
            "[86]\tvalidation_0-auc:0.90013\tvalidation_1-auc:0.83573\n",
            "[87]\tvalidation_0-auc:0.90027\tvalidation_1-auc:0.83583\n",
            "[88]\tvalidation_0-auc:0.90049\tvalidation_1-auc:0.83583\n",
            "[89]\tvalidation_0-auc:0.90105\tvalidation_1-auc:0.83591\n",
            "[90]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83603\n",
            "[91]\tvalidation_0-auc:0.90155\tvalidation_1-auc:0.83599\n",
            "  0%|          | 0/50 [02:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82735\tvalidation_1-auc:0.81086\n",
            "[1]\tvalidation_0-auc:0.82093\tvalidation_1-auc:0.80133\n",
            "[2]\tvalidation_0-auc:0.83454\tvalidation_1-auc:0.81412\n",
            "[3]\tvalidation_0-auc:0.83914\tvalidation_1-auc:0.81722\n",
            "[4]\tvalidation_0-auc:0.84088\tvalidation_1-auc:0.81769\n",
            "[5]\tvalidation_0-auc:0.84242\tvalidation_1-auc:0.81829\n",
            "[6]\tvalidation_0-auc:0.84389\tvalidation_1-auc:0.82037\n",
            "[7]\tvalidation_0-auc:0.84522\tvalidation_1-auc:0.82200\n",
            "[8]\tvalidation_0-auc:0.84807\tvalidation_1-auc:0.82357\n",
            "[9]\tvalidation_0-auc:0.84943\tvalidation_1-auc:0.82381\n",
            "[10]\tvalidation_0-auc:0.84973\tvalidation_1-auc:0.82356\n",
            "[11]\tvalidation_0-auc:0.85210\tvalidation_1-auc:0.82542\n",
            "[12]\tvalidation_0-auc:0.85321\tvalidation_1-auc:0.82615\n",
            "[13]\tvalidation_0-auc:0.85385\tvalidation_1-auc:0.82603\n",
            "[14]\tvalidation_0-auc:0.85490\tvalidation_1-auc:0.82635\n",
            "[15]\tvalidation_0-auc:0.85742\tvalidation_1-auc:0.82812\n",
            "[16]\tvalidation_0-auc:0.85836\tvalidation_1-auc:0.82840\n",
            "[17]\tvalidation_0-auc:0.85897\tvalidation_1-auc:0.82852\n",
            "[18]\tvalidation_0-auc:0.85940\tvalidation_1-auc:0.82866\n",
            "[19]\tvalidation_0-auc:0.86035\tvalidation_1-auc:0.82964\n",
            "[20]\tvalidation_0-auc:0.86207\tvalidation_1-auc:0.83053\n",
            "[21]\tvalidation_0-auc:0.86343\tvalidation_1-auc:0.83002\n",
            "[22]\tvalidation_0-auc:0.86528\tvalidation_1-auc:0.83115\n",
            "[23]\tvalidation_0-auc:0.86568\tvalidation_1-auc:0.83152\n",
            "[24]\tvalidation_0-auc:0.86640\tvalidation_1-auc:0.83166\n",
            "[25]\tvalidation_0-auc:0.86677\tvalidation_1-auc:0.83190\n",
            "[26]\tvalidation_0-auc:0.86697\tvalidation_1-auc:0.83271\n",
            "[27]\tvalidation_0-auc:0.86818\tvalidation_1-auc:0.83328\n",
            "[28]\tvalidation_0-auc:0.86887\tvalidation_1-auc:0.83358\n",
            "[29]\tvalidation_0-auc:0.86908\tvalidation_1-auc:0.83352\n",
            "[30]\tvalidation_0-auc:0.87045\tvalidation_1-auc:0.83422\n",
            "[31]\tvalidation_0-auc:0.87145\tvalidation_1-auc:0.83413\n",
            "[32]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.83441\n",
            "[33]\tvalidation_0-auc:0.87314\tvalidation_1-auc:0.83443\n",
            "[34]\tvalidation_0-auc:0.87407\tvalidation_1-auc:0.83453\n",
            "[35]\tvalidation_0-auc:0.87487\tvalidation_1-auc:0.83466\n",
            "[36]\tvalidation_0-auc:0.87558\tvalidation_1-auc:0.83466\n",
            "[37]\tvalidation_0-auc:0.87663\tvalidation_1-auc:0.83505\n",
            "[38]\tvalidation_0-auc:0.87747\tvalidation_1-auc:0.83420\n",
            "[39]\tvalidation_0-auc:0.87857\tvalidation_1-auc:0.83427\n",
            "[40]\tvalidation_0-auc:0.87941\tvalidation_1-auc:0.83466\n",
            "[41]\tvalidation_0-auc:0.88040\tvalidation_1-auc:0.83513\n",
            "[42]\tvalidation_0-auc:0.88109\tvalidation_1-auc:0.83526\n",
            "[43]\tvalidation_0-auc:0.88225\tvalidation_1-auc:0.83570\n",
            "[44]\tvalidation_0-auc:0.88264\tvalidation_1-auc:0.83594\n",
            "[45]\tvalidation_0-auc:0.88321\tvalidation_1-auc:0.83598\n",
            "[46]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.83602\n",
            "[47]\tvalidation_0-auc:0.88465\tvalidation_1-auc:0.83612\n",
            "[48]\tvalidation_0-auc:0.88558\tvalidation_1-auc:0.83607\n",
            "[49]\tvalidation_0-auc:0.88625\tvalidation_1-auc:0.83597\n",
            "[50]\tvalidation_0-auc:0.88686\tvalidation_1-auc:0.83582\n",
            "[51]\tvalidation_0-auc:0.88742\tvalidation_1-auc:0.83586\n",
            "[52]\tvalidation_0-auc:0.88806\tvalidation_1-auc:0.83642\n",
            "[53]\tvalidation_0-auc:0.88850\tvalidation_1-auc:0.83674\n",
            "[54]\tvalidation_0-auc:0.88903\tvalidation_1-auc:0.83683\n",
            "[55]\tvalidation_0-auc:0.88934\tvalidation_1-auc:0.83712\n",
            "[56]\tvalidation_0-auc:0.89023\tvalidation_1-auc:0.83709\n",
            "[57]\tvalidation_0-auc:0.89075\tvalidation_1-auc:0.83728\n",
            "[58]\tvalidation_0-auc:0.89103\tvalidation_1-auc:0.83731\n",
            "[59]\tvalidation_0-auc:0.89142\tvalidation_1-auc:0.83743\n",
            "[60]\tvalidation_0-auc:0.89182\tvalidation_1-auc:0.83761\n",
            "[61]\tvalidation_0-auc:0.89208\tvalidation_1-auc:0.83735\n",
            "[62]\tvalidation_0-auc:0.89253\tvalidation_1-auc:0.83732\n",
            "[63]\tvalidation_0-auc:0.89280\tvalidation_1-auc:0.83741\n",
            "[64]\tvalidation_0-auc:0.89345\tvalidation_1-auc:0.83764\n",
            "[65]\tvalidation_0-auc:0.89405\tvalidation_1-auc:0.83762\n",
            "[66]\tvalidation_0-auc:0.89422\tvalidation_1-auc:0.83757\n",
            "[67]\tvalidation_0-auc:0.89442\tvalidation_1-auc:0.83766\n",
            "[68]\tvalidation_0-auc:0.89481\tvalidation_1-auc:0.83782\n",
            "[69]\tvalidation_0-auc:0.89513\tvalidation_1-auc:0.83799\n",
            "[70]\tvalidation_0-auc:0.89531\tvalidation_1-auc:0.83802\n",
            "[71]\tvalidation_0-auc:0.89565\tvalidation_1-auc:0.83815\n",
            "[72]\tvalidation_0-auc:0.89587\tvalidation_1-auc:0.83818\n",
            "[73]\tvalidation_0-auc:0.89640\tvalidation_1-auc:0.83786\n",
            "[74]\tvalidation_0-auc:0.89664\tvalidation_1-auc:0.83795\n",
            "[75]\tvalidation_0-auc:0.89688\tvalidation_1-auc:0.83800\n",
            "[76]\tvalidation_0-auc:0.89715\tvalidation_1-auc:0.83811\n",
            "[77]\tvalidation_0-auc:0.89738\tvalidation_1-auc:0.83818\n",
            "[78]\tvalidation_0-auc:0.89756\tvalidation_1-auc:0.83817\n",
            "[79]\tvalidation_0-auc:0.89778\tvalidation_1-auc:0.83840\n",
            "[80]\tvalidation_0-auc:0.89799\tvalidation_1-auc:0.83838\n",
            "[81]\tvalidation_0-auc:0.89809\tvalidation_1-auc:0.83846\n",
            "[82]\tvalidation_0-auc:0.89872\tvalidation_1-auc:0.83860\n",
            "[83]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.83847\n",
            "[84]\tvalidation_0-auc:0.89920\tvalidation_1-auc:0.83847\n",
            "[85]\tvalidation_0-auc:0.89983\tvalidation_1-auc:0.83865\n",
            "[86]\tvalidation_0-auc:0.90012\tvalidation_1-auc:0.83877\n",
            "[87]\tvalidation_0-auc:0.90046\tvalidation_1-auc:0.83896\n",
            "[88]\tvalidation_0-auc:0.90051\tvalidation_1-auc:0.83901\n",
            "[89]\tvalidation_0-auc:0.90057\tvalidation_1-auc:0.83889\n",
            "[90]\tvalidation_0-auc:0.90077\tvalidation_1-auc:0.83891\n",
            "[91]\tvalidation_0-auc:0.90091\tvalidation_1-auc:0.83890\n",
            "[92]\tvalidation_0-auc:0.90105\tvalidation_1-auc:0.83892\n",
            "[93]\tvalidation_0-auc:0.90120\tvalidation_1-auc:0.83893\n",
            "[94]\tvalidation_0-auc:0.90130\tvalidation_1-auc:0.83898\n",
            "[95]\tvalidation_0-auc:0.90147\tvalidation_1-auc:0.83894\n",
            "[96]\tvalidation_0-auc:0.90218\tvalidation_1-auc:0.83897\n",
            "[97]\tvalidation_0-auc:0.90230\tvalidation_1-auc:0.83902\n",
            "[98]\tvalidation_0-auc:0.90248\tvalidation_1-auc:0.83894\n",
            "[99]\tvalidation_0-auc:0.90263\tvalidation_1-auc:0.83884\n",
            "[100]\tvalidation_0-auc:0.90316\tvalidation_1-auc:0.83871\n",
            "[101]\tvalidation_0-auc:0.90340\tvalidation_1-auc:0.83875\n",
            "[102]\tvalidation_0-auc:0.90413\tvalidation_1-auc:0.83858\n",
            "[103]\tvalidation_0-auc:0.90419\tvalidation_1-auc:0.83852\n",
            "[104]\tvalidation_0-auc:0.90429\tvalidation_1-auc:0.83845\n",
            "[105]\tvalidation_0-auc:0.90449\tvalidation_1-auc:0.83848\n",
            "[106]\tvalidation_0-auc:0.90465\tvalidation_1-auc:0.83855\n",
            "[107]\tvalidation_0-auc:0.90484\tvalidation_1-auc:0.83855\n",
            "[108]\tvalidation_0-auc:0.90527\tvalidation_1-auc:0.83856\n",
            "[109]\tvalidation_0-auc:0.90554\tvalidation_1-auc:0.83839\n",
            "[110]\tvalidation_0-auc:0.90593\tvalidation_1-auc:0.83832\n",
            "[111]\tvalidation_0-auc:0.90608\tvalidation_1-auc:0.83825\n",
            "[112]\tvalidation_0-auc:0.90615\tvalidation_1-auc:0.83819\n",
            "[113]\tvalidation_0-auc:0.90628\tvalidation_1-auc:0.83823\n",
            "[114]\tvalidation_0-auc:0.90654\tvalidation_1-auc:0.83832\n",
            "[115]\tvalidation_0-auc:0.90656\tvalidation_1-auc:0.83834\n",
            "[116]\tvalidation_0-auc:0.90681\tvalidation_1-auc:0.83814\n",
            "[117]\tvalidation_0-auc:0.90704\tvalidation_1-auc:0.83812\n",
            "[118]\tvalidation_0-auc:0.90715\tvalidation_1-auc:0.83796\n",
            "[119]\tvalidation_0-auc:0.90728\tvalidation_1-auc:0.83793\n",
            "[120]\tvalidation_0-auc:0.90740\tvalidation_1-auc:0.83790\n",
            "[121]\tvalidation_0-auc:0.90747\tvalidation_1-auc:0.83785\n",
            "[122]\tvalidation_0-auc:0.90762\tvalidation_1-auc:0.83783\n",
            "[123]\tvalidation_0-auc:0.90771\tvalidation_1-auc:0.83786\n",
            "[124]\tvalidation_0-auc:0.90792\tvalidation_1-auc:0.83779\n",
            "[125]\tvalidation_0-auc:0.90821\tvalidation_1-auc:0.83784\n",
            "[126]\tvalidation_0-auc:0.90828\tvalidation_1-auc:0.83782\n",
            "[127]\tvalidation_0-auc:0.90837\tvalidation_1-auc:0.83781\n",
            "  2%|▏         | 1/50 [03:14<2:38:34, 194.17s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82825\tvalidation_1-auc:0.80009\n",
            "[1]\tvalidation_0-auc:0.82290\tvalidation_1-auc:0.79276\n",
            "[2]\tvalidation_0-auc:0.83493\tvalidation_1-auc:0.80180\n",
            "[3]\tvalidation_0-auc:0.83857\tvalidation_1-auc:0.80600\n",
            "[4]\tvalidation_0-auc:0.84348\tvalidation_1-auc:0.80991\n",
            "[5]\tvalidation_0-auc:0.84459\tvalidation_1-auc:0.80746\n",
            "[6]\tvalidation_0-auc:0.84824\tvalidation_1-auc:0.80970\n",
            "[7]\tvalidation_0-auc:0.85110\tvalidation_1-auc:0.81288\n",
            "[8]\tvalidation_0-auc:0.85252\tvalidation_1-auc:0.81518\n",
            "[9]\tvalidation_0-auc:0.85681\tvalidation_1-auc:0.81610\n",
            "[10]\tvalidation_0-auc:0.85429\tvalidation_1-auc:0.81511\n",
            "[11]\tvalidation_0-auc:0.85779\tvalidation_1-auc:0.81792\n",
            "[12]\tvalidation_0-auc:0.85992\tvalidation_1-auc:0.81980\n",
            "[13]\tvalidation_0-auc:0.86127\tvalidation_1-auc:0.81878\n",
            "[14]\tvalidation_0-auc:0.86355\tvalidation_1-auc:0.82074\n",
            "[15]\tvalidation_0-auc:0.86211\tvalidation_1-auc:0.81858\n",
            "[16]\tvalidation_0-auc:0.86242\tvalidation_1-auc:0.81627\n",
            "[17]\tvalidation_0-auc:0.86272\tvalidation_1-auc:0.81555\n",
            "[18]\tvalidation_0-auc:0.86526\tvalidation_1-auc:0.81783\n",
            "[19]\tvalidation_0-auc:0.86938\tvalidation_1-auc:0.81966\n",
            "[20]\tvalidation_0-auc:0.87277\tvalidation_1-auc:0.82183\n",
            "[21]\tvalidation_0-auc:0.87221\tvalidation_1-auc:0.82025\n",
            "[22]\tvalidation_0-auc:0.87500\tvalidation_1-auc:0.82185\n",
            "[23]\tvalidation_0-auc:0.87555\tvalidation_1-auc:0.82284\n",
            "[24]\tvalidation_0-auc:0.87621\tvalidation_1-auc:0.82226\n",
            "[25]\tvalidation_0-auc:0.87843\tvalidation_1-auc:0.82376\n",
            "[26]\tvalidation_0-auc:0.88051\tvalidation_1-auc:0.82485\n",
            "[27]\tvalidation_0-auc:0.88142\tvalidation_1-auc:0.82452\n",
            "[28]\tvalidation_0-auc:0.88247\tvalidation_1-auc:0.82341\n",
            "[29]\tvalidation_0-auc:0.88362\tvalidation_1-auc:0.82462\n",
            "[30]\tvalidation_0-auc:0.88435\tvalidation_1-auc:0.82566\n",
            "[31]\tvalidation_0-auc:0.88484\tvalidation_1-auc:0.82432\n",
            "[32]\tvalidation_0-auc:0.88540\tvalidation_1-auc:0.82245\n",
            "[33]\tvalidation_0-auc:0.88694\tvalidation_1-auc:0.82341\n",
            "[34]\tvalidation_0-auc:0.88761\tvalidation_1-auc:0.82263\n",
            "[35]\tvalidation_0-auc:0.88776\tvalidation_1-auc:0.82136\n",
            "[36]\tvalidation_0-auc:0.88896\tvalidation_1-auc:0.82286\n",
            "[37]\tvalidation_0-auc:0.88887\tvalidation_1-auc:0.82213\n",
            "[38]\tvalidation_0-auc:0.88901\tvalidation_1-auc:0.82142\n",
            "[39]\tvalidation_0-auc:0.88881\tvalidation_1-auc:0.82080\n",
            "[40]\tvalidation_0-auc:0.89081\tvalidation_1-auc:0.82302\n",
            "[41]\tvalidation_0-auc:0.89316\tvalidation_1-auc:0.82464\n",
            "[42]\tvalidation_0-auc:0.89403\tvalidation_1-auc:0.82586\n",
            "[43]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.82714\n",
            "[44]\tvalidation_0-auc:0.89737\tvalidation_1-auc:0.82706\n",
            "[45]\tvalidation_0-auc:0.89888\tvalidation_1-auc:0.82811\n",
            "[46]\tvalidation_0-auc:0.89869\tvalidation_1-auc:0.82768\n",
            "[47]\tvalidation_0-auc:0.89964\tvalidation_1-auc:0.82845\n",
            "[48]\tvalidation_0-auc:0.90040\tvalidation_1-auc:0.82932\n",
            "[49]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83005\n",
            "[50]\tvalidation_0-auc:0.90169\tvalidation_1-auc:0.82927\n",
            "[51]\tvalidation_0-auc:0.90282\tvalidation_1-auc:0.83004\n",
            "[52]\tvalidation_0-auc:0.90359\tvalidation_1-auc:0.83045\n",
            "[53]\tvalidation_0-auc:0.90520\tvalidation_1-auc:0.83097\n",
            "[54]\tvalidation_0-auc:0.90552\tvalidation_1-auc:0.83111\n",
            "[55]\tvalidation_0-auc:0.90634\tvalidation_1-auc:0.83159\n",
            "[56]\tvalidation_0-auc:0.90699\tvalidation_1-auc:0.83111\n",
            "[57]\tvalidation_0-auc:0.90715\tvalidation_1-auc:0.83111\n",
            "[58]\tvalidation_0-auc:0.90784\tvalidation_1-auc:0.83180\n",
            "[59]\tvalidation_0-auc:0.90835\tvalidation_1-auc:0.83202\n",
            "[60]\tvalidation_0-auc:0.90899\tvalidation_1-auc:0.83202\n",
            "[61]\tvalidation_0-auc:0.90931\tvalidation_1-auc:0.83141\n",
            "[62]\tvalidation_0-auc:0.91019\tvalidation_1-auc:0.83165\n",
            "[63]\tvalidation_0-auc:0.91112\tvalidation_1-auc:0.83111\n",
            "[64]\tvalidation_0-auc:0.91139\tvalidation_1-auc:0.83084\n",
            "[65]\tvalidation_0-auc:0.91245\tvalidation_1-auc:0.83098\n",
            "[66]\tvalidation_0-auc:0.91319\tvalidation_1-auc:0.83034\n",
            "[67]\tvalidation_0-auc:0.91346\tvalidation_1-auc:0.83064\n",
            "[68]\tvalidation_0-auc:0.91385\tvalidation_1-auc:0.83038\n",
            "[69]\tvalidation_0-auc:0.91432\tvalidation_1-auc:0.83030\n",
            "[70]\tvalidation_0-auc:0.91516\tvalidation_1-auc:0.83055\n",
            "[71]\tvalidation_0-auc:0.91552\tvalidation_1-auc:0.83092\n",
            "[72]\tvalidation_0-auc:0.91552\tvalidation_1-auc:0.83065\n",
            "[73]\tvalidation_0-auc:0.91640\tvalidation_1-auc:0.83003\n",
            "[74]\tvalidation_0-auc:0.91692\tvalidation_1-auc:0.83005\n",
            "[75]\tvalidation_0-auc:0.91726\tvalidation_1-auc:0.83011\n",
            "[76]\tvalidation_0-auc:0.91793\tvalidation_1-auc:0.82978\n",
            "[77]\tvalidation_0-auc:0.91855\tvalidation_1-auc:0.82990\n",
            "[78]\tvalidation_0-auc:0.91878\tvalidation_1-auc:0.83005\n",
            "[79]\tvalidation_0-auc:0.91910\tvalidation_1-auc:0.83016\n",
            "[80]\tvalidation_0-auc:0.91957\tvalidation_1-auc:0.82994\n",
            "[81]\tvalidation_0-auc:0.91977\tvalidation_1-auc:0.83038\n",
            "[82]\tvalidation_0-auc:0.92012\tvalidation_1-auc:0.83054\n",
            "[83]\tvalidation_0-auc:0.92044\tvalidation_1-auc:0.83032\n",
            "[84]\tvalidation_0-auc:0.92050\tvalidation_1-auc:0.83054\n",
            "[85]\tvalidation_0-auc:0.92092\tvalidation_1-auc:0.83063\n",
            "[86]\tvalidation_0-auc:0.92126\tvalidation_1-auc:0.83074\n",
            "[87]\tvalidation_0-auc:0.92172\tvalidation_1-auc:0.83068\n",
            "[88]\tvalidation_0-auc:0.92186\tvalidation_1-auc:0.83056\n",
            "[89]\tvalidation_0-auc:0.92198\tvalidation_1-auc:0.83075\n",
            "  2%|▏         | 1/50 [04:30<2:38:34, 194.17s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.81981\tvalidation_1-auc:0.80450\n",
            "[1]\tvalidation_0-auc:0.81459\tvalidation_1-auc:0.79594\n",
            "[2]\tvalidation_0-auc:0.82478\tvalidation_1-auc:0.80674\n",
            "[3]\tvalidation_0-auc:0.83694\tvalidation_1-auc:0.81729\n",
            "[4]\tvalidation_0-auc:0.84291\tvalidation_1-auc:0.82242\n",
            "[5]\tvalidation_0-auc:0.84764\tvalidation_1-auc:0.82135\n",
            "[6]\tvalidation_0-auc:0.85119\tvalidation_1-auc:0.82368\n",
            "[7]\tvalidation_0-auc:0.85483\tvalidation_1-auc:0.82483\n",
            "[8]\tvalidation_0-auc:0.85561\tvalidation_1-auc:0.82567\n",
            "[9]\tvalidation_0-auc:0.85790\tvalidation_1-auc:0.82457\n",
            "[10]\tvalidation_0-auc:0.85774\tvalidation_1-auc:0.82253\n",
            "[11]\tvalidation_0-auc:0.86135\tvalidation_1-auc:0.82393\n",
            "[12]\tvalidation_0-auc:0.86420\tvalidation_1-auc:0.82538\n",
            "[13]\tvalidation_0-auc:0.86663\tvalidation_1-auc:0.82392\n",
            "[14]\tvalidation_0-auc:0.86859\tvalidation_1-auc:0.82581\n",
            "[15]\tvalidation_0-auc:0.86910\tvalidation_1-auc:0.82437\n",
            "[16]\tvalidation_0-auc:0.86843\tvalidation_1-auc:0.82157\n",
            "[17]\tvalidation_0-auc:0.86933\tvalidation_1-auc:0.82000\n",
            "[18]\tvalidation_0-auc:0.87151\tvalidation_1-auc:0.82267\n",
            "[19]\tvalidation_0-auc:0.87483\tvalidation_1-auc:0.82457\n",
            "[20]\tvalidation_0-auc:0.87711\tvalidation_1-auc:0.82580\n",
            "[21]\tvalidation_0-auc:0.87693\tvalidation_1-auc:0.82373\n",
            "[22]\tvalidation_0-auc:0.87949\tvalidation_1-auc:0.82541\n",
            "[23]\tvalidation_0-auc:0.88061\tvalidation_1-auc:0.82645\n",
            "[24]\tvalidation_0-auc:0.88024\tvalidation_1-auc:0.82605\n",
            "[25]\tvalidation_0-auc:0.88206\tvalidation_1-auc:0.82706\n",
            "[26]\tvalidation_0-auc:0.88405\tvalidation_1-auc:0.82831\n",
            "[27]\tvalidation_0-auc:0.88528\tvalidation_1-auc:0.82733\n",
            "[28]\tvalidation_0-auc:0.88588\tvalidation_1-auc:0.82621\n",
            "[29]\tvalidation_0-auc:0.88689\tvalidation_1-auc:0.82735\n",
            "[30]\tvalidation_0-auc:0.88775\tvalidation_1-auc:0.82779\n",
            "[31]\tvalidation_0-auc:0.88767\tvalidation_1-auc:0.82669\n",
            "[32]\tvalidation_0-auc:0.88847\tvalidation_1-auc:0.82519\n",
            "[33]\tvalidation_0-auc:0.88941\tvalidation_1-auc:0.82592\n",
            "[34]\tvalidation_0-auc:0.89019\tvalidation_1-auc:0.82523\n",
            "[35]\tvalidation_0-auc:0.89026\tvalidation_1-auc:0.82441\n",
            "[36]\tvalidation_0-auc:0.89102\tvalidation_1-auc:0.82564\n",
            "[37]\tvalidation_0-auc:0.89076\tvalidation_1-auc:0.82516\n",
            "[38]\tvalidation_0-auc:0.89127\tvalidation_1-auc:0.82454\n",
            "[39]\tvalidation_0-auc:0.89114\tvalidation_1-auc:0.82428\n",
            "[40]\tvalidation_0-auc:0.89299\tvalidation_1-auc:0.82556\n",
            "[41]\tvalidation_0-auc:0.89448\tvalidation_1-auc:0.82589\n",
            "[42]\tvalidation_0-auc:0.89512\tvalidation_1-auc:0.82712\n",
            "[43]\tvalidation_0-auc:0.89708\tvalidation_1-auc:0.82770\n",
            "[44]\tvalidation_0-auc:0.89839\tvalidation_1-auc:0.82848\n",
            "[45]\tvalidation_0-auc:0.89964\tvalidation_1-auc:0.82908\n",
            "[46]\tvalidation_0-auc:0.90004\tvalidation_1-auc:0.82824\n",
            "[47]\tvalidation_0-auc:0.90063\tvalidation_1-auc:0.82902\n",
            "[48]\tvalidation_0-auc:0.90139\tvalidation_1-auc:0.82963\n",
            "[49]\tvalidation_0-auc:0.90237\tvalidation_1-auc:0.83047\n",
            "[50]\tvalidation_0-auc:0.90247\tvalidation_1-auc:0.82995\n",
            "[51]\tvalidation_0-auc:0.90321\tvalidation_1-auc:0.83042\n",
            "[52]\tvalidation_0-auc:0.90409\tvalidation_1-auc:0.83071\n",
            "[53]\tvalidation_0-auc:0.90519\tvalidation_1-auc:0.83162\n",
            "[54]\tvalidation_0-auc:0.90548\tvalidation_1-auc:0.83165\n",
            "[55]\tvalidation_0-auc:0.90613\tvalidation_1-auc:0.83211\n",
            "[56]\tvalidation_0-auc:0.90698\tvalidation_1-auc:0.83150\n",
            "[57]\tvalidation_0-auc:0.90708\tvalidation_1-auc:0.83113\n",
            "[58]\tvalidation_0-auc:0.90813\tvalidation_1-auc:0.83197\n",
            "[59]\tvalidation_0-auc:0.90864\tvalidation_1-auc:0.83243\n",
            "[60]\tvalidation_0-auc:0.90935\tvalidation_1-auc:0.83219\n",
            "[61]\tvalidation_0-auc:0.90954\tvalidation_1-auc:0.83221\n",
            "[62]\tvalidation_0-auc:0.91057\tvalidation_1-auc:0.83229\n",
            "[63]\tvalidation_0-auc:0.91127\tvalidation_1-auc:0.83190\n",
            "[64]\tvalidation_0-auc:0.91171\tvalidation_1-auc:0.83178\n",
            "[65]\tvalidation_0-auc:0.91280\tvalidation_1-auc:0.83249\n",
            "[66]\tvalidation_0-auc:0.91342\tvalidation_1-auc:0.83223\n",
            "[67]\tvalidation_0-auc:0.91388\tvalidation_1-auc:0.83302\n",
            "[68]\tvalidation_0-auc:0.91414\tvalidation_1-auc:0.83267\n",
            "[69]\tvalidation_0-auc:0.91454\tvalidation_1-auc:0.83301\n",
            "[70]\tvalidation_0-auc:0.91529\tvalidation_1-auc:0.83356\n",
            "[71]\tvalidation_0-auc:0.91566\tvalidation_1-auc:0.83378\n",
            "[72]\tvalidation_0-auc:0.91589\tvalidation_1-auc:0.83335\n",
            "[73]\tvalidation_0-auc:0.91657\tvalidation_1-auc:0.83314\n",
            "[74]\tvalidation_0-auc:0.91709\tvalidation_1-auc:0.83312\n",
            "[75]\tvalidation_0-auc:0.91776\tvalidation_1-auc:0.83296\n",
            "[76]\tvalidation_0-auc:0.91820\tvalidation_1-auc:0.83277\n",
            "[77]\tvalidation_0-auc:0.91894\tvalidation_1-auc:0.83339\n",
            "[78]\tvalidation_0-auc:0.91915\tvalidation_1-auc:0.83362\n",
            "[79]\tvalidation_0-auc:0.91954\tvalidation_1-auc:0.83378\n",
            "[80]\tvalidation_0-auc:0.92011\tvalidation_1-auc:0.83335\n",
            "[81]\tvalidation_0-auc:0.92029\tvalidation_1-auc:0.83366\n",
            "[82]\tvalidation_0-auc:0.92040\tvalidation_1-auc:0.83369\n",
            "[83]\tvalidation_0-auc:0.92095\tvalidation_1-auc:0.83361\n",
            "[84]\tvalidation_0-auc:0.92104\tvalidation_1-auc:0.83376\n",
            "[85]\tvalidation_0-auc:0.92154\tvalidation_1-auc:0.83423\n",
            "[86]\tvalidation_0-auc:0.92179\tvalidation_1-auc:0.83428\n",
            "[87]\tvalidation_0-auc:0.92194\tvalidation_1-auc:0.83446\n",
            "[88]\tvalidation_0-auc:0.92212\tvalidation_1-auc:0.83433\n",
            "[89]\tvalidation_0-auc:0.92255\tvalidation_1-auc:0.83461\n",
            "[90]\tvalidation_0-auc:0.92287\tvalidation_1-auc:0.83419\n",
            "[91]\tvalidation_0-auc:0.92309\tvalidation_1-auc:0.83434\n",
            "[92]\tvalidation_0-auc:0.92331\tvalidation_1-auc:0.83473\n",
            "[93]\tvalidation_0-auc:0.92347\tvalidation_1-auc:0.83491\n",
            "[94]\tvalidation_0-auc:0.92348\tvalidation_1-auc:0.83506\n",
            "[95]\tvalidation_0-auc:0.92363\tvalidation_1-auc:0.83528\n",
            "[96]\tvalidation_0-auc:0.92411\tvalidation_1-auc:0.83516\n",
            "[97]\tvalidation_0-auc:0.92429\tvalidation_1-auc:0.83529\n",
            "[98]\tvalidation_0-auc:0.92454\tvalidation_1-auc:0.83539\n",
            "[99]\tvalidation_0-auc:0.92474\tvalidation_1-auc:0.83541\n",
            "[100]\tvalidation_0-auc:0.92480\tvalidation_1-auc:0.83538\n",
            "[101]\tvalidation_0-auc:0.92521\tvalidation_1-auc:0.83553\n",
            "[102]\tvalidation_0-auc:0.92548\tvalidation_1-auc:0.83568\n",
            "[103]\tvalidation_0-auc:0.92559\tvalidation_1-auc:0.83579\n",
            "[104]\tvalidation_0-auc:0.92588\tvalidation_1-auc:0.83575\n",
            "[105]\tvalidation_0-auc:0.92613\tvalidation_1-auc:0.83585\n",
            "[106]\tvalidation_0-auc:0.92621\tvalidation_1-auc:0.83599\n",
            "[107]\tvalidation_0-auc:0.92633\tvalidation_1-auc:0.83613\n",
            "[108]\tvalidation_0-auc:0.92643\tvalidation_1-auc:0.83606\n",
            "[109]\tvalidation_0-auc:0.92649\tvalidation_1-auc:0.83601\n",
            "[110]\tvalidation_0-auc:0.92685\tvalidation_1-auc:0.83601\n",
            "[111]\tvalidation_0-auc:0.92701\tvalidation_1-auc:0.83599\n",
            "[112]\tvalidation_0-auc:0.92733\tvalidation_1-auc:0.83576\n",
            "[113]\tvalidation_0-auc:0.92775\tvalidation_1-auc:0.83584\n",
            "[114]\tvalidation_0-auc:0.92817\tvalidation_1-auc:0.83588\n",
            "[115]\tvalidation_0-auc:0.92845\tvalidation_1-auc:0.83574\n",
            "[116]\tvalidation_0-auc:0.92850\tvalidation_1-auc:0.83585\n",
            "[117]\tvalidation_0-auc:0.92875\tvalidation_1-auc:0.83582\n",
            "[118]\tvalidation_0-auc:0.92925\tvalidation_1-auc:0.83568\n",
            "[119]\tvalidation_0-auc:0.92964\tvalidation_1-auc:0.83559\n",
            "[120]\tvalidation_0-auc:0.92972\tvalidation_1-auc:0.83546\n",
            "[121]\tvalidation_0-auc:0.92987\tvalidation_1-auc:0.83563\n",
            "[122]\tvalidation_0-auc:0.93001\tvalidation_1-auc:0.83556\n",
            "[123]\tvalidation_0-auc:0.93019\tvalidation_1-auc:0.83547\n",
            "[124]\tvalidation_0-auc:0.93056\tvalidation_1-auc:0.83512\n",
            "[125]\tvalidation_0-auc:0.93071\tvalidation_1-auc:0.83517\n",
            "[126]\tvalidation_0-auc:0.93070\tvalidation_1-auc:0.83513\n",
            "[127]\tvalidation_0-auc:0.93073\tvalidation_1-auc:0.83513\n",
            "[128]\tvalidation_0-auc:0.93092\tvalidation_1-auc:0.83516\n",
            "[129]\tvalidation_0-auc:0.93098\tvalidation_1-auc:0.83521\n",
            "[130]\tvalidation_0-auc:0.93110\tvalidation_1-auc:0.83524\n",
            "[131]\tvalidation_0-auc:0.93119\tvalidation_1-auc:0.83532\n",
            "[132]\tvalidation_0-auc:0.93158\tvalidation_1-auc:0.83545\n",
            "[133]\tvalidation_0-auc:0.93161\tvalidation_1-auc:0.83532\n",
            "[134]\tvalidation_0-auc:0.93163\tvalidation_1-auc:0.83517\n",
            "[135]\tvalidation_0-auc:0.93168\tvalidation_1-auc:0.83510\n",
            "[136]\tvalidation_0-auc:0.93201\tvalidation_1-auc:0.83511\n",
            "  2%|▏         | 1/50 [06:19<2:38:34, 194.17s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83105\tvalidation_1-auc:0.80702\n",
            "[1]\tvalidation_0-auc:0.82656\tvalidation_1-auc:0.80380\n",
            "[2]\tvalidation_0-auc:0.83896\tvalidation_1-auc:0.81578\n",
            "[3]\tvalidation_0-auc:0.84202\tvalidation_1-auc:0.81814\n",
            "[4]\tvalidation_0-auc:0.84567\tvalidation_1-auc:0.82108\n",
            "[5]\tvalidation_0-auc:0.84707\tvalidation_1-auc:0.81923\n",
            "[6]\tvalidation_0-auc:0.84882\tvalidation_1-auc:0.82043\n",
            "[7]\tvalidation_0-auc:0.85026\tvalidation_1-auc:0.82097\n",
            "[8]\tvalidation_0-auc:0.85331\tvalidation_1-auc:0.82333\n",
            "[9]\tvalidation_0-auc:0.85535\tvalidation_1-auc:0.82342\n",
            "[10]\tvalidation_0-auc:0.85515\tvalidation_1-auc:0.82243\n",
            "[11]\tvalidation_0-auc:0.86041\tvalidation_1-auc:0.82434\n",
            "[12]\tvalidation_0-auc:0.86330\tvalidation_1-auc:0.82489\n",
            "[13]\tvalidation_0-auc:0.86384\tvalidation_1-auc:0.82518\n",
            "[14]\tvalidation_0-auc:0.86652\tvalidation_1-auc:0.82634\n",
            "[15]\tvalidation_0-auc:0.86711\tvalidation_1-auc:0.82562\n",
            "[16]\tvalidation_0-auc:0.86673\tvalidation_1-auc:0.82425\n",
            "[17]\tvalidation_0-auc:0.86733\tvalidation_1-auc:0.82218\n",
            "[18]\tvalidation_0-auc:0.86883\tvalidation_1-auc:0.82453\n",
            "[19]\tvalidation_0-auc:0.87157\tvalidation_1-auc:0.82545\n",
            "[20]\tvalidation_0-auc:0.87410\tvalidation_1-auc:0.82620\n",
            "[21]\tvalidation_0-auc:0.87379\tvalidation_1-auc:0.82423\n",
            "[22]\tvalidation_0-auc:0.87625\tvalidation_1-auc:0.82427\n",
            "[23]\tvalidation_0-auc:0.87808\tvalidation_1-auc:0.82583\n",
            "[24]\tvalidation_0-auc:0.87784\tvalidation_1-auc:0.82416\n",
            "[25]\tvalidation_0-auc:0.88100\tvalidation_1-auc:0.82526\n",
            "[26]\tvalidation_0-auc:0.88274\tvalidation_1-auc:0.82541\n",
            "[27]\tvalidation_0-auc:0.88416\tvalidation_1-auc:0.82452\n",
            "[28]\tvalidation_0-auc:0.88518\tvalidation_1-auc:0.82333\n",
            "[29]\tvalidation_0-auc:0.88664\tvalidation_1-auc:0.82443\n",
            "[30]\tvalidation_0-auc:0.88807\tvalidation_1-auc:0.82513\n",
            "[31]\tvalidation_0-auc:0.88777\tvalidation_1-auc:0.82462\n",
            "[32]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.82415\n",
            "[33]\tvalidation_0-auc:0.88929\tvalidation_1-auc:0.82461\n",
            "[34]\tvalidation_0-auc:0.89054\tvalidation_1-auc:0.82362\n",
            "[35]\tvalidation_0-auc:0.89124\tvalidation_1-auc:0.82304\n",
            "[36]\tvalidation_0-auc:0.89277\tvalidation_1-auc:0.82444\n",
            "[37]\tvalidation_0-auc:0.89292\tvalidation_1-auc:0.82428\n",
            "[38]\tvalidation_0-auc:0.89339\tvalidation_1-auc:0.82431\n",
            "[39]\tvalidation_0-auc:0.89305\tvalidation_1-auc:0.82406\n",
            "[40]\tvalidation_0-auc:0.89527\tvalidation_1-auc:0.82589\n",
            "[41]\tvalidation_0-auc:0.89703\tvalidation_1-auc:0.82680\n",
            "[42]\tvalidation_0-auc:0.89770\tvalidation_1-auc:0.82749\n",
            "[43]\tvalidation_0-auc:0.89903\tvalidation_1-auc:0.82828\n",
            "[44]\tvalidation_0-auc:0.90017\tvalidation_1-auc:0.82916\n",
            "[45]\tvalidation_0-auc:0.90177\tvalidation_1-auc:0.83041\n",
            "[46]\tvalidation_0-auc:0.90216\tvalidation_1-auc:0.83026\n",
            "[47]\tvalidation_0-auc:0.90291\tvalidation_1-auc:0.83095\n",
            "[48]\tvalidation_0-auc:0.90375\tvalidation_1-auc:0.83118\n",
            "[49]\tvalidation_0-auc:0.90462\tvalidation_1-auc:0.83163\n",
            "[50]\tvalidation_0-auc:0.90495\tvalidation_1-auc:0.83128\n",
            "[51]\tvalidation_0-auc:0.90586\tvalidation_1-auc:0.83225\n",
            "[52]\tvalidation_0-auc:0.90657\tvalidation_1-auc:0.83313\n",
            "[53]\tvalidation_0-auc:0.90767\tvalidation_1-auc:0.83372\n",
            "[54]\tvalidation_0-auc:0.90802\tvalidation_1-auc:0.83390\n",
            "[55]\tvalidation_0-auc:0.90877\tvalidation_1-auc:0.83413\n",
            "[56]\tvalidation_0-auc:0.90968\tvalidation_1-auc:0.83383\n",
            "[57]\tvalidation_0-auc:0.90967\tvalidation_1-auc:0.83343\n",
            "[58]\tvalidation_0-auc:0.91015\tvalidation_1-auc:0.83412\n",
            "[59]\tvalidation_0-auc:0.91088\tvalidation_1-auc:0.83422\n",
            "[60]\tvalidation_0-auc:0.91146\tvalidation_1-auc:0.83464\n",
            "[61]\tvalidation_0-auc:0.91147\tvalidation_1-auc:0.83417\n",
            "[62]\tvalidation_0-auc:0.91247\tvalidation_1-auc:0.83404\n",
            "[63]\tvalidation_0-auc:0.91333\tvalidation_1-auc:0.83368\n",
            "[64]\tvalidation_0-auc:0.91368\tvalidation_1-auc:0.83349\n",
            "[65]\tvalidation_0-auc:0.91455\tvalidation_1-auc:0.83413\n",
            "[66]\tvalidation_0-auc:0.91504\tvalidation_1-auc:0.83411\n",
            "[67]\tvalidation_0-auc:0.91529\tvalidation_1-auc:0.83441\n",
            "[68]\tvalidation_0-auc:0.91561\tvalidation_1-auc:0.83408\n",
            "[69]\tvalidation_0-auc:0.91604\tvalidation_1-auc:0.83419\n",
            "[70]\tvalidation_0-auc:0.91691\tvalidation_1-auc:0.83416\n",
            "[71]\tvalidation_0-auc:0.91721\tvalidation_1-auc:0.83447\n",
            "[72]\tvalidation_0-auc:0.91727\tvalidation_1-auc:0.83448\n",
            "[73]\tvalidation_0-auc:0.91781\tvalidation_1-auc:0.83427\n",
            "[74]\tvalidation_0-auc:0.91828\tvalidation_1-auc:0.83410\n",
            "[75]\tvalidation_0-auc:0.91877\tvalidation_1-auc:0.83418\n",
            "[76]\tvalidation_0-auc:0.91924\tvalidation_1-auc:0.83364\n",
            "[77]\tvalidation_0-auc:0.91991\tvalidation_1-auc:0.83402\n",
            "[78]\tvalidation_0-auc:0.92020\tvalidation_1-auc:0.83375\n",
            "[79]\tvalidation_0-auc:0.92053\tvalidation_1-auc:0.83361\n",
            "[80]\tvalidation_0-auc:0.92092\tvalidation_1-auc:0.83322\n",
            "[81]\tvalidation_0-auc:0.92114\tvalidation_1-auc:0.83328\n",
            "[82]\tvalidation_0-auc:0.92134\tvalidation_1-auc:0.83339\n",
            "[83]\tvalidation_0-auc:0.92194\tvalidation_1-auc:0.83297\n",
            "[84]\tvalidation_0-auc:0.92213\tvalidation_1-auc:0.83329\n",
            "[85]\tvalidation_0-auc:0.92240\tvalidation_1-auc:0.83365\n",
            "[86]\tvalidation_0-auc:0.92297\tvalidation_1-auc:0.83360\n",
            "[87]\tvalidation_0-auc:0.92321\tvalidation_1-auc:0.83365\n",
            "[88]\tvalidation_0-auc:0.92337\tvalidation_1-auc:0.83358\n",
            "[89]\tvalidation_0-auc:0.92358\tvalidation_1-auc:0.83392\n",
            "  4%|▍         | 2/50 [07:35<3:06:49, 233.52s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82924\tvalidation_1-auc:0.80102\n",
            "[1]\tvalidation_0-auc:0.82536\tvalidation_1-auc:0.79210\n",
            "[2]\tvalidation_0-auc:0.84060\tvalidation_1-auc:0.80640\n",
            "[3]\tvalidation_0-auc:0.84605\tvalidation_1-auc:0.81051\n",
            "[4]\tvalidation_0-auc:0.85376\tvalidation_1-auc:0.81413\n",
            "[5]\tvalidation_0-auc:0.85685\tvalidation_1-auc:0.81600\n",
            "[6]\tvalidation_0-auc:0.85856\tvalidation_1-auc:0.81648\n",
            "[7]\tvalidation_0-auc:0.86354\tvalidation_1-auc:0.81722\n",
            "[8]\tvalidation_0-auc:0.86781\tvalidation_1-auc:0.81959\n",
            "[9]\tvalidation_0-auc:0.87350\tvalidation_1-auc:0.82146\n",
            "[10]\tvalidation_0-auc:0.87718\tvalidation_1-auc:0.82235\n",
            "[11]\tvalidation_0-auc:0.88170\tvalidation_1-auc:0.82519\n",
            "[12]\tvalidation_0-auc:0.88366\tvalidation_1-auc:0.82526\n",
            "[13]\tvalidation_0-auc:0.88829\tvalidation_1-auc:0.82514\n",
            "[14]\tvalidation_0-auc:0.89029\tvalidation_1-auc:0.82560\n",
            "[15]\tvalidation_0-auc:0.89362\tvalidation_1-auc:0.82604\n",
            "[16]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.82630\n",
            "[17]\tvalidation_0-auc:0.89840\tvalidation_1-auc:0.82502\n",
            "[18]\tvalidation_0-auc:0.90202\tvalidation_1-auc:0.82435\n",
            "[19]\tvalidation_0-auc:0.90520\tvalidation_1-auc:0.82515\n",
            "[20]\tvalidation_0-auc:0.90800\tvalidation_1-auc:0.82654\n",
            "[21]\tvalidation_0-auc:0.90943\tvalidation_1-auc:0.82496\n",
            "[22]\tvalidation_0-auc:0.91279\tvalidation_1-auc:0.82544\n",
            "[23]\tvalidation_0-auc:0.91615\tvalidation_1-auc:0.82517\n",
            "[24]\tvalidation_0-auc:0.91941\tvalidation_1-auc:0.82432\n",
            "[25]\tvalidation_0-auc:0.92066\tvalidation_1-auc:0.82536\n",
            "[26]\tvalidation_0-auc:0.92365\tvalidation_1-auc:0.82502\n",
            "[27]\tvalidation_0-auc:0.92469\tvalidation_1-auc:0.82396\n",
            "[28]\tvalidation_0-auc:0.92637\tvalidation_1-auc:0.82468\n",
            "[29]\tvalidation_0-auc:0.92755\tvalidation_1-auc:0.82588\n",
            "[30]\tvalidation_0-auc:0.92843\tvalidation_1-auc:0.82613\n",
            "[31]\tvalidation_0-auc:0.92959\tvalidation_1-auc:0.82578\n",
            "[32]\tvalidation_0-auc:0.93063\tvalidation_1-auc:0.82559\n",
            "[33]\tvalidation_0-auc:0.93139\tvalidation_1-auc:0.82580\n",
            "[34]\tvalidation_0-auc:0.93288\tvalidation_1-auc:0.82598\n",
            "[35]\tvalidation_0-auc:0.93367\tvalidation_1-auc:0.82563\n",
            "[36]\tvalidation_0-auc:0.93459\tvalidation_1-auc:0.82536\n",
            "[37]\tvalidation_0-auc:0.93523\tvalidation_1-auc:0.82508\n",
            "[38]\tvalidation_0-auc:0.93603\tvalidation_1-auc:0.82509\n",
            "[39]\tvalidation_0-auc:0.93661\tvalidation_1-auc:0.82435\n",
            "[40]\tvalidation_0-auc:0.93751\tvalidation_1-auc:0.82499\n",
            "[41]\tvalidation_0-auc:0.93787\tvalidation_1-auc:0.82560\n",
            "[42]\tvalidation_0-auc:0.93820\tvalidation_1-auc:0.82557\n",
            "[43]\tvalidation_0-auc:0.93880\tvalidation_1-auc:0.82542\n",
            "[44]\tvalidation_0-auc:0.93891\tvalidation_1-auc:0.82572\n",
            "[45]\tvalidation_0-auc:0.93956\tvalidation_1-auc:0.82571\n",
            "[46]\tvalidation_0-auc:0.93970\tvalidation_1-auc:0.82551\n",
            "[47]\tvalidation_0-auc:0.94023\tvalidation_1-auc:0.82547\n",
            "[48]\tvalidation_0-auc:0.94037\tvalidation_1-auc:0.82518\n",
            "[49]\tvalidation_0-auc:0.94050\tvalidation_1-auc:0.82495\n",
            "  4%|▍         | 2/50 [08:23<3:06:49, 233.52s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82312\tvalidation_1-auc:0.80548\n",
            "[1]\tvalidation_0-auc:0.82190\tvalidation_1-auc:0.80234\n",
            "[2]\tvalidation_0-auc:0.84414\tvalidation_1-auc:0.81877\n",
            "[3]\tvalidation_0-auc:0.85187\tvalidation_1-auc:0.82223\n",
            "[4]\tvalidation_0-auc:0.85851\tvalidation_1-auc:0.82431\n",
            "[5]\tvalidation_0-auc:0.86283\tvalidation_1-auc:0.82624\n",
            "[6]\tvalidation_0-auc:0.86415\tvalidation_1-auc:0.82639\n",
            "[7]\tvalidation_0-auc:0.86969\tvalidation_1-auc:0.82646\n",
            "[8]\tvalidation_0-auc:0.87453\tvalidation_1-auc:0.82801\n",
            "[9]\tvalidation_0-auc:0.87842\tvalidation_1-auc:0.82717\n",
            "[10]\tvalidation_0-auc:0.88330\tvalidation_1-auc:0.82738\n",
            "[11]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.82712\n",
            "[12]\tvalidation_0-auc:0.88959\tvalidation_1-auc:0.82843\n",
            "[13]\tvalidation_0-auc:0.89176\tvalidation_1-auc:0.82823\n",
            "[14]\tvalidation_0-auc:0.89251\tvalidation_1-auc:0.82876\n",
            "[15]\tvalidation_0-auc:0.89581\tvalidation_1-auc:0.82883\n",
            "[16]\tvalidation_0-auc:0.89811\tvalidation_1-auc:0.83016\n",
            "[17]\tvalidation_0-auc:0.89929\tvalidation_1-auc:0.82781\n",
            "[18]\tvalidation_0-auc:0.90320\tvalidation_1-auc:0.82912\n",
            "[19]\tvalidation_0-auc:0.90578\tvalidation_1-auc:0.82980\n",
            "[20]\tvalidation_0-auc:0.90944\tvalidation_1-auc:0.82968\n",
            "[21]\tvalidation_0-auc:0.91061\tvalidation_1-auc:0.82901\n",
            "[22]\tvalidation_0-auc:0.91414\tvalidation_1-auc:0.82959\n",
            "[23]\tvalidation_0-auc:0.91741\tvalidation_1-auc:0.82965\n",
            "[24]\tvalidation_0-auc:0.91979\tvalidation_1-auc:0.82931\n",
            "[25]\tvalidation_0-auc:0.92108\tvalidation_1-auc:0.82989\n",
            "[26]\tvalidation_0-auc:0.92336\tvalidation_1-auc:0.82955\n",
            "[27]\tvalidation_0-auc:0.92536\tvalidation_1-auc:0.82850\n",
            "[28]\tvalidation_0-auc:0.92700\tvalidation_1-auc:0.82894\n",
            "[29]\tvalidation_0-auc:0.92862\tvalidation_1-auc:0.82929\n",
            "[30]\tvalidation_0-auc:0.92932\tvalidation_1-auc:0.83004\n",
            "[31]\tvalidation_0-auc:0.93048\tvalidation_1-auc:0.83011\n",
            "[32]\tvalidation_0-auc:0.93228\tvalidation_1-auc:0.82972\n",
            "[33]\tvalidation_0-auc:0.93267\tvalidation_1-auc:0.82966\n",
            "[34]\tvalidation_0-auc:0.93403\tvalidation_1-auc:0.82876\n",
            "[35]\tvalidation_0-auc:0.93535\tvalidation_1-auc:0.82918\n",
            "[36]\tvalidation_0-auc:0.93631\tvalidation_1-auc:0.82977\n",
            "[37]\tvalidation_0-auc:0.93696\tvalidation_1-auc:0.82971\n",
            "[38]\tvalidation_0-auc:0.93810\tvalidation_1-auc:0.82972\n",
            "[39]\tvalidation_0-auc:0.93890\tvalidation_1-auc:0.83000\n",
            "[40]\tvalidation_0-auc:0.93961\tvalidation_1-auc:0.83008\n",
            "[41]\tvalidation_0-auc:0.93998\tvalidation_1-auc:0.83037\n",
            "[42]\tvalidation_0-auc:0.94005\tvalidation_1-auc:0.83059\n",
            "[43]\tvalidation_0-auc:0.94045\tvalidation_1-auc:0.83056\n",
            "[44]\tvalidation_0-auc:0.94062\tvalidation_1-auc:0.83114\n",
            "[45]\tvalidation_0-auc:0.94100\tvalidation_1-auc:0.83140\n",
            "[46]\tvalidation_0-auc:0.94166\tvalidation_1-auc:0.83079\n",
            "[47]\tvalidation_0-auc:0.94187\tvalidation_1-auc:0.83131\n",
            "[48]\tvalidation_0-auc:0.94231\tvalidation_1-auc:0.83110\n",
            "[49]\tvalidation_0-auc:0.94272\tvalidation_1-auc:0.83139\n",
            "[50]\tvalidation_0-auc:0.94427\tvalidation_1-auc:0.83103\n",
            "[51]\tvalidation_0-auc:0.94475\tvalidation_1-auc:0.83099\n",
            "[52]\tvalidation_0-auc:0.94498\tvalidation_1-auc:0.83097\n",
            "[53]\tvalidation_0-auc:0.94553\tvalidation_1-auc:0.83101\n",
            "[54]\tvalidation_0-auc:0.94570\tvalidation_1-auc:0.83115\n",
            "[55]\tvalidation_0-auc:0.94581\tvalidation_1-auc:0.83102\n",
            "[56]\tvalidation_0-auc:0.94625\tvalidation_1-auc:0.83102\n",
            "[57]\tvalidation_0-auc:0.94640\tvalidation_1-auc:0.83090\n",
            "[58]\tvalidation_0-auc:0.94692\tvalidation_1-auc:0.83102\n",
            "[59]\tvalidation_0-auc:0.94748\tvalidation_1-auc:0.83053\n",
            "[60]\tvalidation_0-auc:0.94754\tvalidation_1-auc:0.83053\n",
            "[61]\tvalidation_0-auc:0.94757\tvalidation_1-auc:0.83057\n",
            "[62]\tvalidation_0-auc:0.94780\tvalidation_1-auc:0.83058\n",
            "[63]\tvalidation_0-auc:0.94805\tvalidation_1-auc:0.83022\n",
            "[64]\tvalidation_0-auc:0.94826\tvalidation_1-auc:0.82998\n",
            "[65]\tvalidation_0-auc:0.94915\tvalidation_1-auc:0.83002\n",
            "[66]\tvalidation_0-auc:0.94935\tvalidation_1-auc:0.82990\n",
            "[67]\tvalidation_0-auc:0.94942\tvalidation_1-auc:0.82970\n",
            "[68]\tvalidation_0-auc:0.94951\tvalidation_1-auc:0.82955\n",
            "[69]\tvalidation_0-auc:0.94954\tvalidation_1-auc:0.82929\n",
            "[70]\tvalidation_0-auc:0.95021\tvalidation_1-auc:0.82877\n",
            "[71]\tvalidation_0-auc:0.95027\tvalidation_1-auc:0.82880\n",
            "[72]\tvalidation_0-auc:0.95034\tvalidation_1-auc:0.82880\n",
            "[73]\tvalidation_0-auc:0.95049\tvalidation_1-auc:0.82864\n",
            "[74]\tvalidation_0-auc:0.95062\tvalidation_1-auc:0.82850\n",
            "  4%|▍         | 2/50 [09:32<3:06:49, 233.52s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83612\tvalidation_1-auc:0.80867\n",
            "[1]\tvalidation_0-auc:0.83683\tvalidation_1-auc:0.80604\n",
            "[2]\tvalidation_0-auc:0.84807\tvalidation_1-auc:0.81552\n",
            "[3]\tvalidation_0-auc:0.85761\tvalidation_1-auc:0.81884\n",
            "[4]\tvalidation_0-auc:0.85921\tvalidation_1-auc:0.81968\n",
            "[5]\tvalidation_0-auc:0.86238\tvalidation_1-auc:0.82114\n",
            "[6]\tvalidation_0-auc:0.86553\tvalidation_1-auc:0.82367\n",
            "[7]\tvalidation_0-auc:0.86951\tvalidation_1-auc:0.82473\n",
            "[8]\tvalidation_0-auc:0.87491\tvalidation_1-auc:0.82633\n",
            "[9]\tvalidation_0-auc:0.87836\tvalidation_1-auc:0.82540\n",
            "[10]\tvalidation_0-auc:0.88174\tvalidation_1-auc:0.82534\n",
            "[11]\tvalidation_0-auc:0.88528\tvalidation_1-auc:0.82602\n",
            "[12]\tvalidation_0-auc:0.88836\tvalidation_1-auc:0.82755\n",
            "[13]\tvalidation_0-auc:0.89114\tvalidation_1-auc:0.82785\n",
            "[14]\tvalidation_0-auc:0.89335\tvalidation_1-auc:0.82774\n",
            "[15]\tvalidation_0-auc:0.89798\tvalidation_1-auc:0.82619\n",
            "[16]\tvalidation_0-auc:0.90178\tvalidation_1-auc:0.82830\n",
            "[17]\tvalidation_0-auc:0.90428\tvalidation_1-auc:0.82611\n",
            "[18]\tvalidation_0-auc:0.90761\tvalidation_1-auc:0.82749\n",
            "[19]\tvalidation_0-auc:0.90911\tvalidation_1-auc:0.82832\n",
            "[20]\tvalidation_0-auc:0.91319\tvalidation_1-auc:0.82884\n",
            "[21]\tvalidation_0-auc:0.91422\tvalidation_1-auc:0.82741\n",
            "[22]\tvalidation_0-auc:0.91737\tvalidation_1-auc:0.82848\n",
            "[23]\tvalidation_0-auc:0.91999\tvalidation_1-auc:0.82861\n",
            "[24]\tvalidation_0-auc:0.92204\tvalidation_1-auc:0.82908\n",
            "[25]\tvalidation_0-auc:0.92437\tvalidation_1-auc:0.82944\n",
            "[26]\tvalidation_0-auc:0.92682\tvalidation_1-auc:0.82917\n",
            "[27]\tvalidation_0-auc:0.92831\tvalidation_1-auc:0.82869\n",
            "[28]\tvalidation_0-auc:0.92998\tvalidation_1-auc:0.82953\n",
            "[29]\tvalidation_0-auc:0.93100\tvalidation_1-auc:0.83021\n",
            "[30]\tvalidation_0-auc:0.93174\tvalidation_1-auc:0.83077\n",
            "[31]\tvalidation_0-auc:0.93262\tvalidation_1-auc:0.83168\n",
            "[32]\tvalidation_0-auc:0.93366\tvalidation_1-auc:0.83103\n",
            "[33]\tvalidation_0-auc:0.93426\tvalidation_1-auc:0.83102\n",
            "[34]\tvalidation_0-auc:0.93526\tvalidation_1-auc:0.82969\n",
            "[35]\tvalidation_0-auc:0.93631\tvalidation_1-auc:0.83050\n",
            "[36]\tvalidation_0-auc:0.93704\tvalidation_1-auc:0.83033\n",
            "[37]\tvalidation_0-auc:0.93792\tvalidation_1-auc:0.83042\n",
            "[38]\tvalidation_0-auc:0.93884\tvalidation_1-auc:0.83043\n",
            "[39]\tvalidation_0-auc:0.93949\tvalidation_1-auc:0.83035\n",
            "[40]\tvalidation_0-auc:0.94013\tvalidation_1-auc:0.83032\n",
            "[41]\tvalidation_0-auc:0.94065\tvalidation_1-auc:0.83088\n",
            "[42]\tvalidation_0-auc:0.94092\tvalidation_1-auc:0.83100\n",
            "[43]\tvalidation_0-auc:0.94129\tvalidation_1-auc:0.83104\n",
            "[44]\tvalidation_0-auc:0.94166\tvalidation_1-auc:0.83096\n",
            "[45]\tvalidation_0-auc:0.94220\tvalidation_1-auc:0.83114\n",
            "[46]\tvalidation_0-auc:0.94279\tvalidation_1-auc:0.83115\n",
            "[47]\tvalidation_0-auc:0.94322\tvalidation_1-auc:0.83153\n",
            "[48]\tvalidation_0-auc:0.94349\tvalidation_1-auc:0.83117\n",
            "[49]\tvalidation_0-auc:0.94391\tvalidation_1-auc:0.83117\n",
            "[50]\tvalidation_0-auc:0.94403\tvalidation_1-auc:0.83081\n",
            "[51]\tvalidation_0-auc:0.94460\tvalidation_1-auc:0.83091\n",
            "[52]\tvalidation_0-auc:0.94478\tvalidation_1-auc:0.83101\n",
            "[53]\tvalidation_0-auc:0.94511\tvalidation_1-auc:0.83140\n",
            "[54]\tvalidation_0-auc:0.94588\tvalidation_1-auc:0.83143\n",
            "[55]\tvalidation_0-auc:0.94611\tvalidation_1-auc:0.83130\n",
            "[56]\tvalidation_0-auc:0.94663\tvalidation_1-auc:0.83133\n",
            "[57]\tvalidation_0-auc:0.94670\tvalidation_1-auc:0.83121\n",
            "[58]\tvalidation_0-auc:0.94716\tvalidation_1-auc:0.83145\n",
            "[59]\tvalidation_0-auc:0.94775\tvalidation_1-auc:0.83154\n",
            "[60]\tvalidation_0-auc:0.94802\tvalidation_1-auc:0.83144\n",
            "[61]\tvalidation_0-auc:0.94814\tvalidation_1-auc:0.83104\n",
            "  6%|▌         | 3/50 [10:32<2:42:55, 207.99s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83002\tvalidation_1-auc:0.80012\n",
            "[1]\tvalidation_0-auc:0.82475\tvalidation_1-auc:0.79262\n",
            "[2]\tvalidation_0-auc:0.83639\tvalidation_1-auc:0.80154\n",
            "[3]\tvalidation_0-auc:0.84145\tvalidation_1-auc:0.80716\n",
            "[4]\tvalidation_0-auc:0.84587\tvalidation_1-auc:0.81003\n",
            "[5]\tvalidation_0-auc:0.84527\tvalidation_1-auc:0.80828\n",
            "[6]\tvalidation_0-auc:0.84615\tvalidation_1-auc:0.80958\n",
            "[7]\tvalidation_0-auc:0.84650\tvalidation_1-auc:0.81087\n",
            "[8]\tvalidation_0-auc:0.84966\tvalidation_1-auc:0.81400\n",
            "[9]\tvalidation_0-auc:0.85274\tvalidation_1-auc:0.81666\n",
            "[10]\tvalidation_0-auc:0.85418\tvalidation_1-auc:0.81846\n",
            "[11]\tvalidation_0-auc:0.85496\tvalidation_1-auc:0.81901\n",
            "[12]\tvalidation_0-auc:0.85870\tvalidation_1-auc:0.82118\n",
            "[13]\tvalidation_0-auc:0.86039\tvalidation_1-auc:0.82215\n",
            "[14]\tvalidation_0-auc:0.86082\tvalidation_1-auc:0.82254\n",
            "[15]\tvalidation_0-auc:0.86131\tvalidation_1-auc:0.82243\n",
            "[16]\tvalidation_0-auc:0.86268\tvalidation_1-auc:0.82115\n",
            "[17]\tvalidation_0-auc:0.86342\tvalidation_1-auc:0.81926\n",
            "[18]\tvalidation_0-auc:0.86485\tvalidation_1-auc:0.82094\n",
            "[19]\tvalidation_0-auc:0.86755\tvalidation_1-auc:0.82162\n",
            "[20]\tvalidation_0-auc:0.86991\tvalidation_1-auc:0.82344\n",
            "[21]\tvalidation_0-auc:0.86853\tvalidation_1-auc:0.82127\n",
            "[22]\tvalidation_0-auc:0.87070\tvalidation_1-auc:0.82247\n",
            "[23]\tvalidation_0-auc:0.87229\tvalidation_1-auc:0.82343\n",
            "[24]\tvalidation_0-auc:0.87342\tvalidation_1-auc:0.82382\n",
            "[25]\tvalidation_0-auc:0.87522\tvalidation_1-auc:0.82481\n",
            "[26]\tvalidation_0-auc:0.87624\tvalidation_1-auc:0.82515\n",
            "[27]\tvalidation_0-auc:0.87775\tvalidation_1-auc:0.82538\n",
            "[28]\tvalidation_0-auc:0.87860\tvalidation_1-auc:0.82513\n",
            "[29]\tvalidation_0-auc:0.87932\tvalidation_1-auc:0.82618\n",
            "[30]\tvalidation_0-auc:0.88013\tvalidation_1-auc:0.82679\n",
            "[31]\tvalidation_0-auc:0.88055\tvalidation_1-auc:0.82674\n",
            "[32]\tvalidation_0-auc:0.88160\tvalidation_1-auc:0.82659\n",
            "[33]\tvalidation_0-auc:0.88263\tvalidation_1-auc:0.82729\n",
            "[34]\tvalidation_0-auc:0.88368\tvalidation_1-auc:0.82740\n",
            "[35]\tvalidation_0-auc:0.88415\tvalidation_1-auc:0.82652\n",
            "[36]\tvalidation_0-auc:0.88513\tvalidation_1-auc:0.82700\n",
            "[37]\tvalidation_0-auc:0.88537\tvalidation_1-auc:0.82627\n",
            "[38]\tvalidation_0-auc:0.88612\tvalidation_1-auc:0.82586\n",
            "[39]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.82447\n",
            "[40]\tvalidation_0-auc:0.88852\tvalidation_1-auc:0.82537\n",
            "[41]\tvalidation_0-auc:0.88987\tvalidation_1-auc:0.82694\n",
            "[42]\tvalidation_0-auc:0.89078\tvalidation_1-auc:0.82779\n",
            "[43]\tvalidation_0-auc:0.89262\tvalidation_1-auc:0.82806\n",
            "[44]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.82798\n",
            "[45]\tvalidation_0-auc:0.89512\tvalidation_1-auc:0.82850\n",
            "[46]\tvalidation_0-auc:0.89554\tvalidation_1-auc:0.82839\n",
            "[47]\tvalidation_0-auc:0.89637\tvalidation_1-auc:0.82921\n",
            "[48]\tvalidation_0-auc:0.89680\tvalidation_1-auc:0.82928\n",
            "[49]\tvalidation_0-auc:0.89748\tvalidation_1-auc:0.82975\n",
            "[50]\tvalidation_0-auc:0.89776\tvalidation_1-auc:0.82940\n",
            "[51]\tvalidation_0-auc:0.89840\tvalidation_1-auc:0.82975\n",
            "[52]\tvalidation_0-auc:0.89905\tvalidation_1-auc:0.82982\n",
            "[53]\tvalidation_0-auc:0.90011\tvalidation_1-auc:0.83027\n",
            "[54]\tvalidation_0-auc:0.90027\tvalidation_1-auc:0.83037\n",
            "[55]\tvalidation_0-auc:0.90042\tvalidation_1-auc:0.83036\n",
            "[56]\tvalidation_0-auc:0.90102\tvalidation_1-auc:0.82966\n",
            "[57]\tvalidation_0-auc:0.90123\tvalidation_1-auc:0.82924\n",
            "[58]\tvalidation_0-auc:0.90238\tvalidation_1-auc:0.82957\n",
            "[59]\tvalidation_0-auc:0.90300\tvalidation_1-auc:0.82985\n",
            "[60]\tvalidation_0-auc:0.90370\tvalidation_1-auc:0.83037\n",
            "[61]\tvalidation_0-auc:0.90366\tvalidation_1-auc:0.82976\n",
            "[62]\tvalidation_0-auc:0.90453\tvalidation_1-auc:0.83004\n",
            "[63]\tvalidation_0-auc:0.90542\tvalidation_1-auc:0.82979\n",
            "[64]\tvalidation_0-auc:0.90557\tvalidation_1-auc:0.82968\n",
            "[65]\tvalidation_0-auc:0.90688\tvalidation_1-auc:0.83006\n",
            "[66]\tvalidation_0-auc:0.90755\tvalidation_1-auc:0.83019\n",
            "[67]\tvalidation_0-auc:0.90877\tvalidation_1-auc:0.83072\n",
            "[68]\tvalidation_0-auc:0.90984\tvalidation_1-auc:0.83046\n",
            "[69]\tvalidation_0-auc:0.91025\tvalidation_1-auc:0.83041\n",
            "[70]\tvalidation_0-auc:0.91137\tvalidation_1-auc:0.83070\n",
            "[71]\tvalidation_0-auc:0.91212\tvalidation_1-auc:0.83101\n",
            "[72]\tvalidation_0-auc:0.91221\tvalidation_1-auc:0.83042\n",
            "[73]\tvalidation_0-auc:0.91314\tvalidation_1-auc:0.83036\n",
            "[74]\tvalidation_0-auc:0.91337\tvalidation_1-auc:0.82996\n",
            "[75]\tvalidation_0-auc:0.91385\tvalidation_1-auc:0.82966\n",
            "[76]\tvalidation_0-auc:0.91440\tvalidation_1-auc:0.82934\n",
            "[77]\tvalidation_0-auc:0.91533\tvalidation_1-auc:0.82973\n",
            "[78]\tvalidation_0-auc:0.91539\tvalidation_1-auc:0.82931\n",
            "[79]\tvalidation_0-auc:0.91576\tvalidation_1-auc:0.82969\n",
            "[80]\tvalidation_0-auc:0.91608\tvalidation_1-auc:0.82898\n",
            "[81]\tvalidation_0-auc:0.91671\tvalidation_1-auc:0.82904\n",
            "[82]\tvalidation_0-auc:0.91744\tvalidation_1-auc:0.82956\n",
            "[83]\tvalidation_0-auc:0.91788\tvalidation_1-auc:0.82904\n",
            "[84]\tvalidation_0-auc:0.91837\tvalidation_1-auc:0.82936\n",
            "[85]\tvalidation_0-auc:0.91880\tvalidation_1-auc:0.82994\n",
            "[86]\tvalidation_0-auc:0.91939\tvalidation_1-auc:0.83000\n",
            "[87]\tvalidation_0-auc:0.92001\tvalidation_1-auc:0.83032\n",
            "[88]\tvalidation_0-auc:0.92038\tvalidation_1-auc:0.82991\n",
            "[89]\tvalidation_0-auc:0.92084\tvalidation_1-auc:0.83012\n",
            "[90]\tvalidation_0-auc:0.92125\tvalidation_1-auc:0.82974\n",
            "[91]\tvalidation_0-auc:0.92155\tvalidation_1-auc:0.83002\n",
            "[92]\tvalidation_0-auc:0.92220\tvalidation_1-auc:0.83021\n",
            "[93]\tvalidation_0-auc:0.92289\tvalidation_1-auc:0.83078\n",
            "[94]\tvalidation_0-auc:0.92324\tvalidation_1-auc:0.83105\n",
            "[95]\tvalidation_0-auc:0.92348\tvalidation_1-auc:0.83120\n",
            "[96]\tvalidation_0-auc:0.92389\tvalidation_1-auc:0.83096\n",
            "[97]\tvalidation_0-auc:0.92433\tvalidation_1-auc:0.83138\n",
            "[98]\tvalidation_0-auc:0.92497\tvalidation_1-auc:0.83186\n",
            "[99]\tvalidation_0-auc:0.92528\tvalidation_1-auc:0.83168\n",
            "[100]\tvalidation_0-auc:0.92556\tvalidation_1-auc:0.83172\n",
            "[101]\tvalidation_0-auc:0.92599\tvalidation_1-auc:0.83170\n",
            "[102]\tvalidation_0-auc:0.92652\tvalidation_1-auc:0.83189\n",
            "[103]\tvalidation_0-auc:0.92680\tvalidation_1-auc:0.83173\n",
            "[104]\tvalidation_0-auc:0.92716\tvalidation_1-auc:0.83131\n",
            "[105]\tvalidation_0-auc:0.92747\tvalidation_1-auc:0.83153\n",
            "[106]\tvalidation_0-auc:0.92767\tvalidation_1-auc:0.83160\n",
            "[107]\tvalidation_0-auc:0.92803\tvalidation_1-auc:0.83166\n",
            "[108]\tvalidation_0-auc:0.92836\tvalidation_1-auc:0.83154\n",
            "[109]\tvalidation_0-auc:0.92859\tvalidation_1-auc:0.83165\n",
            "[110]\tvalidation_0-auc:0.92873\tvalidation_1-auc:0.83147\n",
            "[111]\tvalidation_0-auc:0.92886\tvalidation_1-auc:0.83149\n",
            "[112]\tvalidation_0-auc:0.92902\tvalidation_1-auc:0.83143\n",
            "[113]\tvalidation_0-auc:0.92942\tvalidation_1-auc:0.83143\n",
            "[114]\tvalidation_0-auc:0.92994\tvalidation_1-auc:0.83098\n",
            "[115]\tvalidation_0-auc:0.93017\tvalidation_1-auc:0.83083\n",
            "[116]\tvalidation_0-auc:0.93032\tvalidation_1-auc:0.83100\n",
            "[117]\tvalidation_0-auc:0.93066\tvalidation_1-auc:0.83104\n",
            "[118]\tvalidation_0-auc:0.93085\tvalidation_1-auc:0.83106\n",
            "[119]\tvalidation_0-auc:0.93128\tvalidation_1-auc:0.83099\n",
            "[120]\tvalidation_0-auc:0.93147\tvalidation_1-auc:0.83089\n",
            "[121]\tvalidation_0-auc:0.93162\tvalidation_1-auc:0.83097\n",
            "[122]\tvalidation_0-auc:0.93174\tvalidation_1-auc:0.83099\n",
            "[123]\tvalidation_0-auc:0.93181\tvalidation_1-auc:0.83104\n",
            "[124]\tvalidation_0-auc:0.93192\tvalidation_1-auc:0.83109\n",
            "[125]\tvalidation_0-auc:0.93203\tvalidation_1-auc:0.83098\n",
            "[126]\tvalidation_0-auc:0.93216\tvalidation_1-auc:0.83112\n",
            "[127]\tvalidation_0-auc:0.93227\tvalidation_1-auc:0.83118\n",
            "[128]\tvalidation_0-auc:0.93256\tvalidation_1-auc:0.83108\n",
            "[129]\tvalidation_0-auc:0.93273\tvalidation_1-auc:0.83092\n",
            "[130]\tvalidation_0-auc:0.93286\tvalidation_1-auc:0.83085\n",
            "[131]\tvalidation_0-auc:0.93302\tvalidation_1-auc:0.83080\n",
            "  6%|▌         | 3/50 [12:47<2:42:55, 207.99s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82069\tvalidation_1-auc:0.80473\n",
            "[1]\tvalidation_0-auc:0.81502\tvalidation_1-auc:0.79547\n",
            "[2]\tvalidation_0-auc:0.82526\tvalidation_1-auc:0.80691\n",
            "[3]\tvalidation_0-auc:0.83839\tvalidation_1-auc:0.81808\n",
            "[4]\tvalidation_0-auc:0.84157\tvalidation_1-auc:0.81955\n",
            "[5]\tvalidation_0-auc:0.84465\tvalidation_1-auc:0.81724\n",
            "[6]\tvalidation_0-auc:0.84995\tvalidation_1-auc:0.82193\n",
            "[7]\tvalidation_0-auc:0.85236\tvalidation_1-auc:0.82363\n",
            "[8]\tvalidation_0-auc:0.85419\tvalidation_1-auc:0.82414\n",
            "[9]\tvalidation_0-auc:0.85597\tvalidation_1-auc:0.82322\n",
            "[10]\tvalidation_0-auc:0.85874\tvalidation_1-auc:0.82337\n",
            "[11]\tvalidation_0-auc:0.86112\tvalidation_1-auc:0.82520\n",
            "[12]\tvalidation_0-auc:0.86303\tvalidation_1-auc:0.82608\n",
            "[13]\tvalidation_0-auc:0.86479\tvalidation_1-auc:0.82746\n",
            "[14]\tvalidation_0-auc:0.86575\tvalidation_1-auc:0.82766\n",
            "[15]\tvalidation_0-auc:0.86553\tvalidation_1-auc:0.82640\n",
            "[16]\tvalidation_0-auc:0.86607\tvalidation_1-auc:0.82496\n",
            "[17]\tvalidation_0-auc:0.86676\tvalidation_1-auc:0.82429\n",
            "[18]\tvalidation_0-auc:0.86853\tvalidation_1-auc:0.82512\n",
            "[19]\tvalidation_0-auc:0.87105\tvalidation_1-auc:0.82596\n",
            "[20]\tvalidation_0-auc:0.87331\tvalidation_1-auc:0.82700\n",
            "[21]\tvalidation_0-auc:0.87300\tvalidation_1-auc:0.82583\n",
            "[22]\tvalidation_0-auc:0.87472\tvalidation_1-auc:0.82651\n",
            "[23]\tvalidation_0-auc:0.87674\tvalidation_1-auc:0.82755\n",
            "[24]\tvalidation_0-auc:0.87890\tvalidation_1-auc:0.82832\n",
            "[25]\tvalidation_0-auc:0.88013\tvalidation_1-auc:0.82840\n",
            "[26]\tvalidation_0-auc:0.88106\tvalidation_1-auc:0.82853\n",
            "[27]\tvalidation_0-auc:0.88216\tvalidation_1-auc:0.82724\n",
            "[28]\tvalidation_0-auc:0.88316\tvalidation_1-auc:0.82565\n",
            "[29]\tvalidation_0-auc:0.88380\tvalidation_1-auc:0.82628\n",
            "[30]\tvalidation_0-auc:0.88413\tvalidation_1-auc:0.82676\n",
            "[31]\tvalidation_0-auc:0.88562\tvalidation_1-auc:0.82752\n",
            "[32]\tvalidation_0-auc:0.88628\tvalidation_1-auc:0.82673\n",
            "[33]\tvalidation_0-auc:0.88693\tvalidation_1-auc:0.82704\n",
            "[34]\tvalidation_0-auc:0.88759\tvalidation_1-auc:0.82631\n",
            "[35]\tvalidation_0-auc:0.88814\tvalidation_1-auc:0.82527\n",
            "[36]\tvalidation_0-auc:0.88895\tvalidation_1-auc:0.82629\n",
            "[37]\tvalidation_0-auc:0.88872\tvalidation_1-auc:0.82590\n",
            "[38]\tvalidation_0-auc:0.88909\tvalidation_1-auc:0.82541\n",
            "[39]\tvalidation_0-auc:0.88889\tvalidation_1-auc:0.82425\n",
            "[40]\tvalidation_0-auc:0.89085\tvalidation_1-auc:0.82564\n",
            "[41]\tvalidation_0-auc:0.89203\tvalidation_1-auc:0.82630\n",
            "[42]\tvalidation_0-auc:0.89236\tvalidation_1-auc:0.82694\n",
            "[43]\tvalidation_0-auc:0.89338\tvalidation_1-auc:0.82769\n",
            "[44]\tvalidation_0-auc:0.89383\tvalidation_1-auc:0.82805\n",
            "[45]\tvalidation_0-auc:0.89463\tvalidation_1-auc:0.82854\n",
            "[46]\tvalidation_0-auc:0.89464\tvalidation_1-auc:0.82819\n",
            "[47]\tvalidation_0-auc:0.89570\tvalidation_1-auc:0.82896\n",
            "[48]\tvalidation_0-auc:0.89615\tvalidation_1-auc:0.82901\n",
            "[49]\tvalidation_0-auc:0.89700\tvalidation_1-auc:0.82935\n",
            "[50]\tvalidation_0-auc:0.89702\tvalidation_1-auc:0.82916\n",
            "[51]\tvalidation_0-auc:0.89855\tvalidation_1-auc:0.82958\n",
            "[52]\tvalidation_0-auc:0.89926\tvalidation_1-auc:0.83014\n",
            "[53]\tvalidation_0-auc:0.90036\tvalidation_1-auc:0.83025\n",
            "[54]\tvalidation_0-auc:0.90077\tvalidation_1-auc:0.83073\n",
            "[55]\tvalidation_0-auc:0.90126\tvalidation_1-auc:0.83091\n",
            "[56]\tvalidation_0-auc:0.90221\tvalidation_1-auc:0.83047\n",
            "[57]\tvalidation_0-auc:0.90211\tvalidation_1-auc:0.83009\n",
            "[58]\tvalidation_0-auc:0.90351\tvalidation_1-auc:0.83057\n",
            "[59]\tvalidation_0-auc:0.90459\tvalidation_1-auc:0.83114\n",
            "[60]\tvalidation_0-auc:0.90515\tvalidation_1-auc:0.83127\n",
            "[61]\tvalidation_0-auc:0.90506\tvalidation_1-auc:0.83119\n",
            "[62]\tvalidation_0-auc:0.90643\tvalidation_1-auc:0.83126\n",
            "[63]\tvalidation_0-auc:0.90734\tvalidation_1-auc:0.83062\n",
            "[64]\tvalidation_0-auc:0.90748\tvalidation_1-auc:0.83023\n",
            "[65]\tvalidation_0-auc:0.90885\tvalidation_1-auc:0.83062\n",
            "[66]\tvalidation_0-auc:0.90930\tvalidation_1-auc:0.83013\n",
            "[67]\tvalidation_0-auc:0.91046\tvalidation_1-auc:0.83046\n",
            "[68]\tvalidation_0-auc:0.91124\tvalidation_1-auc:0.83011\n",
            "[69]\tvalidation_0-auc:0.91174\tvalidation_1-auc:0.83074\n",
            "[70]\tvalidation_0-auc:0.91273\tvalidation_1-auc:0.83061\n",
            "[71]\tvalidation_0-auc:0.91341\tvalidation_1-auc:0.83113\n",
            "[72]\tvalidation_0-auc:0.91331\tvalidation_1-auc:0.83081\n",
            "[73]\tvalidation_0-auc:0.91405\tvalidation_1-auc:0.83038\n",
            "[74]\tvalidation_0-auc:0.91409\tvalidation_1-auc:0.83026\n",
            "[75]\tvalidation_0-auc:0.91460\tvalidation_1-auc:0.82964\n",
            "[76]\tvalidation_0-auc:0.91513\tvalidation_1-auc:0.82905\n",
            "[77]\tvalidation_0-auc:0.91616\tvalidation_1-auc:0.82958\n",
            "[78]\tvalidation_0-auc:0.91648\tvalidation_1-auc:0.82955\n",
            "[79]\tvalidation_0-auc:0.91693\tvalidation_1-auc:0.83007\n",
            "[80]\tvalidation_0-auc:0.91731\tvalidation_1-auc:0.82945\n",
            "[81]\tvalidation_0-auc:0.91790\tvalidation_1-auc:0.82969\n",
            "[82]\tvalidation_0-auc:0.91843\tvalidation_1-auc:0.83006\n",
            "[83]\tvalidation_0-auc:0.91899\tvalidation_1-auc:0.82979\n",
            "[84]\tvalidation_0-auc:0.91936\tvalidation_1-auc:0.83041\n",
            "[85]\tvalidation_0-auc:0.91997\tvalidation_1-auc:0.83061\n",
            "[86]\tvalidation_0-auc:0.92064\tvalidation_1-auc:0.83103\n",
            "[87]\tvalidation_0-auc:0.92113\tvalidation_1-auc:0.83142\n",
            "[88]\tvalidation_0-auc:0.92162\tvalidation_1-auc:0.83118\n",
            "[89]\tvalidation_0-auc:0.92220\tvalidation_1-auc:0.83122\n",
            "[90]\tvalidation_0-auc:0.92254\tvalidation_1-auc:0.83097\n",
            "[91]\tvalidation_0-auc:0.92295\tvalidation_1-auc:0.83104\n",
            "[92]\tvalidation_0-auc:0.92366\tvalidation_1-auc:0.83128\n",
            "[93]\tvalidation_0-auc:0.92433\tvalidation_1-auc:0.83145\n",
            "[94]\tvalidation_0-auc:0.92457\tvalidation_1-auc:0.83181\n",
            "[95]\tvalidation_0-auc:0.92487\tvalidation_1-auc:0.83202\n",
            "[96]\tvalidation_0-auc:0.92534\tvalidation_1-auc:0.83162\n",
            "[97]\tvalidation_0-auc:0.92575\tvalidation_1-auc:0.83198\n",
            "[98]\tvalidation_0-auc:0.92626\tvalidation_1-auc:0.83212\n",
            "[99]\tvalidation_0-auc:0.92654\tvalidation_1-auc:0.83205\n",
            "[100]\tvalidation_0-auc:0.92682\tvalidation_1-auc:0.83223\n",
            "[101]\tvalidation_0-auc:0.92724\tvalidation_1-auc:0.83260\n",
            "[102]\tvalidation_0-auc:0.92773\tvalidation_1-auc:0.83276\n",
            "[103]\tvalidation_0-auc:0.92807\tvalidation_1-auc:0.83283\n",
            "[104]\tvalidation_0-auc:0.92843\tvalidation_1-auc:0.83240\n",
            "[105]\tvalidation_0-auc:0.92884\tvalidation_1-auc:0.83229\n",
            "[106]\tvalidation_0-auc:0.92908\tvalidation_1-auc:0.83243\n",
            "[107]\tvalidation_0-auc:0.92961\tvalidation_1-auc:0.83304\n",
            "[108]\tvalidation_0-auc:0.92990\tvalidation_1-auc:0.83281\n",
            "[109]\tvalidation_0-auc:0.93006\tvalidation_1-auc:0.83294\n",
            "[110]\tvalidation_0-auc:0.93031\tvalidation_1-auc:0.83283\n",
            "[111]\tvalidation_0-auc:0.93047\tvalidation_1-auc:0.83295\n",
            "[112]\tvalidation_0-auc:0.93089\tvalidation_1-auc:0.83277\n",
            "[113]\tvalidation_0-auc:0.93115\tvalidation_1-auc:0.83271\n",
            "[114]\tvalidation_0-auc:0.93156\tvalidation_1-auc:0.83257\n",
            "[115]\tvalidation_0-auc:0.93198\tvalidation_1-auc:0.83212\n",
            "[116]\tvalidation_0-auc:0.93211\tvalidation_1-auc:0.83217\n",
            "[117]\tvalidation_0-auc:0.93238\tvalidation_1-auc:0.83219\n",
            "[118]\tvalidation_0-auc:0.93244\tvalidation_1-auc:0.83247\n",
            "[119]\tvalidation_0-auc:0.93273\tvalidation_1-auc:0.83229\n",
            "[120]\tvalidation_0-auc:0.93274\tvalidation_1-auc:0.83244\n",
            "[121]\tvalidation_0-auc:0.93302\tvalidation_1-auc:0.83267\n",
            "[122]\tvalidation_0-auc:0.93313\tvalidation_1-auc:0.83268\n",
            "[123]\tvalidation_0-auc:0.93322\tvalidation_1-auc:0.83289\n",
            "[124]\tvalidation_0-auc:0.93340\tvalidation_1-auc:0.83311\n",
            "[125]\tvalidation_0-auc:0.93347\tvalidation_1-auc:0.83312\n",
            "[126]\tvalidation_0-auc:0.93364\tvalidation_1-auc:0.83336\n",
            "[127]\tvalidation_0-auc:0.93370\tvalidation_1-auc:0.83347\n",
            "[128]\tvalidation_0-auc:0.93394\tvalidation_1-auc:0.83335\n",
            "[129]\tvalidation_0-auc:0.93428\tvalidation_1-auc:0.83343\n",
            "[130]\tvalidation_0-auc:0.93453\tvalidation_1-auc:0.83360\n",
            "[131]\tvalidation_0-auc:0.93468\tvalidation_1-auc:0.83364\n",
            "[132]\tvalidation_0-auc:0.93474\tvalidation_1-auc:0.83371\n",
            "[133]\tvalidation_0-auc:0.93486\tvalidation_1-auc:0.83393\n",
            "[134]\tvalidation_0-auc:0.93497\tvalidation_1-auc:0.83391\n",
            "[135]\tvalidation_0-auc:0.93508\tvalidation_1-auc:0.83410\n",
            "[136]\tvalidation_0-auc:0.93522\tvalidation_1-auc:0.83411\n",
            "[137]\tvalidation_0-auc:0.93539\tvalidation_1-auc:0.83415\n",
            "[138]\tvalidation_0-auc:0.93571\tvalidation_1-auc:0.83419\n",
            "[139]\tvalidation_0-auc:0.93596\tvalidation_1-auc:0.83432\n",
            "[140]\tvalidation_0-auc:0.93618\tvalidation_1-auc:0.83413\n",
            "[141]\tvalidation_0-auc:0.93633\tvalidation_1-auc:0.83429\n",
            "[142]\tvalidation_0-auc:0.93644\tvalidation_1-auc:0.83427\n",
            "[143]\tvalidation_0-auc:0.93659\tvalidation_1-auc:0.83423\n",
            "[144]\tvalidation_0-auc:0.93663\tvalidation_1-auc:0.83425\n",
            "[145]\tvalidation_0-auc:0.93675\tvalidation_1-auc:0.83441\n",
            "[146]\tvalidation_0-auc:0.93689\tvalidation_1-auc:0.83435\n",
            "[147]\tvalidation_0-auc:0.93692\tvalidation_1-auc:0.83447\n",
            "[148]\tvalidation_0-auc:0.93706\tvalidation_1-auc:0.83440\n",
            "[149]\tvalidation_0-auc:0.93713\tvalidation_1-auc:0.83430\n",
            "[150]\tvalidation_0-auc:0.93718\tvalidation_1-auc:0.83437\n",
            "[151]\tvalidation_0-auc:0.93727\tvalidation_1-auc:0.83426\n",
            "[152]\tvalidation_0-auc:0.93737\tvalidation_1-auc:0.83423\n",
            "[153]\tvalidation_0-auc:0.93746\tvalidation_1-auc:0.83433\n",
            "[154]\tvalidation_0-auc:0.93774\tvalidation_1-auc:0.83437\n",
            "[155]\tvalidation_0-auc:0.93779\tvalidation_1-auc:0.83433\n",
            "[156]\tvalidation_0-auc:0.93785\tvalidation_1-auc:0.83425\n",
            "[157]\tvalidation_0-auc:0.93804\tvalidation_1-auc:0.83415\n",
            "[158]\tvalidation_0-auc:0.93813\tvalidation_1-auc:0.83432\n",
            "[159]\tvalidation_0-auc:0.93815\tvalidation_1-auc:0.83426\n",
            "[160]\tvalidation_0-auc:0.93824\tvalidation_1-auc:0.83413\n",
            "[161]\tvalidation_0-auc:0.93827\tvalidation_1-auc:0.83415\n",
            "[162]\tvalidation_0-auc:0.93838\tvalidation_1-auc:0.83391\n",
            "[163]\tvalidation_0-auc:0.93849\tvalidation_1-auc:0.83395\n",
            "[164]\tvalidation_0-auc:0.93863\tvalidation_1-auc:0.83391\n",
            "[165]\tvalidation_0-auc:0.93866\tvalidation_1-auc:0.83384\n",
            "[166]\tvalidation_0-auc:0.93870\tvalidation_1-auc:0.83380\n",
            "[167]\tvalidation_0-auc:0.93886\tvalidation_1-auc:0.83367\n",
            "[168]\tvalidation_0-auc:0.93909\tvalidation_1-auc:0.83354\n",
            "[169]\tvalidation_0-auc:0.93918\tvalidation_1-auc:0.83350\n",
            "[170]\tvalidation_0-auc:0.93944\tvalidation_1-auc:0.83334\n",
            "[171]\tvalidation_0-auc:0.93962\tvalidation_1-auc:0.83329\n",
            "[172]\tvalidation_0-auc:0.93976\tvalidation_1-auc:0.83312\n",
            "[173]\tvalidation_0-auc:0.93982\tvalidation_1-auc:0.83313\n",
            "[174]\tvalidation_0-auc:0.93988\tvalidation_1-auc:0.83307\n",
            "[175]\tvalidation_0-auc:0.93997\tvalidation_1-auc:0.83298\n",
            "[176]\tvalidation_0-auc:0.94005\tvalidation_1-auc:0.83292\n",
            "[177]\tvalidation_0-auc:0.94014\tvalidation_1-auc:0.83281\n",
            "  6%|▌         | 3/50 [15:48<2:42:55, 207.99s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83145\tvalidation_1-auc:0.80769\n",
            "[1]\tvalidation_0-auc:0.82651\tvalidation_1-auc:0.80400\n",
            "[2]\tvalidation_0-auc:0.83896\tvalidation_1-auc:0.81584\n",
            "[3]\tvalidation_0-auc:0.84151\tvalidation_1-auc:0.81789\n",
            "[4]\tvalidation_0-auc:0.84431\tvalidation_1-auc:0.82030\n",
            "[5]\tvalidation_0-auc:0.84665\tvalidation_1-auc:0.82037\n",
            "[6]\tvalidation_0-auc:0.84804\tvalidation_1-auc:0.82108\n",
            "[7]\tvalidation_0-auc:0.84973\tvalidation_1-auc:0.82207\n",
            "[8]\tvalidation_0-auc:0.85523\tvalidation_1-auc:0.82344\n",
            "[9]\tvalidation_0-auc:0.85793\tvalidation_1-auc:0.82292\n",
            "[10]\tvalidation_0-auc:0.85956\tvalidation_1-auc:0.82511\n",
            "[11]\tvalidation_0-auc:0.86440\tvalidation_1-auc:0.82563\n",
            "[12]\tvalidation_0-auc:0.86599\tvalidation_1-auc:0.82497\n",
            "[13]\tvalidation_0-auc:0.86705\tvalidation_1-auc:0.82533\n",
            "[14]\tvalidation_0-auc:0.86901\tvalidation_1-auc:0.82765\n",
            "[15]\tvalidation_0-auc:0.86862\tvalidation_1-auc:0.82686\n",
            "[16]\tvalidation_0-auc:0.86786\tvalidation_1-auc:0.82491\n",
            "[17]\tvalidation_0-auc:0.86815\tvalidation_1-auc:0.82472\n",
            "[18]\tvalidation_0-auc:0.86845\tvalidation_1-auc:0.82508\n",
            "[19]\tvalidation_0-auc:0.87058\tvalidation_1-auc:0.82548\n",
            "[20]\tvalidation_0-auc:0.87316\tvalidation_1-auc:0.82589\n",
            "[21]\tvalidation_0-auc:0.87394\tvalidation_1-auc:0.82515\n",
            "[22]\tvalidation_0-auc:0.87585\tvalidation_1-auc:0.82494\n",
            "[23]\tvalidation_0-auc:0.87768\tvalidation_1-auc:0.82476\n",
            "[24]\tvalidation_0-auc:0.87907\tvalidation_1-auc:0.82482\n",
            "[25]\tvalidation_0-auc:0.88094\tvalidation_1-auc:0.82526\n",
            "[26]\tvalidation_0-auc:0.88230\tvalidation_1-auc:0.82587\n",
            "[27]\tvalidation_0-auc:0.88384\tvalidation_1-auc:0.82545\n",
            "[28]\tvalidation_0-auc:0.88514\tvalidation_1-auc:0.82499\n",
            "[29]\tvalidation_0-auc:0.88602\tvalidation_1-auc:0.82635\n",
            "[30]\tvalidation_0-auc:0.88627\tvalidation_1-auc:0.82700\n",
            "[31]\tvalidation_0-auc:0.88678\tvalidation_1-auc:0.82769\n",
            "[32]\tvalidation_0-auc:0.88789\tvalidation_1-auc:0.82708\n",
            "[33]\tvalidation_0-auc:0.88873\tvalidation_1-auc:0.82794\n",
            "[34]\tvalidation_0-auc:0.88973\tvalidation_1-auc:0.82653\n",
            "[35]\tvalidation_0-auc:0.88982\tvalidation_1-auc:0.82564\n",
            "[36]\tvalidation_0-auc:0.89058\tvalidation_1-auc:0.82599\n",
            "[37]\tvalidation_0-auc:0.89095\tvalidation_1-auc:0.82525\n",
            "[38]\tvalidation_0-auc:0.89154\tvalidation_1-auc:0.82480\n",
            "[39]\tvalidation_0-auc:0.89163\tvalidation_1-auc:0.82400\n",
            "[40]\tvalidation_0-auc:0.89277\tvalidation_1-auc:0.82426\n",
            "[41]\tvalidation_0-auc:0.89389\tvalidation_1-auc:0.82472\n",
            "[42]\tvalidation_0-auc:0.89473\tvalidation_1-auc:0.82605\n",
            "[43]\tvalidation_0-auc:0.89547\tvalidation_1-auc:0.82646\n",
            "[44]\tvalidation_0-auc:0.89618\tvalidation_1-auc:0.82674\n",
            "[45]\tvalidation_0-auc:0.89740\tvalidation_1-auc:0.82715\n",
            "[46]\tvalidation_0-auc:0.89753\tvalidation_1-auc:0.82701\n",
            "[47]\tvalidation_0-auc:0.89875\tvalidation_1-auc:0.82751\n",
            "[48]\tvalidation_0-auc:0.89956\tvalidation_1-auc:0.82769\n",
            "[49]\tvalidation_0-auc:0.90026\tvalidation_1-auc:0.82843\n",
            "[50]\tvalidation_0-auc:0.90067\tvalidation_1-auc:0.82794\n",
            "[51]\tvalidation_0-auc:0.90144\tvalidation_1-auc:0.82883\n",
            "[52]\tvalidation_0-auc:0.90216\tvalidation_1-auc:0.82968\n",
            "[53]\tvalidation_0-auc:0.90295\tvalidation_1-auc:0.82976\n",
            "[54]\tvalidation_0-auc:0.90293\tvalidation_1-auc:0.83023\n",
            "[55]\tvalidation_0-auc:0.90325\tvalidation_1-auc:0.83048\n",
            "[56]\tvalidation_0-auc:0.90401\tvalidation_1-auc:0.82952\n",
            "[57]\tvalidation_0-auc:0.90402\tvalidation_1-auc:0.82888\n",
            "[58]\tvalidation_0-auc:0.90506\tvalidation_1-auc:0.82916\n",
            "[59]\tvalidation_0-auc:0.90573\tvalidation_1-auc:0.82942\n",
            "[60]\tvalidation_0-auc:0.90630\tvalidation_1-auc:0.82953\n",
            "[61]\tvalidation_0-auc:0.90660\tvalidation_1-auc:0.82915\n",
            "[62]\tvalidation_0-auc:0.90726\tvalidation_1-auc:0.82945\n",
            "[63]\tvalidation_0-auc:0.90804\tvalidation_1-auc:0.82908\n",
            "[64]\tvalidation_0-auc:0.90834\tvalidation_1-auc:0.82892\n",
            "[65]\tvalidation_0-auc:0.90921\tvalidation_1-auc:0.82913\n",
            "[66]\tvalidation_0-auc:0.91003\tvalidation_1-auc:0.82863\n",
            "[67]\tvalidation_0-auc:0.91084\tvalidation_1-auc:0.82906\n",
            "[68]\tvalidation_0-auc:0.91162\tvalidation_1-auc:0.82847\n",
            "[69]\tvalidation_0-auc:0.91202\tvalidation_1-auc:0.82904\n",
            "[70]\tvalidation_0-auc:0.91295\tvalidation_1-auc:0.82930\n",
            "[71]\tvalidation_0-auc:0.91344\tvalidation_1-auc:0.82971\n",
            "[72]\tvalidation_0-auc:0.91358\tvalidation_1-auc:0.82962\n",
            "[73]\tvalidation_0-auc:0.91415\tvalidation_1-auc:0.82917\n",
            "[74]\tvalidation_0-auc:0.91443\tvalidation_1-auc:0.82897\n",
            "[75]\tvalidation_0-auc:0.91503\tvalidation_1-auc:0.82826\n",
            "[76]\tvalidation_0-auc:0.91544\tvalidation_1-auc:0.82772\n",
            "[77]\tvalidation_0-auc:0.91609\tvalidation_1-auc:0.82842\n",
            "[78]\tvalidation_0-auc:0.91643\tvalidation_1-auc:0.82849\n",
            "[79]\tvalidation_0-auc:0.91693\tvalidation_1-auc:0.82876\n",
            "[80]\tvalidation_0-auc:0.91734\tvalidation_1-auc:0.82818\n",
            "[81]\tvalidation_0-auc:0.91777\tvalidation_1-auc:0.82894\n",
            "[82]\tvalidation_0-auc:0.91828\tvalidation_1-auc:0.82931\n",
            "[83]\tvalidation_0-auc:0.91883\tvalidation_1-auc:0.82870\n",
            "[84]\tvalidation_0-auc:0.91923\tvalidation_1-auc:0.82892\n",
            "[85]\tvalidation_0-auc:0.91974\tvalidation_1-auc:0.82940\n",
            "  8%|▊         | 4/50 [17:24<3:41:12, 288.52s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83024\tvalidation_1-auc:0.80043\n",
            "[1]\tvalidation_0-auc:0.82972\tvalidation_1-auc:0.79085\n",
            "[2]\tvalidation_0-auc:0.84537\tvalidation_1-auc:0.80627\n",
            "[3]\tvalidation_0-auc:0.85060\tvalidation_1-auc:0.81128\n",
            "[4]\tvalidation_0-auc:0.86037\tvalidation_1-auc:0.81422\n",
            "[5]\tvalidation_0-auc:0.86612\tvalidation_1-auc:0.81543\n",
            "[6]\tvalidation_0-auc:0.86896\tvalidation_1-auc:0.81773\n",
            "[7]\tvalidation_0-auc:0.87610\tvalidation_1-auc:0.81964\n",
            "[8]\tvalidation_0-auc:0.87947\tvalidation_1-auc:0.82145\n",
            "[9]\tvalidation_0-auc:0.88383\tvalidation_1-auc:0.82244\n",
            "[10]\tvalidation_0-auc:0.88780\tvalidation_1-auc:0.82311\n",
            "[11]\tvalidation_0-auc:0.89219\tvalidation_1-auc:0.82500\n",
            "[12]\tvalidation_0-auc:0.89604\tvalidation_1-auc:0.82482\n",
            "[13]\tvalidation_0-auc:0.90147\tvalidation_1-auc:0.82690\n",
            "[14]\tvalidation_0-auc:0.90399\tvalidation_1-auc:0.82743\n",
            "[15]\tvalidation_0-auc:0.90810\tvalidation_1-auc:0.82769\n",
            "[16]\tvalidation_0-auc:0.91102\tvalidation_1-auc:0.82677\n",
            "[17]\tvalidation_0-auc:0.91429\tvalidation_1-auc:0.82667\n",
            "[18]\tvalidation_0-auc:0.91829\tvalidation_1-auc:0.82704\n",
            "[19]\tvalidation_0-auc:0.92000\tvalidation_1-auc:0.82744\n",
            "[20]\tvalidation_0-auc:0.92348\tvalidation_1-auc:0.82712\n",
            "[21]\tvalidation_0-auc:0.92625\tvalidation_1-auc:0.82585\n",
            "[22]\tvalidation_0-auc:0.92889\tvalidation_1-auc:0.82588\n",
            "[23]\tvalidation_0-auc:0.93079\tvalidation_1-auc:0.82528\n",
            "[24]\tvalidation_0-auc:0.93265\tvalidation_1-auc:0.82580\n",
            "[25]\tvalidation_0-auc:0.93464\tvalidation_1-auc:0.82567\n",
            "[26]\tvalidation_0-auc:0.93652\tvalidation_1-auc:0.82499\n",
            "[27]\tvalidation_0-auc:0.93793\tvalidation_1-auc:0.82510\n",
            "[28]\tvalidation_0-auc:0.94000\tvalidation_1-auc:0.82522\n",
            "[29]\tvalidation_0-auc:0.94114\tvalidation_1-auc:0.82521\n",
            "[30]\tvalidation_0-auc:0.94239\tvalidation_1-auc:0.82472\n",
            "[31]\tvalidation_0-auc:0.94295\tvalidation_1-auc:0.82407\n",
            "[32]\tvalidation_0-auc:0.94410\tvalidation_1-auc:0.82333\n",
            "[33]\tvalidation_0-auc:0.94462\tvalidation_1-auc:0.82339\n",
            "[34]\tvalidation_0-auc:0.94591\tvalidation_1-auc:0.82308\n",
            "[35]\tvalidation_0-auc:0.94725\tvalidation_1-auc:0.82238\n",
            "[36]\tvalidation_0-auc:0.94753\tvalidation_1-auc:0.82236\n",
            "[37]\tvalidation_0-auc:0.94785\tvalidation_1-auc:0.82151\n",
            "[38]\tvalidation_0-auc:0.94800\tvalidation_1-auc:0.82122\n",
            "[39]\tvalidation_0-auc:0.94804\tvalidation_1-auc:0.82127\n",
            "[40]\tvalidation_0-auc:0.94884\tvalidation_1-auc:0.82132\n",
            "[41]\tvalidation_0-auc:0.94987\tvalidation_1-auc:0.82185\n",
            "[42]\tvalidation_0-auc:0.95011\tvalidation_1-auc:0.82144\n",
            "[43]\tvalidation_0-auc:0.95042\tvalidation_1-auc:0.82167\n",
            "[44]\tvalidation_0-auc:0.95066\tvalidation_1-auc:0.82159\n",
            "  8%|▊         | 4/50 [18:53<3:41:12, 288.52s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82411\tvalidation_1-auc:0.80530\n",
            "[1]\tvalidation_0-auc:0.82777\tvalidation_1-auc:0.80313\n",
            "[2]\tvalidation_0-auc:0.84941\tvalidation_1-auc:0.81770\n",
            "[3]\tvalidation_0-auc:0.85728\tvalidation_1-auc:0.82094\n",
            "[4]\tvalidation_0-auc:0.86418\tvalidation_1-auc:0.82501\n",
            "[5]\tvalidation_0-auc:0.86869\tvalidation_1-auc:0.82792\n",
            "[6]\tvalidation_0-auc:0.87047\tvalidation_1-auc:0.82735\n",
            "[7]\tvalidation_0-auc:0.87725\tvalidation_1-auc:0.82751\n",
            "[8]\tvalidation_0-auc:0.88424\tvalidation_1-auc:0.82813\n",
            "[9]\tvalidation_0-auc:0.88933\tvalidation_1-auc:0.82931\n",
            "[10]\tvalidation_0-auc:0.89217\tvalidation_1-auc:0.82957\n",
            "[11]\tvalidation_0-auc:0.89645\tvalidation_1-auc:0.82885\n",
            "[12]\tvalidation_0-auc:0.90032\tvalidation_1-auc:0.82748\n",
            "[13]\tvalidation_0-auc:0.90370\tvalidation_1-auc:0.82790\n",
            "[14]\tvalidation_0-auc:0.90494\tvalidation_1-auc:0.82885\n",
            "[15]\tvalidation_0-auc:0.91037\tvalidation_1-auc:0.82846\n",
            "[16]\tvalidation_0-auc:0.91355\tvalidation_1-auc:0.82833\n",
            "[17]\tvalidation_0-auc:0.91680\tvalidation_1-auc:0.82948\n",
            "[18]\tvalidation_0-auc:0.92040\tvalidation_1-auc:0.82943\n",
            "[19]\tvalidation_0-auc:0.92384\tvalidation_1-auc:0.82805\n",
            "[20]\tvalidation_0-auc:0.92662\tvalidation_1-auc:0.82805\n",
            "[21]\tvalidation_0-auc:0.92859\tvalidation_1-auc:0.82811\n",
            "[22]\tvalidation_0-auc:0.93072\tvalidation_1-auc:0.82824\n",
            "[23]\tvalidation_0-auc:0.93231\tvalidation_1-auc:0.82831\n",
            "[24]\tvalidation_0-auc:0.93506\tvalidation_1-auc:0.82767\n",
            "[25]\tvalidation_0-auc:0.93743\tvalidation_1-auc:0.82874\n",
            "[26]\tvalidation_0-auc:0.93933\tvalidation_1-auc:0.82952\n",
            "[27]\tvalidation_0-auc:0.94033\tvalidation_1-auc:0.82989\n",
            "[28]\tvalidation_0-auc:0.94197\tvalidation_1-auc:0.83041\n",
            "[29]\tvalidation_0-auc:0.94240\tvalidation_1-auc:0.83054\n",
            "[30]\tvalidation_0-auc:0.94299\tvalidation_1-auc:0.83128\n",
            "[31]\tvalidation_0-auc:0.94378\tvalidation_1-auc:0.83145\n",
            "[32]\tvalidation_0-auc:0.94565\tvalidation_1-auc:0.83064\n",
            "[33]\tvalidation_0-auc:0.94618\tvalidation_1-auc:0.83093\n",
            "[34]\tvalidation_0-auc:0.94732\tvalidation_1-auc:0.83083\n",
            "[35]\tvalidation_0-auc:0.94792\tvalidation_1-auc:0.83146\n",
            "[36]\tvalidation_0-auc:0.94833\tvalidation_1-auc:0.83143\n",
            "[37]\tvalidation_0-auc:0.94885\tvalidation_1-auc:0.83138\n",
            "[38]\tvalidation_0-auc:0.94980\tvalidation_1-auc:0.83145\n",
            "[39]\tvalidation_0-auc:0.94983\tvalidation_1-auc:0.83155\n",
            "[40]\tvalidation_0-auc:0.95018\tvalidation_1-auc:0.83160\n",
            "[41]\tvalidation_0-auc:0.95161\tvalidation_1-auc:0.83128\n",
            "[42]\tvalidation_0-auc:0.95175\tvalidation_1-auc:0.83151\n",
            "[43]\tvalidation_0-auc:0.95228\tvalidation_1-auc:0.83164\n",
            "[44]\tvalidation_0-auc:0.95272\tvalidation_1-auc:0.83166\n",
            "[45]\tvalidation_0-auc:0.95357\tvalidation_1-auc:0.83110\n",
            "[46]\tvalidation_0-auc:0.95372\tvalidation_1-auc:0.83108\n",
            "[47]\tvalidation_0-auc:0.95403\tvalidation_1-auc:0.83094\n",
            "[48]\tvalidation_0-auc:0.95409\tvalidation_1-auc:0.83087\n",
            "[49]\tvalidation_0-auc:0.95460\tvalidation_1-auc:0.83085\n",
            "[50]\tvalidation_0-auc:0.95475\tvalidation_1-auc:0.83098\n",
            "[51]\tvalidation_0-auc:0.95509\tvalidation_1-auc:0.83103\n",
            "[52]\tvalidation_0-auc:0.95515\tvalidation_1-auc:0.83104\n",
            "[53]\tvalidation_0-auc:0.95524\tvalidation_1-auc:0.83098\n",
            "[54]\tvalidation_0-auc:0.95535\tvalidation_1-auc:0.83083\n",
            "[55]\tvalidation_0-auc:0.95547\tvalidation_1-auc:0.83032\n",
            "[56]\tvalidation_0-auc:0.95571\tvalidation_1-auc:0.82979\n",
            "[57]\tvalidation_0-auc:0.95593\tvalidation_1-auc:0.82990\n",
            "[58]\tvalidation_0-auc:0.95602\tvalidation_1-auc:0.83007\n",
            "[59]\tvalidation_0-auc:0.95606\tvalidation_1-auc:0.82973\n",
            "[60]\tvalidation_0-auc:0.95613\tvalidation_1-auc:0.82978\n",
            "[61]\tvalidation_0-auc:0.95623\tvalidation_1-auc:0.82967\n",
            "[62]\tvalidation_0-auc:0.95633\tvalidation_1-auc:0.82957\n",
            "[63]\tvalidation_0-auc:0.95655\tvalidation_1-auc:0.82942\n",
            "[64]\tvalidation_0-auc:0.95747\tvalidation_1-auc:0.82943\n",
            "[65]\tvalidation_0-auc:0.95755\tvalidation_1-auc:0.82947\n",
            "[66]\tvalidation_0-auc:0.95775\tvalidation_1-auc:0.82969\n",
            "[67]\tvalidation_0-auc:0.95785\tvalidation_1-auc:0.82964\n",
            "[68]\tvalidation_0-auc:0.95793\tvalidation_1-auc:0.82960\n",
            "[69]\tvalidation_0-auc:0.95868\tvalidation_1-auc:0.82929\n",
            "[70]\tvalidation_0-auc:0.95881\tvalidation_1-auc:0.82904\n",
            "[71]\tvalidation_0-auc:0.95896\tvalidation_1-auc:0.82845\n",
            "[72]\tvalidation_0-auc:0.95910\tvalidation_1-auc:0.82827\n",
            "[73]\tvalidation_0-auc:0.95929\tvalidation_1-auc:0.82817\n",
            "[74]\tvalidation_0-auc:0.96017\tvalidation_1-auc:0.82830\n",
            "  8%|▊         | 4/50 [20:50<3:41:12, 288.52s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83668\tvalidation_1-auc:0.80842\n",
            "[1]\tvalidation_0-auc:0.83840\tvalidation_1-auc:0.80596\n",
            "[2]\tvalidation_0-auc:0.85330\tvalidation_1-auc:0.81401\n",
            "[3]\tvalidation_0-auc:0.86385\tvalidation_1-auc:0.81954\n",
            "[4]\tvalidation_0-auc:0.86716\tvalidation_1-auc:0.82090\n",
            "[5]\tvalidation_0-auc:0.87120\tvalidation_1-auc:0.82142\n",
            "[6]\tvalidation_0-auc:0.87814\tvalidation_1-auc:0.82493\n",
            "[7]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.82697\n",
            "[8]\tvalidation_0-auc:0.88595\tvalidation_1-auc:0.82856\n",
            "[9]\tvalidation_0-auc:0.89102\tvalidation_1-auc:0.82895\n",
            "[10]\tvalidation_0-auc:0.89426\tvalidation_1-auc:0.82720\n",
            "[11]\tvalidation_0-auc:0.89652\tvalidation_1-auc:0.82704\n",
            "[12]\tvalidation_0-auc:0.90095\tvalidation_1-auc:0.82840\n",
            "[13]\tvalidation_0-auc:0.90723\tvalidation_1-auc:0.82792\n",
            "[14]\tvalidation_0-auc:0.90883\tvalidation_1-auc:0.82794\n",
            "[15]\tvalidation_0-auc:0.91368\tvalidation_1-auc:0.82761\n",
            "[16]\tvalidation_0-auc:0.91749\tvalidation_1-auc:0.82617\n",
            "[17]\tvalidation_0-auc:0.92115\tvalidation_1-auc:0.82526\n",
            "[18]\tvalidation_0-auc:0.92476\tvalidation_1-auc:0.82520\n",
            "[19]\tvalidation_0-auc:0.92871\tvalidation_1-auc:0.82566\n",
            "[20]\tvalidation_0-auc:0.93156\tvalidation_1-auc:0.82795\n",
            "[21]\tvalidation_0-auc:0.93438\tvalidation_1-auc:0.82753\n",
            "[22]\tvalidation_0-auc:0.93671\tvalidation_1-auc:0.82730\n",
            "[23]\tvalidation_0-auc:0.93864\tvalidation_1-auc:0.82658\n",
            "[24]\tvalidation_0-auc:0.94065\tvalidation_1-auc:0.82792\n",
            "[25]\tvalidation_0-auc:0.94296\tvalidation_1-auc:0.82736\n",
            "[26]\tvalidation_0-auc:0.94446\tvalidation_1-auc:0.82763\n",
            "[27]\tvalidation_0-auc:0.94541\tvalidation_1-auc:0.82731\n",
            "[28]\tvalidation_0-auc:0.94654\tvalidation_1-auc:0.82765\n",
            "[29]\tvalidation_0-auc:0.94736\tvalidation_1-auc:0.82775\n",
            "[30]\tvalidation_0-auc:0.94798\tvalidation_1-auc:0.82766\n",
            "[31]\tvalidation_0-auc:0.94860\tvalidation_1-auc:0.82773\n",
            "[32]\tvalidation_0-auc:0.95007\tvalidation_1-auc:0.82819\n",
            "[33]\tvalidation_0-auc:0.95058\tvalidation_1-auc:0.82857\n",
            "[34]\tvalidation_0-auc:0.95109\tvalidation_1-auc:0.82840\n",
            "[35]\tvalidation_0-auc:0.95150\tvalidation_1-auc:0.82911\n",
            "[36]\tvalidation_0-auc:0.95171\tvalidation_1-auc:0.82914\n",
            "[37]\tvalidation_0-auc:0.95206\tvalidation_1-auc:0.82904\n",
            "[38]\tvalidation_0-auc:0.95255\tvalidation_1-auc:0.82827\n",
            "[39]\tvalidation_0-auc:0.95280\tvalidation_1-auc:0.82815\n",
            "[40]\tvalidation_0-auc:0.95350\tvalidation_1-auc:0.82851\n",
            "[41]\tvalidation_0-auc:0.95424\tvalidation_1-auc:0.82861\n",
            "[42]\tvalidation_0-auc:0.95447\tvalidation_1-auc:0.82866\n",
            "[43]\tvalidation_0-auc:0.95463\tvalidation_1-auc:0.82874\n",
            "[44]\tvalidation_0-auc:0.95501\tvalidation_1-auc:0.82860\n",
            "[45]\tvalidation_0-auc:0.95531\tvalidation_1-auc:0.82890\n",
            "[46]\tvalidation_0-auc:0.95554\tvalidation_1-auc:0.82837\n",
            "[47]\tvalidation_0-auc:0.95566\tvalidation_1-auc:0.82846\n",
            "[48]\tvalidation_0-auc:0.95595\tvalidation_1-auc:0.82805\n",
            "[49]\tvalidation_0-auc:0.95623\tvalidation_1-auc:0.82794\n",
            "[50]\tvalidation_0-auc:0.95653\tvalidation_1-auc:0.82720\n",
            "[51]\tvalidation_0-auc:0.95683\tvalidation_1-auc:0.82721\n",
            "[52]\tvalidation_0-auc:0.95733\tvalidation_1-auc:0.82700\n",
            "[53]\tvalidation_0-auc:0.95744\tvalidation_1-auc:0.82667\n",
            "[54]\tvalidation_0-auc:0.95750\tvalidation_1-auc:0.82658\n",
            "[55]\tvalidation_0-auc:0.95768\tvalidation_1-auc:0.82642\n",
            "[56]\tvalidation_0-auc:0.95779\tvalidation_1-auc:0.82650\n",
            "[57]\tvalidation_0-auc:0.95784\tvalidation_1-auc:0.82644\n",
            "[58]\tvalidation_0-auc:0.95822\tvalidation_1-auc:0.82624\n",
            "[59]\tvalidation_0-auc:0.95827\tvalidation_1-auc:0.82568\n",
            "[60]\tvalidation_0-auc:0.95834\tvalidation_1-auc:0.82534\n",
            "[61]\tvalidation_0-auc:0.95843\tvalidation_1-auc:0.82504\n",
            "[62]\tvalidation_0-auc:0.95856\tvalidation_1-auc:0.82453\n",
            "[63]\tvalidation_0-auc:0.95924\tvalidation_1-auc:0.82432\n",
            "[64]\tvalidation_0-auc:0.95931\tvalidation_1-auc:0.82439\n",
            "[65]\tvalidation_0-auc:0.95963\tvalidation_1-auc:0.82423\n",
            " 10%|█         | 5/50 [22:19<3:38:07, 290.82s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82345\tvalidation_1-auc:0.80036\n",
            "[1]\tvalidation_0-auc:0.81778\tvalidation_1-auc:0.79232\n",
            "[2]\tvalidation_0-auc:0.83110\tvalidation_1-auc:0.80149\n",
            "[3]\tvalidation_0-auc:0.83544\tvalidation_1-auc:0.80808\n",
            "[4]\tvalidation_0-auc:0.83937\tvalidation_1-auc:0.81194\n",
            "[5]\tvalidation_0-auc:0.84283\tvalidation_1-auc:0.81352\n",
            "[6]\tvalidation_0-auc:0.84437\tvalidation_1-auc:0.81390\n",
            "[7]\tvalidation_0-auc:0.84560\tvalidation_1-auc:0.81582\n",
            "[8]\tvalidation_0-auc:0.84664\tvalidation_1-auc:0.81727\n",
            "[9]\tvalidation_0-auc:0.84896\tvalidation_1-auc:0.82106\n",
            "[10]\tvalidation_0-auc:0.85152\tvalidation_1-auc:0.82267\n",
            "[11]\tvalidation_0-auc:0.85449\tvalidation_1-auc:0.82413\n",
            "[12]\tvalidation_0-auc:0.85560\tvalidation_1-auc:0.82394\n",
            "[13]\tvalidation_0-auc:0.85644\tvalidation_1-auc:0.82416\n",
            "[14]\tvalidation_0-auc:0.85700\tvalidation_1-auc:0.82536\n",
            "[15]\tvalidation_0-auc:0.85880\tvalidation_1-auc:0.82704\n",
            "[16]\tvalidation_0-auc:0.86078\tvalidation_1-auc:0.82743\n",
            "[17]\tvalidation_0-auc:0.86100\tvalidation_1-auc:0.82591\n",
            "[18]\tvalidation_0-auc:0.86215\tvalidation_1-auc:0.82675\n",
            "[19]\tvalidation_0-auc:0.86396\tvalidation_1-auc:0.82763\n",
            "[20]\tvalidation_0-auc:0.86584\tvalidation_1-auc:0.82916\n",
            "[21]\tvalidation_0-auc:0.86547\tvalidation_1-auc:0.82774\n",
            "[22]\tvalidation_0-auc:0.86756\tvalidation_1-auc:0.82838\n",
            "[23]\tvalidation_0-auc:0.86905\tvalidation_1-auc:0.82891\n",
            "[24]\tvalidation_0-auc:0.87015\tvalidation_1-auc:0.82946\n",
            "[25]\tvalidation_0-auc:0.87149\tvalidation_1-auc:0.83075\n",
            "[26]\tvalidation_0-auc:0.87307\tvalidation_1-auc:0.83064\n",
            "[27]\tvalidation_0-auc:0.87372\tvalidation_1-auc:0.83064\n",
            "[28]\tvalidation_0-auc:0.87438\tvalidation_1-auc:0.83067\n",
            "[29]\tvalidation_0-auc:0.87518\tvalidation_1-auc:0.83113\n",
            "[30]\tvalidation_0-auc:0.87561\tvalidation_1-auc:0.83097\n",
            "[31]\tvalidation_0-auc:0.87671\tvalidation_1-auc:0.83115\n",
            "[32]\tvalidation_0-auc:0.87791\tvalidation_1-auc:0.83149\n",
            "[33]\tvalidation_0-auc:0.87874\tvalidation_1-auc:0.83202\n",
            "[34]\tvalidation_0-auc:0.87919\tvalidation_1-auc:0.83198\n",
            "[35]\tvalidation_0-auc:0.88051\tvalidation_1-auc:0.83218\n",
            "[36]\tvalidation_0-auc:0.88089\tvalidation_1-auc:0.83229\n",
            "[37]\tvalidation_0-auc:0.88165\tvalidation_1-auc:0.83218\n",
            "[38]\tvalidation_0-auc:0.88247\tvalidation_1-auc:0.83258\n",
            "[39]\tvalidation_0-auc:0.88338\tvalidation_1-auc:0.83237\n",
            "[40]\tvalidation_0-auc:0.88453\tvalidation_1-auc:0.83326\n",
            "[41]\tvalidation_0-auc:0.88570\tvalidation_1-auc:0.83382\n",
            "[42]\tvalidation_0-auc:0.88581\tvalidation_1-auc:0.83373\n",
            "[43]\tvalidation_0-auc:0.88674\tvalidation_1-auc:0.83382\n",
            "[44]\tvalidation_0-auc:0.88762\tvalidation_1-auc:0.83413\n",
            "[45]\tvalidation_0-auc:0.88823\tvalidation_1-auc:0.83407\n",
            "[46]\tvalidation_0-auc:0.88906\tvalidation_1-auc:0.83404\n",
            "[47]\tvalidation_0-auc:0.88981\tvalidation_1-auc:0.83429\n",
            "[48]\tvalidation_0-auc:0.89028\tvalidation_1-auc:0.83415\n",
            "[49]\tvalidation_0-auc:0.89095\tvalidation_1-auc:0.83439\n",
            "[50]\tvalidation_0-auc:0.89163\tvalidation_1-auc:0.83457\n",
            "[51]\tvalidation_0-auc:0.89222\tvalidation_1-auc:0.83410\n",
            "[52]\tvalidation_0-auc:0.89258\tvalidation_1-auc:0.83430\n",
            "[53]\tvalidation_0-auc:0.89320\tvalidation_1-auc:0.83429\n",
            "[54]\tvalidation_0-auc:0.89354\tvalidation_1-auc:0.83449\n",
            "[55]\tvalidation_0-auc:0.89401\tvalidation_1-auc:0.83434\n",
            "[56]\tvalidation_0-auc:0.89443\tvalidation_1-auc:0.83397\n",
            "[57]\tvalidation_0-auc:0.89492\tvalidation_1-auc:0.83430\n",
            "[58]\tvalidation_0-auc:0.89538\tvalidation_1-auc:0.83414\n",
            "[59]\tvalidation_0-auc:0.89560\tvalidation_1-auc:0.83396\n",
            "[60]\tvalidation_0-auc:0.89565\tvalidation_1-auc:0.83388\n",
            "[61]\tvalidation_0-auc:0.89581\tvalidation_1-auc:0.83381\n",
            "[62]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.83387\n",
            "[63]\tvalidation_0-auc:0.89662\tvalidation_1-auc:0.83378\n",
            "[64]\tvalidation_0-auc:0.89694\tvalidation_1-auc:0.83359\n",
            "[65]\tvalidation_0-auc:0.89748\tvalidation_1-auc:0.83357\n",
            "[66]\tvalidation_0-auc:0.89814\tvalidation_1-auc:0.83405\n",
            "[67]\tvalidation_0-auc:0.89856\tvalidation_1-auc:0.83388\n",
            "[68]\tvalidation_0-auc:0.89903\tvalidation_1-auc:0.83369\n",
            "[69]\tvalidation_0-auc:0.89918\tvalidation_1-auc:0.83359\n",
            "[70]\tvalidation_0-auc:0.89950\tvalidation_1-auc:0.83333\n",
            "[71]\tvalidation_0-auc:0.89958\tvalidation_1-auc:0.83336\n",
            "[72]\tvalidation_0-auc:0.89966\tvalidation_1-auc:0.83332\n",
            "[73]\tvalidation_0-auc:0.90035\tvalidation_1-auc:0.83303\n",
            "[74]\tvalidation_0-auc:0.90061\tvalidation_1-auc:0.83293\n",
            "[75]\tvalidation_0-auc:0.90111\tvalidation_1-auc:0.83292\n",
            "[76]\tvalidation_0-auc:0.90139\tvalidation_1-auc:0.83285\n",
            "[77]\tvalidation_0-auc:0.90158\tvalidation_1-auc:0.83296\n",
            "[78]\tvalidation_0-auc:0.90185\tvalidation_1-auc:0.83289\n",
            "[79]\tvalidation_0-auc:0.90194\tvalidation_1-auc:0.83268\n",
            " 10%|█         | 5/50 [23:34<3:38:07, 290.82s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.81667\tvalidation_1-auc:0.80288\n",
            "[1]\tvalidation_0-auc:0.81099\tvalidation_1-auc:0.79332\n",
            "[2]\tvalidation_0-auc:0.82507\tvalidation_1-auc:0.80799\n",
            "[3]\tvalidation_0-auc:0.83712\tvalidation_1-auc:0.81801\n",
            "[4]\tvalidation_0-auc:0.84209\tvalidation_1-auc:0.82228\n",
            "[5]\tvalidation_0-auc:0.84651\tvalidation_1-auc:0.82610\n",
            "[6]\tvalidation_0-auc:0.84772\tvalidation_1-auc:0.82694\n",
            "[7]\tvalidation_0-auc:0.85001\tvalidation_1-auc:0.82743\n",
            "[8]\tvalidation_0-auc:0.85195\tvalidation_1-auc:0.82885\n",
            "[9]\tvalidation_0-auc:0.85622\tvalidation_1-auc:0.82918\n",
            "[10]\tvalidation_0-auc:0.85766\tvalidation_1-auc:0.82952\n",
            "[11]\tvalidation_0-auc:0.86056\tvalidation_1-auc:0.82932\n",
            "[12]\tvalidation_0-auc:0.86140\tvalidation_1-auc:0.83056\n",
            "[13]\tvalidation_0-auc:0.86256\tvalidation_1-auc:0.83038\n",
            "[14]\tvalidation_0-auc:0.86309\tvalidation_1-auc:0.82968\n",
            "[15]\tvalidation_0-auc:0.86365\tvalidation_1-auc:0.82996\n",
            "[16]\tvalidation_0-auc:0.86438\tvalidation_1-auc:0.83060\n",
            "[17]\tvalidation_0-auc:0.86519\tvalidation_1-auc:0.82948\n",
            "[18]\tvalidation_0-auc:0.86651\tvalidation_1-auc:0.83008\n",
            "[19]\tvalidation_0-auc:0.86838\tvalidation_1-auc:0.83159\n",
            "[20]\tvalidation_0-auc:0.86956\tvalidation_1-auc:0.83237\n",
            "[21]\tvalidation_0-auc:0.86914\tvalidation_1-auc:0.83043\n",
            "[22]\tvalidation_0-auc:0.87090\tvalidation_1-auc:0.83132\n",
            "[23]\tvalidation_0-auc:0.87221\tvalidation_1-auc:0.83226\n",
            "[24]\tvalidation_0-auc:0.87309\tvalidation_1-auc:0.83188\n",
            "[25]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83182\n",
            "[26]\tvalidation_0-auc:0.87503\tvalidation_1-auc:0.83210\n",
            "[27]\tvalidation_0-auc:0.87577\tvalidation_1-auc:0.83139\n",
            "[28]\tvalidation_0-auc:0.87633\tvalidation_1-auc:0.83180\n",
            "[29]\tvalidation_0-auc:0.87707\tvalidation_1-auc:0.83172\n",
            "[30]\tvalidation_0-auc:0.87771\tvalidation_1-auc:0.83305\n",
            "[31]\tvalidation_0-auc:0.87886\tvalidation_1-auc:0.83370\n",
            "[32]\tvalidation_0-auc:0.87971\tvalidation_1-auc:0.83327\n",
            "[33]\tvalidation_0-auc:0.88046\tvalidation_1-auc:0.83408\n",
            "[34]\tvalidation_0-auc:0.88099\tvalidation_1-auc:0.83362\n",
            "[35]\tvalidation_0-auc:0.88198\tvalidation_1-auc:0.83387\n",
            "[36]\tvalidation_0-auc:0.88289\tvalidation_1-auc:0.83413\n",
            "[37]\tvalidation_0-auc:0.88360\tvalidation_1-auc:0.83412\n",
            "[38]\tvalidation_0-auc:0.88428\tvalidation_1-auc:0.83412\n",
            "[39]\tvalidation_0-auc:0.88500\tvalidation_1-auc:0.83396\n",
            "[40]\tvalidation_0-auc:0.88614\tvalidation_1-auc:0.83503\n",
            "[41]\tvalidation_0-auc:0.88705\tvalidation_1-auc:0.83554\n",
            "[42]\tvalidation_0-auc:0.88757\tvalidation_1-auc:0.83594\n",
            "[43]\tvalidation_0-auc:0.88869\tvalidation_1-auc:0.83641\n",
            "[44]\tvalidation_0-auc:0.88946\tvalidation_1-auc:0.83663\n",
            "[45]\tvalidation_0-auc:0.89028\tvalidation_1-auc:0.83663\n",
            "[46]\tvalidation_0-auc:0.89076\tvalidation_1-auc:0.83635\n",
            "[47]\tvalidation_0-auc:0.89178\tvalidation_1-auc:0.83630\n",
            "[48]\tvalidation_0-auc:0.89243\tvalidation_1-auc:0.83617\n",
            "[49]\tvalidation_0-auc:0.89274\tvalidation_1-auc:0.83644\n",
            "[50]\tvalidation_0-auc:0.89344\tvalidation_1-auc:0.83660\n",
            "[51]\tvalidation_0-auc:0.89402\tvalidation_1-auc:0.83672\n",
            "[52]\tvalidation_0-auc:0.89447\tvalidation_1-auc:0.83655\n",
            "[53]\tvalidation_0-auc:0.89502\tvalidation_1-auc:0.83689\n",
            "[54]\tvalidation_0-auc:0.89524\tvalidation_1-auc:0.83713\n",
            "[55]\tvalidation_0-auc:0.89558\tvalidation_1-auc:0.83736\n",
            "[56]\tvalidation_0-auc:0.89643\tvalidation_1-auc:0.83737\n",
            "[57]\tvalidation_0-auc:0.89697\tvalidation_1-auc:0.83714\n",
            "[58]\tvalidation_0-auc:0.89741\tvalidation_1-auc:0.83700\n",
            "[59]\tvalidation_0-auc:0.89765\tvalidation_1-auc:0.83709\n",
            "[60]\tvalidation_0-auc:0.89791\tvalidation_1-auc:0.83715\n",
            "[61]\tvalidation_0-auc:0.89805\tvalidation_1-auc:0.83716\n",
            "[62]\tvalidation_0-auc:0.89837\tvalidation_1-auc:0.83719\n",
            "[63]\tvalidation_0-auc:0.89910\tvalidation_1-auc:0.83693\n",
            "[64]\tvalidation_0-auc:0.89941\tvalidation_1-auc:0.83700\n",
            "[65]\tvalidation_0-auc:0.90005\tvalidation_1-auc:0.83679\n",
            "[66]\tvalidation_0-auc:0.90029\tvalidation_1-auc:0.83647\n",
            "[67]\tvalidation_0-auc:0.90068\tvalidation_1-auc:0.83642\n",
            "[68]\tvalidation_0-auc:0.90103\tvalidation_1-auc:0.83622\n",
            "[69]\tvalidation_0-auc:0.90119\tvalidation_1-auc:0.83632\n",
            "[70]\tvalidation_0-auc:0.90142\tvalidation_1-auc:0.83639\n",
            "[71]\tvalidation_0-auc:0.90160\tvalidation_1-auc:0.83646\n",
            "[72]\tvalidation_0-auc:0.90174\tvalidation_1-auc:0.83654\n",
            "[73]\tvalidation_0-auc:0.90232\tvalidation_1-auc:0.83674\n",
            "[74]\tvalidation_0-auc:0.90241\tvalidation_1-auc:0.83683\n",
            "[75]\tvalidation_0-auc:0.90304\tvalidation_1-auc:0.83696\n",
            "[76]\tvalidation_0-auc:0.90357\tvalidation_1-auc:0.83691\n",
            "[77]\tvalidation_0-auc:0.90371\tvalidation_1-auc:0.83685\n",
            "[78]\tvalidation_0-auc:0.90384\tvalidation_1-auc:0.83685\n",
            "[79]\tvalidation_0-auc:0.90417\tvalidation_1-auc:0.83681\n",
            "[80]\tvalidation_0-auc:0.90448\tvalidation_1-auc:0.83670\n",
            "[81]\tvalidation_0-auc:0.90465\tvalidation_1-auc:0.83678\n",
            "[82]\tvalidation_0-auc:0.90481\tvalidation_1-auc:0.83678\n",
            "[83]\tvalidation_0-auc:0.90521\tvalidation_1-auc:0.83703\n",
            "[84]\tvalidation_0-auc:0.90542\tvalidation_1-auc:0.83708\n",
            "[85]\tvalidation_0-auc:0.90589\tvalidation_1-auc:0.83718\n",
            " 10%|█         | 5/50 [24:29<3:38:07, 290.82s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82827\tvalidation_1-auc:0.80952\n",
            "[1]\tvalidation_0-auc:0.82705\tvalidation_1-auc:0.80755\n",
            "[2]\tvalidation_0-auc:0.83888\tvalidation_1-auc:0.81859\n",
            "[3]\tvalidation_0-auc:0.84175\tvalidation_1-auc:0.82134\n",
            "[4]\tvalidation_0-auc:0.84312\tvalidation_1-auc:0.82235\n",
            "[5]\tvalidation_0-auc:0.84581\tvalidation_1-auc:0.82313\n",
            "[6]\tvalidation_0-auc:0.84786\tvalidation_1-auc:0.82412\n",
            "[7]\tvalidation_0-auc:0.84995\tvalidation_1-auc:0.82431\n",
            "[8]\tvalidation_0-auc:0.85377\tvalidation_1-auc:0.82717\n",
            "[9]\tvalidation_0-auc:0.85591\tvalidation_1-auc:0.82657\n",
            "[10]\tvalidation_0-auc:0.85807\tvalidation_1-auc:0.82707\n",
            "[11]\tvalidation_0-auc:0.85961\tvalidation_1-auc:0.82732\n",
            "[12]\tvalidation_0-auc:0.86053\tvalidation_1-auc:0.82742\n",
            "[13]\tvalidation_0-auc:0.86181\tvalidation_1-auc:0.82783\n",
            "[14]\tvalidation_0-auc:0.86339\tvalidation_1-auc:0.82960\n",
            "[15]\tvalidation_0-auc:0.86495\tvalidation_1-auc:0.82805\n",
            "[16]\tvalidation_0-auc:0.86579\tvalidation_1-auc:0.82876\n",
            "[17]\tvalidation_0-auc:0.86693\tvalidation_1-auc:0.82885\n",
            "[18]\tvalidation_0-auc:0.86809\tvalidation_1-auc:0.82912\n",
            "[19]\tvalidation_0-auc:0.86898\tvalidation_1-auc:0.82960\n",
            "[20]\tvalidation_0-auc:0.87090\tvalidation_1-auc:0.83126\n",
            "[21]\tvalidation_0-auc:0.87147\tvalidation_1-auc:0.83015\n",
            "[22]\tvalidation_0-auc:0.87225\tvalidation_1-auc:0.83061\n",
            "[23]\tvalidation_0-auc:0.87337\tvalidation_1-auc:0.83150\n",
            "[24]\tvalidation_0-auc:0.87418\tvalidation_1-auc:0.83200\n",
            "[25]\tvalidation_0-auc:0.87516\tvalidation_1-auc:0.83228\n",
            "[26]\tvalidation_0-auc:0.87588\tvalidation_1-auc:0.83266\n",
            "[27]\tvalidation_0-auc:0.87703\tvalidation_1-auc:0.83248\n",
            "[28]\tvalidation_0-auc:0.87810\tvalidation_1-auc:0.83264\n",
            "[29]\tvalidation_0-auc:0.87913\tvalidation_1-auc:0.83306\n",
            "[30]\tvalidation_0-auc:0.88034\tvalidation_1-auc:0.83394\n",
            "[31]\tvalidation_0-auc:0.88141\tvalidation_1-auc:0.83409\n",
            "[32]\tvalidation_0-auc:0.88175\tvalidation_1-auc:0.83335\n",
            "[33]\tvalidation_0-auc:0.88239\tvalidation_1-auc:0.83394\n",
            "[34]\tvalidation_0-auc:0.88316\tvalidation_1-auc:0.83414\n",
            "[35]\tvalidation_0-auc:0.88402\tvalidation_1-auc:0.83473\n",
            "[36]\tvalidation_0-auc:0.88479\tvalidation_1-auc:0.83487\n",
            "[37]\tvalidation_0-auc:0.88583\tvalidation_1-auc:0.83480\n",
            "[38]\tvalidation_0-auc:0.88632\tvalidation_1-auc:0.83457\n",
            "[39]\tvalidation_0-auc:0.88733\tvalidation_1-auc:0.83437\n",
            "[40]\tvalidation_0-auc:0.88850\tvalidation_1-auc:0.83523\n",
            "[41]\tvalidation_0-auc:0.88986\tvalidation_1-auc:0.83552\n",
            "[42]\tvalidation_0-auc:0.89032\tvalidation_1-auc:0.83650\n",
            "[43]\tvalidation_0-auc:0.89077\tvalidation_1-auc:0.83629\n",
            "[44]\tvalidation_0-auc:0.89116\tvalidation_1-auc:0.83652\n",
            "[45]\tvalidation_0-auc:0.89161\tvalidation_1-auc:0.83666\n",
            "[46]\tvalidation_0-auc:0.89226\tvalidation_1-auc:0.83618\n",
            "[47]\tvalidation_0-auc:0.89278\tvalidation_1-auc:0.83618\n",
            "[48]\tvalidation_0-auc:0.89327\tvalidation_1-auc:0.83591\n",
            "[49]\tvalidation_0-auc:0.89401\tvalidation_1-auc:0.83602\n",
            "[50]\tvalidation_0-auc:0.89445\tvalidation_1-auc:0.83573\n",
            "[51]\tvalidation_0-auc:0.89492\tvalidation_1-auc:0.83571\n",
            "[52]\tvalidation_0-auc:0.89543\tvalidation_1-auc:0.83573\n",
            "[53]\tvalidation_0-auc:0.89588\tvalidation_1-auc:0.83587\n",
            "[54]\tvalidation_0-auc:0.89622\tvalidation_1-auc:0.83590\n",
            "[55]\tvalidation_0-auc:0.89661\tvalidation_1-auc:0.83602\n",
            "[56]\tvalidation_0-auc:0.89740\tvalidation_1-auc:0.83587\n",
            "[57]\tvalidation_0-auc:0.89769\tvalidation_1-auc:0.83578\n",
            "[58]\tvalidation_0-auc:0.89813\tvalidation_1-auc:0.83605\n",
            "[59]\tvalidation_0-auc:0.89848\tvalidation_1-auc:0.83618\n",
            "[60]\tvalidation_0-auc:0.89859\tvalidation_1-auc:0.83620\n",
            "[61]\tvalidation_0-auc:0.89897\tvalidation_1-auc:0.83595\n",
            "[62]\tvalidation_0-auc:0.89933\tvalidation_1-auc:0.83602\n",
            "[63]\tvalidation_0-auc:0.89970\tvalidation_1-auc:0.83607\n",
            "[64]\tvalidation_0-auc:0.89990\tvalidation_1-auc:0.83583\n",
            "[65]\tvalidation_0-auc:0.90025\tvalidation_1-auc:0.83606\n",
            "[66]\tvalidation_0-auc:0.90081\tvalidation_1-auc:0.83595\n",
            "[67]\tvalidation_0-auc:0.90115\tvalidation_1-auc:0.83607\n",
            "[68]\tvalidation_0-auc:0.90156\tvalidation_1-auc:0.83619\n",
            "[69]\tvalidation_0-auc:0.90188\tvalidation_1-auc:0.83639\n",
            "[70]\tvalidation_0-auc:0.90217\tvalidation_1-auc:0.83625\n",
            "[71]\tvalidation_0-auc:0.90243\tvalidation_1-auc:0.83664\n",
            "[72]\tvalidation_0-auc:0.90260\tvalidation_1-auc:0.83653\n",
            "[73]\tvalidation_0-auc:0.90323\tvalidation_1-auc:0.83643\n",
            "[74]\tvalidation_0-auc:0.90355\tvalidation_1-auc:0.83627\n",
            " 12%|█▏        | 6/50 [25:16<3:04:54, 252.15s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82364\tvalidation_1-auc:0.80032\n",
            "[1]\tvalidation_0-auc:0.81888\tvalidation_1-auc:0.79226\n",
            "[2]\tvalidation_0-auc:0.83198\tvalidation_1-auc:0.80265\n",
            "[3]\tvalidation_0-auc:0.83619\tvalidation_1-auc:0.80855\n",
            "[4]\tvalidation_0-auc:0.84222\tvalidation_1-auc:0.81275\n",
            "[5]\tvalidation_0-auc:0.84363\tvalidation_1-auc:0.81137\n",
            "[6]\tvalidation_0-auc:0.84715\tvalidation_1-auc:0.81405\n",
            "[7]\tvalidation_0-auc:0.84876\tvalidation_1-auc:0.81496\n",
            "[8]\tvalidation_0-auc:0.85004\tvalidation_1-auc:0.81698\n",
            "[9]\tvalidation_0-auc:0.85253\tvalidation_1-auc:0.81816\n",
            "[10]\tvalidation_0-auc:0.85171\tvalidation_1-auc:0.81619\n",
            "[11]\tvalidation_0-auc:0.85652\tvalidation_1-auc:0.81993\n",
            "[12]\tvalidation_0-auc:0.85893\tvalidation_1-auc:0.82175\n",
            "[13]\tvalidation_0-auc:0.86161\tvalidation_1-auc:0.82367\n",
            "[14]\tvalidation_0-auc:0.86270\tvalidation_1-auc:0.82489\n",
            "[15]\tvalidation_0-auc:0.86243\tvalidation_1-auc:0.82306\n",
            "[16]\tvalidation_0-auc:0.86234\tvalidation_1-auc:0.82164\n",
            "[17]\tvalidation_0-auc:0.86218\tvalidation_1-auc:0.82195\n",
            "[18]\tvalidation_0-auc:0.86459\tvalidation_1-auc:0.82436\n",
            "[19]\tvalidation_0-auc:0.86682\tvalidation_1-auc:0.82609\n",
            "[20]\tvalidation_0-auc:0.86986\tvalidation_1-auc:0.82976\n",
            "[21]\tvalidation_0-auc:0.86995\tvalidation_1-auc:0.82735\n",
            "[22]\tvalidation_0-auc:0.87253\tvalidation_1-auc:0.82912\n",
            "[23]\tvalidation_0-auc:0.87471\tvalidation_1-auc:0.83047\n",
            "[24]\tvalidation_0-auc:0.87682\tvalidation_1-auc:0.83197\n",
            "[25]\tvalidation_0-auc:0.87888\tvalidation_1-auc:0.83258\n",
            "[26]\tvalidation_0-auc:0.88100\tvalidation_1-auc:0.83279\n",
            "[27]\tvalidation_0-auc:0.88241\tvalidation_1-auc:0.83142\n",
            "[28]\tvalidation_0-auc:0.88323\tvalidation_1-auc:0.83042\n",
            "[29]\tvalidation_0-auc:0.88429\tvalidation_1-auc:0.83138\n",
            "[30]\tvalidation_0-auc:0.88543\tvalidation_1-auc:0.83237\n",
            "[31]\tvalidation_0-auc:0.88672\tvalidation_1-auc:0.83304\n",
            "[32]\tvalidation_0-auc:0.88821\tvalidation_1-auc:0.83331\n",
            "[33]\tvalidation_0-auc:0.88887\tvalidation_1-auc:0.83288\n",
            "[34]\tvalidation_0-auc:0.89023\tvalidation_1-auc:0.83212\n",
            "[35]\tvalidation_0-auc:0.89058\tvalidation_1-auc:0.83171\n",
            "[36]\tvalidation_0-auc:0.89130\tvalidation_1-auc:0.83254\n",
            "[37]\tvalidation_0-auc:0.89168\tvalidation_1-auc:0.83203\n",
            "[38]\tvalidation_0-auc:0.89246\tvalidation_1-auc:0.83174\n",
            "[39]\tvalidation_0-auc:0.89298\tvalidation_1-auc:0.83108\n",
            "[40]\tvalidation_0-auc:0.89425\tvalidation_1-auc:0.83187\n",
            "[41]\tvalidation_0-auc:0.89502\tvalidation_1-auc:0.83227\n",
            "[42]\tvalidation_0-auc:0.89561\tvalidation_1-auc:0.83224\n",
            "[43]\tvalidation_0-auc:0.89667\tvalidation_1-auc:0.83269\n",
            "[44]\tvalidation_0-auc:0.89710\tvalidation_1-auc:0.83297\n",
            "[45]\tvalidation_0-auc:0.89784\tvalidation_1-auc:0.83335\n",
            "[46]\tvalidation_0-auc:0.89830\tvalidation_1-auc:0.83342\n",
            "[47]\tvalidation_0-auc:0.89876\tvalidation_1-auc:0.83325\n",
            "[48]\tvalidation_0-auc:0.89910\tvalidation_1-auc:0.83308\n",
            "[49]\tvalidation_0-auc:0.89940\tvalidation_1-auc:0.83277\n",
            "[50]\tvalidation_0-auc:0.89969\tvalidation_1-auc:0.83258\n",
            "[51]\tvalidation_0-auc:0.90034\tvalidation_1-auc:0.83257\n",
            "[52]\tvalidation_0-auc:0.90067\tvalidation_1-auc:0.83272\n",
            "[53]\tvalidation_0-auc:0.90102\tvalidation_1-auc:0.83303\n",
            "[54]\tvalidation_0-auc:0.90119\tvalidation_1-auc:0.83318\n",
            "[55]\tvalidation_0-auc:0.90137\tvalidation_1-auc:0.83296\n",
            "[56]\tvalidation_0-auc:0.90179\tvalidation_1-auc:0.83275\n",
            "[57]\tvalidation_0-auc:0.90201\tvalidation_1-auc:0.83262\n",
            "[58]\tvalidation_0-auc:0.90229\tvalidation_1-auc:0.83287\n",
            "[59]\tvalidation_0-auc:0.90238\tvalidation_1-auc:0.83291\n",
            "[60]\tvalidation_0-auc:0.90273\tvalidation_1-auc:0.83267\n",
            "[61]\tvalidation_0-auc:0.90280\tvalidation_1-auc:0.83261\n",
            "[62]\tvalidation_0-auc:0.90310\tvalidation_1-auc:0.83233\n",
            "[63]\tvalidation_0-auc:0.90366\tvalidation_1-auc:0.83228\n",
            "[64]\tvalidation_0-auc:0.90374\tvalidation_1-auc:0.83208\n",
            "[65]\tvalidation_0-auc:0.90413\tvalidation_1-auc:0.83187\n",
            "[66]\tvalidation_0-auc:0.90430\tvalidation_1-auc:0.83201\n",
            "[67]\tvalidation_0-auc:0.90532\tvalidation_1-auc:0.83195\n",
            "[68]\tvalidation_0-auc:0.90545\tvalidation_1-auc:0.83189\n",
            "[69]\tvalidation_0-auc:0.90551\tvalidation_1-auc:0.83196\n",
            "[70]\tvalidation_0-auc:0.90623\tvalidation_1-auc:0.83210\n",
            "[71]\tvalidation_0-auc:0.90638\tvalidation_1-auc:0.83236\n",
            "[72]\tvalidation_0-auc:0.90651\tvalidation_1-auc:0.83201\n",
            "[73]\tvalidation_0-auc:0.90660\tvalidation_1-auc:0.83195\n",
            "[74]\tvalidation_0-auc:0.90687\tvalidation_1-auc:0.83179\n",
            "[75]\tvalidation_0-auc:0.90773\tvalidation_1-auc:0.83198\n",
            " 12%|█▏        | 6/50 [26:03<3:04:54, 252.15s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.81608\tvalidation_1-auc:0.80402\n",
            "[1]\tvalidation_0-auc:0.81585\tvalidation_1-auc:0.79593\n",
            "[2]\tvalidation_0-auc:0.83396\tvalidation_1-auc:0.81568\n",
            "[3]\tvalidation_0-auc:0.84334\tvalidation_1-auc:0.82185\n",
            "[4]\tvalidation_0-auc:0.84644\tvalidation_1-auc:0.82261\n",
            "[5]\tvalidation_0-auc:0.84952\tvalidation_1-auc:0.82057\n",
            "[6]\tvalidation_0-auc:0.85162\tvalidation_1-auc:0.82414\n",
            "[7]\tvalidation_0-auc:0.85410\tvalidation_1-auc:0.82747\n",
            "[8]\tvalidation_0-auc:0.85696\tvalidation_1-auc:0.82934\n",
            "[9]\tvalidation_0-auc:0.85687\tvalidation_1-auc:0.82709\n",
            "[10]\tvalidation_0-auc:0.85676\tvalidation_1-auc:0.82342\n",
            "[11]\tvalidation_0-auc:0.86044\tvalidation_1-auc:0.82476\n",
            "[12]\tvalidation_0-auc:0.86206\tvalidation_1-auc:0.82619\n",
            "[13]\tvalidation_0-auc:0.86465\tvalidation_1-auc:0.82735\n",
            "[14]\tvalidation_0-auc:0.86576\tvalidation_1-auc:0.82749\n",
            "[15]\tvalidation_0-auc:0.86643\tvalidation_1-auc:0.82617\n",
            "[16]\tvalidation_0-auc:0.86625\tvalidation_1-auc:0.82494\n",
            "[17]\tvalidation_0-auc:0.86668\tvalidation_1-auc:0.82430\n",
            "[18]\tvalidation_0-auc:0.86882\tvalidation_1-auc:0.82696\n",
            "[19]\tvalidation_0-auc:0.87127\tvalidation_1-auc:0.82905\n",
            "[20]\tvalidation_0-auc:0.87369\tvalidation_1-auc:0.83057\n",
            "[21]\tvalidation_0-auc:0.87359\tvalidation_1-auc:0.82885\n",
            "[22]\tvalidation_0-auc:0.87530\tvalidation_1-auc:0.82999\n",
            "[23]\tvalidation_0-auc:0.87756\tvalidation_1-auc:0.83076\n",
            "[24]\tvalidation_0-auc:0.87961\tvalidation_1-auc:0.83073\n",
            "[25]\tvalidation_0-auc:0.88136\tvalidation_1-auc:0.83177\n",
            "[26]\tvalidation_0-auc:0.88309\tvalidation_1-auc:0.83199\n",
            "[27]\tvalidation_0-auc:0.88365\tvalidation_1-auc:0.83080\n",
            "[28]\tvalidation_0-auc:0.88432\tvalidation_1-auc:0.83015\n",
            "[29]\tvalidation_0-auc:0.88618\tvalidation_1-auc:0.83077\n",
            "[30]\tvalidation_0-auc:0.88721\tvalidation_1-auc:0.83211\n",
            "[31]\tvalidation_0-auc:0.88825\tvalidation_1-auc:0.83227\n",
            "[32]\tvalidation_0-auc:0.88950\tvalidation_1-auc:0.83168\n",
            "[33]\tvalidation_0-auc:0.89030\tvalidation_1-auc:0.83291\n",
            "[34]\tvalidation_0-auc:0.89095\tvalidation_1-auc:0.83258\n",
            "[35]\tvalidation_0-auc:0.89136\tvalidation_1-auc:0.83210\n",
            "[36]\tvalidation_0-auc:0.89271\tvalidation_1-auc:0.83258\n",
            "[37]\tvalidation_0-auc:0.89303\tvalidation_1-auc:0.83250\n",
            "[38]\tvalidation_0-auc:0.89355\tvalidation_1-auc:0.83209\n",
            "[39]\tvalidation_0-auc:0.89424\tvalidation_1-auc:0.83197\n",
            "[40]\tvalidation_0-auc:0.89548\tvalidation_1-auc:0.83319\n",
            "[41]\tvalidation_0-auc:0.89640\tvalidation_1-auc:0.83321\n",
            "[42]\tvalidation_0-auc:0.89710\tvalidation_1-auc:0.83371\n",
            "[43]\tvalidation_0-auc:0.89766\tvalidation_1-auc:0.83419\n",
            "[44]\tvalidation_0-auc:0.89817\tvalidation_1-auc:0.83477\n",
            "[45]\tvalidation_0-auc:0.89873\tvalidation_1-auc:0.83524\n",
            "[46]\tvalidation_0-auc:0.89966\tvalidation_1-auc:0.83481\n",
            "[47]\tvalidation_0-auc:0.90016\tvalidation_1-auc:0.83489\n",
            "[48]\tvalidation_0-auc:0.90058\tvalidation_1-auc:0.83518\n",
            "[49]\tvalidation_0-auc:0.90101\tvalidation_1-auc:0.83502\n",
            "[50]\tvalidation_0-auc:0.90127\tvalidation_1-auc:0.83509\n",
            "[51]\tvalidation_0-auc:0.90169\tvalidation_1-auc:0.83496\n",
            "[52]\tvalidation_0-auc:0.90185\tvalidation_1-auc:0.83515\n",
            "[53]\tvalidation_0-auc:0.90293\tvalidation_1-auc:0.83539\n",
            "[54]\tvalidation_0-auc:0.90310\tvalidation_1-auc:0.83558\n",
            "[55]\tvalidation_0-auc:0.90338\tvalidation_1-auc:0.83557\n",
            "[56]\tvalidation_0-auc:0.90417\tvalidation_1-auc:0.83574\n",
            "[57]\tvalidation_0-auc:0.90432\tvalidation_1-auc:0.83569\n",
            "[58]\tvalidation_0-auc:0.90518\tvalidation_1-auc:0.83612\n",
            "[59]\tvalidation_0-auc:0.90546\tvalidation_1-auc:0.83609\n",
            "[60]\tvalidation_0-auc:0.90578\tvalidation_1-auc:0.83587\n",
            "[61]\tvalidation_0-auc:0.90592\tvalidation_1-auc:0.83596\n",
            "[62]\tvalidation_0-auc:0.90689\tvalidation_1-auc:0.83663\n",
            "[63]\tvalidation_0-auc:0.90727\tvalidation_1-auc:0.83642\n",
            "[64]\tvalidation_0-auc:0.90753\tvalidation_1-auc:0.83623\n",
            "[65]\tvalidation_0-auc:0.90810\tvalidation_1-auc:0.83603\n",
            "[66]\tvalidation_0-auc:0.90903\tvalidation_1-auc:0.83635\n",
            "[67]\tvalidation_0-auc:0.90946\tvalidation_1-auc:0.83615\n",
            "[68]\tvalidation_0-auc:0.90997\tvalidation_1-auc:0.83609\n",
            "[69]\tvalidation_0-auc:0.91021\tvalidation_1-auc:0.83616\n",
            "[70]\tvalidation_0-auc:0.91034\tvalidation_1-auc:0.83595\n",
            "[71]\tvalidation_0-auc:0.91063\tvalidation_1-auc:0.83602\n",
            "[72]\tvalidation_0-auc:0.91068\tvalidation_1-auc:0.83598\n",
            "[73]\tvalidation_0-auc:0.91127\tvalidation_1-auc:0.83597\n",
            "[74]\tvalidation_0-auc:0.91145\tvalidation_1-auc:0.83599\n",
            "[75]\tvalidation_0-auc:0.91186\tvalidation_1-auc:0.83577\n",
            "[76]\tvalidation_0-auc:0.91203\tvalidation_1-auc:0.83599\n",
            "[77]\tvalidation_0-auc:0.91213\tvalidation_1-auc:0.83583\n",
            "[78]\tvalidation_0-auc:0.91221\tvalidation_1-auc:0.83583\n",
            "[79]\tvalidation_0-auc:0.91286\tvalidation_1-auc:0.83572\n",
            "[80]\tvalidation_0-auc:0.91297\tvalidation_1-auc:0.83576\n",
            "[81]\tvalidation_0-auc:0.91307\tvalidation_1-auc:0.83584\n",
            "[82]\tvalidation_0-auc:0.91350\tvalidation_1-auc:0.83583\n",
            "[83]\tvalidation_0-auc:0.91366\tvalidation_1-auc:0.83575\n",
            "[84]\tvalidation_0-auc:0.91436\tvalidation_1-auc:0.83570\n",
            "[85]\tvalidation_0-auc:0.91481\tvalidation_1-auc:0.83593\n",
            "[86]\tvalidation_0-auc:0.91491\tvalidation_1-auc:0.83599\n",
            "[87]\tvalidation_0-auc:0.91500\tvalidation_1-auc:0.83589\n",
            "[88]\tvalidation_0-auc:0.91513\tvalidation_1-auc:0.83581\n",
            "[89]\tvalidation_0-auc:0.91525\tvalidation_1-auc:0.83562\n",
            "[90]\tvalidation_0-auc:0.91535\tvalidation_1-auc:0.83564\n",
            "[91]\tvalidation_0-auc:0.91598\tvalidation_1-auc:0.83577\n",
            " 12%|█▏        | 6/50 [26:59<3:04:54, 252.15s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82769\tvalidation_1-auc:0.80883\n",
            "[1]\tvalidation_0-auc:0.82441\tvalidation_1-auc:0.80623\n",
            "[2]\tvalidation_0-auc:0.83826\tvalidation_1-auc:0.81762\n",
            "[3]\tvalidation_0-auc:0.84575\tvalidation_1-auc:0.82041\n",
            "[4]\tvalidation_0-auc:0.84692\tvalidation_1-auc:0.82035\n",
            "[5]\tvalidation_0-auc:0.84841\tvalidation_1-auc:0.81896\n",
            "[6]\tvalidation_0-auc:0.85165\tvalidation_1-auc:0.82204\n",
            "[7]\tvalidation_0-auc:0.85452\tvalidation_1-auc:0.82432\n",
            "[8]\tvalidation_0-auc:0.85812\tvalidation_1-auc:0.82704\n",
            "[9]\tvalidation_0-auc:0.85882\tvalidation_1-auc:0.82601\n",
            "[10]\tvalidation_0-auc:0.85810\tvalidation_1-auc:0.82482\n",
            "[11]\tvalidation_0-auc:0.86096\tvalidation_1-auc:0.82631\n",
            "[12]\tvalidation_0-auc:0.86387\tvalidation_1-auc:0.82689\n",
            "[13]\tvalidation_0-auc:0.86544\tvalidation_1-auc:0.82741\n",
            "[14]\tvalidation_0-auc:0.86716\tvalidation_1-auc:0.82757\n",
            "[15]\tvalidation_0-auc:0.86874\tvalidation_1-auc:0.82642\n",
            "[16]\tvalidation_0-auc:0.86847\tvalidation_1-auc:0.82506\n",
            "[17]\tvalidation_0-auc:0.86933\tvalidation_1-auc:0.82409\n",
            "[18]\tvalidation_0-auc:0.87081\tvalidation_1-auc:0.82523\n",
            "[19]\tvalidation_0-auc:0.87289\tvalidation_1-auc:0.82652\n",
            "[20]\tvalidation_0-auc:0.87617\tvalidation_1-auc:0.82843\n",
            "[21]\tvalidation_0-auc:0.87604\tvalidation_1-auc:0.82733\n",
            "[22]\tvalidation_0-auc:0.87744\tvalidation_1-auc:0.82915\n",
            "[23]\tvalidation_0-auc:0.87896\tvalidation_1-auc:0.83017\n",
            "[24]\tvalidation_0-auc:0.88112\tvalidation_1-auc:0.83120\n",
            "[25]\tvalidation_0-auc:0.88286\tvalidation_1-auc:0.83302\n",
            "[26]\tvalidation_0-auc:0.88495\tvalidation_1-auc:0.83304\n",
            "[27]\tvalidation_0-auc:0.88630\tvalidation_1-auc:0.83247\n",
            "[28]\tvalidation_0-auc:0.88669\tvalidation_1-auc:0.83105\n",
            "[29]\tvalidation_0-auc:0.88786\tvalidation_1-auc:0.83228\n",
            "[30]\tvalidation_0-auc:0.88883\tvalidation_1-auc:0.83250\n",
            "[31]\tvalidation_0-auc:0.88999\tvalidation_1-auc:0.83300\n",
            "[32]\tvalidation_0-auc:0.89052\tvalidation_1-auc:0.83239\n",
            "[33]\tvalidation_0-auc:0.89151\tvalidation_1-auc:0.83345\n",
            "[34]\tvalidation_0-auc:0.89273\tvalidation_1-auc:0.83261\n",
            "[35]\tvalidation_0-auc:0.89357\tvalidation_1-auc:0.83146\n",
            "[36]\tvalidation_0-auc:0.89425\tvalidation_1-auc:0.83240\n",
            "[37]\tvalidation_0-auc:0.89485\tvalidation_1-auc:0.83185\n",
            "[38]\tvalidation_0-auc:0.89590\tvalidation_1-auc:0.83191\n",
            "[39]\tvalidation_0-auc:0.89637\tvalidation_1-auc:0.83181\n",
            "[40]\tvalidation_0-auc:0.89743\tvalidation_1-auc:0.83252\n",
            "[41]\tvalidation_0-auc:0.89847\tvalidation_1-auc:0.83319\n",
            "[42]\tvalidation_0-auc:0.89899\tvalidation_1-auc:0.83359\n",
            "[43]\tvalidation_0-auc:0.89984\tvalidation_1-auc:0.83391\n",
            "[44]\tvalidation_0-auc:0.90063\tvalidation_1-auc:0.83392\n",
            "[45]\tvalidation_0-auc:0.90088\tvalidation_1-auc:0.83416\n",
            "[46]\tvalidation_0-auc:0.90138\tvalidation_1-auc:0.83370\n",
            "[47]\tvalidation_0-auc:0.90159\tvalidation_1-auc:0.83448\n",
            "[48]\tvalidation_0-auc:0.90206\tvalidation_1-auc:0.83492\n",
            "[49]\tvalidation_0-auc:0.90259\tvalidation_1-auc:0.83520\n",
            "[50]\tvalidation_0-auc:0.90293\tvalidation_1-auc:0.83520\n",
            "[51]\tvalidation_0-auc:0.90344\tvalidation_1-auc:0.83543\n",
            "[52]\tvalidation_0-auc:0.90373\tvalidation_1-auc:0.83553\n",
            "[53]\tvalidation_0-auc:0.90395\tvalidation_1-auc:0.83562\n",
            "[54]\tvalidation_0-auc:0.90409\tvalidation_1-auc:0.83572\n",
            "[55]\tvalidation_0-auc:0.90456\tvalidation_1-auc:0.83601\n",
            "[56]\tvalidation_0-auc:0.90519\tvalidation_1-auc:0.83611\n",
            "[57]\tvalidation_0-auc:0.90538\tvalidation_1-auc:0.83598\n",
            "[58]\tvalidation_0-auc:0.90581\tvalidation_1-auc:0.83616\n",
            "[59]\tvalidation_0-auc:0.90603\tvalidation_1-auc:0.83636\n",
            "[60]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.83613\n",
            "[61]\tvalidation_0-auc:0.90659\tvalidation_1-auc:0.83605\n",
            "[62]\tvalidation_0-auc:0.90690\tvalidation_1-auc:0.83616\n",
            "[63]\tvalidation_0-auc:0.90791\tvalidation_1-auc:0.83591\n",
            "[64]\tvalidation_0-auc:0.90806\tvalidation_1-auc:0.83591\n",
            "[65]\tvalidation_0-auc:0.90904\tvalidation_1-auc:0.83607\n",
            "[66]\tvalidation_0-auc:0.90947\tvalidation_1-auc:0.83584\n",
            "[67]\tvalidation_0-auc:0.90972\tvalidation_1-auc:0.83618\n",
            "[68]\tvalidation_0-auc:0.91028\tvalidation_1-auc:0.83627\n",
            "[69]\tvalidation_0-auc:0.91038\tvalidation_1-auc:0.83642\n",
            "[70]\tvalidation_0-auc:0.91070\tvalidation_1-auc:0.83627\n",
            "[71]\tvalidation_0-auc:0.91111\tvalidation_1-auc:0.83639\n",
            "[72]\tvalidation_0-auc:0.91136\tvalidation_1-auc:0.83632\n",
            "[73]\tvalidation_0-auc:0.91161\tvalidation_1-auc:0.83640\n",
            "[74]\tvalidation_0-auc:0.91199\tvalidation_1-auc:0.83635\n",
            "[75]\tvalidation_0-auc:0.91211\tvalidation_1-auc:0.83638\n",
            "[76]\tvalidation_0-auc:0.91231\tvalidation_1-auc:0.83635\n",
            "[77]\tvalidation_0-auc:0.91298\tvalidation_1-auc:0.83622\n",
            "[78]\tvalidation_0-auc:0.91313\tvalidation_1-auc:0.83614\n",
            "[79]\tvalidation_0-auc:0.91364\tvalidation_1-auc:0.83610\n",
            "[80]\tvalidation_0-auc:0.91382\tvalidation_1-auc:0.83577\n",
            "[81]\tvalidation_0-auc:0.91398\tvalidation_1-auc:0.83596\n",
            "[82]\tvalidation_0-auc:0.91445\tvalidation_1-auc:0.83590\n",
            "[83]\tvalidation_0-auc:0.91484\tvalidation_1-auc:0.83595\n",
            "[84]\tvalidation_0-auc:0.91497\tvalidation_1-auc:0.83568\n",
            "[85]\tvalidation_0-auc:0.91509\tvalidation_1-auc:0.83559\n",
            "[86]\tvalidation_0-auc:0.91555\tvalidation_1-auc:0.83556\n",
            "[87]\tvalidation_0-auc:0.91577\tvalidation_1-auc:0.83548\n",
            "[88]\tvalidation_0-auc:0.91592\tvalidation_1-auc:0.83542\n",
            "[89]\tvalidation_0-auc:0.91624\tvalidation_1-auc:0.83560\n",
            "[90]\tvalidation_0-auc:0.91649\tvalidation_1-auc:0.83537\n",
            "[91]\tvalidation_0-auc:0.91659\tvalidation_1-auc:0.83535\n",
            "[92]\tvalidation_0-auc:0.91667\tvalidation_1-auc:0.83529\n",
            "[93]\tvalidation_0-auc:0.91675\tvalidation_1-auc:0.83513\n",
            "[94]\tvalidation_0-auc:0.91694\tvalidation_1-auc:0.83509\n",
            "[95]\tvalidation_0-auc:0.91702\tvalidation_1-auc:0.83506\n",
            "[96]\tvalidation_0-auc:0.91735\tvalidation_1-auc:0.83490\n",
            "[97]\tvalidation_0-auc:0.91767\tvalidation_1-auc:0.83505\n",
            "[98]\tvalidation_0-auc:0.91787\tvalidation_1-auc:0.83495\n",
            " 14%|█▍        | 7/50 [28:00<2:39:56, 223.16s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83097\tvalidation_1-auc:0.79909\n",
            "[1]\tvalidation_0-auc:0.82711\tvalidation_1-auc:0.79094\n",
            "[2]\tvalidation_0-auc:0.84272\tvalidation_1-auc:0.80348\n",
            "[3]\tvalidation_0-auc:0.84655\tvalidation_1-auc:0.80796\n",
            "[4]\tvalidation_0-auc:0.84892\tvalidation_1-auc:0.81017\n",
            "[5]\tvalidation_0-auc:0.85238\tvalidation_1-auc:0.81149\n",
            "[6]\tvalidation_0-auc:0.85281\tvalidation_1-auc:0.81176\n",
            "[7]\tvalidation_0-auc:0.85702\tvalidation_1-auc:0.81488\n",
            "[8]\tvalidation_0-auc:0.85920\tvalidation_1-auc:0.81766\n",
            "[9]\tvalidation_0-auc:0.86255\tvalidation_1-auc:0.81668\n",
            "[10]\tvalidation_0-auc:0.86474\tvalidation_1-auc:0.81960\n",
            "[11]\tvalidation_0-auc:0.86610\tvalidation_1-auc:0.81962\n",
            "[12]\tvalidation_0-auc:0.86860\tvalidation_1-auc:0.82012\n",
            "[13]\tvalidation_0-auc:0.87080\tvalidation_1-auc:0.82104\n",
            "[14]\tvalidation_0-auc:0.87159\tvalidation_1-auc:0.82159\n",
            "[15]\tvalidation_0-auc:0.87376\tvalidation_1-auc:0.82178\n",
            "[16]\tvalidation_0-auc:0.87517\tvalidation_1-auc:0.82176\n",
            "[17]\tvalidation_0-auc:0.87838\tvalidation_1-auc:0.82333\n",
            "[18]\tvalidation_0-auc:0.88010\tvalidation_1-auc:0.82319\n",
            "[19]\tvalidation_0-auc:0.88163\tvalidation_1-auc:0.82272\n",
            "[20]\tvalidation_0-auc:0.88373\tvalidation_1-auc:0.82295\n",
            "[21]\tvalidation_0-auc:0.88793\tvalidation_1-auc:0.82357\n",
            "[22]\tvalidation_0-auc:0.88894\tvalidation_1-auc:0.82390\n",
            "[23]\tvalidation_0-auc:0.88993\tvalidation_1-auc:0.82413\n",
            "[24]\tvalidation_0-auc:0.89138\tvalidation_1-auc:0.82428\n",
            "[25]\tvalidation_0-auc:0.89267\tvalidation_1-auc:0.82443\n",
            "[26]\tvalidation_0-auc:0.89441\tvalidation_1-auc:0.82455\n",
            "[27]\tvalidation_0-auc:0.89665\tvalidation_1-auc:0.82432\n",
            "[28]\tvalidation_0-auc:0.89813\tvalidation_1-auc:0.82519\n",
            "[29]\tvalidation_0-auc:0.89902\tvalidation_1-auc:0.82579\n",
            "[30]\tvalidation_0-auc:0.90025\tvalidation_1-auc:0.82569\n",
            "[31]\tvalidation_0-auc:0.90125\tvalidation_1-auc:0.82604\n",
            "[32]\tvalidation_0-auc:0.90289\tvalidation_1-auc:0.82533\n",
            "[33]\tvalidation_0-auc:0.90355\tvalidation_1-auc:0.82555\n",
            "[34]\tvalidation_0-auc:0.90532\tvalidation_1-auc:0.82526\n",
            "[35]\tvalidation_0-auc:0.90694\tvalidation_1-auc:0.82548\n",
            "[36]\tvalidation_0-auc:0.90735\tvalidation_1-auc:0.82579\n",
            "[37]\tvalidation_0-auc:0.90830\tvalidation_1-auc:0.82596\n",
            "[38]\tvalidation_0-auc:0.90965\tvalidation_1-auc:0.82522\n",
            "[39]\tvalidation_0-auc:0.90988\tvalidation_1-auc:0.82569\n",
            "[40]\tvalidation_0-auc:0.91195\tvalidation_1-auc:0.82700\n",
            "[41]\tvalidation_0-auc:0.91335\tvalidation_1-auc:0.82731\n",
            "[42]\tvalidation_0-auc:0.91383\tvalidation_1-auc:0.82746\n",
            "[43]\tvalidation_0-auc:0.91540\tvalidation_1-auc:0.82796\n",
            "[44]\tvalidation_0-auc:0.91656\tvalidation_1-auc:0.82803\n",
            "[45]\tvalidation_0-auc:0.91769\tvalidation_1-auc:0.82862\n",
            "[46]\tvalidation_0-auc:0.91879\tvalidation_1-auc:0.82839\n",
            "[47]\tvalidation_0-auc:0.91985\tvalidation_1-auc:0.82801\n",
            "[48]\tvalidation_0-auc:0.92069\tvalidation_1-auc:0.82866\n",
            "[49]\tvalidation_0-auc:0.92158\tvalidation_1-auc:0.82928\n",
            "[50]\tvalidation_0-auc:0.92276\tvalidation_1-auc:0.82857\n",
            "[51]\tvalidation_0-auc:0.92373\tvalidation_1-auc:0.82846\n",
            "[52]\tvalidation_0-auc:0.92448\tvalidation_1-auc:0.82839\n",
            "[53]\tvalidation_0-auc:0.92507\tvalidation_1-auc:0.82827\n",
            "[54]\tvalidation_0-auc:0.92528\tvalidation_1-auc:0.82829\n",
            "[55]\tvalidation_0-auc:0.92588\tvalidation_1-auc:0.82823\n",
            "[56]\tvalidation_0-auc:0.92677\tvalidation_1-auc:0.82788\n",
            "[57]\tvalidation_0-auc:0.92715\tvalidation_1-auc:0.82785\n",
            "[58]\tvalidation_0-auc:0.92798\tvalidation_1-auc:0.82799\n",
            "[59]\tvalidation_0-auc:0.92848\tvalidation_1-auc:0.82832\n",
            "[60]\tvalidation_0-auc:0.92886\tvalidation_1-auc:0.82870\n",
            "[61]\tvalidation_0-auc:0.92928\tvalidation_1-auc:0.82871\n",
            "[62]\tvalidation_0-auc:0.93026\tvalidation_1-auc:0.82874\n",
            "[63]\tvalidation_0-auc:0.93091\tvalidation_1-auc:0.82907\n",
            "[64]\tvalidation_0-auc:0.93164\tvalidation_1-auc:0.82897\n",
            "[65]\tvalidation_0-auc:0.93224\tvalidation_1-auc:0.82896\n",
            "[66]\tvalidation_0-auc:0.93259\tvalidation_1-auc:0.82864\n",
            "[67]\tvalidation_0-auc:0.93318\tvalidation_1-auc:0.82834\n",
            "[68]\tvalidation_0-auc:0.93362\tvalidation_1-auc:0.82841\n",
            "[69]\tvalidation_0-auc:0.93408\tvalidation_1-auc:0.82822\n",
            "[70]\tvalidation_0-auc:0.93458\tvalidation_1-auc:0.82852\n",
            "[71]\tvalidation_0-auc:0.93490\tvalidation_1-auc:0.82858\n",
            "[72]\tvalidation_0-auc:0.93548\tvalidation_1-auc:0.82793\n",
            "[73]\tvalidation_0-auc:0.93610\tvalidation_1-auc:0.82801\n",
            "[74]\tvalidation_0-auc:0.93660\tvalidation_1-auc:0.82762\n",
            "[75]\tvalidation_0-auc:0.93710\tvalidation_1-auc:0.82751\n",
            "[76]\tvalidation_0-auc:0.93763\tvalidation_1-auc:0.82765\n",
            "[77]\tvalidation_0-auc:0.93798\tvalidation_1-auc:0.82753\n",
            "[78]\tvalidation_0-auc:0.93813\tvalidation_1-auc:0.82748\n",
            "[79]\tvalidation_0-auc:0.93841\tvalidation_1-auc:0.82734\n",
            " 14%|█▍        | 7/50 [29:41<2:39:56, 223.16s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82259\tvalidation_1-auc:0.80379\n",
            "[1]\tvalidation_0-auc:0.82744\tvalidation_1-auc:0.80103\n",
            "[2]\tvalidation_0-auc:0.83732\tvalidation_1-auc:0.80830\n",
            "[3]\tvalidation_0-auc:0.84562\tvalidation_1-auc:0.81737\n",
            "[4]\tvalidation_0-auc:0.85044\tvalidation_1-auc:0.82088\n",
            "[5]\tvalidation_0-auc:0.85335\tvalidation_1-auc:0.82356\n",
            "[6]\tvalidation_0-auc:0.85677\tvalidation_1-auc:0.82564\n",
            "[7]\tvalidation_0-auc:0.86036\tvalidation_1-auc:0.82703\n",
            "[8]\tvalidation_0-auc:0.86452\tvalidation_1-auc:0.82760\n",
            "[9]\tvalidation_0-auc:0.86698\tvalidation_1-auc:0.82794\n",
            "[10]\tvalidation_0-auc:0.86986\tvalidation_1-auc:0.82835\n",
            "[11]\tvalidation_0-auc:0.87160\tvalidation_1-auc:0.82891\n",
            "[12]\tvalidation_0-auc:0.87382\tvalidation_1-auc:0.82822\n",
            "[13]\tvalidation_0-auc:0.87477\tvalidation_1-auc:0.82789\n",
            "[14]\tvalidation_0-auc:0.87606\tvalidation_1-auc:0.82775\n",
            "[15]\tvalidation_0-auc:0.87656\tvalidation_1-auc:0.82816\n",
            "[16]\tvalidation_0-auc:0.87730\tvalidation_1-auc:0.82866\n",
            "[17]\tvalidation_0-auc:0.87944\tvalidation_1-auc:0.82824\n",
            "[18]\tvalidation_0-auc:0.88198\tvalidation_1-auc:0.82954\n",
            "[19]\tvalidation_0-auc:0.88334\tvalidation_1-auc:0.83019\n",
            "[20]\tvalidation_0-auc:0.88520\tvalidation_1-auc:0.83047\n",
            "[21]\tvalidation_0-auc:0.88779\tvalidation_1-auc:0.83007\n",
            "[22]\tvalidation_0-auc:0.89110\tvalidation_1-auc:0.83045\n",
            "[23]\tvalidation_0-auc:0.89241\tvalidation_1-auc:0.83043\n",
            "[24]\tvalidation_0-auc:0.89419\tvalidation_1-auc:0.83029\n",
            "[25]\tvalidation_0-auc:0.89564\tvalidation_1-auc:0.83011\n",
            "[26]\tvalidation_0-auc:0.89651\tvalidation_1-auc:0.83043\n",
            "[27]\tvalidation_0-auc:0.89732\tvalidation_1-auc:0.83122\n",
            "[28]\tvalidation_0-auc:0.90051\tvalidation_1-auc:0.83060\n",
            "[29]\tvalidation_0-auc:0.90154\tvalidation_1-auc:0.83064\n",
            "[30]\tvalidation_0-auc:0.90355\tvalidation_1-auc:0.83131\n",
            "[31]\tvalidation_0-auc:0.90432\tvalidation_1-auc:0.83140\n",
            "[32]\tvalidation_0-auc:0.90596\tvalidation_1-auc:0.83133\n",
            "[33]\tvalidation_0-auc:0.90649\tvalidation_1-auc:0.83165\n",
            "[34]\tvalidation_0-auc:0.90729\tvalidation_1-auc:0.83142\n",
            "[35]\tvalidation_0-auc:0.90901\tvalidation_1-auc:0.83178\n",
            "[36]\tvalidation_0-auc:0.91038\tvalidation_1-auc:0.83271\n",
            "[37]\tvalidation_0-auc:0.91105\tvalidation_1-auc:0.83319\n",
            "[38]\tvalidation_0-auc:0.91200\tvalidation_1-auc:0.83280\n",
            "[39]\tvalidation_0-auc:0.91234\tvalidation_1-auc:0.83378\n",
            "[40]\tvalidation_0-auc:0.91402\tvalidation_1-auc:0.83438\n",
            "[41]\tvalidation_0-auc:0.91524\tvalidation_1-auc:0.83440\n",
            "[42]\tvalidation_0-auc:0.91571\tvalidation_1-auc:0.83448\n",
            "[43]\tvalidation_0-auc:0.91707\tvalidation_1-auc:0.83495\n",
            "[44]\tvalidation_0-auc:0.91800\tvalidation_1-auc:0.83472\n",
            "[45]\tvalidation_0-auc:0.91932\tvalidation_1-auc:0.83482\n",
            "[46]\tvalidation_0-auc:0.92042\tvalidation_1-auc:0.83423\n",
            "[47]\tvalidation_0-auc:0.92150\tvalidation_1-auc:0.83417\n",
            "[48]\tvalidation_0-auc:0.92223\tvalidation_1-auc:0.83461\n",
            "[49]\tvalidation_0-auc:0.92295\tvalidation_1-auc:0.83467\n",
            "[50]\tvalidation_0-auc:0.92400\tvalidation_1-auc:0.83405\n",
            "[51]\tvalidation_0-auc:0.92541\tvalidation_1-auc:0.83434\n",
            "[52]\tvalidation_0-auc:0.92651\tvalidation_1-auc:0.83414\n",
            "[53]\tvalidation_0-auc:0.92752\tvalidation_1-auc:0.83413\n",
            "[54]\tvalidation_0-auc:0.92799\tvalidation_1-auc:0.83422\n",
            "[55]\tvalidation_0-auc:0.92873\tvalidation_1-auc:0.83401\n",
            "[56]\tvalidation_0-auc:0.92980\tvalidation_1-auc:0.83373\n",
            "[57]\tvalidation_0-auc:0.93015\tvalidation_1-auc:0.83352\n",
            "[58]\tvalidation_0-auc:0.93086\tvalidation_1-auc:0.83364\n",
            "[59]\tvalidation_0-auc:0.93123\tvalidation_1-auc:0.83362\n",
            "[60]\tvalidation_0-auc:0.93178\tvalidation_1-auc:0.83331\n",
            "[61]\tvalidation_0-auc:0.93247\tvalidation_1-auc:0.83334\n",
            "[62]\tvalidation_0-auc:0.93325\tvalidation_1-auc:0.83315\n",
            "[63]\tvalidation_0-auc:0.93390\tvalidation_1-auc:0.83331\n",
            "[64]\tvalidation_0-auc:0.93434\tvalidation_1-auc:0.83314\n",
            "[65]\tvalidation_0-auc:0.93475\tvalidation_1-auc:0.83325\n",
            "[66]\tvalidation_0-auc:0.93542\tvalidation_1-auc:0.83306\n",
            "[67]\tvalidation_0-auc:0.93612\tvalidation_1-auc:0.83343\n",
            "[68]\tvalidation_0-auc:0.93681\tvalidation_1-auc:0.83349\n",
            "[69]\tvalidation_0-auc:0.93724\tvalidation_1-auc:0.83360\n",
            "[70]\tvalidation_0-auc:0.93781\tvalidation_1-auc:0.83384\n",
            "[71]\tvalidation_0-auc:0.93818\tvalidation_1-auc:0.83388\n",
            "[72]\tvalidation_0-auc:0.93861\tvalidation_1-auc:0.83407\n",
            "[73]\tvalidation_0-auc:0.93895\tvalidation_1-auc:0.83402\n",
            " 14%|█▍        | 7/50 [31:15<2:39:56, 223.16s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83307\tvalidation_1-auc:0.80979\n",
            "[1]\tvalidation_0-auc:0.83451\tvalidation_1-auc:0.80736\n",
            "[2]\tvalidation_0-auc:0.84565\tvalidation_1-auc:0.81388\n",
            "[3]\tvalidation_0-auc:0.84975\tvalidation_1-auc:0.81860\n",
            "[4]\tvalidation_0-auc:0.85290\tvalidation_1-auc:0.81911\n",
            "[5]\tvalidation_0-auc:0.85551\tvalidation_1-auc:0.82052\n",
            "[6]\tvalidation_0-auc:0.85809\tvalidation_1-auc:0.82166\n",
            "[7]\tvalidation_0-auc:0.86095\tvalidation_1-auc:0.82143\n",
            "[8]\tvalidation_0-auc:0.86552\tvalidation_1-auc:0.82277\n",
            "[9]\tvalidation_0-auc:0.86763\tvalidation_1-auc:0.82303\n",
            "[10]\tvalidation_0-auc:0.86949\tvalidation_1-auc:0.82404\n",
            "[11]\tvalidation_0-auc:0.87175\tvalidation_1-auc:0.82508\n",
            "[12]\tvalidation_0-auc:0.87220\tvalidation_1-auc:0.82523\n",
            "[13]\tvalidation_0-auc:0.87372\tvalidation_1-auc:0.82537\n",
            "[14]\tvalidation_0-auc:0.87560\tvalidation_1-auc:0.82592\n",
            "[15]\tvalidation_0-auc:0.87730\tvalidation_1-auc:0.82687\n",
            "[16]\tvalidation_0-auc:0.87900\tvalidation_1-auc:0.82677\n",
            "[17]\tvalidation_0-auc:0.88106\tvalidation_1-auc:0.82701\n",
            "[18]\tvalidation_0-auc:0.88190\tvalidation_1-auc:0.82672\n",
            "[19]\tvalidation_0-auc:0.88308\tvalidation_1-auc:0.82636\n",
            "[20]\tvalidation_0-auc:0.88625\tvalidation_1-auc:0.82576\n",
            "[21]\tvalidation_0-auc:0.88912\tvalidation_1-auc:0.82593\n",
            "[22]\tvalidation_0-auc:0.89132\tvalidation_1-auc:0.82568\n",
            "[23]\tvalidation_0-auc:0.89281\tvalidation_1-auc:0.82607\n",
            "[24]\tvalidation_0-auc:0.89408\tvalidation_1-auc:0.82609\n",
            "[25]\tvalidation_0-auc:0.89595\tvalidation_1-auc:0.82639\n",
            "[26]\tvalidation_0-auc:0.89773\tvalidation_1-auc:0.82653\n",
            "[27]\tvalidation_0-auc:0.89968\tvalidation_1-auc:0.82625\n",
            "[28]\tvalidation_0-auc:0.90123\tvalidation_1-auc:0.82720\n",
            "[29]\tvalidation_0-auc:0.90269\tvalidation_1-auc:0.82734\n",
            "[30]\tvalidation_0-auc:0.90344\tvalidation_1-auc:0.82783\n",
            "[31]\tvalidation_0-auc:0.90406\tvalidation_1-auc:0.82779\n",
            "[32]\tvalidation_0-auc:0.90589\tvalidation_1-auc:0.82746\n",
            "[33]\tvalidation_0-auc:0.90645\tvalidation_1-auc:0.82754\n",
            "[34]\tvalidation_0-auc:0.90809\tvalidation_1-auc:0.82626\n",
            "[35]\tvalidation_0-auc:0.91058\tvalidation_1-auc:0.82632\n",
            "[36]\tvalidation_0-auc:0.91168\tvalidation_1-auc:0.82640\n",
            "[37]\tvalidation_0-auc:0.91264\tvalidation_1-auc:0.82683\n",
            "[38]\tvalidation_0-auc:0.91402\tvalidation_1-auc:0.82553\n",
            "[39]\tvalidation_0-auc:0.91484\tvalidation_1-auc:0.82565\n",
            "[40]\tvalidation_0-auc:0.91593\tvalidation_1-auc:0.82578\n",
            "[41]\tvalidation_0-auc:0.91724\tvalidation_1-auc:0.82530\n",
            "[42]\tvalidation_0-auc:0.91765\tvalidation_1-auc:0.82572\n",
            "[43]\tvalidation_0-auc:0.91863\tvalidation_1-auc:0.82548\n",
            "[44]\tvalidation_0-auc:0.91946\tvalidation_1-auc:0.82554\n",
            "[45]\tvalidation_0-auc:0.92026\tvalidation_1-auc:0.82545\n",
            "[46]\tvalidation_0-auc:0.92137\tvalidation_1-auc:0.82563\n",
            "[47]\tvalidation_0-auc:0.92213\tvalidation_1-auc:0.82548\n",
            "[48]\tvalidation_0-auc:0.92279\tvalidation_1-auc:0.82588\n",
            "[49]\tvalidation_0-auc:0.92326\tvalidation_1-auc:0.82590\n",
            "[50]\tvalidation_0-auc:0.92427\tvalidation_1-auc:0.82518\n",
            "[51]\tvalidation_0-auc:0.92516\tvalidation_1-auc:0.82528\n",
            "[52]\tvalidation_0-auc:0.92585\tvalidation_1-auc:0.82576\n",
            "[53]\tvalidation_0-auc:0.92677\tvalidation_1-auc:0.82591\n",
            "[54]\tvalidation_0-auc:0.92704\tvalidation_1-auc:0.82630\n",
            "[55]\tvalidation_0-auc:0.92762\tvalidation_1-auc:0.82645\n",
            "[56]\tvalidation_0-auc:0.92881\tvalidation_1-auc:0.82603\n",
            "[57]\tvalidation_0-auc:0.92935\tvalidation_1-auc:0.82563\n",
            "[58]\tvalidation_0-auc:0.93015\tvalidation_1-auc:0.82646\n",
            "[59]\tvalidation_0-auc:0.93050\tvalidation_1-auc:0.82707\n",
            " 16%|█▌        | 8/50 [32:34<2:47:40, 239.54s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82148\tvalidation_1-auc:0.79855\n",
            "[1]\tvalidation_0-auc:0.81700\tvalidation_1-auc:0.79029\n",
            "[2]\tvalidation_0-auc:0.83550\tvalidation_1-auc:0.80793\n",
            "[3]\tvalidation_0-auc:0.83972\tvalidation_1-auc:0.81275\n",
            "[4]\tvalidation_0-auc:0.84520\tvalidation_1-auc:0.81639\n",
            "[5]\tvalidation_0-auc:0.84497\tvalidation_1-auc:0.81702\n",
            "[6]\tvalidation_0-auc:0.84703\tvalidation_1-auc:0.81860\n",
            "[7]\tvalidation_0-auc:0.84903\tvalidation_1-auc:0.81869\n",
            "[8]\tvalidation_0-auc:0.85120\tvalidation_1-auc:0.82088\n",
            "[9]\tvalidation_0-auc:0.85201\tvalidation_1-auc:0.82148\n",
            "[10]\tvalidation_0-auc:0.85215\tvalidation_1-auc:0.82056\n",
            "[11]\tvalidation_0-auc:0.85458\tvalidation_1-auc:0.82178\n",
            "[12]\tvalidation_0-auc:0.85576\tvalidation_1-auc:0.82306\n",
            "[13]\tvalidation_0-auc:0.85687\tvalidation_1-auc:0.82264\n",
            "[14]\tvalidation_0-auc:0.85927\tvalidation_1-auc:0.82436\n",
            "[15]\tvalidation_0-auc:0.86143\tvalidation_1-auc:0.82519\n",
            "[16]\tvalidation_0-auc:0.86330\tvalidation_1-auc:0.82593\n",
            "[17]\tvalidation_0-auc:0.86465\tvalidation_1-auc:0.82670\n",
            "[18]\tvalidation_0-auc:0.86605\tvalidation_1-auc:0.82664\n",
            "[19]\tvalidation_0-auc:0.86720\tvalidation_1-auc:0.82689\n",
            "[20]\tvalidation_0-auc:0.86794\tvalidation_1-auc:0.82741\n",
            "[21]\tvalidation_0-auc:0.86916\tvalidation_1-auc:0.82784\n",
            "[22]\tvalidation_0-auc:0.87030\tvalidation_1-auc:0.82783\n",
            "[23]\tvalidation_0-auc:0.87141\tvalidation_1-auc:0.82757\n",
            "[24]\tvalidation_0-auc:0.87213\tvalidation_1-auc:0.82756\n",
            "[25]\tvalidation_0-auc:0.87312\tvalidation_1-auc:0.82854\n",
            "[26]\tvalidation_0-auc:0.87387\tvalidation_1-auc:0.82860\n",
            "[27]\tvalidation_0-auc:0.87499\tvalidation_1-auc:0.82861\n",
            "[28]\tvalidation_0-auc:0.87633\tvalidation_1-auc:0.82897\n",
            "[29]\tvalidation_0-auc:0.87779\tvalidation_1-auc:0.83024\n",
            "[30]\tvalidation_0-auc:0.87901\tvalidation_1-auc:0.83060\n",
            "[31]\tvalidation_0-auc:0.87997\tvalidation_1-auc:0.83040\n",
            "[32]\tvalidation_0-auc:0.88108\tvalidation_1-auc:0.83131\n",
            "[33]\tvalidation_0-auc:0.88246\tvalidation_1-auc:0.83260\n",
            "[34]\tvalidation_0-auc:0.88352\tvalidation_1-auc:0.83284\n",
            "[35]\tvalidation_0-auc:0.88415\tvalidation_1-auc:0.83277\n",
            "[36]\tvalidation_0-auc:0.88526\tvalidation_1-auc:0.83337\n",
            "[37]\tvalidation_0-auc:0.88564\tvalidation_1-auc:0.83346\n",
            "[38]\tvalidation_0-auc:0.88627\tvalidation_1-auc:0.83350\n",
            "[39]\tvalidation_0-auc:0.88680\tvalidation_1-auc:0.83326\n",
            "[40]\tvalidation_0-auc:0.88763\tvalidation_1-auc:0.83323\n",
            "[41]\tvalidation_0-auc:0.88786\tvalidation_1-auc:0.83352\n",
            "[42]\tvalidation_0-auc:0.88849\tvalidation_1-auc:0.83313\n",
            "[43]\tvalidation_0-auc:0.88894\tvalidation_1-auc:0.83307\n",
            "[44]\tvalidation_0-auc:0.88937\tvalidation_1-auc:0.83297\n",
            "[45]\tvalidation_0-auc:0.89025\tvalidation_1-auc:0.83276\n",
            "[46]\tvalidation_0-auc:0.89085\tvalidation_1-auc:0.83292\n",
            "[47]\tvalidation_0-auc:0.89111\tvalidation_1-auc:0.83299\n",
            "[48]\tvalidation_0-auc:0.89163\tvalidation_1-auc:0.83273\n",
            "[49]\tvalidation_0-auc:0.89183\tvalidation_1-auc:0.83280\n",
            "[50]\tvalidation_0-auc:0.89220\tvalidation_1-auc:0.83280\n",
            "[51]\tvalidation_0-auc:0.89232\tvalidation_1-auc:0.83285\n",
            "[52]\tvalidation_0-auc:0.89266\tvalidation_1-auc:0.83269\n",
            "[53]\tvalidation_0-auc:0.89294\tvalidation_1-auc:0.83255\n",
            "[54]\tvalidation_0-auc:0.89384\tvalidation_1-auc:0.83223\n",
            "[55]\tvalidation_0-auc:0.89454\tvalidation_1-auc:0.83215\n",
            "[56]\tvalidation_0-auc:0.89473\tvalidation_1-auc:0.83210\n",
            "[57]\tvalidation_0-auc:0.89508\tvalidation_1-auc:0.83181\n",
            "[58]\tvalidation_0-auc:0.89548\tvalidation_1-auc:0.83205\n",
            "[59]\tvalidation_0-auc:0.89563\tvalidation_1-auc:0.83193\n",
            "[60]\tvalidation_0-auc:0.89608\tvalidation_1-auc:0.83174\n",
            "[61]\tvalidation_0-auc:0.89623\tvalidation_1-auc:0.83176\n",
            "[62]\tvalidation_0-auc:0.89655\tvalidation_1-auc:0.83159\n",
            "[63]\tvalidation_0-auc:0.89674\tvalidation_1-auc:0.83144\n",
            "[64]\tvalidation_0-auc:0.89725\tvalidation_1-auc:0.83115\n",
            "[65]\tvalidation_0-auc:0.89800\tvalidation_1-auc:0.83115\n",
            "[66]\tvalidation_0-auc:0.89812\tvalidation_1-auc:0.83119\n",
            "[67]\tvalidation_0-auc:0.89828\tvalidation_1-auc:0.83119\n",
            "[68]\tvalidation_0-auc:0.89851\tvalidation_1-auc:0.83110\n",
            "[69]\tvalidation_0-auc:0.89887\tvalidation_1-auc:0.83092\n",
            "[70]\tvalidation_0-auc:0.89932\tvalidation_1-auc:0.83100\n",
            " 16%|█▌        | 8/50 [33:22<2:47:40, 239.54s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.81564\tvalidation_1-auc:0.80325\n",
            "[1]\tvalidation_0-auc:0.81516\tvalidation_1-auc:0.79369\n",
            "[2]\tvalidation_0-auc:0.83326\tvalidation_1-auc:0.81540\n",
            "[3]\tvalidation_0-auc:0.83860\tvalidation_1-auc:0.82152\n",
            "[4]\tvalidation_0-auc:0.84310\tvalidation_1-auc:0.82451\n",
            "[5]\tvalidation_0-auc:0.84457\tvalidation_1-auc:0.82640\n",
            "[6]\tvalidation_0-auc:0.84606\tvalidation_1-auc:0.82712\n",
            "[7]\tvalidation_0-auc:0.84729\tvalidation_1-auc:0.82732\n",
            "[8]\tvalidation_0-auc:0.85014\tvalidation_1-auc:0.82850\n",
            "[9]\tvalidation_0-auc:0.85215\tvalidation_1-auc:0.82910\n",
            "[10]\tvalidation_0-auc:0.85484\tvalidation_1-auc:0.82954\n",
            "[11]\tvalidation_0-auc:0.85645\tvalidation_1-auc:0.82970\n",
            "[12]\tvalidation_0-auc:0.85800\tvalidation_1-auc:0.83007\n",
            "[13]\tvalidation_0-auc:0.86039\tvalidation_1-auc:0.83175\n",
            "[14]\tvalidation_0-auc:0.86132\tvalidation_1-auc:0.83218\n",
            "[15]\tvalidation_0-auc:0.86240\tvalidation_1-auc:0.83226\n",
            "[16]\tvalidation_0-auc:0.86385\tvalidation_1-auc:0.83312\n",
            "[17]\tvalidation_0-auc:0.86504\tvalidation_1-auc:0.83299\n",
            "[18]\tvalidation_0-auc:0.86619\tvalidation_1-auc:0.83318\n",
            "[19]\tvalidation_0-auc:0.86736\tvalidation_1-auc:0.83465\n",
            "[20]\tvalidation_0-auc:0.86854\tvalidation_1-auc:0.83482\n",
            "[21]\tvalidation_0-auc:0.86979\tvalidation_1-auc:0.83411\n",
            "[22]\tvalidation_0-auc:0.87067\tvalidation_1-auc:0.83436\n",
            "[23]\tvalidation_0-auc:0.87181\tvalidation_1-auc:0.83473\n",
            "[24]\tvalidation_0-auc:0.87304\tvalidation_1-auc:0.83420\n",
            "[25]\tvalidation_0-auc:0.87384\tvalidation_1-auc:0.83414\n",
            "[26]\tvalidation_0-auc:0.87521\tvalidation_1-auc:0.83514\n",
            "[27]\tvalidation_0-auc:0.87605\tvalidation_1-auc:0.83516\n",
            "[28]\tvalidation_0-auc:0.87745\tvalidation_1-auc:0.83472\n",
            "[29]\tvalidation_0-auc:0.87839\tvalidation_1-auc:0.83486\n",
            "[30]\tvalidation_0-auc:0.87942\tvalidation_1-auc:0.83540\n",
            "[31]\tvalidation_0-auc:0.88025\tvalidation_1-auc:0.83579\n",
            "[32]\tvalidation_0-auc:0.88131\tvalidation_1-auc:0.83602\n",
            "[33]\tvalidation_0-auc:0.88234\tvalidation_1-auc:0.83605\n",
            "[34]\tvalidation_0-auc:0.88313\tvalidation_1-auc:0.83574\n",
            "[35]\tvalidation_0-auc:0.88385\tvalidation_1-auc:0.83657\n",
            "[36]\tvalidation_0-auc:0.88448\tvalidation_1-auc:0.83692\n",
            "[37]\tvalidation_0-auc:0.88495\tvalidation_1-auc:0.83734\n",
            "[38]\tvalidation_0-auc:0.88545\tvalidation_1-auc:0.83733\n",
            "[39]\tvalidation_0-auc:0.88634\tvalidation_1-auc:0.83711\n",
            "[40]\tvalidation_0-auc:0.88671\tvalidation_1-auc:0.83730\n",
            "[41]\tvalidation_0-auc:0.88734\tvalidation_1-auc:0.83740\n",
            "[42]\tvalidation_0-auc:0.88793\tvalidation_1-auc:0.83727\n",
            "[43]\tvalidation_0-auc:0.88854\tvalidation_1-auc:0.83754\n",
            "[44]\tvalidation_0-auc:0.88908\tvalidation_1-auc:0.83754\n",
            "[45]\tvalidation_0-auc:0.89020\tvalidation_1-auc:0.83704\n",
            "[46]\tvalidation_0-auc:0.89043\tvalidation_1-auc:0.83692\n",
            "[47]\tvalidation_0-auc:0.89140\tvalidation_1-auc:0.83681\n",
            "[48]\tvalidation_0-auc:0.89167\tvalidation_1-auc:0.83681\n",
            "[49]\tvalidation_0-auc:0.89275\tvalidation_1-auc:0.83662\n",
            "[50]\tvalidation_0-auc:0.89334\tvalidation_1-auc:0.83654\n",
            "[51]\tvalidation_0-auc:0.89375\tvalidation_1-auc:0.83656\n",
            "[52]\tvalidation_0-auc:0.89385\tvalidation_1-auc:0.83647\n",
            "[53]\tvalidation_0-auc:0.89408\tvalidation_1-auc:0.83651\n",
            "[54]\tvalidation_0-auc:0.89419\tvalidation_1-auc:0.83651\n",
            "[55]\tvalidation_0-auc:0.89449\tvalidation_1-auc:0.83651\n",
            "[56]\tvalidation_0-auc:0.89525\tvalidation_1-auc:0.83605\n",
            "[57]\tvalidation_0-auc:0.89559\tvalidation_1-auc:0.83595\n",
            "[58]\tvalidation_0-auc:0.89577\tvalidation_1-auc:0.83593\n",
            "[59]\tvalidation_0-auc:0.89592\tvalidation_1-auc:0.83593\n",
            "[60]\tvalidation_0-auc:0.89606\tvalidation_1-auc:0.83590\n",
            "[61]\tvalidation_0-auc:0.89616\tvalidation_1-auc:0.83584\n",
            "[62]\tvalidation_0-auc:0.89643\tvalidation_1-auc:0.83607\n",
            "[63]\tvalidation_0-auc:0.89661\tvalidation_1-auc:0.83589\n",
            "[64]\tvalidation_0-auc:0.89678\tvalidation_1-auc:0.83572\n",
            "[65]\tvalidation_0-auc:0.89707\tvalidation_1-auc:0.83572\n",
            "[66]\tvalidation_0-auc:0.89781\tvalidation_1-auc:0.83599\n",
            "[67]\tvalidation_0-auc:0.89792\tvalidation_1-auc:0.83607\n",
            "[68]\tvalidation_0-auc:0.89843\tvalidation_1-auc:0.83611\n",
            "[69]\tvalidation_0-auc:0.89858\tvalidation_1-auc:0.83601\n",
            "[70]\tvalidation_0-auc:0.89877\tvalidation_1-auc:0.83595\n",
            "[71]\tvalidation_0-auc:0.89886\tvalidation_1-auc:0.83587\n",
            "[72]\tvalidation_0-auc:0.89899\tvalidation_1-auc:0.83561\n",
            " 16%|█▌        | 8/50 [34:14<2:47:40, 239.54s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.82576\tvalidation_1-auc:0.81143\n",
            "[1]\tvalidation_0-auc:0.82718\tvalidation_1-auc:0.80755\n",
            "[2]\tvalidation_0-auc:0.83892\tvalidation_1-auc:0.81555\n",
            "[3]\tvalidation_0-auc:0.84486\tvalidation_1-auc:0.82072\n",
            "[4]\tvalidation_0-auc:0.84583\tvalidation_1-auc:0.82229\n",
            "[5]\tvalidation_0-auc:0.84697\tvalidation_1-auc:0.82283\n",
            "[6]\tvalidation_0-auc:0.84894\tvalidation_1-auc:0.82278\n",
            "[7]\tvalidation_0-auc:0.85100\tvalidation_1-auc:0.82316\n",
            "[8]\tvalidation_0-auc:0.85300\tvalidation_1-auc:0.82457\n",
            "[9]\tvalidation_0-auc:0.85424\tvalidation_1-auc:0.82617\n",
            "[10]\tvalidation_0-auc:0.85498\tvalidation_1-auc:0.82683\n",
            "[11]\tvalidation_0-auc:0.85619\tvalidation_1-auc:0.82812\n",
            "[12]\tvalidation_0-auc:0.85804\tvalidation_1-auc:0.82915\n",
            "[13]\tvalidation_0-auc:0.86060\tvalidation_1-auc:0.82985\n",
            "[14]\tvalidation_0-auc:0.86228\tvalidation_1-auc:0.82988\n",
            "[15]\tvalidation_0-auc:0.86275\tvalidation_1-auc:0.82993\n",
            "[16]\tvalidation_0-auc:0.86369\tvalidation_1-auc:0.82999\n",
            "[17]\tvalidation_0-auc:0.86457\tvalidation_1-auc:0.83064\n",
            "[18]\tvalidation_0-auc:0.86495\tvalidation_1-auc:0.83082\n",
            "[19]\tvalidation_0-auc:0.86724\tvalidation_1-auc:0.83226\n",
            "[20]\tvalidation_0-auc:0.86845\tvalidation_1-auc:0.83182\n",
            "[21]\tvalidation_0-auc:0.87003\tvalidation_1-auc:0.83185\n",
            "[22]\tvalidation_0-auc:0.87273\tvalidation_1-auc:0.83294\n",
            "[23]\tvalidation_0-auc:0.87388\tvalidation_1-auc:0.83261\n",
            "[24]\tvalidation_0-auc:0.87558\tvalidation_1-auc:0.83299\n",
            "[25]\tvalidation_0-auc:0.87684\tvalidation_1-auc:0.83363\n",
            "[26]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.83422\n",
            "[27]\tvalidation_0-auc:0.87956\tvalidation_1-auc:0.83484\n",
            "[28]\tvalidation_0-auc:0.88079\tvalidation_1-auc:0.83571\n",
            "[29]\tvalidation_0-auc:0.88202\tvalidation_1-auc:0.83517\n",
            "[30]\tvalidation_0-auc:0.88258\tvalidation_1-auc:0.83525\n",
            "[31]\tvalidation_0-auc:0.88385\tvalidation_1-auc:0.83534\n",
            "[32]\tvalidation_0-auc:0.88469\tvalidation_1-auc:0.83543\n",
            "[33]\tvalidation_0-auc:0.88540\tvalidation_1-auc:0.83549\n",
            "[34]\tvalidation_0-auc:0.88571\tvalidation_1-auc:0.83567\n",
            "[35]\tvalidation_0-auc:0.88617\tvalidation_1-auc:0.83558\n",
            "[36]\tvalidation_0-auc:0.88693\tvalidation_1-auc:0.83620\n",
            "[37]\tvalidation_0-auc:0.88742\tvalidation_1-auc:0.83647\n",
            "[38]\tvalidation_0-auc:0.88799\tvalidation_1-auc:0.83701\n",
            "[39]\tvalidation_0-auc:0.88844\tvalidation_1-auc:0.83753\n",
            "[40]\tvalidation_0-auc:0.88871\tvalidation_1-auc:0.83769\n",
            "[41]\tvalidation_0-auc:0.88938\tvalidation_1-auc:0.83747\n",
            "[42]\tvalidation_0-auc:0.88977\tvalidation_1-auc:0.83726\n",
            "[43]\tvalidation_0-auc:0.89002\tvalidation_1-auc:0.83721\n",
            "[44]\tvalidation_0-auc:0.89056\tvalidation_1-auc:0.83728\n",
            "[45]\tvalidation_0-auc:0.89185\tvalidation_1-auc:0.83722\n",
            "[46]\tvalidation_0-auc:0.89308\tvalidation_1-auc:0.83723\n",
            "[47]\tvalidation_0-auc:0.89329\tvalidation_1-auc:0.83745\n",
            "[48]\tvalidation_0-auc:0.89359\tvalidation_1-auc:0.83756\n",
            "[49]\tvalidation_0-auc:0.89478\tvalidation_1-auc:0.83782\n",
            "[50]\tvalidation_0-auc:0.89573\tvalidation_1-auc:0.83760\n",
            "[51]\tvalidation_0-auc:0.89605\tvalidation_1-auc:0.83761\n",
            "[52]\tvalidation_0-auc:0.89639\tvalidation_1-auc:0.83759\n",
            "[53]\tvalidation_0-auc:0.89659\tvalidation_1-auc:0.83767\n",
            "[54]\tvalidation_0-auc:0.89676\tvalidation_1-auc:0.83764\n",
            "[55]\tvalidation_0-auc:0.89741\tvalidation_1-auc:0.83735\n",
            "[56]\tvalidation_0-auc:0.89772\tvalidation_1-auc:0.83715\n",
            "[57]\tvalidation_0-auc:0.89805\tvalidation_1-auc:0.83720\n",
            "[58]\tvalidation_0-auc:0.89842\tvalidation_1-auc:0.83705\n",
            "[59]\tvalidation_0-auc:0.89876\tvalidation_1-auc:0.83730\n",
            "[60]\tvalidation_0-auc:0.89906\tvalidation_1-auc:0.83720\n",
            "[61]\tvalidation_0-auc:0.89946\tvalidation_1-auc:0.83733\n",
            "[62]\tvalidation_0-auc:0.89974\tvalidation_1-auc:0.83722\n",
            "[63]\tvalidation_0-auc:0.89995\tvalidation_1-auc:0.83721\n",
            "[64]\tvalidation_0-auc:0.90009\tvalidation_1-auc:0.83719\n",
            "[65]\tvalidation_0-auc:0.90043\tvalidation_1-auc:0.83712\n",
            "[66]\tvalidation_0-auc:0.90049\tvalidation_1-auc:0.83709\n",
            "[67]\tvalidation_0-auc:0.90118\tvalidation_1-auc:0.83701\n",
            "[68]\tvalidation_0-auc:0.90138\tvalidation_1-auc:0.83682\n",
            "[69]\tvalidation_0-auc:0.90191\tvalidation_1-auc:0.83660\n",
            "[70]\tvalidation_0-auc:0.90218\tvalidation_1-auc:0.83646\n",
            "[71]\tvalidation_0-auc:0.90258\tvalidation_1-auc:0.83661\n",
            "[72]\tvalidation_0-auc:0.90276\tvalidation_1-auc:0.83640\n",
            "[73]\tvalidation_0-auc:0.90304\tvalidation_1-auc:0.83625\n",
            "[74]\tvalidation_0-auc:0.90316\tvalidation_1-auc:0.83622\n",
            "[75]\tvalidation_0-auc:0.90333\tvalidation_1-auc:0.83628\n",
            "[76]\tvalidation_0-auc:0.90434\tvalidation_1-auc:0.83615\n",
            "[77]\tvalidation_0-auc:0.90466\tvalidation_1-auc:0.83631\n",
            "[78]\tvalidation_0-auc:0.90478\tvalidation_1-auc:0.83607\n",
            " 18%|█▊        | 9/50 [35:13<2:26:28, 214.36s/trial, best loss: -0.8364669798899221]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-auc:0.83118\tvalidation_1-auc:0.79893\n",
            "[1]\tvalidation_0-auc:0.83050\tvalidation_1-auc:0.79106\n",
            "[2]\tvalidation_0-auc:0.84450\tvalidation_1-auc:0.80439\n",
            "[3]\tvalidation_0-auc:0.85345\tvalidation_1-auc:0.80894\n",
            "[4]\tvalidation_0-auc:0.85794\tvalidation_1-auc:0.81180\n",
            " 18%|█▊        | 9/50 [35:23<2:41:13, 235.95s/trial, best loss: -0.8364669798899221]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-53642985bebc>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m best = fmin(fn = objective_func,\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_search_space\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-2f9d08f44704>\u001b[0m in \u001b[0;36mobjective_func\u001b[0;34m(xgb_search_space)\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m       xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n\u001b[0m\u001b[1;32m     23\u001b[0m                   eval_set=[(X_tr, y_tr), (X_val, y_val)])\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1488\u001b[0m             )\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             self._Booster = train(\n\u001b[0m\u001b[1;32m   1491\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1492\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                                                     dtrain.handle))\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "xgb_clf = XGBClassifier(n_estimators=100)\n",
        "\n",
        "params = {\n",
        "    'max_depth':[5,7],\n",
        "    'min_child_weight':[1,3],\n",
        "    'colsample_bytree':[0.5, 0.75]\n",
        "    }\n",
        "\n",
        "gridcv = GridSearchCV(xgb_clf, param_grid = params, cv=3)\n",
        "gridcv.fit(X_train, y_train, early_stopping_rounds=30,\n",
        "            eval_metric=\"auc\", eval_set=[(X_train, y_train), (X_test, y_test)], verbose=0)\n",
        "\n",
        "\n",
        "print('최적 파라미터:', gridcv.best_params_)\n",
        "\n",
        "xgb_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:1])\n",
        "print('ROC AUC:{0:.4f}'.format(xgb_roc_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lKdC6t9mo6OM",
        "outputId": "af90cb6f-94d2-476c-b4ed-93ab75d44807"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 파라미터: {'colsample_bytree': 0.5, 'max_depth': 5, 'min_child_weight': 3}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1ccf9a9447aa>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'최적 파라미터:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mxgb_roc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC AUC:{0:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_roc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         return _average_binary_score(\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    342\u001b[0m         )\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15204, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
        "plot_importance(xgb_clf, ax=ax, max_num_features=20, height=0.4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "OlDnl3AZpB52",
        "outputId": "3a4220be-83b0-4e8f-a8e9-c2da83835b51"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+cAAAK9CAYAAABGnB2ZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeXyMV///8dckIossslgSQjSxVSOC1lq7IKXWWouoUhRVtS+RWGovbrRurVIVpbeiLYpQW+21VClRSxr7TiRps87vD7/MtyOLaDHB+/l4zEPmXOc61+eaOYn5zDnXuQxGo9GIiIiIiIiIiFiMlaUDEBEREREREXneKTkXERERERERsTAl5yIiIiIiIiIWpuRcRERERERExMKUnIuIiIiIiIhYmJJzEREREREREQtTci4iIiIiIiJiYUrORURERERERCxMybmIiIiIiIiIhSk5FxEREcmBRYsWYTAYiI6OtnQoIiLyDFJyLiIiIplKT0YzewwbNuyxHHPXrl2EhYVx+/btx9L+8ywhIYGwsDC2bt1q6VBERCQTeSwdgIiIiORuY8eOpUSJEmZlL7300mM51q5duwgPDyckJIT8+fM/lmP8U507d6Z9+/bY2tpaOpR/JCEhgfDwcADq1Klj2WBERCQDJeciIiKSrSZNmlC5cmVLh/GvxMfHky9fvn/VhrW1NdbW1o8ooicnLS2NpKQkS4chIiIPoGntIiIi8q/88MMPvPrqq+TLlw8nJydee+01jh07ZlbnyJEjhISE8MILL2BnZ0fhwoV56623uHHjhqlOWFgYgwcPBqBEiRKmKfTR0dFER0djMBhYtGhRhuMbDAbCwsLM2jEYDPz222907NgRV1dXatasadq+ZMkSKlWqhL29PW5ubrRv355z58498Dwzu+bcx8eHpk2bsnXrVipXroy9vT3+/v6mqeMrV67E398fOzs7KlWqxKFDh8zaDAkJwdHRkTNnztCoUSPy5cuHl5cXY8eOxWg0mtWNj4/ngw8+wNvbG1tbW0qXLs20adMy1DMYDPTt25eIiAjKlSuHra0t8+bNo0CBAgCEh4ebXtv01y0n78/fX9tTp06ZZje4uLjQrVs3EhISMrxmS5Ys4ZVXXsHBwQFXV1dq1arFxo0bzerkpP+IiDwPNHIuIiIi2bpz5w7Xr183K/Pw8ADgyy+/pGvXrjRq1IjJkyeTkJDAJ598Qs2aNTl06BA+Pj4AREZGcubMGbp160bhwoU5duwY8+fP59ixY+zZsweDwUCrVq04efIkX331FTNmzDAdo0CBAly7du2h437jjTcoWbIkH374oSmBnTBhAqNHj6Zt27a8/fbbXLt2jdmzZ1OrVi0OHTr0j6bSnzp1io4dO/LOO+/w5ptvMm3aNJo1a8a8efMYMWIEffr0AWDixIm0bduWqKgorKz+b3wkNTWVxo0bU7VqVaZMmcL69esZM2YMKSkpjB07FgCj0cjrr7/Oli1b6N69OxUqVGDDhg0MHjyYCxcuMGPGDLOYfvzxR77++mv69u2Lh4cHAQEBfPLJJ/Tu3ZuWLVvSqlUrAMqXLw/k7P35u7Zt21KiRAkmTpzIwYMH+eyzzyhYsCCTJ0821QkPDycsLIzq1aszduxY8ubNy969e/nxxx8JCgoCct5/RESeC0YRERGRTCxcuNAIZPowGo3Gu3fvGvPnz2/s0aOH2X6XL182uri4mJUnJCRkaP+rr74yAsbt27ebyqZOnWoEjGfPnjWre/bsWSNgXLhwYYZ2AOOYMWNMz8eMGWMEjB06dDCrFx0dbbS2tjZOmDDBrPzXX3815smTJ0N5Vq/H32MrXry4ETDu2rXLVLZhwwYjYLS3tzf+8ccfpvL//ve/RsC4ZcsWU1nXrl2NgLFfv36msrS0NONrr71mzJs3r/HatWtGo9FoXL16tREwjh8/3iymNm3aGA0Gg/HUqVNmr4eVlZXx2LFjZnWvXbuW4bVKl9P3J/21feutt8zqtmzZ0uju7m56/vvvvxutrKyMLVu2NKampprVTUtLMxqND9d/RESeB5rWLiIiItmaO3cukZGRZg+4N9p6+/ZtOnTowPXr100Pa2trqlSpwpYtW0xt2Nvbm37+66+/uH79OlWrVgXg4MGDjyXuXr16mT1fuXIlaWlptG3b1izewoULU7JkSbN4H8aLL75ItWrVTM+rVKkCQL169ShWrFiG8jNnzmRoo2/fvqaf06elJyUlsWnTJgDWrVuHtbU1/fv3N9vvgw8+wGg08sMPP5iV165dmxdffDHH5/Cw78/9r+2rr77KjRs3iI2NBWD16tWkpaURGhpqNksg/fzg4fqPiMjzQNPaRUREJFuvvPJKpgvC/f7778C9JDQzzs7Opp9v3rxJeHg4y5Yt4+rVq2b17ty58wij/T/3rzD/+++/YzQaKVmyZKb1bWxs/tFx/p6AA7i4uADg7e2dafmtW7fMyq2srHjhhRfMykqVKgVgur79jz/+wMvLCycnJ7N6ZcuWNW3/u/vP/UEe9v25/5xdXV2Be+fm7OzM6dOnsbKyyvYLgofpPyIizwMl5yIiIvKPpKWlAfeuGy5cuHCG7Xny/N/HjLZt27Jr1y4GDx5MhQoVcHR0JC0tjcaNG5vayc791zynS01NzXKfv48Gp8drMBj44YcfMl113dHR8YFxZCarFdyzKjfet4Db43D/uT/Iw74/j+LcHqb/iIg8D/RXT0RERP4RX19fAAoWLEiDBg2yrHfr1i02b95MeHg4oaGhpvL0kdO/yyoJTx+ZvX37tln5/SPGD4rXaDRSokQJ08h0bpCWlsaZM2fMYjp58iSAaUG04sWLs2nTJu7evWs2en7ixAnT9gfJ6rV9mPcnp3x9fUlLS+O3336jQoUKWdaBB/cfEZHnha45FxERkX+kUaNGODs78+GHH5KcnJxhe/oK6+mjrPePqs6cOTPDPun3Ir8/CXd2dsbDw4Pt27eblX/88cc5jrdVq1ZYW1sTHh6eIRaj0ZjhtmFP0pw5c8ximTNnDjY2NtSvXx+A4OBgUlNTzeoBzJgxA4PBQJMmTR54DAcHByDja/sw709OtWjRAisrK8aOHZth5D39ODntPyIizwuNnIuIiMg/4uzszCeffELnzp2pWLEi7du3p0CBAsTExLB27Vpq1KjBnDlzcHZ2platWkyZMoXk5GSKFCnCxo0bOXv2bIY2K1WqBMDIkSNp3749NjY2NGvWjHz58vH2228zadIk3n77bSpXrsz27dtNI8w54evry/jx4xk+fDjR0dG0aNECJycnzp49y6pVq+jZsyeDBg16ZK9PTtnZ2bF+/Xq6du1KlSpV+OGHH1i7di0jRoww3Zu8WbNm1K1bl5EjRxIdHU1AQAAbN27k22+/ZcCAAaZR6OzY29vz4osvsnz5ckqVKoWbmxsvvfQSL730Uo7fn5zy8/Nj5MiRjBs3jldffZVWrVpha2vL/v378fLyYuLEiTnuPyIizwsl5yIiIvKPdezYES8vLyZNmsTUqVNJTEykSJEivPrqq3Tr1s1Ub+nSpfTr14+5c+diNBoJCgrihx9+wMvLy6y9l19+mXHjxjFv3jzWr19PWloaZ8+eJV++fISGhnLt2jVWrFjB119/TZMmTfjhhx8oWLBgjuMdNmwYpUqVYsaMGYSHhwP3Fm4LCgri9ddffzQvykOytrZm/fr19O7dm8GDB+Pk5MSYMWPMpphbWVnx3XffERoayvLly1m4cCE+Pj5MnTqVDz74IMfH+uyzz+jXrx/vv/8+SUlJjBkzhpdeeinH78/DGDt2LCVKlGD27NmMHDkSBwcHypcvT+fOnU11ctp/RESeBwbjk1iVREREREQyCAkJYcWKFcTFxVk6FBERsTBdcy4iIiIiIiJiYUrORURERERERCxMybmIiIiIiIiIhemacxEREREREREL08i5iIiIiIiIiIUpORcRERERERGxMN3nXOQRS0tL4+LFizg5OWEwGCwdjoiIiIiIWIjRaOTu3bt4eXlhZZX92LiSc5FH7OLFi3h7e1s6DBERERERySXOnTtH0aJFs62j5FzkEXNycgLg7NmzuLm5WTgaed4lJyezceNGgoKCsLGxsXQ48pxTf5TcQn1RchP1x2dbbGws3t7ephwhO0rORR6x9KnsTk5OODs7Wzgaed4lJyfj4OCAs7Oz/sMXi1N/lNxCfVFyE/XH50NOLnfVgnAiIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmFKzkVEREREREQsTMm5iIiIiIiIiIUpORcRERERERGxMCXnIiIiIiIiIham5FxERERERETEwpSci4iIiIiIiFiYknMRERERERERC1NyLiIiIiIiImJhSs5FRERERERELEzJuYiIiIiIiIiFKTkXERERERERsTAl5yIiIiIiIiIWpuRcRERERERExMKUnIuIiIiIiIhYmJJzEREREREREQszGI1Go6WDEHmWxMbG4uLigu8Hy0nJk8/S4chzztbayJRXUhmyz5rEVIOlw5HnnPqj5Bbqi5KbPEv9MXrSa5YOIddJzw3u3LmDs7NztnU1ci4iIiIiIiKPxaRJkzAYDAwYMMBU9s477+Dr64u9vT0FChSgefPmnDhxwmy/mJgYXnvtNRwcHChYsCCDBw8mJSXFtP2nn36iRo0auLu7Y29vT5kyZZgxY8YD4zly5AivvvoqdnZ2eHt7M2XKlEd2rv+WknN5rrz++usUK1YMOzs7PD096dy5MxcvXjSrs2HDBqpWrYqTkxMFChSgdevWREdHWyZgEREREZGn1P79+/nvf/9L+fLlzcorVarEwoULOX78OBs2bMBoNBIUFERqaioAqampvPbaayQlJbFr1y6++OILFi1aRGhoqKmNfPny0bdvX7Zv387x48cZNWoUo0aNYv78+VnGExsbS1BQEMWLF+fAgQNMnTqVsLCwbPd5kpScy3MhKSkJgLp16/L1118TFRXFN998w+nTp2nTpo2p3tmzZ2nevDn16tXj8OHDbNiwgevXr9OqVStLhS4iIiIi8tSJi4ujU6dOfPrpp7i6uppt69mzJ7Vq1cLHx4eKFSsyfvx4zp07ZxoQ27hxI7/99htLliyhQoUKNGnShHHjxjF37lzT5/rAwEA6dOhAuXLl8PHx4c0336RRo0bs2LEjy5giIiJISkri888/p1y5crRv357+/fvz0UcfPbbX4WEoOZdcZ/78+Xh5eZGWlmZW3rx5c9566y1Onz5N8+bNKVSoEI6Ojrz88sts2rTJrK6Pjw/jxo2jS5cuODs707NnTwDef/99qlatSvHixalevTrDhg1jz549JCcnA3DgwAFSU1MZP348vr6+VKxYkUGDBnH48GFTHRERERERyd67777La6+9RoMGDbKtFx8fz8KFCylRogTe3t4A7N69G39/fwoVKmSq16hRI2JjYzl27Fim7Rw6dIhdu3ZRu3btLI+1e/duatWqRd68ec3ajYqK4tatWw9zeo9FHksHIHK/N954g379+rFlyxbq168PwM2bN1m/fj3r1q0jLi6O4OBgJkyYgK2tLYsXL6ZZs2ZERUVRrFgxUzvTpk0jNDSUMWPGZHqcmzdvEhERQfXq1bGxsQHuTbGxsrJi4cKFhISEEBcXx5dffkmDBg1Mde6XmJhIYmKi6XlsbCwAtlZGrK213qJYlq2V0exfEUtSf5TcQn1RcpNnqT+mD2YtX76cAwcOsHv3bpKTkzEajaSlpZkNds2bN4/hw4cTHx9PqVKlWLduHQaDgeTkZC5evEjBggXN6ru5uQFw/vx5XnrpJVN5iRIluHbtGikpKYwePZquXbtmOah26dIlfHx8Mm333LlzODo6ProX4/97mAE+JeeS67i6utKkSROWLl1qSs5XrFiBh4cHdevWxcrKioCAAFP9cePGsWrVKr777jv69u1rKq9Xrx4ffPBBhvaHDh3KnDlzSEhIoGrVqqxZs8a0rUSJEmzcuJG2bdvyzjvvkJqaSrVq1Vi3bl2W8U6cOJHw8PAM5aMC03BwSP1Hr4HIozauctqDK4k8IeqPkluoL0pu8iz0x3Xr1nHt2jUGDRpEeHg4P/74IwA3btzg7NmzZp+p3d3dmTp1Krdu3WL16tW89tprTJo0ibx58xITE8O1a9fM6qcPhu3fv99shm1oaCh//vknJ0+e5KOPPuLu3bvUqlUr0/iuXbuGlZWVWbvnzp0DYPv27Zw9e/bRvRj/X0JCQo7r6lZqkiv973//o0ePHly5cgVbW1tq165N5cqVmT59OnFxcYSFhbF27VouXbpESkoKf/75Jx988IFptUUfHx969OjByJEjM7R9/fp1bt68yR9//EF4eDguLi6sWbMGg8HA5cuXqVWrFi1atKBDhw7cvXuX0NBQ8uTJQ2RkJAZDxttbZDZy7u3tzYuDl5Fio1upiWXZWhkZVzmN0T9bkZj2dN+eRZ5+6o+SW6gvSm7yLPXHo2GN+Pbbb3njjTewtrY2laempmIwGLCysiIuLs5sG9xbH6pgwYLMmzeP9u3bExYWxpo1a/j5559Ndc6ePUvp0qXZu3cvgYGBmR7/ww8/JCIiIsup7926dSM2NpZvvvnGVLZ161aCgoK4cuVKhmvjH4XY2Fg8PDxydCs1jZxLrtSsWTOMRiNr167l5ZdfZseOHaZbIwwaNIjIyEimTZuGn58f9vb2tGnTxrQ4RLp8+TJPjD08PPDw8KBUqVKULVsWb29v9uzZQ7Vq1Zg7dy4uLi5mt1RYsmQJ3t7e7N27l6pVq2Zoz9bWFltb2wzliWkGUp7ye1XKsyMxzfDU3ztVnh3qj5JbqC9KbvIs9EcbGxsaNWrEr7/+alberVs3ypQpw9ChQ7Gzs8uwX1paGkajkdTUVGxsbKhZsyaTJk3i1q1bFCxYELiXRDs7OxMQEJDl5aYGg4GkpKQst9eoUcM0eJdeZ8uWLZQuXdp0nEctq1gyo+RcciU7OztatWpFREQEp06donTp0lSsWBGAnTt3EhISQsuWLYF7K0H+01udpU+JSR/5TkhIwMrKfJ3E9G/27l+gTkREREREzDk5OZldEw73Bs3c3d156aWXOHPmDMuXLycoKIgCBQpw/vx5Jk2ahL29PcHBwQAEBQXx4osv0rlzZ6ZMmcLly5cZNWoU7777rmlQbO7cuRQrVowyZcoA96alT5s2jf79+5uOO2fOHFatWsXmzZsB6NixI+Hh4XTv3p2hQ4dy9OhRZs2alaP7oz8JSs4l1+rUqRNNmzbl2LFjvPnmm6bykiVLsnLlSpo1a4bBYGD06NE5Spz37t3L/v37qVmzJq6urpw+fZrRo0fj6+tLtWrVAHjttdeYMWMGY8eONU1rHzFiBMWLF89y+oyIiIiIiOSMnZ0dO3bsYObMmdy6dYtChQpRq1Ytdu3aZRq9tra2Zs2aNfTu3Ztq1aqRL18+unbtytixY03tpKWlMXz4cM6ePUuePHnw9fVl8uTJvPPOO6Y6169f5/Tp06bnLi4ubNy4kXfffZdKlSrh4eFBaGio6c5OlqbkXHKtevXq4ebmRlRUFB07djSVf/TRR7z11ltUr14dDw8Phg4dalohPTsODg6sXLmSMWPGEB8fj6enJ40bN2bUqFGmb+Dq1avH0qVLmTJlClOmTMHBwYFq1aqxfv167O3tH9u5ioiIiIg8q7Zu3Wr62cvLK9vFltMVL14823r9+vWjX79+2bYRFhZGWFiYWVn58uWzvRe6JWlBOJFHLDY2FhcXF65fv467u7ulw5HnXHJyMuvWrSM4OPihrnkSeRzUHyW3UF+U3ET98dmWnhvkZEE4q2y3ioiIiIiIiMhjp+RcRERERERExMKUnIuIiIiIiIhYmJJzEREREREREQtTci4iIiIiIiJiYUrORURERERERCxMybmIiIiIiIiIhSk5FxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmFKzkVEREREREQsTMm5iIiIiIiIiIUpORcRERERERGxMCXnIiIiIiIiIhaWx9IBiDyrqkzcTEqefJYOQ55zttZGprwCL4VtIDHVYOlw5BkTPek1ALZv387UqVM5cOAAly5dYtWqVbRo0cJU78qVKwwdOpSNGzdy48YN6tSpw5w5cyhZsiQAN2/eZMyYMWzcuJGYmBgKFChAixYtGDduHC4uLhmOe+PGDQICArhw4QK3bt0if/78WcZ48+ZN+vXrx/fff4+VlRWtW7dm1qxZODo6PtLXQkRE5N/SyLk8VyZMmED16tVxcHDI8sOcwWDI8Fi2bNmTDVRE5CkSHx9PQEAAc+fOzbDNaDTSokULzpw5wzfffMOMGTMoVqwYDRo0ID4+HoCLFy9y8eJFpk2bxtGjR1m0aBHr16+ne/fumR6ve/fulC9fPkexderUiWPHjhEZGcmaNWvYvn07PXv2/OcnKyIi8pho5FyeC0lJSeTNm5ekpCTeeOMNqlWrxoIFC7Ksv3DhQho3bmx6nt2ojIjI865JkyY0adIk022///47e/bs4ejRo5QqVYqrV6/SvXt3vL29+eqrr3j77bd56aWX+Oabb0z7+Pr6MmHCBN58801SUlLIk+f/Pq588skn3L59m9DQUH744Yds4zp+/Djr169n//79VK5cGYDZs2cTHBzMtGnT8PLyegRnLyIi8mho5Fxynfnz5+Pl5UVaWppZefPmzXnrrbc4ffo0zZs3p1ChQjg6OvLyyy+zadMms7o+Pj6MGzeOLl264OzsbBolCQ8P5/3338ff3z/bGPLnz0/hwoVNDzs7u0d7kiIiz4nExEQAs7+jVlZW2Nra8tNPP2W53507d3B2djZLzH/77TfGjh3L4sWLsbJ68EeY3bt3kz9/flNiDtCgQQOsrKzYu3fvPzkdERGRx0Yj55LrvPHGG/Tr148tW7ZQv3594N41g+vXr2fdunXExcURHBzMhAkTsLW1ZfHixTRr1oyoqCiKFStmamfatGmEhoYyZsyYh47h3Xff5e233+aFF16gV69edOvWDYMh8+t1ExMTTR8+AWJjYwGwtTJibW186GOLPEq2Vkazf0UepeTk5EzLU1JSTNt8fX0pVqwYQ4cOZdasWSQnJzNp0iTOnz/PxYsXM23j+vXrjBs3ju7du5u2JyYm0r59eyZOnIinpycnT540xZBVHBcuXKBAgQIZtru5uXHhwoUs95NnX/p7rz4guYH647PtYd5XJeeS67i6utKkSROWLl1qSs5XrFiBh4cHdevWxcrKioCAAFP9cePGsWrVKr777jv69u1rKq9Xrx4ffPDBQx9/7Nix1KtXDwcHBzZu3EifPn2Ii4ujf//+mdafOHEi4eHhGcpHBabh4JD60McXeRzGVU57cCWRh7Ru3bpMyw8cOICNjY3pef/+/ZkzZw5FixY1/Q2vWLEiN27cyNBGQkICY8aMwcPDg5dfftm0/fPPP8fFxQVXV1fWrVvHr7/+CsDGjRuzXNwtKiqK+Pj4DMdISkri6NGjWcYvz4/IyEhLhyBiov74bEpISMhxXSXnkit16tSJHj168PHHH2Nra0tERATt27fHysqKuLg4wsLCWLt2LZcuXSIlJYU///yTmJgYszb+Po3xYYwePdr0c2BgIPHx8UydOjXL5Hz48OEMHDjQ9Dw2NhZvb2/GH7Iixcb6H8Ug8qjYWhkZVzmN0T9bkZim1drl0Toa1ijT8kqVKhEcHGxW1r9/f65fv05kZCRt2rShTp06GerdvXuX1157DW9vb1avXm02FT40NJSjR4/SunVr4N5CcwBdu3Zl2LBhmc6Sunr1KmvXrjU7RkpKCnFxcdSvXz9DjPL8SE5OJjIykoYNG5p9kSRiCeqPz7b0WbU5oeRccqVmzZphNBpZu3YtL7/8Mjt27GDGjBkADBo0iMjISKZNm4afnx/29va0adOGpKQkszby5Xs0tzGrUqUK48aNIzExEVtb2wzbbW1tMy1PTDOQoltXSS6RmGbQrdTkkcvqQ2SePHky3ebh4YGLiwvR0dEcOHCA8ePHm+rFxsby2muvYWtry/fff4+Dg4PZvitXruTPP/80Pd+/fz9vvfUWO3bswNfXN9Pj1axZk9u3b3PkyBEqVaoEwJYtW0hLS6NGjRr6ECzY2NioH0iuof74bHqY91TJueRKdnZ2tGrVioiICE6dOkXp0qWpWLEiADt37iQkJISWLVsCEBcXR3R09GOL5fDhw7i6umaagIuIyL2/w6dOnTI9P3v2LIcPH8bNzY1ixYrxv//9jwIFCuDp6cnevXt57733aNGiBUFBQcC9xDwoKIiEhASWLFlCbGysaaShQIECWFtb4+vra3bM69evA1C2bFnTHTX27dtHly5d2Lx5M0WKFKFs2bI0btyYHj16MG/ePJKTk+nbty/t27fXSu0iIpLrKDmXXKtTp040bdqUY8eO8eabb5rKS5YsycqVK2nWrBkGg4HRo0dnWNk9KzExMdy8eZOYmBhSU1M5fPgwAH5+fjg6OvL9999z5coVqlatip2dHZGRkXz44YcMGjTocZyiiMgz4eeff6Zu3bqm5+mX+nTt2pVFixZx6dIlBg4cyJUrV8ifPz9vv/02YWFhpvoHDx40rZ7u5+dn1vbZs2fx8fHJURwJCQlERUWZLb4TERFB3759qV+/PlZWVrRu3Zr//Oc///BMRUREHh8l55Jr1atXDzc3N6KioujYsaOp/KOPPuKtt96ievXqeHh4MHTo0BxfyxEaGsoXX3xheh4YGAjcm+ZYp04dbGxsmDt3Lu+//z5GoxE/Pz8++ugjevTo8WhPTkTkGVKnTh3TNeCZ6d+/P/379yc5OZl169YRHBxsNs3vQfvn9JiZlbm5ubF06dKHaltERMQSDMaH/d9QRLIVGxuLi4sL169fx93d3dLhyHMuq2RIxBLUHyW3UF+U3ET98dmWnhvcuXMHZ2fnbOtaPaGYRERERERERCQLSs5FRERERERELEzJuYiIiIiIiIiFKTkXERERERERsTAl5yIiIiIiIiIWpuRcRERERERExMKUnIuIiIiIiIhYmJJzEREREREREQtTci4iIiIiIiJiYUrORURERERERCxMybmIiIiIiIiIhSk5FxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmF5LB2AyLOqysTNpOTJZ+kw5Dlna21kyivwUtgGElMNlg7niYue9BoA27dvZ+rUqRw4cIBLly6xatUqWrRoYaoXFhbGsmXLOHfuHHnz5qVSpUpMmDCBKlWqmOqcPHmSwYMHs3PnTpKSkihfvjzjxo2jbt26ACxatIhu3bplGseVK1coWLBgpttu3rxJv379+P7777GysqJ169bMmjULR0fHR/QqiIiIyNPgqR05NxgMrF69Osvt0dHRGAwGDh8+/MRielTq1KnDgAEDTM99fHyYOXOmxeJ5Ep7m90tEcr/4+HgCAgKYO3dupttLlSrFnDlz+PXXX/npp5/w8fEhKCiIa9eumeo0bdqUlJQUfvzxRw4cOEBAQABNmzbl8uXLALRr145Lly6ZPRo1akTt2rWzTMwBOnXqxLFjx4iMjGTNmjVs376dnj17PtoXQERERHK9pzY5f57s37//qfigFhISgsFgMHs0btzY0mE9lJUrV1K5cmXy589Pvnz5qFChAl9++aWlwxKRf6lJkyaMHz+eli1bZrq9Y8eONGjQgBdeeIFy5crx0UcfERsby5EjRwC4fv06v//+O8OGDaN8+fKULFmSSZMmkZCQwNGjRwGwt7encOHCpoe1tTU//vgj3bt3zzKu48ePs379ej777DOqVKlCzZo1mT17NsuWLePixYuP/oUQERGRXEvJ+VOgQIECODg4WDqMLCUlJZl+bty4sdmo0VdffWXByB6em5sbI0eOZPfu3Rw5coRu3brRrVs3NmzYYOnQROQJSUpKYv78+bi4uBAQEACAu7s7pUuXZvHixcTHx5OSksJ///tfChYsSKVKlTJtZ/HixTg4ONCmTZssj7V7927y589P5cqVTWUNGjTAysqKvXv3PtoTExERkVzNosn5ihUr8Pf3x97eHnd3dxo0aEB8fDz79++nYcOGeHh44OLiQu3atTl48GC2be3bt4/AwEDs7OyoXLkyhw4dylBn27ZtvPLKK9ja2uLp6cmwYcNISUnJUax16tShX79+DBgwAFdXVwoVKsSnn35KfHw83bp1w8nJCT8/P3744Qez/Y4ePUqTJk1wdHSkUKFCdO7cmevXr5u2x8fH06VLFxwdHfH09GT69OkZjn3/tPaYmBiaN2+Oo6Mjzs7OtG3blitXrjzwHE6ePInBYODEiRNm5TNmzMDX1xeA1NRUunfvTokSJbC3t6d06dLMmjXLrH5ISAgtWrRgwoQJeHl5Ubp0adM2W1tbs5EjV1fXB8b1d2fOnKFu3bo4ODgQEBDA7t27Tdtu3LhBhw4dKFKkCA4ODvj7+2dI/tPS0pgyZQp+fn7Y2tpSrFgxJkyYYNp+7tw52rZtS/78+XFzc6N58+ZER0ebttepU4eWLVtStmxZfH19ee+99yhfvjw//fTTQ52HiDx91qxZg6OjI3Z2dsyYMYPIyEg8PDyAe5dSbdq0iUOHDuHk5ISdnR0fffQR69evz/Lv3IIFC+jYsSP29vZZHvPy5csZprznyZMHNzc303R5EREReT5YbEG4S5cu0aFDB6ZMmULLli25e/cuO3bswGg0cvfuXbp27crs2bMxGo1Mnz6d4OBgfv/9d5ycnDK0FRcXR9OmTWnYsCFLlizh7NmzvPfee2Z1Lly4QHBwMCEhISxevJgTJ07Qo0cP7OzsCAsLy1HMX3zxBUOGDGHfvn0sX76c3r17s2rVKlq2bMmIESOYMWMGnTt3JiYmBgcHB27fvk29evV4++23mTFjBn/++SdDhw6lbdu2/PjjjwAMHjyYbdu28e2331KwYEFGjBjBwYMHqVChQqYxpKWlmRLzbdu2kZKSwrvvvku7du3YunVrtvGXKlWKypUrExERwbhx40zlERERdOzY0dR+0aJF+d///oe7uzu7du2iZ8+eeHp60rZtW9M+mzdvxtnZmcjISLNjbN26lYIFC+Lq6kq9evUYP3487u7uOXp9AUaOHMm0adMoWbIkI0eOpEOHDpw6dYo8efLw119/UalSJYYOHYqzszNr166lc+fO+Pr68sorrwAwfPhwPv30U2bMmEHNmjW5dOmS6cuI5ORkGjVqRLVq1dixYwd58uRh/PjxNG7cmCNHjpA3b16zWIxGIz/++CNRUVFMnjw5y5gTExNJTEw0PY+NjQXA1sqItbUxx+cu8jjYWhnN/n3eJCcnZ1qekpKSYVvNmjXZv38/N27cYMGCBbRt25affvqJggULYjQa6d27NwUKFGDLli3Y29vz+eef06xZM3bt2oWnp6dZW3v27OH48eMsXLgwyxjg3heiRqMx0zqpqanZ7vs0Sj+fZ+285Omjvii5ifrjs+1h3leD0Wi0yCe2gwcPUqlSJaKjoylevHi2ddPS0sifPz9Lly6ladOmwL1RjPTVdufPn8+IESM4f/48dnZ2AMybN4/evXtz6NAhKlSowMiRI/nmm284fvw4BsO9FYs//vhjhg4dyp07d7Cyyn4SQZ06dUhNTWXHjh3AvQ9NLi4utGrVisWLFwP3RkA8PT3ZvXs3VatWZfz48ezYscNsSvT58+fx9vYmKioKLy8v3N3dWbJkCW+88QZwb9XeokWL0rNnT9NouY+PDwMGDGDAgAFERkbSpEkTzp49i7e3NwC//fYb5cqVY9++fbz88svZnsfMmTOZM2cOp06dAu6NppcuXZrjx49TpkyZTPfp27cvly9fZsWKFcC9kfP169cTExNjltAuW7YMBwcHSpQowenTpxkxYgSOjo7s3r0ba2vrbOOKjo6mRIkSfPbZZ6brM9PPK7vYmjZtSpkyZZg2bRp3796lQIECzJkzh7fffjtD3SVLljB+/HizPpCUlET+/PlZvXo1QUFBANy5c4ciRYqQmJiItbU1H3/8MW+99VaWsYeFhREeHp6hfOnSpbn6cgSR51WLFi0YNmwYVatWzbZe7969qV+/Pm3atOGXX34hPDycJUuWmP1e9+7dmwYNGtC6dWuzfWfPns2ZM2eYMWNGtsfYtGkTCxcuJCIiwlSWmprKG2+8wZAhQx4Yo4iIiORuCQkJdOzYkTt37uDs7JxtXYuNnAcEBFC/fn38/f1p1KgRQUFBtGnTBldXV65cucKoUaPYunUrV69eJTU1lYSEBGJiYjJt6/jx45QvX96UmANUq1YtQ51q1aqZkjKAGjVqEBcXx/nz5ylWrNgDYy5fvrzpZ2tra9zd3fH39zeVFSpUCICrV68C8Msvv7Bly5ZMb4dz+vRp/vzzT5KSksxu1ePm5mY2TTyzc/X29jYl5gAvvvgi+fPn5/jx4w9Mztu3b8+gQYPYs2cPVatWJSIigooVK5olv3PnzuXzzz8nJibGFOP9I/n+/v4ZRprbt29vtr18+fL4+vqydetW6tevn21c6f7+GqePRF29epUyZcqQmprKhx9+yNdff82FCxdISkoiMTHR9EH5+PHjJCYmZnmsX375hVOnTmWYffHXX39x+vRp03MnJycOHz5MXFwcmzdvZuDAgbzwwgvUqVMn03aHDx/OwIEDTc9jY2Px9vZm/CErUmyy/1JC5HGztTIyrnIao3+2IjHt+buV2tGwRpmWV6pUieDg4Gz3tbe3x8fHh+DgYNLS0oB762r8/W+6o6MjJUuWNGsrLi6ON998k/Hjxz/wGCVKlGDOnDkULlyYihUrAhAZGYnRaKRXr154eXnl6DyfFsnJyURGRtKwYUNsbGwsHY48x9QXJTdRf3y2pc+qzQmLJefW1tZERkaya9cuNm7cyOzZsxk5ciR79+6ld+/e3Lhxg1mzZlG8eHFsbW2pVq2a2cJjlnD/L4vBYDArS0/80z/ExcXF0axZs0ynRHt6eppGr5+kwoULU69ePZYuXUrVqlVZunQpvXv3Nm1ftmwZgwYNYvr06VSrVg0nJyemTp2aYWGifPkefP/uF154AQ8PD06dOpXj5Dy713Pq1KnMmjWLmTNn4u/vT758+RgwYICpX2R3XSfcez8qVapkNkKVrkCBAqafrays8PPzA6BChQocP36ciRMnZpmc29raYmtrm6E8Mc1AynN4X2nJnRLTDM/lfc7T/6bExcWZ/c09d+4cx44dw83NDXd3dyZMmMDrr7+Op6cn169fZ+7cuVy4cIH27dtjY2PDq6++iqurK2+//TahoaHY29vz6aefEh0dzeuvv272t2vlypWkpKTQtWvXDP9v7Nu3jy5durB582aKFClC+fLlady4Mb1792bevHkkJyczYMAA2rdv/8BZZU8zGxsbfQCVXEF9UXIT9cdn08O8pxZdEM5gMFCjRg3Cw8M5dOgQefPmZdWqVezcuZP+/fsTHBxMuXLlsLW1NVtE7X5ly5blyJEj/PXXX6ayPXv2ZKize/du/j6Lf+fOnTg5OVG0aNFHf3JAxYoVOXbsGD4+Pvj5+Zk98uXLh6+vLzY2NmaJ761btzh58mSWbZYtW5Zz585x7tw5U9lvv/3G7du3efHFF3MUV6dOnVi+fDm7d+/mzJkzZiPeO3fupHr16vTp04fAwED8/PzMRpUfxvnz57lx40aGazH/qZ07d9K8eXPefPNNAgICeOGFF8xeq5IlS2Jvb8/mzZsz3b9ixYr8/vvvFCxYMMP74eLikuVx09LSzK4pF5Gnz88//0xgYCCBgYEADBw4kMDAQEJDQ7G2tubEiRO0bt2aUqVK0axZM27cuMGOHTsoV64cAB4eHqxfv564uDjq1atH5cqV+emnn/j2229NK7qnW7BgAa1atSJ//vwZ4khISCAqKsrs+rOIiAjKlClD/fr1CQ4OpmbNmsyfP//xvRgiIiKSK1ls5Hzv3r1s3ryZoKAgChYsyN69e7l27Rply5alZMmSfPnll1SuXJnY2FgGDx6c7ahox44dGTlyJD169GD48OFER0czbdo0szp9+vRh5syZ9OvXj759+xIVFcWYMWMYOHDgA683/6feffddPv30Uzp06MCQIUNwc3Pj1KlTLFu2jM8++wxHR0e6d+/O4MGDcXd3p2DBgowcOTLbeBo0aIC/vz+dOnVi5syZpKSk0KdPH2rXrm12K57stGrVit69e9O7d2/q1q1rNm2yZMmSLF68mA0bNlCiRAm+/PJL9u/fT4kSJbJtMy4ujvDwcFq3bk3hwoU5ffo0Q4YMwc/Pj0aNMp9W+rBKlizJihUr2LVrF66urnz00UdcuXLF9KWEnZ0dQ4cOZciQIeTNm5caNWpw7do1jh07Rvfu3enUqRNTp06lefPmjB07lqJFi/LHH3+wcuVKhgwZQtGiRZk4cSKVK1fG19eXxMRE1q1bx5dffsknn3zySM5BRCyjTp06ZLfEysqVKx/YRuXKlXN0W8Vdu3Y9VBxubm4sXbr0ge2KiIjIs81iI+fOzs5s376d4OBgSpUqxahRo5g+fTpNmjRhwYIF3Lp1i4oVK9K5c2f69++f4VYzf+fo6Mj333/Pr7/+SmBgICNHjswwlbxIkSKsW7eOffv2ERAQQK9evejevTujRo16bOfo5eXFzp07SU1NJSgoCH9/fwYMGED+/PlNCfjUqVN59dVXadasGQ0aNKBmzZpZ3jMX7s02+Pbbb3F1daVWrVo0aNCAF154geXLl+c4LicnJ5o1a8Yvv/xCp06dzLa98847tGrVinbt2lGlShVu3LhBnz59HtimtbU1R44c4fXXX6dUqVJ0796dSpUqsWPHjkynfP8To0aNomLFijRq1Ig6depQuHBhWrRoYVZn9OjRfPDBB4SGhlK2bFnatWtnWgPAwcGB7du3U6xYMVq1akXZsmXp3r07f/31l2lxhvj4ePr06UO5cuWoUaMG33zzDUuWLMl0gTkREREREZFHxWKrtYs8q2JjY3FxceH69esPdRs5kcchOTmZdevWERwcrOvYxOLUHyW3UF+U3ET98dmWnhvkZLV2i15zLiIiIiIiIiJKzgGIiYnB0dExy0dWt3DLjcqVK5fleWS2SvmT8uGHH2YZV5MmTSwWl4iIiIiISG5gsQXhchMvLy8OHz6c7fanxbp168xWAf679PuwW0KvXr1o27ZtptsedAs0ERERERGRZ52ScyBPnjym+1o/7XLrfXHd3Nxwc3OzdBgiIiIiIiK5kqa1i4iIiIiIiFiYknMRERERERERC1NyLiIiIiIiImJhSs5FRERERERELEzJuYiIiIiIiIiFKTkXERERERERsTAl5yIiIiIiIiIWpuRcRERERERExMKUnIuIiIiIiIhYmJJzEREREREREQtTci4iIiIiIiJiYUrORURERERERCwsj6UDEHlWVZm4mZQ8+SwdhjznbK2NTHkFXgrbQGKqwdLhZCt60muWDkFERETEYp7akXODwcDq1auz3B4dHY3BYODw4cNPLKZHpU6dOgwYMMD03MfHh5kzZ1osnifhaX6/ROTR2b59O82aNcPLyyvD3/nk5GSGDh2Kv78/+fLlw8vLiy5dunDx4kWzNnx8fDAYDGaPSZMmmban/725/7Fnz55sY4uJieG1117DwcGBggULMnjwYFJSUh7p+YuIiMjz66lNzp8n+/fvp2fPnpYO44FCQkIyfNht3LixpcN6KJ9++imvvvoqrq6uuLq60qBBA/bt22fpsESeG/Hx8QQEBDB37twM2xISEjh48CCjR4/m4MGDrFy5kqioKF5//fUMdceOHculS5dMj379+mWos2nTJrM6lSpVyjKu1NRUXnvtNZKSkti1axdffPEFixYtIjQ09N+dsIiIiMj/p2ntT4ECBQpYOoRsJSUlkTdvXgAaN27MwoULTdtsbW0tFdY/snXrVjp06ED16tWxs7Nj8uTJBAUFcezYMYoUKWLp8ESeeU2aNKFJkyaZbnNxcSEyMtKsbM6cObzyyivExMRQrFgxU7mTkxOFCxfO9lju7u4PrJNu48aN/Pbbb2zatIlChQpRoUIFxo0bx9ChQwkLCzP9DRQRERH5pyw6cr5ixQr8/f2xt7fH3d2dBg0aEB8fz/79+2nYsCEeHh64uLhQu3ZtDh48mG1b+/btIzAwEDs7OypXrsyhQ4cy1Nm2bRuvvPIKtra2eHp6MmzYsBxPSaxTpw79+vVjwIABuLq6UqhQIT799FPi4+Pp1q0bTk5O+Pn58cMPP5jtd/ToUZo0aYKjoyOFChWic+fOXL9+3bQ9Pj6eLl264OjoiKenJ9OnT89w7PuntcfExNC8eXMcHR1xdnambdu2XLly5YHncPLkSQwGAydOnDArnzFjBr6+vsC90aHu3btTokQJ7O3tKV26NLNmzTKrHxISQosWLZgwYQJeXl6ULl3atM3W1pbChQubHq6urg+M6+/OnDlD3bp1cXBwICAggN27d5u23bhxgw4dOlCkSBEcHBzw9/fnq6++Mts/LS2NKVOm4Ofnh62tLcWKFWPChAmm7efOnaNt27bkz58fNzc3mjdvTnR0tGl7REQEffr0oUKFCpQpU4bPPvuMtLQ0Nm/e/FDnISJPxp07dzAYDOTPn9+sfNKkSbi7uxMYGMjUqVMz/Vv/+uuvU7BgQWrWrMl3332X7XF2796Nv78/hQoVMpU1atSI2NhYjh079kjORURERJ5vFhs5v3TpEh06dGDKlCm0bNmSu3fvsmPHDoxGI3fv3qVr167Mnj0bo9HI9OnTCQ4O5vfff8fJySlDW3FxcTRt2pSGDRuyZMkSzp49y3vvvWdW58KFCwQHBxMSEsLixYs5ceIEPXr0wM7OjrCwsBzF/MUXXzBkyBD27dvH8uXL6d27N6tWraJly5aMGDGCGTNm0LlzZ2JiYnBwcOD27dvUq1ePt99+mxkzZvDnn38ydOhQ2rZty48//gjA4MGD2bZtG99++y0FCxZkxIgRHDx4kAoVKmQaQ1pamikx37ZtGykpKbz77ru0a9eOrVu3Zht/qVKlqFy5MhEREYwbN85UHhERQceOHU3tFy1alP/973+4u7uza9cuevbsiaenJ23btjXts3nzZpydnTOMYm3dupWCBQvi6upKvXr1GD9+PO7u7jl6fQFGjhzJtGnTKFmyJCNHjqRDhw6cOnWKPHny8Ndff1GpUiWGDh2Ks7Mza9eupXPnzvj6+vLKK68AMHz4cD799FNmzJhBzZo1uXTpkunLiOTkZBo1akS1atXYsWMHefLkYfz48TRu3JgjR45kOvKVkJBAcnIybm5uWcacmJhIYmKi6XlsbCwAtlZGrK2NOT53kcfB1spo9m9ulpycnKEsJSUl03KAv/76iyFDhtCuXTvs7e1N9d59910CAwNxdXVlz549jBo1igsXLjB16lTg3peIU6ZMoXr16lhZWbFy5UpatGjBihUraNasWabHunjxIgULFjSLJf3vwvnz53nppZf+1bk/L9Jfv6zeU5EnRX1RchP1x2fbw7yvBqPRaJFPbAcPHqRSpUpER0dTvHjxbOumpaWRP39+li5dStOmTYF7C8KtWrWKFi1aMH/+fEaMGMH58+exs7MDYN68efTu3ZtDhw5RoUIFRo4cyTfffMPx48cxGO6tWPzxxx8zdOhQ7ty5g5VV9pMI6tSpQ2pqKjt27ADujTC7uLjQqlUrFi9eDMDly5fx9PRk9+7dVK1alfHjx7Njxw42bNhgauf8+fN4e3sTFRWFl5cX7u7uLFmyhDfeeAOAmzdvUrRoUXr27GkaLffx8WHAgAEMGDCAyMhImjRpwtmzZ/H29gbgt99+o1y5cuzbt4+XX3452/OYOXMmc+bM4dSpU8C90fTSpUtz/PhxypQpk+k+ffv25fLly6xYsQK4N3K+fv16YmJizBLaZcuW4eDgQIkSJTh9+jQjRozA0dGR3bt3Y21tnW1c0dHRlChRgs8++4zu3bubnVd2sTVt2pQyZcowbdo07t69S4ECBZgzZw5vv/12hrpLlixh/PjxZn0gKSmJ/Pnzs3r1aoKCgjLs06dPHzZs2MCxY8dMfet+YWFhhIeHZyhfunQpDg4O2Z63iGStRYsWDBs2jKpVq2bYlpKSwuTJk7lx4wbjx4/P9ndt06ZNfPLJJyxbtgwbG5tM68ycOZMrV64wceLETLfPnTuXa9eumX2Zm5iYSLt27Rg9enS216uLiIjI8yshIYGOHTty584dnJ2ds61rsZHzgIAA6tevj7+/P40aNSIoKIg2bdrg6urKlStXGDVqFFu3buXq1aukpqaSkJBATExMpm0dP36c8uXLmyVP1apVy1CnWrVqpqQMoEaNGsTFxXH+/HmzaxWzUr58edPP1tbWuLu74+/vbypLn+549epVAH755Re2bNmCo6NjhrZOnz7Nn3/+SVJSElWqVDGVu7m5mU0Tz+xcvb29TYk5wIsvvkj+/Pk5fvz4A5Pz9u3bM2jQIPbs2UPVqlWJiIigYsWKZsnv3Llz+fzzz4mJiTHFeP9Ivr+/f4aR5vbt25ttL1++PL6+vmzdupX69etnG1e6v7/Gnp6ewL3Xs0yZMqSmpvLhhx/y9ddfc+HCBZKSkkhMTDR9KD9+/DiJiYlZHuuXX37h1KlTGWZf/PXXX5w+fTpD/UmTJrFs2TK2bt2aZWIO90brBw4caHoeGxuLt7c34w9ZkWKT/ZcSIo+brZWRcZXTGP2zFYlpuftWakfDGmUoq1SpEsHBwWZlycnJdOjQgb/++oudO3c+cHZO8eLFmTNnDmXKlMny7+sff/zBxIkTMxwr3b59+1izZo3Z9rNnzwL3viQMDAzMNga5Jzk5mcjISBo2bJjlFyUiT4L6ouQm6o/PtvRZtTlhseTc2tqayMhIdu3axcaNG5k9ezYjR45k79699O7dmxs3bjBr1iyKFy+Ora0t1apVIykpyVLhAmT4ZTEYDGZl6Yl/WloacG+6fbNmzZg8eXKGtjw9PU2j109S4cKFqVevHkuXLqVq1aosXbqU3r17m7YvW7aMQYMGMX36dKpVq4aTkxNTp05l7969Zu3ky/fg+3e/8MILeHh4cOrUqRwn59m9nlOnTmXWrFnMnDnTdCulAQMGmPqFvb19tm3HxcVRqVIlIiIiMmy7f9G9adOmMWnSJDZt2mT2hUFmbG1tM134LjHNQEouv6+0PD8S0wy5/j7nmX0gyZMnj1l5cnIynTp14vTp02zZsiVHC2YeO3YMKysrihQpkuWHnl9//RVPT88st9esWZNJkyZx69YtChYsCNy7jMfZ2ZmAgAB9mHpINjY2es0kV1BflNxE/fHZ9DDvqUVXazcYDNSoUYMaNWoQGhpK8eLFWbVqFTt37uTjjz82jVCcO3fObBG1+5UtW5Yvv/ySv/76yzTCef/9asuWLcs333yD0Wg0JX07d+7EycmJokWLPpbzq1ixIt988w0+Pj7kyZPxpfb19cXGxoa9e/eaRu5v3brFyZMnqV27dqZtli1blnPnznHu3Dmzae23b9/mxRdfzFFcnTp1YsiQIXTo0IEzZ86YjXjv3LmT6tWr06dPH1NZZqPKOXH+/Hlu3LhhGgH/t3bu3Enz5s158803gXtJ+8mTJ03nXbJkSezt7dm8eXOm09orVqzI8uXLKViwYLZTSqZMmcKECRPYsGEDlStXfiSxi0jOxMXFmX1xefbsWQ4fPoybmxuenp60adOGgwcPsmbNGlJTU7l8+TJwb9ZR3rx52b17N3v37qVu3bo4OTmxe/du3n//fd58803TApVffPEFefPmNY12r1y5ks8//5zPPvvMdNxVq1YxfPhw05oVQUFBvPjii3Tu3JkpU6Zw+fJlRo0axbvvvvvU3ZVCREREcieLrda+d+9ePvzwQ37++WdiYmJYuXIl165do2zZspQsWZIvv/yS48ePs3fvXjp16pTtqGjHjh0xGAz06NGD3377jXXr1jFt2jSzOn369OHcuXP069ePEydO8O233zJmzBgGDhz4wOvN/6l3332Xmzdv0qFDB/bv38/p06fZsGED3bp1IzU1FUdHR7p3787gwYP58ccfOXr0KCEhIdnG06BBA/z9/enUqRMHDx5k3759dOnShdq1a+c4kWzVqhV3796ld+/e1K1bFy8vL9O2kiVL8vPPP7NhwwZOnjzJ6NGj2b9//wPbjIuLY/DgwezZs4fo6Gg2b95M8+bN8fPzo1GjjFNV/4mSJUuaZlscP36cd955x2yVejs7O4YOHcqQIUNYvHgxp0+fZs+ePSxYsAC496WEh4cHzZs3Z8eOHZw9e5atW7fSv39/zp8/D8DkyZMZPXo0n3/+OT4+Ply+fJnLly8TFxf3SM5BRLL3888/ExgYaEqcBw4cSGBgIKGhoVy4cIHvvvuO8+fPU6FCBTw9PU2PXbt2AfdmsixbtozatWtTrlw5JkyYwPvvv8/8+fPNjjNu3DgqVapElSpV+Pbbb1m+fDndunUzbb9z5w5RUVGm59bW1qxZswZra2uqVavGm2++SZcuXRg7duwTeFVERETkeWCxkXNnZ2e2b9/OzJkziY2NpXjx4kyfPp0mTZpQuHBhevbsScWKFfH29ubDDz9k0KBBWbbl6OjI999/T69evQgMDOTFF19k8uTJtG7d2lSnSJEirFu3jsGDBxMQEICbmxvdu3dn1KhRj+0cvby82LlzJ0OHDiUoKIjExESKFy9O48aNTQn41KlTTdPfnZyc+OCDD7hz506WbRoMBr799lv69etHrVq1sLKyonHjxsyePTvHcTk5OdGsWTO+/vprPv/8c7Nt77zzDocOHaJdu3YYDAY6dOhAnz59Mtwi7n7W1tYcOXKEL774gtu3b+Pl5UVQUBDjxo17ZKNKo0aN4syZMzRq1AgHBwd69uxJixYtzF6v0aNHkydPHkJDQ7l48SKenp706tULAAcHB7Zv387QoUNNX1AUKVKE+vXrm0bSP/nkE5KSkmjTpo3ZsceMGZPjVf1F5J+rU6cO2a1T+qA1TCtWrJhh5tT9unbtSteuXbOtExISQkhIiFlZ8eLFWbduXbb7iYiIiPxTFlutXeRZFRsbi4uLC9evX3+o28iJPA7JycmsW7eO4OBgXccmFqf+KLmF+qLkJuqPz7b03CAnq7VbbFq7iIiIiIiIiNyj5ByIiYnB0dExy0dWt3DLjcqVK5fleWS2SvmT8uGHH2YZV5MmTSwWl4iIiIiISG5g0dXacwsvLy8OHz6c7fanxbp160hOTs50W/p92C2hV69etG3bNtNtD7oFmoiIiIiIyLNOyTn37qPr5+dn6TAeieLFi1s6hEy5ubnh5uZm6TBERERERERyJU1rFxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmFKzkVEREREREQsTMm5iIiIiIiIiIUpORcRERERERGxMCXnIiIiIiIiIham5FxERERERETEwpSci4iIiIiIiFiYknMRERERERERC8tj6QBEnlVVJm4mJU8+S4chzzlbayNTXoGXwjaQmGp4LMeInvQaANu3b2fq1KkcOHCAS5cusWrVKlq0aGGqt3LlSubNm8eBAwe4efMmhw4dokKFCpm2aTQaCQ4OZv369WbtLFq0iG7dumW6z5UrVyhYsGCm227evEm/fv34/vvvsbKyonXr1syaNQtHR8d/fN4iIiIij5JGzuWBDAYDq1evznJ7dHQ0BoOBw4cPP7GYRCT3iY+PJyAggLlz52a5vWbNmkyePPmBbc2cORODIeOXCe3atePSpUtmj0aNGlG7du0sE3OATp06cezYMSIjI1mzZg3bt2+nZ8+eOT85ERERkcdMI+fyXHn99dc5fPgwV69exdXVlQYNGjB58mS8vLxMdY4cOcK7777L/v37KVCgAP369WPIkCEWjFrk6dCkSROaNGmS5fbOnTsD977Qy87hw4eZPn06P//8M56enmbb7O3tsbe3Nz2/du0aP/74IwsWLMiyvePHj7N+/Xr2799P5cqVAZg9ezbBwcFMmzbN7PdfRERExFI0ci7PhaSkJADq1q3L119/TVRUFN988w2nT5+mTZs2pnqxsbEEBQVRvHhxDhw4wNSpUwkLC2P+/PmWCl3kuZKQkEDHjh2ZO3cuhQsXfmD9xYsX4+DgYPZ7fL/du3eTP39+U2IO0KBBA6ysrNi7d+8jiVtERETk39LI+XNixYoVhIeHc+rUKRwcHAgMDOTbb7/lt99+Y8SIERw6dIjk5GQqVKjAjBkzqFixYpZt7du3j3feeYfjx4/z0ksvMXLkyAx1tm3bxuDBg/nll19wc3Oja9eujB8/njx5su9y8+fPJywsjPPnz2Nl9X/fHTVv3hx3d3c+//xzTp8+zcCBA9mzZw/x8fGULVuWiRMn0qBBA1N9Hx8funfvzu+//87q1atp1aoVixYt4v333zfVKV68OMOGDaNFixYkJydjY2NDREQESUlJfP755+TNm5dy5cpx+PBhPvrooyynwCYmJpKYmGh6HhsbC4CtlRFra2O25yvyuNlaGc3+fRySk5MzLU9JScl0W3pZcnJyhu3vvfceVatWJTg42LQtq3YAPvvsM9q3b0+ePHmyrHPhwgUKFCiQYbubmxsXLlzIcj959P7+3otYkvqi5Cbqj8+2h3lflZw/By5dukSHDh2YMmUKLVu25O7du+zYsQOj0cjdu3fp2rUrs2fPxmg0Mn36dIKDg/n9999xcnLK0FZcXBxNmzalYcOGLFmyhLNnz/Lee++Z1blw4QLBwcGEhISwePFiTpw4QY8ePbCzsyMsLCzbWN944w369evHli1bqF+/PnBvIaf169ezbt06UwzBwcFMmDABW1tbFi9eTLNmzYiKiqJYsWKmtqZNm0ZoaChjxozJ9Fg3b94kIiKC6tWrY2NjA9wbYatVqxZ58+Y11WvUqBGTJ0/m1q1buLq6Zmhn4sSJhIeHZygfFZiGg0Nqtucr8qSMq5z22NpO/92834EDB0y/W3935coVAH766ScuXrxoKt+3bx9r167lo48+Mmszq3ZOnDjBiRMnePvtt7OMASAqKor4+PgMdZKSkjh69Gi2+8rjERkZaekQRAD1Rcld1B+fTQkJCTmuq+T8OXDp0iVSUlJo1aoVxYsXB8Df3x+AevXqmdWdP38++fPnZ9u2bTRt2jRDW0uXLiUtLY0FCxZgZ2dHuXLlOH/+PL179zbV+fjjj/H29mbOnDkYDAbKlCnDxYsXGTp0KKGhoWYj4vdzdXWlSZMmLF261JScr1ixAg8PD+rWrQtAQEAAAQEBpn3GjRvHqlWr+O677+jbt6+pvF69enzwwQcZjjF06FDmzJlDQkICVatWZc2aNaZtly9fpkSJEmb1CxUqZNqWWXI+fPhwBg4caHoeGxuLt7c34w9ZkWJjneW5ijwJtlZGxlVOY/TPViSmPZ7V2o+GNcq0vFKlSgQHB2coT7/mvGbNmmartW/evJnLly/z5ptvmtWfMmUKNWvWZNOmTWblq1evJiAggP79+2cb39WrV1m7dq1ZLCkpKcTFxVG/fv1MY5THIzk5mcjISBo2bJjpFy4iT4r6ouQm6o/PtvRZtTmh5Pw5EBAQQP369fH396dRo0YEBQXRpk0bXF1duXLlCqNGjWLr1q1cvXqV1NRUEhISiImJybSt48ePU758eezs7Exl1apVy1CnWrVqZist16hRg7i4OM6fP282up2ZTp060aNHDz7++GNsbW2JiIigffv2pqQ+Li6OsLAw1q5da/ri4c8//8wQ89+vL/27wYMH0717d/744w/Cw8Pp0qULa9asyXRl6JywtbXF1tY2Q3limoGUx3TrKpGHlZhmeGy3Usvqg0SePHky3ZZeZmNjY7Z9xIgRGS4f8ff3Z8aMGTRr1sysblxcHCtWrGDixIkP/CBTs2ZNbt++zZEjR6hUqRIAW7ZsIS0tjRo1auiDkAXc/96LWIr6ouQm6o/Ppod5T5WcPwesra2JjIxk165dbNy4kdmzZzNy5Ej27t1L7969uXHjBrNmzaJ48eLY2tpSrVo10wJqltCsWTOMRiNr167l5ZdfZseOHcyYMcO0fdCgQURGRjJt2jT8/Pywt7enTZs2GWLOly/ze4x7eHjg4eFBqVKlKFu2LN7e3uzZs4dq1apRuHBh05TbdOnPc7I4lcjzLC4ujlOnTpmenz17lsOHD+Pm5kaxYsW4efMmMTExpqnsUVFRwL3frb8/7lesWLEMM1qWL19OSkpKhlF2uDc9vkuXLmzevJkiRYpQtmxZGjduTI8ePZg3bx7Jycn07duX9u3ba6V2ERERyTW0WvtzwmAwUKNGDcLDwzl06BB58+Zl1apV7Ny5k/79+xMcHEy5cuWwtbXl+vXrWbZTtmxZjhw5wl9//WUq27NnT4Y6u3fvxmj8vwWodu7ciZOTE0WLFn1grHZ2drRq1YqIiAi++uorSpcubbZA3c6dOwkJCaFly5b4+/tTuHDhB96aKStpafeuw01f0K1atWps377dbOGGyMhISpcunemUdhH5Pz///DOBgYEEBgYCMHDgQAIDAwkNDQXgu+++IzAwkNdeew2A9u3bExgYyLx58x76WAsWLKBVq1bkz58/w7aEhASioqLMfo8jIiIoU6aMaRp7zZo1dRcGERERyVU0cv4c2Lt3L5s3byYoKIiCBQuyd+9erl27RtmyZSlZsiRffvkllStXJjY2lsGDB5vdQ/h+HTt2ZOTIkfTo0YPhw4cTHR3NtGnTzOr06dOHmTNn0q9fP/r27UtUVBRjxoxh4MCB2V5v/nedOnWiadOmHDt2LMPIWMmSJVm5ciXNmjXDYDAwevRoU5L9oNdh//791KxZE1dXV06fPs3o0aPx9fU1Tc3v2LEj4eHhdO/enaFDh3L06FFmzZplNnIvIpmrU6eO2Zdy9wsJCSEkJOSh2syqvV27dj1UHG5ubixduvShji0iIiLyJCk5fw44Ozuzfft2Zs6cSWxsLMWLF2f69Ok0adKEwoUL07NnTypWrIi3tzcffvghgwYNyrItR0dHvv/+e3r16kVgYCAvvvgikydPpnXr1qY6RYoUYd26dQwePJiAgADc3Nzo3r07o0aNynHM9erVw83NjaioKDp27Gi27aOPPuKtt96ievXqeHh4MHTo0BwttODg4MDKlSsZM2YM8fHxeHp60rhxY0aNGmW6ZtzFxYWNGzfy7rvvUqlSJTw8PAgNDc3yNmrZ2Tu8Pu7u7g+9n8ijlJyczLp16zga1kjXsYmIiIjkYgZjdsMcIvLQYmNjcXFx4fr160rOxeLSk/Pg4GAl52Jx6o+SW6gvSm6i/vhsS88N7ty5g7Ozc7Z1dc25iIiIiIiIiIUpOZcnKiYmBkdHxywfWd3CTURERERE5Fmma87lifLy8uLw4cPZbhcREREREXneKDmXJypPnjz4+flZOgwREREREZFcRdPaRURERERERCxMybmIiIiIiIiIhSk5FxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmFKzkVEREREREQsTMm5iIiIiIiIiIUpORcRERERERGxMCXnIiIiIiIiIhaWx9IBiDyrqkzcTEqefJYOQ55zttZGprwCL4VtIDHV8K/bi570GgDbt29n6tSpHDhwgEuXLrFq1SpatGhhqrdy5UrmzZvHgQMHuHnzJocOHaJChQpmbc2fP5+lS5dy8OBB7t69y61bt8ifP79ZnZMnTzJ48GB27txJUlIS5cuXZ9y4cdStWzfLGI1GI2PGjOHTTz/l9u3b1KhRg08++YSSJUv+6/MXEREReVye25Fzg8HA6tWrs9weHR2NwWDg8OHDTyymR6VOnToMGDDA9NzHx4eZM2daLJ7cYtGiRRk++IvIPxMfH09AQABz587NcnvNmjWZPHlylm0kJCTQuHFjRowYkWWdpk2bkpKSwo8//siBAwcICAigadOmXL58Oct9pkyZwn/+8x/mzZvH3r17yZcvH40aNeKvv/7K+QmKiIiIPGEaOX8O7N+/n3z5cv8IbkhICF988YVZWaNGjVi/fv1jOV5YWBirV6/O8AXMO++8w6ZNm7h48SKOjo5Ur16dyZMnU6ZMmccSh8jTqEmTJjRp0iTL7Z07dwbufdGZlfQvEbdu3Zrp9uvXr/P777+zYMECypcvD8CkSZP4+OOPOXr0KIULF86wj9FoZObMmYwaNYrmzZsDsHjxYgoVKsTq1atp3759Ds5ORERE5Ml7bkfOnycFChTAwcHB0mFkKSkpyfRz48aNuXTpkunx1VdfPfF4KlWqxMKFCzl+/DgbNmzAaDQSFBREamrqE49F5Hnm7u5O6dKlWbx4MfHx8aSkpPDf//6XggULUqlSpUz3OXv2LJcvX6ZBgwamMhcXF6pUqcLu3bufVOgiIiIiD+2pTs5XrFiBv78/9vb2uLu706BBA+Lj49m/fz8NGzbEw8MDFxcXateuzcGDB7Nta9++fQQGBmJnZ0flypU5dOhQhjrbtm3jlVdewdbWFk9PT4YNG0ZKSkqOYq1Tpw79+vVjwIABuLq6UqhQIT799FPi4+Pp1q0bTk5O+Pn58cMPP5jtd/ToUZo0aYKjoyOFChWic+fOXL9+3bQ9Pj6eLl264OjoiKenJ9OnT89w7PuntcfExNC8eXMcHR1xdnambdu2XLly5YHncPLkSQwGAydOnDArnzFjBr6+vgCkpqbSvXt3SpQogb29PaVLl2bWrFlm9UNCQmjRogUTJkzAy8uL0qVLm7bZ2tpSuHBh08PV1fWBccG9kTeDwcDt27dNZYcPH8ZgMGQ6crdo0SLCw8P55ZdfMBgMGAwGFi1aBEDPnj2pVasWPj4+VKxYkfHjx3Pu3LlsRwBF5NEzGAxs2rSJQ4cO4eTkhJ2dHR999BHr16/P8m9D+nT3QoUKmZUXKlQo26nwIiIiIpb21E5rv3TpEh06dGDKlCm0bNmSu3fvsmPHDoxGI3fv3qVr167Mnj0bo9HI9OnTCQ4O5vfff8fJySlDW3FxcTRt2pSGDRuyZMkSzp49y3vvvWdW58KFCwQHBxMSEsLixYs5ceIEPXr0wM7OjrCwsBzF/MUXXzBkyBD27dvH8uXL6d27N6tWraJly5aMGDGCGTNm0LlzZ2JiYnBwcOD27dvUq1ePt99+mxkzZvDnn38ydOhQ2rZty48//gjA4MGD2bZtG99++y0FCxZkxIgRHDx4MMPCS+nS0tJMifm2bdtISUnh3XffpV27dllOLU1XqlQpKleuTEREBOPGjTOVR0RE0LFjR1P7RYsW5X//+x/u7u7s2rWLnj174unpSdu2bU37bN68GWdnZyIjI82OsXXrVgoWLIirqyv16tVj/PjxuLu75+j1fRjt2rXj6NGjrF+/nk2bNgH3RtfuFx8fz8KFCylRogTe3t6ZtpWYmEhiYqLpeWxsLAC2VkasrY2PPHaRh2FrZTT7999KTk7OtDwlJSXTbellycnJ2e6bWR2j0Ujv3r0pUKAAW7Zswd7ens8//5xmzZqxa9cuPD09c9xWWloaBoMhyxjkyfh7fxCxJPVFyU3UH59tD/O+PtXJeUpKCq1ataJ48eIA+Pv7A1CvXj2zuvPnzyd//vxs27aNpk2bZmhr6dKlpKWlsWDBAuzs7ChXrhznz5+nd+/epjoff/wx3t7ezJkzB4PBQJkyZbh48SJDhw4lNDQUK6sHT0IICAhg1KhRAAwfPpxJkybh4eFBjx49AAgNDeWTTz7hyJEjVK1alTlz5hAYGMiHH35oauPzzz/H29ubkydP4uXlxYIFC1iyZAn169cH7n0BULRo0Sxj2Lx5M7/++itnz541JZuLFy+mXLly7N+/n5dffjnbc+jUqRNz5swxJecnT57kwIEDLFmyBAAbGxvCw8NN9UuUKMHu3bv5+uuvzZLzfPny8dlnn5E3b15TWePGjWnVqhUlSpTg9OnTjBgxgiZNmrB7926sra0f+Po+DHt7exwdHcmTJ0+m161+/PHHDBkyhPj4eEqXLk1kZKRZrH83ceJEs3NONyowDQcHTYWX3GFc5bRH0s66desyLT9w4AA2NjYZytNn5fz0009cvHgx031//fVXADZu3Iijo6Op/JdffmHdunUsWbKE27dvc/v2bZo0acJ3333HqFGjaN26dYa20kfHv/nmG1544QVT+YkTJyhRokSW8cuTdf8XsyKWor4ouYn647MpISEhx3Wf2uQ8ICCA+vXr4+/vT6NGjQgKCqJNmza4urpy5coVRo0axdatW7l69SqpqakkJCQQExOTaVvHjx+nfPny2NnZmcqqVauWoU61atUwGP7vVkQ1atQgLi6O8+fPU6xYsQfGnL6gEYC1tTXu7u6mLxTg/6ZhXr16Fbj3wXTLli1mH1bTnT59mj///JOkpCSqVKliKndzczObJp7ZuXp7e5uNAr/44ovkz5+f48ePPzA5b9++PYMGDWLPnj1UrVqViIgIKlasaLZY2ty5c/n888+JiYkxxXj/SL6/v3+GZPfvCzX5+/tTvnx5fH192bp1q+nLhyelU6dONGzYkEuXLjFt2jTatm3Lzp07zfpIuuHDhzNw4EDT89jYWLy9vRl/yIoUm0f7pYLIw7K1MjKuchqjf7YiMe3f30rtaFijTMsrVapEcHBwhvL0y0Fq1qyZ5Yye9AUrg4KCzO6okJZ27wuFxo0bm/0ddHR0pGTJkpkez2g0EhYWRnJysml7bGwsp06dYtiwYZnuI09OcnIykZGRNGzYMNMvc0SeFPVFyU3UH59t6bNqc+KpTc6tra2JjIxk165dbNy4kdmzZzNy5Ej27t1L7969uXHjBrNmzaJ48eLY2tpSrVo1s4XHLOH+XzaDwWBWlp74p38gjYuLo1mzZpneisjT05NTp049xmgzV7hwYerVq8fSpUupWrUqS5cuNZthsGzZMgYNGsT06dOpVq0aTk5OTJ06lb1795q1k5PV41944QU8PDw4derUA5Pz9JkLRuP/Td39N1ODXFxccHFxoWTJklStWhVXV1dWrVpFhw4dMtS1tbXF1tY2Q3limoGUR3BfaZFHITHN8Ejuc57+NysuLs7sb9C5c+c4duwYbm5uFCtWjJs3bxITE2MaLT9z5gw2Njam9STg3ij35cuXTQn8iRMncHJyolixYri5ufHqq6/i6urK22+/TWhoKPb29nz66adER0fz+uuvm2IpU6YMEydOpGXLlsC9VeAnTpxImTJlKFGiBKNHj8bLy4s2bdroQ08uYWNjo/dCcgX1RclN1B+fTQ/znj7VC8IZDAZq1KhBeHg4hw4dIm/evKxatYqdO3fSv39/goODKVeuHLa2tmaLqN2vbNmyHDlyxOweuHv27MlQZ/fu3WbJ386dO3Fycsp2Gvm/UbFiRY4dO4aPjw9+fn5mj3z58uHr64uNjY1Z4nvr1i1OnjyZZZtly5bl3LlznDt3zlT222+/cfv2bV588cUcxdWpUyeWL1/O7t27OXPmjNmI986dO6levTp9+vQhMDAQPz8/Tp8+/Q/OHs6fP8+NGzcyva70fgUKFADuXe6Q7kH3qM+bN2+OVmA3Go0YjUaz68pFnnc///wzgYGBBAYGAjBw4EACAwMJDQ0F4LvvviMwMJDXXnsNuDczJjAwkHnz5pnamDdvHoGBgaZLe2rVqkVgYCDfffcdAB4eHqxfv564uDjq1atH5cqV+emnn/j2228JCAgwtRMVFcWdO3dMz4cMGUK/fv3o2bMnL7/8MnFxcaxfvz7TmS8iIiIiucVTm5zv3buXDz/8kJ9//pmYmBhWrlzJtWvXKFu2LCVLluTLL7/k+PHj7N27l06dOmFvb59lWx07dsRgMNCjRw9+++031q1bx7Rp08zq9OnTh3PnztGvXz9OnDjBt99+y5gxYxg4cGCOrjf/J959911u3rxJhw4d2L9/P6dPn2bDhg1069aN1NRUHB0d6d69O4MHD+bHH3/k6NGjhISEZBtPgwYN8Pf3p1OnThw8eJB9+/bRpUsXateuTeXKlXMUV6tWrbh79y69e/embt26eHl5mbaVLFmSn3/+mQ0bNnDy5ElGjx7N/v37H9hmXFwcgwcPZs+ePURHR7N582aaN2+On58fjRplPo327/z8/PD29iYsLIzff/+dtWvXZrpy/d/5+Phw9uxZDh8+zPXr10lMTOTMmTNMnDiRAwcOEBMTw65du3jjjTewt7fXdFiRv6lTp47pi6u/P9LvehASEpLp9r8voBkWFpZpnZCQEFOdypUrs2HDBm7cuEFsbCy7d+/OcH/1+/cxGAyMHTuWy5cv89dff7Fp0yZKlSr1GF8NERERkX/vqU3OnZ2d2b59O8HBwZQqVYpRo0Yxffp0mjRpwoIFC7h16xYVK1akc+fO9O/fn4IFC2bZlqOjI99//z2//vorgYGBjBw5MsNU8iJFirBu3Tr27dtHQEAAvXr1onv37qYF3h4HLy8vdu7cSWpqKkFBQfj7+zNgwADy589vSsCnTp3Kq6++SrNmzWjQoAE1a9bM8v6/cO9D67fffourqyu1atWiQYMGvPDCCyxfvjzHcTk5OdGsWTN++eUXOnXqZLbtnXfeoVWrVrRr144qVapw48YN+vTp88A2ra2tOXLkCK+//jqlSpWie/fuVKpUiR07dmQ6Zfx+NjY2fPXVV5w4cYLy5cszefJkxo8fn+0+rVu3pnHjxtStW5cCBQrw1VdfYWdnx44dOwgODsbPz4927drh5OTErl27su1DIiIiIiIi/4bB+Pd52iLyr8XGxuLi4sL169cfy23gRB5GcnIy69atIzg4WNexicWpP0puob4ouYn647MtPTe4c+cOzs7O2dZ9akfORURERERERJ4VSs4fgZiYGBwdHbN8ZHULt9yoXLlyWZ5HRESExeL68MMPs4zr/utPRUREREREnjZP7a3UchMvL69sVwb/+4Jpud26deuyvAVZ+n3YLaFXr160bds2023ZLfYnIiIiIiLyNFBy/gjkyZMHPz8/S4fxSBQvXtzSIWTKzc0NNzc3S4chIiIiIiLyWGhau4iIiIiIiIiFKTkXERERERERsTAl5yIiIiIiIiIWpuRcRERERERExMKUnIuIiIiIiIhYmJJzEREREREREQtTci4iIiIiIiJiYUrORURERERERCxMybmIiIiIiIiIhSk5FxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTC8lg6AJFnVZWJm0nJk8/SYUguEj3pNUuHICIiIiK5lEbO5bnh4+PDzJkzLR2GPOdSU1MZPXo0JUqUwN7eHl9fX8aNG4fRaDTVWblyJUFBQbi7u2MwGDh8+HCGdurUqYPBYDB79OrVK9tjG41GQkND8fT0xN7engYNGvD7778/6lMUERERkX9Aybk8dtHR0XTv3t0sGRkzZgxJSUmmOlu3bqV58+Z4enqSL18+KlSoQERExGONy2AwsHr1arOyn376iRo1auDu7o69vT1lypRhxowZjzUOeb5MnjyZTz75hDlz5nD8+HEmT57MlClTmD17tqlOfHw8NWvWZPLkydm21aNHDy5dumR6TJkyJdv6U6ZM4T//+Q/z5s1j79695MuXj0aNGvHXX389knMTERERkX9O09rlsUpKSuLEiROkpaXx3//+Fz8/P44ePUqPHj2Ij49n2rRpAOzatYvy5cszdOhQChUqxJo1a+jSpQsuLi40bdr0icWbL18++vbtS/ny5cmXLx8//fQT77zzDvny5aNnz55PLA55du3atYvmzZvz2mv3prj7+Pjw1VdfsW/fPlOdzp07A/e+2MqOg4MDhQsXztFxjUYjM2fOZNSoUTRv3hyAxYsXU6hQIVavXk379u3/wdmIiIiIyKOikXMLqVOnDv3792fIkCG4ublRuHBhwsLCgHsfyO+fynr79m0MBgNbt24F7o00GwwGNmzYQGBgIPb29tSrV4+rV6/yww8/ULZsWZydnenYsSMJCQkPjGf+/Pl4eXmRlpZmVt68eXPeeustAE6fPk3z5s0pVKgQjo6OvPzyy2zatMmsvo+PD+PGjaNLly44OzvTs2dPGjduzMKFCwkKCuKFF17g9ddfZ9CgQaxcudK034gRIxg3bhzVq1fH19eX9957j8aNG5vVedDrOWDAALOyFi1aEBISkml9Hx8fAFq2bInBYDA9DwwMpEOHDpQrVw4fHx/efPNNGjVqxI4dO3IUh8iDVK9enc2bN3Py5EkAfvnlF3766SeaNGny0G1FRETg4eHBSy+9xPDhw7P9XT979iyXL1+mQYMGpjIXFxeqVKnC7t27H/5EREREROSR0si5BX3xxRcMHDiQvXv3snv3bkJCQqhRowYlS5bMcRthYWHMmTMHBwcH2rZtS9u2bbG1tWXp0qXExcXRsmVLZs+ezdChQ7Nt54033qBfv35s2bKF+vXrA3Dz5k3Wr1/PunXrAIiLiyM4OJgJEyZga2vL4sWLadasGVFRURQrVszU1rRp0wgNDWXMmDFZHu/OnTu4ubllG9OdO3coW7ZsTl+Kh7J//34KFizIwoULady4MdbW1pnWO3ToELt27WL8+PFZtpWYmEhiYqLpeWxsLAC2VkasrY1Z7SbPoeTkZD744ANu3bpFmTJlsLa2JjU1lbFjx9K2bVuSk5Mz1E//9/5t7dq1o1ixYnh6evLrr78ycuRIjh8/zv/+979M27hw4QIAbm5uZm0VKFCAixcvZmhf5HH4e58WsST1RclN1B+fbQ/zvio5t6Dy5cubEtiSJUsyZ84cNm/e/FDJ+fjx46lRowYA3bt3Z/jw4Zw+fZoXXngBgDZt2rBly5YHJueurq40adKEpUuXmpLzFStW4OHhQd26dQEICAggICDAtM+4ceNYtWoV3333HX379jWV16tXjw8++CDLY506dYrZs2ebprRn5uuvv2b//v3897//fcAr8M8UKFAAgPz582c6Lbho0aJcu3aNlJQUwsLCePvtt7Nsa+LEiYSHh2coHxWYhoND6qMLWp5669atY8eOHSxatIiBAwfi7e3N2bNnmTJlCteuXaNevXpm9a9cuQLcWwvh4sWLZtu8vLxISUnh3Llz5M+fn3feeYfQ0FAWLFiAp6dnhmPv378fgM2bN5t9MXbp0iUMBoPpSziRJyEyMtLSIYgA6ouSu6g/PptyMos5nZJzCypfvrzZc09PT65evfqP2yhUqBAODg6mxDy97O/XsmanU6dO9OjRg48//hhbW1siIiJo3749Vlb3rn6Ii4sjLCyMtWvXcunSJVJSUvjzzz+JiYkxa6dy5cpZHuPChQs0btyYN954gx49emRaZ8uWLXTr1o1PP/2UcuXK5Sj2R23Hjh3ExcWxZ88ehg0bhp+fHx06dMi07vDhwxk4cKDpeWxsLN7e3ow/ZEWKTeYj8vJ8OhrWiL59+xIaGkrv3r1N5a6urixdujTDF1bp15zXrFmTChUqZNt27dq1CQ0Nxdvbm6CgIFN5cnIykZGRNG3alGHDhvHSSy+ZtTV9+nQCAgIIDg7+1+cn8iDp/bFhw4bY2NhYOhx5jqkvSm6i/vhsS59VmxNKzi3o/l8+g8FAWlqaKRn++62VspoO8fc2DAZDlm3mRLNmzTAajaxdu5aXX36ZHTt2mK1UPmjQICIjI5k2bRp+fn7Y29vTpk0bs1XX4d6iapm5ePEidevWpXr16syfPz/TOtu2baNZs2bMmDGDLl265ChuACsrK7PXC/7d1KASJUoA4O/vz5UrVwgLC8syObe1tcXW1jZDeWKagZRUwz+OQZ49NjY2JCQkYGNjY/a7mjdvXoxGY4bf3/Tn99fPzLFjxwDw9vbOtG7JkiUpXLgw27dv5+WXXwbu/Wexb98++vTpow8D8kTlpE+LPAnqi5KbqD8+mx7mPVVyngulT7m+dOkSgYGBAJne5/hRs7Ozo1WrVkRERHDq1ClKly5NxYoVTdt37txJSEgILVu2BO6NpD9oNel0Fy5coG7dulSqVImFCxeavoD4u61bt9K0aVMmT5780CujFyhQgEuXLpmep6amcvToUdOU/MzY2NiQmvrgaedpaWlm15SL/BvNmjVjwoQJFCtWjHLlynHo0CE++ugj08KLcG+9h5iYGNNU9qioKAAKFy5M4cKFOX36NEuXLiU4OBh3d3eOHDnC+++/T61atcxm05QpU4Zx48aRN29eDAYDAwYMYPz48ZQsWZISJUowevRovLy8aNGixRN9DUREREQkIyXnuZC9vT1Vq1Zl0qRJlChRgqtXrzJq1KgncuxOnTrRtGlTjh07xptvvmm2rWTJkqxcuZJmzZphMBgYPXp0jkblL1y4QJ06dShevDjTpk3j2rVrpm3p13tv2bKFpk2b8t5779G6dWsuX74M3BtRfNDCcXDvOveBAweydu1afH19+eijj7h9+3a2+/j4+LB582Zq1KiBra0trq6uzJ07l2LFilGmTBkAtm/fzrRp0+jfv/8DYxDJidmzZzN69Gj69OnD1atX8fLyMl0vnu67776jW7dupufptzkbM2YMYWFh5M2bl02bNjFz5kzi4+Px9vamdevWGf5OREVFERsbi4eHBwBDhgwhPj6enj17cvv2bWrWrMn69euxs7N7AmcuIiIiItlRcp5Lff7553Tv3p1KlSpRunRppkyZYnYd6eNSr1493NzciIqKomPHjmbb0kf3qlevjoeHB0OHDs3RNRSRkZGcOnWKU6dOUbRoUbNt6VPRv/jiCxISEpg4cSITJ040ba9du7bp9nHZeeutt/jll1/o0qULefLk4f3338921BzuXWs7cOBAPv30U4oUKUJ0dDRpaWkMHz6cs2fPkidPHnx9fZk8eTLvvPPOA2MQyQknJydmzpzJzJkzs6wTEhKS5W0A4d7U9W3btj3wWEajkeTkZNNibwaDgbFjxzJ27NiHDVtEREREHjOD8f4LdUXkX4mNjcXFxYXr16/j7u5u6XDkOZeenAcHB+s6NrE49UfJLdQXJTdRf3y2pecGd+7cwdnZOdu6GS/8FREREREREZEnSsn5cyImJgZHR8csH/ffDi23yS72HTt2WDo8ERERERGRf0XXnD8nvLy8sl3x3cvL68kF8w9kF3uRIkWeXCAiIiIiIiKPgZLz50SePHnw8/OzdBj/2NMcu4iIiIiIyINoWruIiIiIiIiIhSk5FxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmFKzkVEREREREQsTMm5iIiIiIiIiIUpORcRERERERGxMCXnIiIiIiIiIham5FxERERERETEwpSci4iIiIiIiFhYHksHIPKsqjJxMyl58lk6DHkCoie9BoCPjw9//PFHhu19+vRh7ty51KlTh23btplte+edd5g3b57p+f79+xk2bBgHDhzAYDDwyiuvMGXKFAICArI8/l9//cUHH3zAsmXLSExMpFGjRnz88ccUKlToEZ2hiIiIiDxuGjmXXCEkJIQWLVpYOgyRf2X//v1cunTJ9IiMjATgjTfeMNXp0aOHWZ0pU6aYtsXFxdG4cWOKFSvG3r17+emnn3BycqJRo0YkJydnedz333+f77//nv/9739s27aNixcv0qpVq8d3oiIiIiLyyCk5l4eSmJhIhQoVMBgMHD582FQeHR2NwWDI8NizZ4/lgv0HXn/9dYoVK4adnR2enp507tyZixcvWjoseUoUKFCAwoULmx5r1qzB19eX2rVrm+o4ODiY1XF2djZtO3HiBDdv3mTs2LGULl2acuXKMWbMGK5cuZLpiDzAnTt3WLBgAR999BH16tWjUqVKLFy4kF27dj11v38iIiIizzMl55KtpKQks+dDhgzBy8sry/qbNm0yGxWsVKnS4w7xkapbty5ff/01UVFRfPPNN5w+fZo2bdpYOix5CiUlJbFkyRLeeustDAaDqTwiIgIPDw9eeuklhg8fTkJCgmlb6dKlcXd3Z8GCBSQlJfHnn3+yYMECypYti4+PT6bHOXDgAMnJyTRo0MBUVqZMGYoVK8bu3bsf2/mJiIiIyKOla87/oTp16lC+fHns7Oz47LPPyJs3L7169SIsLIzo6GhKlCjBoUOHqFChAgC3b9/G1dWVLVu2UKdOHbZu3UrdunVZv349w4YN48SJE1SrVo1ly5Zx4MABBg4cyIULF2jatCmfffYZDg4O2cYzf/58wsLCOH/+PFZW//edS/PmzXF3d+fzzz/n9OnTDBw4kD179hAfH0/ZsmWZOHGi2Yd6Hx8funfvzu+//87q1atp1aoVixYtAuCHH35g48aNfPPNN/zwww+ZxuHu7k7hwoX/8es6bdo0pk+fTlJSEu3bt2fmzJnY2NgA8OWXXzJr1iyioqLIly8f9erVY+bMmRQsWNC0/7Fjxxg6dCjbt2/HaDRSoUIFFi1ahK+vLwCfffYZ06dP5+zZs/j4+NC/f3/69Olj2v/99983/Vy8eHGGDRtGixYtSE5ONsVxv8TERBITE03PY2NjAbC1MmJtbfzHr4U8PTKbcr5ixQpu375Np06dTNvbtWtHsWLF8PT05Ndff2XkyJEcP36c//3vfwDY2dkRGRnJG2+8wbhx4wDw8/Nj7dq1GI3GTI9z/vx58ubNS758+cy2FyxYkAsXLpjKspsWL/KkqD9KbqG+KLmJ+uOz7WHeVyXn/8IXX3zBwIED2bt3L7t37yYkJIQaNWpQsmTJHLcRFhbGnDlzcHBwoG3btrRt2xZbW1uWLl1KXFwcLVu2ZPbs2QwdOjTbdt544w369evHli1bqF+/PgA3b95k/fr1rFu3Drh3PWtwcDATJkzA1taWxYsX06xZM6KioihWrJiprWnTphEaGsqYMWNMZVeuXKFHjx6sXr062y8KXn/9df766y9KlSrFkCFDeP3113P8WmzZsgVPT0+2bNnCqVOnaNeuHRUqVKBHjx7AvY49btw4SpcuzdWrVxk4cCAhISGm87tw4QK1atWiTp06/Pjjjzg7O7Nz505SUlKAeyOWoaGhzJkzh8DAQA4dOkSPHj3Ily8fXbt2zRDPzZs3iYiIoHr16lkm5gATJ04kPDw8Q/mowDQcHFJzfP7y9Ervg383depUAgMDOXz4sOkSEC8vL1JSUjh37hz58+fnnXfeITQ0lAULFuDp6UliYiKjRo2iWLFi9OrVi7S0NFavXk39+vWZOnUqtra2GY5z+PBh0tLSMsRw584dzpw5Y7ruPf1fkdxA/VFyC/VFyU3UH59Nf58l+SAGo9Goob1/oE6dOqSmprJjxw5T2SuvvEK9evXo1atXjkfON23aZEqmJ02axPDhwzl9+jQvvPACAL169SI6Opr169c/MKYWLVqYpsTCvdH08PBwzp07Zzaa/ncvvfQSvXr1om/fvsC9kfPAwEBWrVplqmM0GgkODqZGjRqMGjUq05kB169fZ/HixdSoUQMrKyu++eYbpkyZwurVq3OUoIeEhLB161ZOnz6NtbU1AG3btsXKyoply5Zlus/PP//Myy+/zN27d3F0dGTEiBEsW7aMqKioTJNpPz8/xo0bR4cOHUxl48ePZ926dezatctUNnToUObMmUNCQgJVq1ZlzZo1uLu7Zxl7ZiPn3t7evDh4GSk2Wq39eXA0rJHZ8z/++IPSpUvz9ddfZ9v/4+PjcXV1Zc2aNQQFBbFw4UJGjx5NTEyM6Xc2KSmJggUL8t///pd27dplaGPLli00atSIq1evkj9/flO5n58f/fr1o0+fPkRGRtKwYcNsv2QSeRKSk5PVHyVXUF+U3ET98dkWGxuLh4cHd+7cMVtrKDMaOf8Xypcvb/bc09OTq1ev/uM2ChUqhIODgykxTy/bt29fjtrq1KkTPXr04OOPP8bW1paIiAjat29v+pAfFxdHWFgYa9eu5dKlS6SkpPDnn38SExNj1k7lypXNns+ePZu7d+8yfPjwLI/t4eHBwIEDTc9ffvllLl68yNSpU3M8el6uXDlTYg6Ypv6mO3DgAGFhYfzyyy/cunWLtLQ0AGJiYnjxxRc5fPgwr776aqZ/1OLj4zl9+jTdu3c3jcQDpKSk4OLiYlZ38ODBdO/enT/++IPw8HC6dOnCmjVrzK4b/jtbW9tMRzQT0wykpGa+jzxb7u9zS5YsoWDBgjRv3pw8ebL+M3vs2DEAvL29sbGxITExESsrK/LmzWvqb+mLK1pZWWXat6tUqYKNjQ3bt2+ndevWAERFRRETE0PNmjVN+9jY2Og/fMk11B8lt1BflNxE/fHZ9DDvqRaE+xfuf6ENBgNpaWmmZPjvkxKyutbg720YDIYs28yJZs2aYTQaWbt2LefOnWPHjh106tTJtH3QoEGsWrWKDz/8kB07dnD48GH8/f0zLPqWL5/5aO+PP/7I7t27sbW1JU+ePPj5+QH3kvjMpoOnq1KlCqdOncpR7JD16wn3kutGjRrh7OxMREQE+/fvN43up8dvb2+fZdtxcXEAfPrpp6ZpxocPH+bo0aMZVrT28PCgVKlSNGzYkGXLlrFu3Tqtei05lpaWxsKFC+natatZYn769GnGjRvHgQMHiI6O5rvvvqNLly7UqlXL9CVdw4YNuXXrFu+++y7Hjx/n2LFjdOvWjTx58lC3bl3g3uUbZcqUMX1p5+LiQvfu3Rk4cCBbtmzhwIEDdOvWjWrVqlG1atUn/wKIiIiIyD+ikfPHoECBAgBcunSJwMBAALPbjj0udnZ2tGrVioiICE6dOkXp0qWpWLGiafvOnTsJCQmhZcuWwL2ENTo6+oHt/uc//2H8+PGm5xcvXqRRo0YsX76cKlWqZLnf4cOH8fT0/Ocn9DcnTpzgxo0bTJo0CW9vb+DetPa/K1++PF988UWmi7cVKlQILy8vzpw5Y/aFxYOkfznw92nrItnZtGkTMTExvPXWW2blefPmZdOmTcycOZP4+Hi8vb1p3bo1o0aNMtUpU6YM33//PeHh4VSrVg0rKysCAwNZv3696XcpOTmZqKgos+uXZsyYgZWVFa1btyYxMZFGjRrx8ccfP5kTFhEREZFHQsn5Y2Bvb0/VqlWZNGkSJUqU4OrVq2YfwB+nTp060bRpU44dO8abb75ptq1kyZKsXLmSZs2aYTAYGD16dI5G5f++WByAo6MjAL6+vhQtWhS4tzhe3rx5TV9GrFy5ks8//5zPPvvsUZwWxYoVI2/evMyePZtevXpx9OhR02rW6fr27cvs2bNp3749w4cPx8XFhT179vDKK69QunRpwsPD6d+/Py4uLjRu3JjExER+/vlnbt26ZVrYb//+/dSsWRNXV1dOnz7N6NGj8fX1pVq1ao/kPOTZFxQURGZLeXh7e7Nt27YH7t+wYUMaNmyY5XYfH58M7dvZ2TF37lzmzp378AGLiIiISK6g5Pwx+fzzz+nevTuVKlWidOnSTJkyhaCgoMd+3Hr16uHm5kZUVBQdO3Y02/bRRx/x1ltvUb16dTw8PBg6dKjptl+Pwrhx4/jjjz/IkycPZcqUYfny5Y/sHuEFChRg0aJFjBgxgv/85z9UrFiRadOmmV3P7u7uzo8//sjgwYOpXbs21tbWVKhQgRo1agDw9ttv4+DgwNSpUxk8eDD58uXD39+fAQMGAODg4MDKlSsZM2YM8fHxeHp60rhxY0aNGpXpNeUPsnd4/WwXkhMREREREUmn1dpFHrHY2FhcXFy4fv26knOxuOTkZNatW0dwcLAWmRGLU3+U3EJ9UXIT9cdnW3pukJPV2rUgnIiIiIiIiIiFKTl/SsTExODo6Jjl4/7boeU22cX+93vFi4iIiIiIPI90zflTwsvLK9sV3728vJ5cMP9AdrEXKVLkyQUiIiIiIiKSCyk5f0r8/f7iT6OnOXYREREREZHHTdPaRURERERERCxMybmIiIiIiIiIhSk5FxEREREREbEwJeciIiIiIiIiFqbkXERERERERMTClJyLiIiIiIiIWJiScxERERERERELU3IuIiIiIiIiYmFKzkVEREREREQsTMm5iIiIiIiIiIUpORcRERERERGxMCXnIiIiIiIiIhaWx9IBiDyrqkzcTEqefJYOQ/6B6EmvAXDhwgWGDh3KDz/8QEJCAn5+fixcuJDKlSsDEBcXx7Bhw1i9ejU3btygRIkS9O/fn169epnaeuedd9i0aRMXL17E0dGR6tWrM3nyZMqUKZPl8Y1GI2PGjOHTTz/l9u3b1KhRg08++YSSJUs+3hMXEREREYt5bkfODQYDq1evznJ7dHQ0BoOBw4cPP7GYHpU6deowYMAA03MfHx9mzpxpsXhyi0WLFpE/f35LhyFPiVu3blGjRg1sbGz44Ycf+O2335g+fTqurq6mOgMHDmT9+vUsWbKE48ePM2DAAPr27ct3331nqlOpUiUWLlzI8ePH2bBhA0ajkaCgIFJTU7M89pQpU/jPf/7DvHnz2Lt3L/ny5aNRo0b89ddfj/WcRURERMRyntvk/Hmyf/9+evbsaekwHigkJASDwWD2aNy48WM7XlhYGBUqVMhQPn/+fOrUqYOzszMGg4Hbt28/thgk95o8eTLe3t4sXLiQV155hRIlShAUFISvr6+pzq5du+jatSt16tTBx8eHnj17EhAQwL59+0x1evbsSa1atfDx8aFixYqMHz+ec+fOER0dnelxjUYjM2fOZNSoUTRv3pzy5cuzePFiLl68mO0XiiIiIiLydFNy/hwoUKAADg4Olg4jS0lJSaafGzduzKVLl0yPr7766onHk5CQQOPGjRkxYsQTP7bkHt999x2VK1fmjTfeoGDBggQGBvLpp5+a1alevTrfffcdFy5cwGg0smXLFk6ePElQUFCmbcbHx7Nw4UJKlCiBt7d3pnXOnj3L5cuXadCgganMxcWFKlWqsHv37kd3giIiIiKSqzzVyfmKFSvw9/fH3t4ed3d3GjRoQHx8PPv376dhw4Z4eHjg4uJC7dq1OXjwYLZt7du3j8DAQOzs7KhcuTKHDh3KUGfbtm288sor2Nra4unpybBhw0hJSclRrHXq1KFfv34MGDAAV1dXChUqxKeffkp8fDzdunXDyckJPz8/fvjhB7P9jh49SpMmTXB0dKRQoUJ07tyZ69evm7bHx8fTpUsXHB0d8fT0ZPr06RmOff+09piYGJo3b46joyPOzs60bduWK1euPPAcTp48icFg4MSJE2blM2bMMI0mpqam0r17d0qUKIG9vT2lS5dm1qxZZvVDQkJo0aIFEyZMwMvLi9KlS5u22draUrhwYdPj71OIs7N169YMo9yHDx/GYDBkOkK5aNEiwsPD+eWXX0yj9IsWLQJgwIABDBs2jKpVq+bo2PJsOnPmjOk67w0bNtC7d2/69+/PF198Yaoze/ZsXnzxRYoWLUrevHlp3Lgxc+fOpVatWmZtffzxxzg6OuLo6MgPP/xAZGQkefPmzfS4ly9fBqBQoUJm5YUKFTJtExEREZFnz1O7INylS5fo0KEDU6ZMoWXLlty9e5cdO3ZgNBq5e/cuXbt2Zfbs2RiNRqZPn05wcDC///47Tk5OGdqKi4ujadOmNGzYkCVLlnD27Fnee+89szoXLlwgODiYkJAQFi9ezIkTJ+jRowd2dnaEhYXlKOYvvviCIUOGsG/fPpYvX07v3r1ZtWoVLVu2ZMSIEcyYMYPOnTsTExODg4MDt2/fpl69erz99tvMmDGDP//8k6FDh9K27f9j787jqqr2/4+/DoOMgoKg4gQKDpkozoql4gDylcwxlTKVq1k5JDmEmmJqWOJQjjmmXcwGh5uJFimaOWdqZskNjEzFKFMJBwTh94c/9vUIKJoK6vv5eJxH7LXXXvuzz1lIn7PWXrsHW7ZsAWDkyJFs27aN//znP7i7uzNmzBi+++67fKdrA2RnZxuJ+bZt28jKyuLll1/mmWeeYevWrTeNv3r16jRs2JCYmBgmTZpklMfExNC7d2+j/YoVK/LJJ5/g6urKzp07GThwIOXLl6dHjx7GMZs3b8bJyYm4uDizc2zduhV3d3dKly5NQEAAkydPxtXVtVDv7+145pln+OGHH9i0aRNfffUVcG108k5kZGSQkZFhbKelpQFgY5GDpWXOPw9W7rvMzEyys7Np0KABEydOBODxxx/n+++/Z/78+UZ/nzVrFrt27WLNmjVUrlyZb775hpdffhl3d3fatGljtNejRw9atWrF6dOnmTFjBt27d2fbtm3Y2trmOXfuF36ZmZlkZmYa5dnZ2ZhMJrOywl7L9f8VKUrqj1JcqC9KcaL++HC7nc/1gU7Os7Ky6NKlC1WqVAGgTp06AAQEBJjVXbhwIaVKlWLbtm107NgxT1srV64kOzubJUuWYGtrS+3atTlx4gQvvviiUWfevHlUqlSJOXPmYDKZqFmzJqdOnWL06NGMHz8eC4tbT0KoW7cu48aNAyAiIoKpU6dSpkwZBgwYAMD48eOZP38+33//PU2bNmXOnDn4+fnx5ptvGm0sXbqUSpUq8d///hcPDw+WLFnCv//9byMRWL58ORUrViwwhs2bN3P48GF++eUXY1rtihUrqF27Nvv27aNRo0Y3vYbQ0FDmzJljJOf//e9/2b9/P//+978BsLa2NpIZAC8vL3bt2sXHH39slpw7ODiwePFis9HDoKAgunTpgpeXF0lJSYwZM4YOHTqwa9cuLC0tb/n+3g47OzscHR2xsrKiXLly/6itqKgos2vONc4vG3v7ghf9kuIrNjaWUqVK4ejoSGxsrFGelZXFzz//TGxsLBkZGYwbN47XXnsNCwsLTpw4gaenJ02bNmXMmDFMmDAh37b79u3Ls88+S2RkZJ4RdvjfyPnq1aupWrWqUX706FG8vLzM4rkdN34RJlKU1B+luFBflOJE/fHhdPHixULXfWCT87p169KmTRvq1KlDYGAg7du3p1u3bpQuXZrff/+dcePGsXXrVlJTU7l69SoXL17k+PHj+bb1008/4evrazaK1axZszx1mjVrhslkMsr8/f1JT0/nxIkTVK5c+ZYx+/r6Gj9bWlri6upqfKEA/5vGmpqaCsChQ4eIj4/H0dExT1tJSUlcunSJK1eu0KRJE6PcxcXFbJp4ftdaqVIls/tdH3vsMUqVKsVPP/10y+S8Z8+ejBgxgt27d9O0aVNiYmKoX7++2WOh5s6dy9KlSzl+/LgR440j+XXq1Mkzrbdnz55m+319falWrRpbt241G4UsbiIiIggPDze209LSqFSpEpMPWJBlfXe/VJD744fIQAICAjhx4gTBwcFG+ZYtW6hevTrBwcGkpaWRlZVF48aNzRYu/PzzzwHMjrteRkYGFhYWPPbYY/nWycnJITIykszMTGN/WloaiYmJvPbaawW2W5DMzEzi4uJo164d1tbWt3WsyN2m/ijFhfqiFCfqjw+33Fm1hfHAJueWlpbExcWxc+dOvvzyS2bPns3YsWPZs2cPL774ImfOnOGdd96hSpUq2NjY0KxZM7OFx4rCjb9sJpPJrCw38c/OzgauTbcPCQnhrbfeytNW+fLlSUxMvIfR5q9cuXIEBASwcuVKmjZtysqVK81mGKxatYoRI0Ywffp0mjVrRsmSJZk2bRp79uwxa8fB4dbP/65atSplypQhMTHxlsl57syFnJz/TSO/X1ODbGxssLGxyVOekW0i66opnyOkuLO2tubVV1+lefPmTJs2jR49erB3714WL17MwoULsba2xtXVlZYtWxIREUHJkiWpUqUK27Zt49///jczZszA2tqaY8eO8dFHH9G+fXvc3Nw4ceIEU6dOxc7OjpCQEOP3v2bNmkRFRdG5c2fg2roHUVFR1KxZEy8vL15//XU8PDzo1q3bHf/Rtra21h98KTbUH6W4UF+U4kT98eF0O5/pA5ucw7Vk1t/fH39/f8aPH0+VKlVYu3YtO3bsYN68ecYI02+//Wa2iNqNatWqxQcffMDly5eN0fPdu3fnqbN69WpycnKMJHrHjh2ULFnyptPI/4n69euzevVqPD09sbLK+1FVq1YNa2tr9uzZY4zcnz17lv/+97+0bNky3zZr1arFb7/9xm+//WaMnv/444+cO3eOxx57rFBxhYaGMmrUKHr16sWxY8fMRrx37NhB8+bNeemll4yypKSkQl/z9U6cOMGZM2coX778Leu6ubkB1253yF1E7lbPqC9RosRNnzUtj7ZGjRqxdu1aIiIieOONN/Dy8mLWrFmEhoYadVatWkVERAShoaH89ddfVKlShSlTpjBo0CAAbG1t2b59O7NmzeLs2bOULVuWJ598kp07d+Lu7m60k5CQwPnz543tUaNGceHCBQYOHMi5c+do0aIFmzZtyvcedRERERF5ODywyfmePXvYvHkz7du3x93dnT179vDHH39Qq1YtfHx8+OCDD2jYsCFpaWmMHDkSOzu7Atvq3bs3Y8eOZcCAAURERJCcnEx0dLRZnZdeeolZs2YxZMgQBg8eTEJCAhMmTCA8PLxQ95vfiZdffplFixbRq1cvRo0ahYuLC4mJiaxatYrFixfj6OhIWFgYI0eOxNXVFXd3d8aOHXvTeNq2bUudOnUIDQ1l1qxZZGVl8dJLL9GyZUsaNmxYqLi6dOnCiy++yIsvvkjr1q3x8PAw9vn4+LBixQq++OILvLy8+OCDD9i3bx9eXl43bTM9PZ2JEyfStWtXypUrR1JSEqNGjcLb25vAwMBbxuTt7U2lSpWIjIxkypQp/Pe//8135frreXp68ssvv3Dw4EEqVqxIyZIlsbGx4fTp05w+fdqYmXD48GFKlixJ5cqVcXFxKcQ7JA+Ljh075rtORa5y5cqxbNmyAvd7eHgU6h7x62d8wLUvHt944w3eeOONwgcrIiIiIg+0B/ZRak5OTnz99dcEBwdTvXp1xo0bx/Tp0+nQoQNLlizh7Nmz1K9fn+eee46hQ4eajVLdyNHRkfXr13P48GH8/PwYO3ZsnqnkFSpUIDY2lr1791K3bl0GDRpEWFiYscDbveDh4cGOHTu4evUq7du3p06dOrzyyiuUKlXKSMCnTZvGE088QUhICG3btqVFixY0aNCgwDZNJhP/+c9/KF26NE8++SRt27alatWqfPTRR4WOq2TJkoSEhHDo0CGzUUSAF154gS5duvDMM8/QpEkTzpw5YzaKXhBLS0u+//57nnrqKapXr05YWBgNGjRg+/bt+U4Zv5G1tTUffvghR48exdfXl7feeovJkyff9JiuXbsSFBRE69atcXNzM56pvmDBAvz8/IyF+p588kn8/Pz47LPPbhmHiIiIiIjInTDl3DhkIyL/SFpaGs7Ozvz555/35DFwIrcjMzOT2NhYgoODdR+bFDn1Ryku1BelOFF/fLjl5gbnz5/HycnppnUf2JFzERERERERkYeFkvO74Pjx4zg6Ohb4KugRbsVR7dq1C7yOmJiYIovrzTffLDCuDh06FFlcIiIiIiIid8MDuyBcceLh4XHTlcGvXzCtuIuNjS3wEWS5z2EvCoMGDaJHjx757rvZYn8iIiIiIiIPAiXnd4GVlRXe3t5FHcZdUaVKlaIOIV8uLi5aKV1ERERERB5amtYuIiIiIiIiUsSUnIuIiIiIiIgUMSXnIiIiIiIiIkVMybmIiIiIiIhIEVNyLiIiIiIiIlLElJyLiIiIiIiIFLG7lpyfO3fubjUlIiIiIiIi8ki5o+T8rbfe4qOPPjK2e/TogaurKxUqVODQoUN3LTgRERERERGRR8EdJecLFiygUqVKAMTFxREXF8fGjRvp0KEDI0eOvKsBioiIiIiIiDzsrO7koNOnTxvJ+eeff06PHj1o3749np6eNGnS5K4GKCIiIiIiIvKwu6OR89KlS/Pbb78BsGnTJtq2bQtATk4OV69evXvRiYiIiIiIiDwC7mjkvEuXLvTu3RsfHx/OnDlDhw4dADhw4ADe3t53NUARERERERGRh90dJeczZ87E09OT3377jbfffhtHR0cAUlJSeOmll+5qgCIPqiZRm8mycijqMOQ2JE/9v6IOQUREREQeUXc0rd3a2poRI0bwzjvv4OfnZ5QPHz6cf/3rX3ctOJG7ydPTk1mzZhV1GPIAOHnyJM8++yyurq7Y2dlRp04dvv32W7M6P/30E0899RTOzs44ODjQqFEjjh8/buw/ffo0zz33HOXKlcPBwYH69euzevXqW5577ty5eHp6YmtrS5MmTdi7d+9dvz4RERERKX7u+DnnH3zwAS1atMDDw4Nff/0VgFmzZvGf//znrgUnD5+MjAzq1auHyWTi4MGDRnlycjImkynPa/fu3fcsFpPJxLp168zKvvnmG/z9/Y2krGbNmsycOfOexSDFz9mzZ/H398fa2pqNGzfy448/Mn36dEqXLm3USUpKokWLFtSsWZOtW7fy/fff8/rrr2Nra2vU6dOnDwkJCXz22WccPnyYLl260KNHDw4cOFDguT/66CPCw8OZMGEC3333HXXr1iUwMJDU1NR7es0iIiIiUvTuKDmfP38+4eHhdOjQgXPnzhmLwJUqVUojk2LmypUrZtujRo3Cw8OjwPpfffUVKSkpxqtBgwb3OkQzDg4ODB48mK+//pqffvqJcePGMW7cOBYuXHhf45Ci89Zbb1GpUiWWLVtG48aN8fLyon379lSrVs2oM3bsWIKDg3n77bfx8/OjWrVqPPXUU7i7uxt1du7cyZAhQ2jcuDFVq1Zl3LhxlCpViv379xd47hkzZjBgwAD69evHY489xoIFC7C3t2fp0qX39JpFREREpOjdUXI+e/ZsFi1axNixY7G0tDTKGzZsyOHDh+9acA+zVq1aMXToUEaNGoWLiwvlypUjMjIS+N8o8vUjy+fOncNkMrF161YAtm7dislk4osvvsDPzw87OzsCAgJITU1l48aN1KpVCycnJ3r37s3FixdvGc/ChQvx8PAgOzvbrLxTp070798fuDZa2KlTJ8qWLYujoyONGjXiq6++Mqvv6enJpEmT6NOnD05OTgwcONDYt3HjRr788kuio6MLjMPV1ZVy5coZL2tr61vGDtfez1deecWs7Omnn6Zv37751vf09ASgc+fOmEwmY9vPz49evXpRu3ZtPD09efbZZwkMDGT79u2FikMefJ999hkNGzake/fuuLu74+fnx6JFi4z92dnZbNiwgerVqxMYGIi7uztNmjTJMwujefPmfPTRR/z1119kZ2ezatUqLl++TKtWrfI975UrV9i/f7/x9AsACwsL2rZty65du+7FpYqIiIhIMXJHC8L98ssvZvea57KxseHChQv/OKhHxfLlywkPD2fPnj3s2rWLvn374u/vj4+PT6HbiIyMZM6cOdjb29OjRw969OiBjY0NK1euJD09nc6dOzN79mxGjx5903a6d+/OkCFDiI+Pp02bNgD89ddfbNq0idjYWADS09MJDg5mypQp2NjYsGLFCkJCQkhISKBy5cpGW9HR0YwfP54JEyYYZb///jsDBgxg3bp12NvbFxjHU089xeXLl6levTqjRo3iqaeeKvR7cTv27duHu7s7y5YtIygoyOxLpusdOHCAnTt3Mnny5ALbysjIICMjw9hOS0sDwMYiB0vLnLsbuNxTmZmZHDt2jPnz5zNs2DBGjhzJ/v37GTp0KBYWFvTp04fTp0+Tnp7O1KlTmThxIpMnT+bLL7+kS5cuxMXF8eSTTwIQExNDaGgorq6uWFlZYW9vzyeffEKVKlXIzMzMc+6UlBSuXr2Kq6ur2f4yZcrw008/5XtMYa/p+v+KFCX1Ryku1BelOFF/fLjdzud6R8m5l5cXBw8epEqVKmblmzZtolatWnfS5CPJ19fXSGB9fHyYM2cOmzdvvq3kfPLkyfj7+wMQFhZGREQESUlJVK1aFYBu3boRHx9/y+S8dOnSdOjQgZUrVxrJ+aeffkqZMmVo3bo1AHXr1qVu3brGMZMmTWLt2rV89tlnDB482CgPCAjg1VdfNbZzcnLo27cvgwYNomHDhiQnJ+c5v6OjI9OnT8ff3x8LCwtWr17N008/zbp16+5Jgu7m5gZcuxWjXLlyefZXrFiRP/74g6ysLCIjI2+60GFUVBQTJ07MUz7OLxt7+6t3L2i552JjY7l69SrVqlWjefPmpKSk4OHhQZs2bZg2bRplypThr7/+AqBBgwb4+Phw6tQpHn/8cRo2bMjEiRONvr9w4UKSk5OZOHEiTk5O7Nmzh+7du/Pmm28aMzWul9vuzp07jZ8Bjh07xrlz54wvye5UXFzcPzpe5G5Sf5TiQn1RihP1x4dTYWYx57qj5Dw8PJyXX36Zy5cvk5OTw969e/nwww+Jiopi8eLFd9LkI8nX19dsu3z58re98NP1bZQtWxZ7e3sjMc8tK+xqz6GhoQwYMIB58+ZhY2NDTEwMPXv2xMLi2t0P6enpREZGsmHDBlJSUsjKyuLSpUtmK1TDtdsbrjd79mz+/vtvIiIiCjx3mTJlCA8PN7YbNWrEqVOnmDZt2j0bPb+Z7du3k56ezu7du3nttdfw9vamV69e+daNiIgwiz0tLY1KlSox+YAFWdb5j8hL8fRDZCAeHh40b96c4OBgo/y3334jKiqK4OBgrly5wsCBA2nTpo1Zne3bt7Nz506Cg4NJSkoiNjaWAwcOULt2bQBefvllgoKCOHLkSL6PnLxy5QoDBgygWrVqZu1++umn1KhRw6zsdmRmZhIXF0e7du0KfZuIyL2i/ijFhfqiFCfqjw+33Fm1hXFHyfm//vUv7OzsGDduHBcvXqR37954eHjwzjvv0LNnzztp8pF04y+fyWQiOzvbSIZzcv43Jbqg6RDXt2EymQpsszBCQkLIyclhw4YNNGrUiO3bt5utVD5ixAji4uKIjo7G29sbOzs7unXrlmfRNwcH82d7b9myhV27dmFjY2NW3rBhQ0JDQ1m+fHm+8TRp0qTQ3yBaWFiYvV/wz6YGeXl5AVCnTh1+//13IiMjC0zObWxs8lwbQEa2iayrpjuOQe4/a2tr/P39+fnnn81+l5KSkqhSpQrW1tZYW1vTqFEjEhMT89Tx9PTE2tra6Hs2NjZmdaysrIzz5HfuBg0asG3bNrp16wZcu789Pj6ewYMH/+M/1rmxixQH6o9SXKgvSnGi/vhwup3P9LaT86ysLFauXElgYCChoaFcvHiR9PR0s1WK5Z/JnXKdkpJi3Nt//eJw94qtrS1dunQhJiaGxMREatSoQf369Y39O3bsoG/fvnTu3Bm4NpKe3xT1G7377rtm92yfOnWKwMBAPvroI5o0aVLgcQcPHqR8+fKFit3NzY2UlBRj++rVq/zwww/GlPz8WFtbG08auJns7Gyze8rl4TZ8+HCaN2/Om2++SY8ePdi7dy8LFy40W7F/5MiRPPPMMzz55JO0bt2aTZs2sX79emPBxpo1a+Lt7c0LL7xAdHQ0rq6urFu3jri4OD7//HOjnTZt2tC5c2fjtpDw8HCef/55GjZsSOPGjZk1axYXLlygX79+9/U9EBEREZH777aTcysrKwYNGsRPP/0EgL29/U0X+JLbZ2dnR9OmTZk6dSpeXl6kpqYybty4+3Lu0NBQOnbsyJEjR3j22WfN9vn4+LBmzRpCQkIwmUy8/vrrhRqVv36xOLh2fzlAtWrVqFixInBtcbwSJUoYX0asWbOGpUuXFvo2iYCAAMLDw9mwYQPVqlVjxowZnDt37qbHeHp6snnzZvz9/bGxsaF06dLMnTuXypUrU7NmTQC+/vproqOjGTp0aKHikAdfo0aNWLt2LREREbzxxht4eXkxa9YsQkNDjTqdO3dmwYIFREVFMXToUGrUqMHq1atp0aIFcO2Ln9jYWF577TVCQkJIT0/H29ub5cuXm01PT0pK4s8//zS2n3nmGf744w/Gjx/P6dOnqVevHps2baJs2bL37w0QERERkSJxR9PaGzduzIEDB/IsCCd3z9KlSwkLC6NBgwbUqFGDt99+m/bt29/z8wYEBODi4kJCQgK9e/c22zdjxgz69+9P8+bNKVOmDKNHj76teyhuZdKkSfz6669YWVlRs2ZNPvroI2N6763079+fQ4cO0adPH6ysrBg+fPhNR80Bpk+fTnh4OIsWLaJChQokJyeTnZ1NREQEv/zyC1ZWVlSrVo233nqLF1544W5cojwgOnbsSMeOHW9ap3///sZjBvPj4+PD6tWrb9pGfjNPBg8ebLbAooiIiIg8Gkw5N96oWwgff/wxERERDB8+nAYNGuS5x/jGhc5EHiVpaWk4Ozvz559/4urqWtThyCMuMzOT2NhYgoODdR+bFDn1Ryku1BelOFF/fLjl5gbnz5/HycnppnXvaOQ8d9G366f6mkwmcnJyMJlMhbqPV0RERERERESuuaPk/Jdffrnbccg9dvz4cR577LEC9//444957g0vTnLvU8/Pxo0beeKJJ+5jNCIiIiIiInfXHSXnutf8wePh4XHTFd89PDzuXzB34GaxV6hQ4f4FIiIiIiIicg/cUXK+YsWKm+7v06fPHQUj946VlRXe3t5FHcYde5BjFxERERERuZU7Ss6HDRtmtp2ZmcnFixcpUaIE9vb2Ss5FREREREREboPFnRx09uxZs1d6ejoJCQm0aNGCDz/88G7HKCIiIiIiIvJQu6PkPD8+Pj5MnTo1z6i6iIiIiIiIiNzcXUvO4dp9zadOnbqbTYqIiIiIiIg89O7onvPPPvvMbDsnJ4eUlBTmzJmDv7//XQlMRERERERE5FFxR8n5008/bbZtMplwc3MjICCA6dOn3424RERERERERB4Zd5ScZ2dn3+04RERERERERB5Zd3TP+RtvvMHFixfzlF+6dIk33njjHwclIiIiIiIi8ii5o+R84sSJpKen5ym/ePEiEydO/MdBiYiIiIiIiDxK7ig5z8nJwWQy5Sk/dOgQLi4u/zgoERERERERkUfJbd1zXrp0aUwmEyaTierVq5sl6FevXiU9PZ1Bgwbd9SBFREREREREHma3lZzPmjWLnJwc+vfvz8SJE3F2djb2lShRAk9PT5o1a3bXgxQRERERERF5mN1Wcv78888D4OXlRfPmzbG2tr4nQYmIiIiIiIg8Su7oUWotW7Y0fr58+TJXrlwx2+/k5PTPohJ5CDSJ2kyWlUNRh/HISZ76f0RGRuZZnLJGjRocPXqU5ORkvLy88j32448/pnv37gDs27eP1157jf3792MymWjcuDFvv/02devWLfDcly9f5tVXX2XVqlVkZGQQGBjIvHnzKFu27N27QBERERF5KN3RgnAXL15k8ODBuLu74+DgQOnSpc1eIrerb9++PP3000UdhjxEateuTUpKivH65ptvAKhUqZJZeUpKChMnTsTR0ZEOHToAkJ6eTlBQEJUrV2bPnj188803lCxZksDAQDIzMws85/Dhw1m/fj2ffPIJ27Zt49SpU3Tp0uW+XK+IiIiIPNjuKDkfOXIkW7ZsYf78+djY2LB48WImTpyIh4cHK1asuNsxSjGSkZFBvXr1MJlMHDx40ChPTk42Fgu8/rV79+6iC/Y2JScnExYWhpeXF3Z2dlSrVo0JEybkmRkiDwYrKyvKlStnvMqUKQOApaWlWXm5cuVYu3YtPXr0wNHREYCjR4/y119/8cYbb1CjRg1q167NhAkT+P333/n111/zPd/58+dZsmQJM2bMICAggAYNGrBs2TJ27tz5QP0eiIiIiEjRuKPkfP369cybN4+uXbtiZWXFE088wbhx43jzzTeJiYm52zFKEboxMR01ahQeHh4F1v/qq6/MRiQbNGhwr0O8a44ePUp2djbvvfceR44cYebMmSxYsIAxY8YUdWhyB37++Wc8PDyoWrUqoaGhHD9+PN96+/fv5+DBg4SFhRllNWrUwNXVlSVLlnDlyhUuXbrEkiVLqFWrFp6engW2k5mZSdu2bY2ymjVrUrlyZXbt2nVXr01EREREHj53dM/5X3/9RdWqVYFr95f/9ddfALRo0YIXX3zx7kVXjLVq1QpfX19sbW1ZvHgxJUqUYNCgQURGRhr3tB44cIB69eoBcO7cOUqXLk18fDytWrVi69attG7dmk2bNvHaa69x9OhRmjVrxqpVq9i/fz/h4eGcPHmSjh07snjxYuzt7W8az8KFC4mMjOTEiRNYWPzvO5dOnTrh6urK0qVLSUpKIjw8nN27d3PhwgVq1apFVFSUWTLh6elJWFgYP//8M+vWraNLly68//77AGzcuJEvv/yS1atXs3HjxnzjcHV1pVy5cnf8vkZHRzN9+nSuXLlCz549mTVrlrHw4AcffMA777xDQkICDg4OBAQEMGvWLNzd3Y3jjxw5wujRo/n666/JycmhXr16vP/++1SrVg2AxYsXM336dH755Rc8PT0ZOnQoL730EgBBQUEEBQUZbVWtWpWEhATmz59PdHR0gTFnZGSQkZFhbKelpQFgY5GDpWXOHb8XcmcyMzNp0KABixcvpnr16pw+fZrJkyfzxBNPcODAAUqWLGlWf9GiRdSsWZNGjRoZU9ZtbW2Ji4uje/fuTJo0CQBvb282bNhATk5OvlPbT5w4QYkSJXBwcDDb7+7uzsmTJ286Hf5eyj1vUZ1f5Hrqj1JcqC9KcaL++HC7nc/1jpLzqlWr8ssvv1C5cmVq1qzJxx9/TOPGjVm/fj2lSpW6kyYfSMuXLyc8PJw9e/awa9cu+vbti7+/Pz4+PoVuIzIykjlz5mBvb0+PHj3o0aMHNjY2rFy5kvT0dDp37szs2bMZPXr0Tdvp3r07Q4YMIT4+njZt2gDXvkTZtGkTsbGxwLX7aIODg5kyZQo2NjasWLGCkJAQEhISqFy5stFWdHQ048ePZ8KECUbZ77//zoABA1i3bt1Nvyh46qmnuHz5MtWrV2fUqFE89dRThX4v4uPjKV++PPHx8SQmJvLMM89Qr149BgwYAFzr2JMmTaJGjRqkpqYSHh5O3759jes7efIkTz75JK1atWLLli04OTmxY8cOsrKyAIiJiWH8+PHMmTMHPz8/Dhw4wIABA3BwcDCeRHCj8+fP4+LictO4o6Ki8iw+BjDOLxt7+6uFvn65O3L7g729PSdOnABg8ODBDBw4kPHjx9OuXTujbkZGBh988AE9evQwjsstHzduHJUrV2bQoEFkZ2ezbt062rRpw7Rp07Cxsclz3oMHD5KdnW3WDlzrQ8eOHctTfr/FxcUV6flFrqf+KMWF+qIUJ+qPD6eLFy8Wuq4pJyfntof2Zs6ciaWlJUOHDuWrr74iJCTEGE2aMWMGw4YNu90mHzitWrXi6tWrbN++3Shr3LgxAQEBDBo0qNAj51999ZWRTE+dOpWIiAiSkpKMmQmDBg0iOTmZTZs23TKmp59+2piKC9dG0ydOnMhvv/1mNpp+vccff5xBgwYxePBg4NrIuZ+fH2vXrjXq5OTkEBwcjL+/P+PGjct3ZsCff/7JihUr8Pf3x8LCgtWrV/P222+zbt26QiXoffv2ZevWrSQlJWFpaQlAjx49sLCwYNWqVfke8+2339KoUSP+/vtvHB0dGTNmDKtWrSIhISHfx/x5e3szadIkevXqZZRNnjyZ2NhYdu7cmad+YmIiDRo0IDo62viCID/5jZxXqlSJx0auIstaq7Xfbz9EBuZb3qxZMwICApgyZYpR9u9//5sXXniB5ORk3NzcjPJly5bx+uuvc/z4ceN358qVK7i7u/Pee+/xzDPP5Gk/Pj6ewMBAUlNTzb6k9Pb2ZsiQIUX272JmZiZxcXG0a9dOj7+UIqf+KMWF+qIUJ+qPD7e0tDTKlCnD+fPnb/lUszsaOR8+fLjxc9u2bTl69Cj79+/H29sbX1/fO2nygXTjtZYvX57U1NQ7bqNs2bLY29sbiXlu2d69ewvVVmhoKAMGDGDevHnY2NgQExNDz549jeQiPT2dyMhINmzYQEpKCllZWVy6dCnPvbgNGzY02549ezZ///03ERERBZ67TJkyhIeHG9uNGjXi1KlTTJs2rdCj57Vr1zYSc7j2fh4+fNjY3r9/P5GRkRw6dIizZ8+SnZ0NwPHjx3nsscc4ePAgTzzxRL7/qF24cIGkpCTCwsLMEu2srCycnZ3z1D958iRBQUF07979pok5gI2NTb4jqRnZJrKumm594XJX5ff5p6enc+zYMfr06WO2f/ny5Tz11FN51lHIyMjAwsKCEiVKYDJd+wxzFzm0sLDI9xxNmjTB2tqar7/+mq5duwKQkJDA8ePHadGiRZH/sbW2ti7yGERyqT9KcaG+KMWJ+uPD6XY+0ztaEO56ly9fpkqVKnTp0uWRSswh7xttMpnIzs42kuHrJyUUdK/B9W2YTKYC2yyM3BkMGzZs4LfffmP79u2EhoYa+0eMGMHatWt588032b59OwcPHqROnTp5Fn1zcDAf7d2yZQu7du3CxsYGKysrvL29gWtJfEHTweFaspKYmFio2KHg9xOuJdeBgYE4OTkRExPDvn37jNH93Pjt7OwKbDs9PR24dn/xwYMHjdcPP/yQZyXtU6dO0bp1a5o3b87ChQsLHb8UHyNGjGDbtm0kJyezc+dOOnfujKWlpdmsicTERL7++mv+9a9/5Tm+Xbt2nD17lpdffpmffvqJI0eO0K9fP6ysrGjdujVw7QucmjVrGl+eOTs7ExYWRnh4OPHx8ezfv59+/frRrFkzmjZten8uXEREREQeWHc0cn716lXefPNNFixYwO+//85///tfqlatyuuvv24sKPYoy50em5KSgp+fH4DZY8fuFVtbW7p06UJMTAyJiYnUqFGD+vXrG/t37NhB37596dy5M3AtYU1OTr5lu++++y6TJ082tk+dOkVgYCAfffQRTZo0KfC4gwcPUr58+Tu/oOscPXqUM2fOMHXqVCpVqgRcm9Z+PV9fX5YvX05mZmaeRL9s2bJ4eHhw7Ngxsy8sbnTy5Elat25tPAaroNsBpHg7ceIEvXr14syZM7i5udGiRQt2795tNnV96dKlVKxYkfbt2+c5vmbNmqxfv56JEyfSrFkzLCws8PPzY9OmTUafzszMJCEhwew+opkzZ2JhYUHXrl3JyMggMDCQefPm3fsLFhEREZEH3h0l51OmTGH58uW8/fbbZlN+H3/8cWbNmvXIJ+d2dnY0bdqUqVOn4uXlRWpqKuPGjbsv5w4NDaVjx44cOXKEZ5991myfj48Pa9asISQkBJPJxOuvv16oUfnrF4sDjGdBV6tWjYoVKwLXpgeXKFHC+DJizZo1LF26lMWLF9+Ny6Jy5cqUKFGC2bNnM2jQIH744QdjFe1cgwcPZvbs2fTs2ZOIiAicnZ3ZvXs3jRs3pkaNGkycOJGhQ4fi7OxMUFAQGRkZfPvtt5w9e9ZYHb9Vq1ZUqVKF6Oho/vjjD6Ptf7ICvdx/Ba1TcL0333yTN998s8D97dq1M1s87kaenp7cuGSHra0tc+fOZe7cuYUPVkRERESEO0zOV6xYwcKFC2nTpg2DBg0yyuvWrcvRo0fvWnAPsqVLlxIWFkaDBg2oUaMGb7/9dr4jdHdbQEAALi4uJCQk0Lt3b7N9M2bMoH///jRv3pwyZcowevRo47Ffd8OkSZP49ddfsbKyombNmnz00Ud069btrrTt5ubG+++/z5gxY3j33XepX78+0dHRZvezu7q6smXLFkaOHEnLli2xtLSkXr16+Pv7A/Cvf/0Le3t7pk2bxsiRI3FwcKBOnTq88sorwLUVMhMTE0lMTDS+dMh1B+smsieiDa6urnd+0SIiIiIi8si4o9Xa7ezsOHr0KFWqVKFkyZIcOnSIqlWr8uOPP9K4cWPj/l6RR1FaWhrOzs78+eefSs6lyGVmZhIbG0twcLAWmZEip/4oxYX6ohQn6o8Pt9zcoDCrtd/RDbWPPfaY2SPEcn366afGtGYRERERERERKZw7mtY+fvx4nn/+eU6ePEl2djZr1qwhISGBFStW8Pnnn9/tGIX/PS6sID/++GOee8OLk9z71POzceNGnnjiifsYjYiIiIiISPFyW8n5sWPH8PLyolOnTqxfv5433ngDBwcHxo8fT/369Vm/fv1NF1CSO+fh4XHTFd9vfE5zcXOz2CtUqHD/AhERERERESmGbis59/HxISUlBXd3d5544glcXFw4fPgwZcuWvVfxyf93/fPFH0QPcuwiIiIiIiL32m3dc37j2nEbN27kwoULdzUgERERERERkUfNHS0Il+tOHi8lIiIiIiIiIuZuKzk3mUyYTKY8ZSIiIiIiIiJy527rnvOcnBz69u2LjY0NAJcvX2bQoEE4ODiY1VuzZs3di1BERERERETkIXdbyfnzzz9vtv3ss8/e1WBEREREREREHkW3lZwvW7bsXsUhIiIiIiIi8sj6RwvCiYiIiIiIiMg/p+RcREREREREpIgpORcREREREREpYkrORURERERERIqYknMRERERERGRIqbkXERERERERKSI3daj1ESk8JpEbSbLyqGow3hkJE/9PwAiIyOZOHGi2b4aNWpw9OhRY3vXrl2MHTuWPXv2YGlpSb169fjiiy+ws7MD4LvvvmP06NHs27cPS0tLunbtyowZM3B0dCzw/Dk5OUyYMIFFixZx7tw5/P39mT9/Pj4+PvfgakVERETkYaORc7krTCYT69atK3B/cnIyJpOJgwcP3reY5NFVu3ZtUlJSjNc333xj7Nu1axdBQUG0b9+evXv3sm/fPgYPHoyFxbV/Dk+dOkXbtm3x9vZmz549bNq0iSNHjtC3b9+bnvPtt9/m3XffZcGCBezZswcHBwcCAwO5fPnyvbxUEREREXlIaORc5Aaenp78+uuvZmVRUVG89tprRRSR3C4rKyvKlSuX777hw4czdOhQs8+zRo0axs+ff/451tbWzJ0710jYFyxYgK+vL4mJiXh7e+dpMycnh1mzZjFu3Dg6deoEwIoVKyhbtizr1q2jZ8+ed/PyREREROQhpJFzkf/vypUrxs9vvPGG2cjrkCFDijAyuV0///wzHh4eVK1aldDQUI4fPw5Aamoqe/bswd3dnebNm1O2bFlatmxpNrKekZFBiRIljMQcMKa7X1/ver/88gunT5+mbdu2RpmzszNNmjRh165d9+ISRUREROQho+RcDJ9++il16tTBzs4OV1dX2rZty4ULF9i3bx/t2rWjTJkyODs707JlS7777rubtrV37178/PywtbWlYcOGHDhwIE+dbdu20bhxY2xsbChfvjyvvfYaWVlZt4xz4cKFeHh4kJ2dbVbeqVMn+vfvD0BSUhKdOnWibNmyODo60qhRI7766iuz+p6enkyaNIk+ffrg5OTEwIEDjX0lS5akXLlyxsvBQfeOPyiaNGnC+++/z6ZNm5g/fz6//PILTzzxBH///TfHjh0Drt2XPmDAADZt2kT9+vVp06YNP//8MwABAQGcPn2aadOmceXKFc6ePWuMsqekpOR7ztOnTwNQtmxZs/KyZcsa+0REREREbkbT2gW4lnT06tWLt99+m86dO/P333+zfft2cnJy+Pvvv3n++eeZPXs2OTk5TJ8+neDgYH7++WdKliyZp6309HQ6duxIu3bt+Pe//80vv/zCsGHDzOqcPHmS4OBg+vbty4oVKzh69CgDBgzA1taWyMjIm8bavXt3hgwZQnx8PG3atAHgr7/+YtOmTcTGxhoxBAcHM2XKFGxsbFixYgUhISEkJCRQuXJlo63o6GjGjx/PhAkTzM4xdepUJk2aROXKlenduzfDhw/Hyir/X5eMjAwyMjKM7bS0NABsLHKwtMy56bXI3ZOZmQlgNnpdq1Yt6tevj7e3Nx9++CE1a9YE4F//+hfPPvsscO1e8a+++opFixYxZcoUqlevzpIlSxg1ahQRERFYWloyePBgypYtS05OjnGe6+V+qZSZmWm2Pzs7G5PJlO8x90vuuYsyBpFc6o9SXKgvSnGi/vhwu53PVcm5ANeS86ysLLp06UKVKlUAqFOnDnBtJPF6CxcupFSpUmzbto2OHTvmaWvlypVkZ2ezZMkSbG1tqV27NidOnODFF1806sybN49KlSoxZ84cTCYTNWvW5NSpU4wePZrx48ebTSm+UenSpenQoQMrV640kvNPP/2UMmXK0Lp1awDq1q1L3bp1jWMmTZrE2rVr+eyzzxg8eLBRHhAQwKuvvmrW/tChQ6lfvz4uLi7s3LmTiIgIUlJSmDFjRr7xREVF5VkdHGCcXzb29lcLvA65u3K/mMmPu7s7X375pbF95coVs/rOzs7s2bPHKHN2dua9997j3Llz2NjYYDKZmDVrFufOncv3PLmj46tXr6Zq1apG+dGjR/Hy8rppbPdLXFxcUYcgYlB/lOJCfVGKE/XHh9PFixcLXVfJuQDXktk2bdpQp04dAgMDad++Pd26daN06dL8/vvvjBs3jq1bt5KamsrVq1e5ePGicR/vjX766Sd8fX2xtbU1ypo1a5anTrNmzTCZTEaZv78/6enpnDhxwmx0Oz+hoaEMGDCAefPmYWNjQ0xMDD179jSS+vT0dCIjI9mwYYPxxcOlS5fyxNywYcM8bYeHhxs/+/r6UqJECV544QWioqKwsbHJUz8iIsLsmLS0NCpVqsTkAxZkWVve9Drk7vkhMjDf8vT0dM6cOYO/vz99+/Zl4sSJ2NnZERwcbNSZMGECgYGBZmXXe//997G1tWXkyJGUKlUqz/6cnBwiIyPJzMw02khLSyMxMZHXXnutwHbvh8zMTOLi4mjXrh3W1tZFFocIqD9K8aG+KMWJ+uPDLXdWbWEoORcALC0tiYuLY+fOnXz55ZfMnj3beA70iy++yJkzZ3jnnXeoUqUKNjY2NGvWzGwBtfstJCSEnJwcNmzYQKNGjdi+fTszZ8409o8YMYK4uDiio6Px9vbGzs6Obt265Ym5MPeSN2nShKysLJKTk81W9c5lY2OTb9KekW0i66opT7ncG7l/zEaMGEFISAhVqlTh1KlTTJgwAUtLS5599llKlCjByJEjmTBhAvXr16devXosX76chIQEVq9ebbQxZ84cmjdvjqOjI3FxcYwcOZKpU6fi5uZmnK9mzZpERUXRuXNnAF555RWioqKoWbMmXl5evP7663h4eNCtW7di8YfW2tq6WMQhAuqPUnyoL0pxov74cLqdz1TJuRhMJhP+/v74+/szfvx4qlSpwtq1a9mxYwfz5s0zRv9+++03/vzzzwLbqVWrFh988AGXL182Rs93796dp87q1avJyckxRs937NhByZIlqVix4i1jtbW1pUuXLsTExJCYmEiNGjWoX7++sX/Hjh307dvXSJzS09NJTk6+rfcj18GDB7GwsMDd3f2Ojpf768SJE/Tq1YszZ87g5uZGixYt2L17t5FYv/LKK1y+fJnhw4fz119/UbduXeLi4qhWrZrRxt69e5kwYQLp6enUrFmT9957j+eee87sPAkJCZw/f97YHjVqFBcuXGDgwIGcO3eOFi1asGnTJrMZJCIiIiIiBVFyLgDs2bOHzZs30759e9zd3dmzZw9//PEHtWrVwsfHhw8++ICGDRuSlpbGyJEjjUdL5ad3796MHTuWAQMGEBERQXJyMtHR0WZ1XnrpJWbNmsWQIUMYPHgwCQkJTJgwgfDw8Jveb3690NBQOnbsyJEjR4zFvXL5+PiwZs0aQkJCMJlMvP7663lWd8/Prl272LNnD61bt6ZkyZLs2rWL4cOH8+yzz1K6dOlCxSVFa9WqVbes89prr930ufUrVqy4ZRs5OeaL/ZlMJt544w3eeOONWwcpIiIiInIDJecCgJOTE19//TWzZs0iLS2NKlWqMH36dDp06EC5cuUYOHAg9evXp1KlSrz55puMGDGiwLYcHR1Zv349gwYNws/Pj8cee4y33nqLrl27GnUqVKhAbGwsI0eOpG7duri4uBAWFsa4ceMKHXNAQAAuLi4kJCTQu3dvs30zZsygf//+NG/enDJlyjB69OhC3e9hY2PDqlWriIyMJCMjAy8vL4YPH252T7mIiIiIiMjdZsq5cfhHRP6RtLQ0nJ2d+fPPP3F1dS3qcOQRl5mZSWxsLMHBwbqPTYqc+qMUF+qLUpyoPz7ccnOD8+fP4+TkdNO6hZs/LCIiIiIiIiL3jJJzKXaOHz+Oo6Njga+CHuEmIiIiIiLyoNI951LseHh4cPDgwZvuFxEREREReZgoOZdix8rKCm9v76IOQ0RERERE5L7RtHYRERERERGRIqbkXERERERERKSIKTkXERERERERKWJKzkVERERERESKmJJzERERERERkSKm5FxERERERESkiCk5FxERERERESliSs5FREREREREipiScxEREREREZEipuRcREREREREpIgpORcREREREREpYkrORURERERERIqYVVEHIPKwahK1mSwrh6IO46GUPPX/ijoEEREREZG7SiPn8sjw9PRk1qxZRR2G3CWRkZGYTCazV82aNY39L7zwAtWqVcPOzg43Nzc6derE0aNH823rzJkzVKxYEZPJxLlz52563r/++ovQ0FCcnJwoVaoUYWFhpKen381LExEREZFHkJJzueeSk5MJCwvDy8sLOzs7qlWrxoQJE7hy5YpRZ+vWrXTq1Iny5cvj4OBAvXr1iImJuadxmUwm1q1bZ1aWkpJC7969qV69OhYWFrzyyiv3NAb5Z2rXrk1KSorx+uabb4x9DRo0YNmyZfz000988cUX5OTk0L59e65evZqnnbCwMHx9fQt1ztDQUI4cOUJcXByff/45X3/9NQMHDrxr1yQiIiIijyZNa5d76sqVKxw9epTs7Gzee+89vL29+eGHHxgwYAAXLlwgOjoagJ07d+Lr68vo0aMpW7Ysn3/+OX369MHZ2ZmOHTvet3gzMjJwc3Nj3LhxzJw5876dV+6MlZUV5cqVy3ff9Qmzp6cnkydPpm7duiQnJ1OtWjVj3/z58zl37hzjx49n48aNNz3fTz/9xKZNm9i3bx8NGzYEYPbs2QQHBxMdHY2Hh8dduCoREREReRRp5LyItGrViqFDhzJq1ChcXFwoV64ckZGRwLWRZpPJxMGDB436586dw2QysXXrVuDaSLPJZOKLL77Az88POzs7AgICSE1NZePGjdSqVQsnJyd69+7NxYsXbxnPwoUL8fDwIDs726y8U6dO9O/fH4CkpCQ6depE2bJlcXR0pFGjRnz11Vdm9T09PZk0aRJ9+vTBycmJgQMHEhQUxLJly2jfvj1Vq1blqaeeYsSIEaxZs8Y4bsyYMUyaNInmzZtTrVo1hg0bRlBQkFmdW72fN45yP/300/Tt2zff+p6engB07twZk8lkbHt6evLOO+8YXwxI8fbzzz/j4eFB1apVCQ0N5fjx4/nWu3DhAsuWLcPLy4tKlSoZ5T/++CNvvPEGK1aswMLi1v8c7tq1i1KlShmJOUDbtm2xsLBgz549//yCREREROSRpZHzIrR8+XLCw8PZs2cPu3btom/fvvj7++Pj41PoNiIjI5kzZw729vb06NGDHj16YGNjw8qVK0lPT6dz587Mnj2b0aNH37Sd7t27M2TIEOLj42nTpg1w7d7aTZs2ERsbC0B6ejrBwcFMmTIFGxsbVqxYQUhICAkJCVSuXNloKzo6mvHjxzNhwoQCz3f+/HlcXFxuGtP58+epVatWYd+K27Jv3z7c3d1ZtmwZQUFBWFpa3nFbGRkZZGRkGNtpaWkA2FjkYGmZ849jlbwyMzNp0KABixcvpnr16pw+fZrJkyfzxBNPcODAAUqWLAnAggULiIiI4MKFC1SvXp3Y2FhMJhOZmZlkZGTQs2dPoqKiKF++PP/973+NtjMzM/M978mTJ3Fzc8uz38XFhZMnTxZ4XFHKjak4xiaPHvVHKS7UF6U4UX98uN3O56rkvAj5+voaCayPjw9z5sxh8+bNt5WcT548GX9/f+DafbMREREkJSVRtWpVALp160Z8fPwtk/PSpUvToUMHVq5caSTnn376KWXKlKF169YA1K1bl7p16xrHTJo0ibVr1/LZZ58xePBgozwgIIBXX321wHMlJiYye/ZsY0p7fj7++GP27dvHe++9d4t34M64ubkBUKpUqQKnRRdWVFQUEydOzFM+zi8be/u89zfLP5f7hZG9vT0nTpwAYPDgwQwcOJDx48fTrl07AFxdXZk2bRpnz55l3bp1/N///R9Tp06lRIkSLF26FGdnZ0qXLk1sbCyHDx8G4Msvv8TR0THf8yYkJHDhwgXj/LmuXLnCDz/8kKe8OImLiyvqEEQM6o9SXKgvSnGi/vhwKsws5lxKzovQjQtQlS9fntTU1Dtuo2zZstjb2xuJeW7Z3r17C9VWaGgoAwYMYN68edjY2BATE0PPnj2N6b7p6elERkayYcMGUlJSyMrK4tKlS3mmEl8/5fdGJ0+eJCgoiO7duzNgwIB868THx9OvXz8WLVpE7dq1CxV7UYqIiCA8PNzYTktLo1KlSkw+YEGW9Z2PyEvBfogMzLd85syZ2NvbExwcnGffsGHDcHd35/Llyzz99NOMHz+eH374ga5duwKQk3NtlsPzzz/Pa6+9lu/Mj9TUVDZs2GDWflZWFunp6bRp0ybf8xa1zMxM4uLiaNeuHdbW1kUdjjzi1B+luFBflOJE/fHhljurtjCUnBehG3/5TCYT2dnZRjKcmyxAwdMhrm/DZDIV2GZhhISEkJOTw4YNG2jUqBHbt283WxRtxIgRxMXFER0djbe3N3Z2dnTr1s1s1XUAB4f8n+196tQpWrduTfPmzVm4cGG+dbZt20ZISAgzZ86kT58+hYobwMLCwuz9gvs3NcjGxgYbG5s85RnZJrKumu5LDI+a/P5wpaenc+zYMfr06ZPv/uzsbHJycrh69SrW1tasWbOGS5cuGfv37dtH//792b59O9WqVcu3jRYtWnDu3Dm+//57GjRoAFz7Mik7Oxt/f/9i/QfV2tq6WMcnjxb1Ryku1BelOFF/fDjdzmeq5LwYyp1ynZKSgp+fH4DZ4nD3iq2tLV26dCEmJobExERq1KhB/fr1jf07duygb9++dO7cGbiWDCUnJxeq7ZMnT9K6dWvj8Vb5Lb61detWOnbsyFtvvXXbj6Zyc3MjJSXF2L569So//PCDMSU/P9bW1vk+VkseDCNGjCAkJIQqVapw6tQpJkyYgKWlJb169eLYsWN89NFHtG/fHjc3N06cOMHUqVOxs7MzRrevX7Ed4M8//wSgVq1alCpVCoC9e/fSp08fNm/eTIUKFahVqxZBQUEMGDCABQsWkJmZyeDBg+nZs6dWahcRERGRf0TJeTFkZ2dH06ZNmTp1Kl5eXqSmpjJu3Lj7cu7Q0FA6duzIkSNHePbZZ832+fj4sGbNGkJCQjCZTLz++uuFGpU/efIkrVq1okqVKkRHR/PHH38Y+3Lv946Pj6djx44MGzaMrl27cvr0aQBKlChxy4Xj4Np97uHh4WzYsIFq1aoxY8YMzp07d9NjPD092bx5M/7+/tjY2FC6dGngf1+EpKen88cff3Dw4EFKlCjBY489dss45P45ceIEvXr14syZM7i5udGiRQt2795tLNi2fft2Zs2axdmzZylbtixPPvkkO3fuxN3dvdDnuHjxIgkJCWazMGJiYhg8eDBt2rTBwsKCrl278u67796LSxQRERGRR4iS82Jq6dKlhIWF0aBBA2rUqMHbb79N+/bt7/l5AwICcHFxISEhgd69e5vtmzFjBv3796d58+aUKVOG0aNHF+oeiri4OBITE0lMTKRixYpm+3Knoi9fvpyLFy8SFRVFVFSUsb9ly5bG4+Nupn///hw6dIg+ffpgZWXF8OHDbzpqDjB9+nTCw8NZtGgRFSpUMGYB5M5WANi/fz8rV66kSpUqhZ4lIPfHqlWrCtzn4eFx24uztWrVKs+tEfmVubi4sHLlyttqW0RERETkVkw5N/6fp4j8I2lpaTg7O/Pnn3/i6upa1OHIIy4zM5PY2FiCg4N1H5sUOfVHKS7UF6U4UX98uOXmBufPn8fJyemmdfPe+CsiIiIiIiIi95WS80fE8ePHcXR0LPB14+PQipubxb59+/aiDk9EREREROQf0T3njwgPD4+brvhe3FeavlnsFSpUuH+BiIiIiIiI3ANKzh8RVlZWeHt7F3UYd+xBjl1ERERERORWNK1dREREREREpIgpORcREREREREpYkrORURERERERIqYknMRERERERGRIqbkXERERERERKSIKTkXERERERERKWJKzkVERERERESKmJJzERERERERkSKm5FxERERERESkiCk5FxERERERESliSs5FREREREREipiScxEREREREZEipuRcREREREREpIhZFXUAIg+rJlGbybJyKOowHnjJU/+PyMhIJk6caFZeo0YNjh49CsDly5d59dVXWbVqFRkZGQQGBjJv3jzKli1r1DeZTHna/vDDD+nZs2eB5/7rr78YMmQI69evx8LCgq5du/LOO+/g6Oh4l65OREREROQajZxLsdC3b1+efvrpog5DirHatWuTkpJivL755htj3/Dhw1m/fj2ffPIJ27Zt49SpU3Tp0iVPG8uWLTNr41Z9LjQ0lCNHjhAXF8fnn3/O119/zcCBA+/2pYmIiIiIKDmXW0tOTiYsLAwvLy/s7OyoVq0aEyZM4MqVK0adrVu30qlTJ8qXL4+DgwP16tUjJiamCKO+M0899RSVK1fG1taW8uXL89xzz3Hq1KmiDksAKysrypUrZ7zKlCkDwPnz51myZAkzZswgICCABg0asGzZMnbu3Mnu3bvN2ihVqpRZG7a2tgWe76effmLTpk0sXryYJk2a0KJFC2bPns2qVavUJ0RERETkrlNyLjd15coVjh49SnZ2Nu+99x5Hjhxh5syZLFiwgDFjxhj1du7cia+vL6tXr+b777+nX79+9OnTh88//7wIo799rVu35uOPPyYhIYHVq1eTlJREt27dijosAX7++Wc8PDyoWrUqoaGhHD9+HID9+/eTmZlJ27Ztjbo1a9akcuXK7Nq1y6yNl19+mTJlytC4cWOWLl1KTk5OgefbtWsXpUqVomHDhkZZ27ZtsbCwYM+ePXf56kRERETkUad7zu9Qq1at8PX1xdbWlsWLF1OiRAkGDRpEZGQkycnJeHl5ceDAAerVqwfAuXPnKF26NPHx8bRq1YqtW7fSunVrNm3axGuvvcbRo0dp1qwZq1atYv/+/YSHh3Py5Ek6duzI4sWLsbe3v2k8CxcuJDIykhMnTmBh8b/vXDp16oSrqytLly4lKSmJ8PBwdu/ezYULF6hVqxZRUVFmSY2npydhYWH8/PPPrFu3ji5duvD+++8TFBRk1KlatSoJCQnMnz+f6OhoALNEHWDYsGF8+eWXrFmzho4dOxb6fY2Ojmb69OlcuXKFnj17MmvWLKytrQH44IMPeOedd0hISMDBwYGAgABmzZqFu7u7cfyRI0cYPXo0X3/9NTk5OdSrV4/333+fatWqAbB48WKmT5/OL7/8gqenJ0OHDuWll14yjh8+fLjxc5UqVXjttdd4+umnyczMNOK4UUZGBhkZGcZ2WloaADYWOVhaFpz8SeFkZmbSoEEDFi9eTPXq1Tl9+jSTJ0/miSee4MCBA5w4cYISJUrg4OBAZmamcZy7uzsnT540yiZMmEDr1q2xs7Pjq6++4qWXXuL8+fMMHjw43/OePHkSNzc3szYBXFxczNot7nLjfFDilYeb+qMUF+qLUpyoPz7cbudzVXL+Dyxfvpzw8HD27NnDrl276Nu3L/7+/vj4+BS6jcjISObMmYO9vT09evSgR48e2NjYsHLlStLT0+ncuTOzZ89m9OjRN22ne/fuDBkyhPj4eNq0aQNcW8xq06ZNxMbGApCenk5wcDBTpkzBxsaGFStWEBISQkJCApUrVzbaio6OZvz48UyYMKHA850/fx4XF5ebxnT+/Hlq1apV2LeC+Ph4ypcvT3x8PImJiTzzzDPUq1ePAQMGANc69qRJk6hRowapqamEh4fTt29f4/pOnjzJk08+SatWrdiyZQtOTk7s2LGDrKwsAGJiYhg/fjxz5szBz8+PAwcOMGDAABwcHHj++efzxPPXX38RExND8+bNC0zMAaKiovIsVgYwzi8be/urhb5+yV/u52tvb8+JEycAGDx4MAMHDmT8+PGUKFGC7Oxso16u8+fPc+zYMaPcz8+Pc+fOce7cOWrXrk2nTp2YMmUKVatWzfe8CQkJXLhwIU+7V65c4YcffshTXtzFxcUVdQgiBvVHKS7UF6U4UX98OF28eLHQdU05N5vXKQVq1aoVV69eZfv27UZZ48aNCQgIYNCgQYUeOf/qq6+MZHrq1KlERESQlJRkJAyDBg0iOTmZTZs23TKmp59+GldXV5YsWQJcG02fOHEiv/32m9lo+vUef/xxBg0aZIweenp64ufnx9q1aws8T2JiIg0aNCA6OtpInG/08ccf89xzz/Hdd99Ru3btW8bet29ftm7dSlJSEpaWlgD06NEDCwsLVq1ale8x3377LY0aNeLvv//G0dGRMWPGsGrVKhISEvJNpr29vZk0aRK9evUyyiZPnkxsbCw7d+40ykaPHs2cOXO4ePEiTZs25fPPP8fV1bXA2PMbOa9UqRKPjVxFlrVWa/+nfogMzLe8WbNmBAQE0LZtWwIDA0lNTaVUqVLGfm9vb4YMGcKwYcPyPT42Npann36av//+Gxsbmzz733//fUaNGkVqaqpRlpWVRcmSJfnwww8fmAUMMzMziYuLo127djf9kknkflB/lOJCfVGKE/XHh1taWhplypTh/PnzODk53bSuRs7/AV9fX7Pt8uXLm/2P/O22UbZsWezt7c1G8sqWLcvevXsL1VZoaCgDBgxg3rx52NjYEBMTQ8+ePY3EPD09ncjISDZs2EBKSgpZWVlcunTJuHc31/X32N7o5MmTBAUF0b179wIT8/j4ePr168eiRYsKlZjnql27tpGYw7X38/Dhw8b2/v37iYyM5NChQ5w9e5bs7GwAjh8/zmOPPcbBgwd54okn8v1H7cKFCyQlJREWFmYWd1ZWFs7OzmZ1R44cSVhYGL/++isTJ0407p3P71FcADY2NvkmdxnZJrKu5n+MFF5+n2d6ejrHjh2jT58+NGnSBGtra77++mu6du0KXBv1Pn78OC1atCjwj9wPP/xA6dKlC3wsWosWLTh37hzff/89DRo0AK717ezsbPz9/R+4P57W1tYPXMzy8FJ/lOJCfVGKE/XHh9PtfKZKzv+BG99ok8lEdna2kQxfPymhoHsNrm/DZDIV2GZhhISEkJOTw4YNG2jUqBHbt29n5syZxv4RI0YQFxdHdHQ03t7e2NnZ0a1bN7NV1wEcHPIf7T116hStW7emefPmLFy4MN8627ZtIyQkhJkzZ9KnT59CxZ3rZtd+4cIFAgMDCQwMJCYmBjc3N44fP05gYKARv52dXYFtp6enA7Bo0SKaNGlitu/6LwQAypQpQ5kyZahevTq1atWiUqVK7N69m2bNmt3W9cjdM2LECEJCQqhSpQqnTp1iwoQJWFpa0qtXL5ydnQkLCyM8PBwXFxecnJwYMmQIzZo1o2nTpgCsX7+e33//naZNm2Jra0tcXBxvvvkmI0aMMM6xd+9e+vTpw+bNm6lQoQK1atUiKCiIAQMGsGDBAjIzMxk8eDA9e/bEw8OjqN4KEREREXlIKTm/B9zc3ABISUnBz88PgIMHD97z89ra2tKlSxdiYmJITEykRo0a1K9f39i/Y8cO+vbtS+fOnYFrCWtycnKh2j558iStW7c2HlOV3zT5rVu30rFjR9566627/izoo0ePcubMGaZOnUqlSpWAa9Par+fr68vy5cvzXbytbNmyeHh4cOzYMUJDQwt93twvB66fti7334kTJ+jVqxdnzpzBzc2NFi1asHv3buN3bebMmVhYWNC1a1cyMjIIDAxk3rx5xvHW1tbMnTuX4cOHk5OTg7e3NzNmzDCbRXHx4kUSEhLMvkiLiYlh8ODBtGnTxmj/3XffvX8XLiIiIiKPDCXn94CdnR1NmzZl6tSpeHl5kZqayrhx4+7LuUNDQ+nYsSNHjhzh2WefNdvn4+PDmjVrCAkJwWQy8frrrxdqVP7kyZO0atWKKlWqEB0dzR9//GHsK1euHHBtum/Hjh0ZNmwYXbt25fTp0wCUKFHilgvHFUblypUpUaIEs2fPZtCgQfzwww9MmjTJrM7gwYOZPXs2PXv2JCIiAmdnZ3bv3k3jxo2pUaMGEydOZOjQoTg7OxMUFERGRgbffvstZ8+eNRb227dvHy1atKB06dIkJSXx+uuvU61aNY2aF7GC1h3IZWtry9y5c5k7d26++4OCgsyeOJCfVq1a5Xm0mouLCytXrry9YEVERERE7oCS83tk6dKlhIWF0aBBA2rUqMHbb79N+/bt7/l5AwICcHFxISEhgd69e5vtmzFjBv3796d58+aUKVOG0aNHG4/9upm4uDgSExNJTEykYsWKZvtyk5nly5dz8eJFoqKiiIqKMva3bNmSrVu3/uPrcnNz4/3332fMmDG8++671K9fn+joaJ566imjjqurK1u2bGHkyJG0bNkSS0tL6tWrh7+/PwD/+te/sLe3Z9q0aYwcORIHBwfq1KnDK6+8AlxbDXzNmjVMmDCBCxcuUL58eYKCghg3bly+95Tfyp6INjddSE5ERERERCSXVmsXucvS0tJwdnbmzz//VHIuRS4zM5PY2FiCg4O1yIwUOfVHKS7UF6U4UX98uOXmBoVZrT3/52uJiIiIiIiIyH2j5PwBcfz4cRwdHQt83fg4tOLmZrFf/6x4ERERERGRR5HuOX9AeHh43HTF9+L+aKebxV6hQoX7F4iIiIiIiEgxpOT8AWFlZYW3t3dRh3HHHuTYRURERERE7jVNaxcREREREREpYkrORURERERERIqYknMRERERERGRIqbkXERERERERKSIKTkXERERERERKWJKzkVERERERESKmJJzERERERERkSKm5FxERERERESkiCk5FxERERERESliSs5FREREREREipiScxEREREREZEipuRcREREREREpIhZFXUAIg+rJlGbybJyKOowir3kqf+Xp2zq1KlEREQwbNgwZs2aBUCrVq3Ytm2bWb0XXniBBQsWGNsmkylPWx9++CE9e/Ys8Px//fUXQ4YMYf369VhYWNC1a1feeecdHB0d7/CKRERERERun5JzKRb69u3LuXPnWLduXVGHIkVs3759vPfee/j6+ubZN2DAAN544w1j297ePk+dZcuWERQUZGyXKlXqpucLDQ0lJSWFuLg4MjMz6devHwMHDmTlypV3fhEiIiIiIrdJ09rllpKTkwkLC8PLyws7OzuqVavGhAkTuHLlilFn69atdOrUifLly+Pg4EC9evWIiYkpwqhvX2GuU+6t9PR0QkNDWbRoEaVLl86z397ennLlyhkvJyenPHVKlSplVsfW1rbA8/30009s2rSJxYsX06RJE1q0aMHs2bNZtWoVp06duqvXJiIiIiJyM0rO5aauXLnC0aNHyc7O5r333uPIkSPMnDmTBQsWMGbMGKPezp078fX1ZfXq1Xz//ff069ePPn368Pnnnxdh9LenMNcp99bLL7/M//3f/9G2bdt898fExFCmTBkef/xxIiIiuHjxYr5tlClThsaNG7N06VJycnIKPN+uXbsoVaoUDRs2NMratm2LhYUFe/bs+ecXJCIiIiJSSErO71CrVq0YOnQoo0aNwsXFhXLlyhEZGQlcG4E1mUwcPHjQqH/u3DlMJhNbt24Fro00m0wmvvjiC/z8/LCzsyMgIIDU1FQ2btxIrVq1cHJyonfv3vkmIDdauHAhHh4eZGdnm5V36tSJ/v37A5CUlESnTp0oW7Ysjo6ONGrUiK+++sqsvqenJ5MmTaJPnz44OTkxcOBAgoKCWLZsGe3bt6dq1ao89dRTjBgxgjVr1hjHjRkzhkmTJtG8eXOqVavGsGHDCAoKMqtTGNHR0ZQvXx5XV1defvllMjMzjX0ffPABDRs2pGTJkpQrV47evXuTmppqdvyRI0fo2LEjTk5OlCxZkieeeIKkpCRj/+LFi6lVqxa2trbUrFmTefPmGfsKc51y76xatYrvvvuOqKiofPf37t2bf//738THxxMREcEHH3zAs88+a1bnjTfe4OOPPyYuLo6uXbvy0ksvMXv27ALPefr0adzd3c3KrKyscHFx4fTp0//8okRERERECkn3nP8Dy5cvJzw8nD179rBr1y769u2Lv78/Pj4+hW4jMjKSOXPmYG9vT48ePejRowc2NjasXLmS9PR0OnfuzOzZsxk9evRN2+nevTtDhgwhPj6eNm3aANcWutq0aROxsbHAtSnDwcHBTJkyBRsbG1asWEFISAgJCQlUrlzZaCs6Oprx48czYcKEAs93/vx5XFxcbhrT+fPnqVWrVmHfCuLj4ylfvjzx8fEkJibyzDPPUK9ePQYMGABAZmYmkyZNokaNGqSmphIeHk7fvn2N6zt58iRPPvkkrVq1YsuWLTg5ObFjxw6ysrKAa6Ou48ePZ86cOfj5+XHgwAEGDBiAg4MDzz///B1fZ0ZGBhkZGcZ2WloaADYWOVhaFjxqK9dkZmby22+/MWzYMGJjY7G0tCQzM5OcnByys7ONL2j69etnHFOzZk3c3NwIDAzk6NGjVKtWDYDXXnvNqPP444+TlpbGtGnTePHFF/M999WrV8nJyTH7Euj6ffmVP2hyr+FhuBZ58Kk/SnGhvijFifrjw+12Plcl5/+Ar6+vkcD6+PgwZ84cNm/efFvJ+eTJk/H39wcgLCyMiIgIkpKSqFq1KgDdunUjPj7+lsl56dKl6dChAytXrjSS808//ZQyZcrQunVrAOrWrUvdunWNYyZNmsTatWv57LPPGDx4sFEeEBDAq6++WuC5EhMTmT17NtHR0QXW+fjjj42FvQqrdOnSzJkzB0tLS2rWrMn//d//sXnzZiM5z50BAFC1alXeffddGjVqRHp6Oo6OjsydOxdnZ2dWrVqFtbU1ANWrVzeOmTBhAtOnT6dLly4AeHl58eOPP/Lee+/lm5wX5joBoqKimDhxYp7ycX7Z2NtfLfT1P6piY2PZvXs3qampNG7c2CjPzs5m+/btzJ07l08++QRLS0uz4y5fvgxcG3H38/PLt20LCwtOnDjBf/7zH6NPXC81NZVTp04ZX/DAtaT8zJkznDx50qz8QRcXF1fUIYgY1B+luFBflOJE/fHhVJhZ0LmUnP8DN64mXb58+TzTrG+njbJly2Jvb28k5rlle/fuLVRboaGhDBgwgHnz5mFjY0NMTAw9e/bEwuLa3Qvp6elERkayYcMGUlJSyMrK4tKlSxw/ftysnevvv73RyZMnCQoKonv37kbSfKP4+Hj69evHokWLqF27dqFiB6hdu7ZZAla+fHkOHz5sbO/fv5/IyEgOHTrE2bNnjSn8x48f57HHHuPgwYM88cQT+SZhFy5cICkpibCwMLO4s7KycHZ2vqPrzBUREUF4eLixnZaWRqVKlZh8wIIsa8ubHCkAP0QG8sQTT9CjRw+z8gEDBlCjRg1GjBjB448/nue4nTt3AhASEpLvyu4Ahw4donTp0nTq1Cnf/V5eXsyZM4dy5cpRv3594NofxpycHAYNGoSHh8c/ubRiITMzk7i4ONq1a5fv74bI/aT+KMWF+qIUJ+qPD7fcWbWFoeT8H7jxl8dkMpGdnW0kw9cvRFXQdIbr2zCZTAW2WRghISHk5OSwYcMGGjVqxPbt25k5c6axf8SIEcTFxREdHY23tzd2dnZ069Ytz2rkDg75P5v71KlTtG7dmubNm7Nw4cJ862zbto2QkBBmzpxJnz59ChV3rptd+4ULFwgMDCQwMJCYmBjc3Nw4fvw4gYGBRvx2dnYFtp2eng7AokWLaNKkidm+G0dkC3Od17OxscHGxiZPeUa2iayreZ+7Leasra1xcXHJc/uAo6Mjbm5u+Pn5kZSUxMqVKwkODsbV1ZXvv/+e4cOH8+STT9KgQQMA1q9fz++//07Tpk2xtbUlLi6Ot956ixEjRhh9a+/evfTp04fNmzdToUIFfH19CQoK4sUXX2TBggVkZmbyyiuv0LNnT6pUqXLf34t7ydraWn/wpdhQf5TiQn1RihP1x4fT7XymSs7vATc3NwBSUlKM6bbXLw53r9ja2tKlSxdiYmJITEykRo0axmggwI4dO+jbty+dO3cGriWsycnJhWr75MmTtG7dmgYNGrBs2TLjC4jrbd26lY4dO/LWW28xcODAu3JNuY4ePcqZM2eYOnUqlSpVAuDbb781q+Pr68vy5cvJzMzM80tQtmxZPDw8OHbsGKGhoQWepzDXKfdfiRIl+Oqrr5g1axYXLlygUqVKdO3alXHjxhl1rK2tmTt3LsOHDycnJwdvb29mzJhhNvPh4sWLJCQkmH1ZFhMTw+DBg2nTpg0WFhZ07dqVd999975en4iIiIiIkvN7wM7OjqZNmzJ16lS8vLxITU01SyLupdDQUDp27MiRI0fyrGTt4+PDmjVrCAkJwWQy8frrrxdqVP7kyZO0atWKKlWqEB0dzR9//GHsK1euHHBtKnvHjh0ZNmwYXbt2NVa6LlGixC0XVCuMypUrU6JECWbPns2gQYP44YcfmDRpklmdwYMHM3v2bHr27ElERATOzs7s3r2bxo0bU6NGDSZOnMjQoUNxdnYmKCiIjIwMvv32W86ePUt4eHihrlPun9wnGwBUqlSJbdu23bR+UFAQQUFBN63TqlWrPI9Wc3FxYeXKlXccp4iIiIjI3aBhwXtk6dKlZGVl0aBBA1555RUmT558X84bEBCAi4sLCQkJ9O7d22zfjBkzKF26NM2bNyckJITAwECzkfWCxMXFkZiYyObNm6lYsSLly5c3XrmWL1/OxYsXiYqKMtufu/jaP+Xm5sb777/PJ598wmOPPcbUqVPzLNTm6urKli1bSE9Pp2XLljRo0IBFixYZo+j/+te/WLx4McuWLaNOnTq0bNmS999/Hy8vr0Jfp4iIiIiIyL1gyrlxGElE/pG0tDScnZ35888/cXV1Lepw5BGXmZlJbGwswcHBuo9Nipz6oxQX6otSnKg/Ptxyc4Pz58/j5OR007oaORcREREREREpYkrOHxDHjx/H0dGxwNeNj0Mrbm4W+/bt24s6PBERERERkSKlBeEeEB4eHjdd8b24P4/5ZrFXqFDh/gUiIiIiIiJSDCk5f0BYWVnh7e1d1GHcsQc5dhERERERkXtN09pFREREREREipiScxEREREREZEipuRcREREREREpIgpORcREREREREpYkrORURERERERIqYknMRERERERGRIqbkXERERERERKSIKTkXERERERERKWJKzkVERERERESKmJJzERERERERkSKm5FxERERERESkiCk5FxERERERESliVkUdgMjDqknUZrKsHIo6jCKRPPX/ijoEEREREZEHikbO5ZHh6enJrFmzijqMR8r8+fPx9fXFyckJJycnmjVrxsaNG439SUlJdO7cGTc3N5ycnOjRowe///67sT85OZmwsDC8vLyws7OjWrVqTJgwgStXrtz0vJcvX+bll1/G1dUVR0dHunbtatauiIiIiEhxo+Rc7quMjAzq1auHyWTi4MGDRnlycjImkynPa/fu3fcsFpPJxLp168zKUlJS6N27N9WrV8fCwoJXXnnlnp3/UVCxYkWmTp3K/v37+fbbbwkICKBTp04cOXKECxcu0L59e0wmE1u2bGHHjh1cuXKFkJAQsrOzATh69CjZ2dm89957HDlyhJkzZ7JgwQLGjBlz0/MOHz6c9evX88knn7Bt2zZOnTpFly5d7scli4iIiIjcEU1rl3vqypUrlChRwtgeNWoUHh4eHDp0KN/6X331FbVr1za2XV1d73mM18vIyMDNzY1x48Yxc+bM+3ruh1FISIjZ9pQpU5g/fz67d+/m5MmTJCcnc+DAAZycnABYvnw5pUuXZsuWLbRt25agoCCCgoKM46tWrUpCQgLz588nOjo633OeP3+eJUuWsHLlSgICAgBYtmwZtWrVYvfu3TRt2vQeXa2IiIiIyJ3TyHkRadWqFUOHDmXUqFG4uLhQrlw5IiMjgf+NIl8/snzu3DlMJhNbt24FYOvWrZhMJr744gv8/Pyws7MjICCA1NRUNm7cSK1atXBycqJ3795cvHjxlvEsXLgQDw8PY8QyV6dOnejfvz9wbQpyp06dKFu2LI6OjjRq1IivvvrKrL6npyeTJk2iT58+ODk5MXDgQGPfxo0b+fLLLwtMquBaMl6uXDnjZW1tfcvY4dr7eeMo99NPP03fvn3zre/p6QlA586dMZlMxranpyfvvPMOffr0wdnZuVDnlsK5evUqq1at4sKFCzRr1oyMjAxMJhM2NjZGHVtbWywsLPjmm28KbOf8+fO4uLgUuH///v1kZmbStm1bo6xmzZpUrlyZXbt23Z2LERERERG5yzRyXoSWL19OeHg4e/bsYdeuXfTt2xd/f398fHwK3UZkZCRz5szB3t6eHj160KNHD2xsbFi5ciXp6el07tyZ2bNnM3r06Ju20717d4YMGUJ8fDxt2rQB4K+//mLTpk3ExsYCkJ6eTnBwMFOmTMHGxoYVK1YQEhJCQkIClStXNtqKjo5m/PjxTJgwwSj7/fffGTBgAOvWrcPe3r7AOJ566ikuX75M9erVGTVqFE899VSh34vbsW/fPtzd3Vm2bBlBQUFYWlrecVsZGRlkZGQY22lpaQDYWORgaZnzj2N9EGVmZho/Hz58mCeffJLLly/j6OjIJ598go+PD6VKlcLBwYGRI0cyadIkcnJyGDt2LFevXuXkyZNmbeRKTExk9uzZvPXWW/nuBzhx4gQlSpTAwcHBrI67u3uB7T7Mcq/3UbtuKZ7UH6W4UF+U4kT98eF2O5+rkvMi5OvraySwPj4+zJkzh82bN99Wcj558mT8/f0BCAsLIyIigqSkJKpWrQpAt27diI+Pv2VyXrp0aTp06MDKlSuN5PzTTz+lTJkytG7dGoC6detSt25d45hJkyaxdu1aPvvsMwYPHmyUBwQE8OqrrxrbOTk59O3bl0GDBtGwYUOSk5PznN/R0ZHp06fj7++PhYUFq1ev5umnn2bdunX3JEF3c3MDoFSpUpQrV+4ftRUVFcXEiRPzlI/zy8be/uo/avtBlfuFDlz7Byk6OpoLFy6wa9cunnvuOaZMmUKlSpUYPnw4CxYsYM6cOZhMJp544gmqVq3KiRMnzNoAOHPmDGPHjqVx48aUL18+z/5cBw8eJDs7O8/+8+fPc+zYsQKPe9jFxcUVdQgiBvVHKS7UF6U4UX98OBVmFnMuJedFyNfX12y7fPnypKam3nEbZcuWxd7e3kjMc8v27t1bqLZCQ0MZMGAA8+bNw8bGhpiYGHr27ImFxbW7H9LT04mMjGTDhg2kpKSQlZXFpUuXOH78uFk7DRs2NNuePXs2f//9NxEREQWeu0yZMoSHhxvbjRo14tSpU0ybNu2ejZ7fLREREWaxp6WlUalSJSYfsCDL+s5H5B9kP0QG5ls+dOhQgoKCOHToEC+88ALBwcGMHTuWP//8EysrK0qVKkWlSpVo2bIlwcHBxnGnTp2ibdu2tGnThiVLlhh9Mj92dnbMnDmT5s2bU6pUKbNzN2/e3KzdR0FmZiZxcXG0a9eu0LeJiNwr6o9SXKgvSnGi/vhwy51VWxhKzovQjb98JpOJ7OxsI/HIyfnflOiCpkNc34bJZCqwzcIICQkhJyeHDRs20KhRI7Zv3262KNqIESOIi4sjOjoab29v7Ozs6NatW57HWjk4mD/be8uWLezatcvs3mK4lsSHhoayfPnyfONp0qRJob9BtLCwMHu/4P5NDbKxsclzbQAZ2SayrpruSwzFzc3+sOTk5JCZmWlWp3z58sC1vpKamkrnzp2N/SdPnqRdu3Y0bNiQ5cuX3/IWhCZNmmBtbc3XX39N165dAUhISOD48eO0aNHikf2jZ21t/cheuxQ/6o9SXKgvSnGi/vhwup3PVMl5MZQ75TolJQU/Pz8As8Xh7hVbW1u6dOlCTEwMiYmJ1KhRg/r16xv7d+zYQd++fencuTNwbSQ9vynqN3r33XeZPHmysX3q1CkCAwP56KOPaNKkSYHHHTx40EjabsXNzY2UlBRj++rVq/zwww/GlPz8WFtbc/Xqoznt/H6JiIigQ4cOVK5cmb///puVK1eydetWvvjiC+B/q6i7ubmxa9cuhg0bxvDhw6lRowZwLTFv1aoVVapUITo6mj/++MNoO/d2hJMnT9KmTRtWrFhB48aNcXZ2JiwsjPDwcFxcXHBycmLIkCE0a9ZMK7WLiIiISLGl5LwYsrOzo2nTpkydOhUvLy9SU1MZN27cfTl3aGgoHTt25MiRIzz77LNm+3x8fFizZg0hISGYTCZef/31Qo3KX79YHFy7vxygWrVqVKxYEbi2OF6JEiWMLyPWrFnD0qVLWbx4caHiDggIIDw8nA0bNlCtWjVmzJjBuXPnbnqMp6cnmzdvxt/fHxsbG0qXLg3874uQ9PR0/vjjDw4ePEiJEiV47LHHChWL/E9qaip9+vQhJSUFZ2dnfH19+eKLL2jXrh1wbUQ7IiKCv/76C09PT8aOHcvw4cON4+Pi4khMTCQxMdHoK7lyZ0pkZmaSkJBgdj/PzJkzsbCwoGvXrmRkZBAYGMi8efPuwxWLiIiIiNwZJefF1NKlSwkLC6NBgwbUqFGDt99+m/bt29/z8wYEBODi4kJCQgK9e/c22zdjxgz69+9P8+bNKVOmDKNHj76teyhuZdKkSfz6669YWVlRs2ZNPvroI7p161aoY/v378+hQ4fo06cPVlZWDB8+/Kaj5gDTp08nPDycRYsWUaFCBWMWQO4XBHDtsVwrV66kSpUqhZolIOaWLFly0/1Tp05l6tSpBe7v27dvgY/Dy+Xp6ZnnlgZbW1vmzp3L3LlzCx2riIiIiEhRMuXc+H+1IvKPpKWl4ezszJ9//omrq2tRhyOPuMzMTGJjYwkODtZ9bFLk1B+luFBflOJE/fHhlpsbnD9/Hicnp5vWLXjJYxERERERERG5L5ScPyKOHz+Oo6Njga8bH4dW3Nws9u3btxd1eCIiIiIiIv+I7jl/RHh4eNx0xXcPD4/7F8wduFnsFSpUuH+BiIiIiIiI3ANKzh8RVlZWeHt7F3UYd+xBjl1ERERERORWNK1dREREREREpIgpORcREREREREpYkrORURERERERIqYknMRERERERGRIqbkXERERERERKSIKTkXERERERERKWJKzkVERERERESKmJJzERERERERkSKm5FxERERERESkiCk5FxERERERESliSs5FREREREREipiScxEREREREZEipuRcREREREREpIhZFXUAIg+rJlGbybJyKOow7rvkqf/H/PnzmT9/PsnJyQDUrl2b8ePH06FDBwBOnz7NyJEjiYuL4++//6ZGjRqMHTuWrl27Gu14enry66+/mrUdFRXFa6+9VuC5L1++zKuvvsqqVavIyMggMDCQefPmUbZs2bt/oSIiIiIid5FGzuWWTCYT69atK3B/cnIyJpOJgwcP3reYpHirWLEiU6dOZf/+/Xz77bcEBATQqVMnjhw5AkCfPn1ISEjgs88+4/Dhw3Tp0oUePXpw4MABs3beeOMNUlJSjNeQIUNuet7hw4ezfv16PvnkE7Zt28apU6fo0qXLPbtOEREREZG7Rcm5PJIyMjKoV69eni8Vtm7dSqdOnShfvjwODg7Uq1ePmJiYogv0ARUSEkJwcDA+Pj5Ur16dKVOm4OjoyO7duwHYuXMnQ4YMoXHjxlStWpVx48ZRqlQp9u/fb9ZOyZIlKVeunPFycCh4JsL58+dZsmQJM2bMICAggAYNGrBs2TJ27txpnFdEREREpLhSci6PhCtXrphtjxo1Cg8Pjzz1du7cia+vL6tXr+b777+nX79+9OnTh88///x+hfrQuXr1KqtWreLChQs0a9YMgObNm/PRRx/x119/kZ2dzapVq7h8+TKtWrUyO3bq1Km4urri5+fHtGnTyMrKKvA8+/fvJzMzk7Zt2xplNWvWpHLlyuzateueXJuIiIiIyN2ie84fEZ9++ikTJ04kMTERe3t7/Pz8+M9//sOPP/7ImDFjOHDgAJmZmdSrV4+ZM2dSv379Atvau3cvL7zwAj/99BOPP/44Y8eOzVNn27ZtjBw5kkOHDuHi4sLzzz/P5MmTsbK6eZdbuHAhkZGRnDhxAguL/3131KlTJ1xdXVm6dClJSUmEh4eze/duLly4QK1atYiKijJLyjw9PQkLC+Pnn39m3bp1dOnShffffx+AjRs38uWXX7J69Wo2btxodv4xY8aYbQ8bNowvv/ySNWvW0LFjx3xjzsjIICMjw9hOS0sDwMYiB0vLnJte78MoMzMTgMOHD/Pkk09y+fJlHB0d+eSTT/Dx8SEzM5OYmBhCQ0NxdXXFysoKe3t7PvnkE6pUqWIc//LLL+Pn50fp0qXZvXs348aN4+TJk0ybNi3f8544cYISJUrg4OBgtAHg7u7OyZMnzcoeJbnX/ahevxQv6o9SXKgvSnGi/vhwu53PVcn5IyAlJYVevXrx9ttv07lzZ/7++2+2b99OTk4Of//9N88//zyzZ88mJyeH6dOnExwczM8//0zJkiXztJWenk7Hjh1p164d//73v/nll18YNmyYWZ2TJ08SHBxM3759WbFiBUePHmXAgAHY2toSGRl501i7d+/OkCFDiI+Pp02bNgD89ddfbNq0idjYWCOG4OBgpkyZgo2NDStWrCAkJISEhAQqV65stBUdHc348eOZMGGCUfb7778zYMAA1q1bh729faHev/Pnz1OrVq0C90dFRTFx4sQ85eP8srG3v1qoczxMcj+nzMxMoqOjuXDhArt27eK5555jypQpVKpUiYULF5KcnMzEiRNxcnJiz549dO/enTfffBNPT08AqlevzoULF7hw4QIVK1bk2WefZc6cObRo0QJra+s85z148CDZ2dnG+XOdP3+eY8eO5Sl/1MTFxRV1CCIG9UcpLtQXpThRf3w4Xbx4sdB1TTk5OY/e0N4j5rvvvqNBgwYkJydTpUqVm9bNzs6mVKlSrFy50hgpNplMrF27lqeffpqFCxcyZswYTpw4ga2tLQALFizgxRdf5MCBA9SrV4+xY8eyevVqfvrpJ0wmEwDz5s1j9OjRnD9/3mxEPD9PP/00rq6uLFmyBLg2mj5x4kR+++23Ao99/PHHGTRoEIMHDwaujZz7+fmxdu1ao05OTg7BwcH4+/szbtw4kpOT8fLyMuLOz8cff8xzzz3Hd999R+3atfOtk9/IeaVKlXhs5CqyrB+91dp/iAzMtzwoKIiqVavy6quvUqtWLQ4cOGD2ngYFBVGtWjXmzp2b7/FHjhzBz8+Pw4cPU6NGjTz74+PjCQwMJDU1lVKlShnl3t7eDBkyJM+XSI+KzMxM4uLiaNeuXb5faojcT+qPUlyoL0pxov74cEtLS6NMmTKcP38eJyenm9bVyPkjoG7durRp04Y6deoQGBhI+/bt6datG6VLl+b3339n3LhxbN26ldTUVK5evcrFixc5fvx4vm399NNP+Pr6Gok5YNxHfH2dZs2aGYk5gL+/P+np6Zw4ccJsdDs/oaGhDBgwgHnz5mFjY0NMTAw9e/Y0EvP09HQiIyPZsGEDKSkpZGVlcenSpTwxN2zY0Gx79uzZ/P3330RERNz6TeNastevXz8WLVpUYGIOYGNjg42NTZ7yjGwTWVdN+RzxcCvoj0pOTg6ZmZnG1B4bGxuzurm3PBR0/JEjR7CwsKBChQr51mnSpAnW1tZ8/fXXxiPZEhISOH78eIGj7Y8Sa2vrR/49kOJD/VGKC/VFKU7UHx9Ot/OZakG4R4ClpSVxcXFs3LiRxx57jNmzZ1OjRg1++eUXnn/+eQ4ePMg777zDzp07OXjwIK6urnkWULufQkJCyMnJYcOGDfz2229s376d0NBQY/+IESNYu3Ytb775Jtu3b+fgwYPUqVMnT8w3ruy9ZcsWdu3ahY2NDVZWVnh7ewPXkvjnn3/erO62bdsICQlh5syZ9OnT5x5d6cMrIiKCr7/+muTkZA4fPkxERARbt24lNDSUmjVr4u3tzQsvvMDevXtJSkpi+vTpxMXF8fTTTwOwa9cuZs2axaFDhzh27BgxMTEMHz6cZ599ltKlSwPXbp+oWbMme/fuBcDZ2ZmwsDDCw8OJj49n//799OvXj2bNmtG0adOieitERERERApFI+ePCJPJhL+/P/7+/owfP54qVaqwdu1aduzYwbx58wgODgbgt99+488//yywnVq1avHBBx9w+fJlY/T8xsdU1apVi9WrV5OTk2OMnu/YsYOSJUtSsWLFW8Zqa2tLly5diImJITExkRo1apgtULdjxw769u1L586dgWsj6cnJybds991332Xy5MnG9qlTpwgMDOSjjz6iSZMmRvnWrVvp2LEjb731FgMHDrxlu5JXamoqffr0ISUlBWdnZ3x9ffniiy9o164dcO2+9Ndee42QkBDS09Px9vZm+fLlRj+0sbFh1apVREZGkpGRgZeXF8OHDyc8PNw4R2ZmJgkJCWb38cycORMLCwu6du1KRkYGgYGBzJs37/5evIiIiIjIHVBy/gjYs2cPmzdvpn379ri7u7Nnzx7++OMPatWqhY+PDx988AENGzYkLS2NkSNHYmdnV2BbvXv3ZuzYsQwYMICIiAiSk5OJjo42q/PSSy8xa9YshgwZwuDBg0lISGDChAmEh4ff8n7zXKGhoXTs2JEjR47w7LPPmu3z8fFhzZo1hISEYDKZeP3118nOzr5lmzdOp3d0dASgWrVqxpcG8fHxdOzYkWHDhtG1a1dOnz4NQIkSJXBxcSlU7IKxXkBBfHx8WL16dYH769evf8tnk3t6enLjkhm2trbMnTu3wPvWRURERESKKyXnjwAnJye+/vprZs2aRVpaGlWqVGH69Ol06NCBcuXKMXDgQOrXr0+lSpV48803GTFiRIFtOTo6sn79egYNGoSfnx+PPfYYb731lnGPL0CFChWIjY1l5MiR1K1bFxcXF8LCwhg3blyhYw4ICMDFxYWEhAR69+5ttm/GjBn079+f5s2bU6ZMGUaPHm08vuyfWr58ORcvXiQqKoqoqCijvGXLlmzduvW22toT0QZXV9e7EpeIiIiIiDzctFq7yF2WlpaGs7Mzf/75p5JzKXKZmZnExsYSHBysRWakyKk/SnGhvijFifrjwy03NyjMau1aEE5ERERERESkiCk5l/vq+PHjODo6Fvgq6BFuIiIiIiIiDzPdcy73lYeHBwcPHrzpfhERERERkUeNknO5r65/vriIiIiIiIhco2ntIiIiIiIiIkVMybmIiIiIiIhIEVNyLiIiIiIiIlLElJyLiIiIiIiIFDEl5yIiIiIiIiJFTMm5iIiIiIiISBFTci4iIiIiIiJSxJSci4iIiIiIiBQxJeciIiIiIiIiRUzJuYiIiIiIiEgRU3IuIiIiIiIiUsSUnIuIiIiIiIgUMauiDkDkYdUkajNZVg5FHcZ9lTz1/5g/fz7z588nOTkZgNq1azN+/Hg6dOhAcnIyXl5e+R778ccf0717dwA2b97M66+/zuHDh3FwcOD5559nypQpWFkV/E/W5cuXefXVV1m1ahUZGRkEBgYyb948ypYte9evU0RERETkbtPI+UOuVatWvPLKK0UdRrFgMplYt25dUYfx0KtYsSJTp05l//79fPvttwQEBNCpUyeOHDlCpUqVSElJMXtNnDgRR0dHOnToAMChQ4cIDg4mKCiIAwcO8NFHH/HZZ5/x2muv3fS8w4cPZ/369XzyySds27aNU6dO0aVLl/txySIiIiIi/5iSc7mvzpw5Q8WKFTGZTJw7d84o37p1KyaTKc/r9OnT9ySO5ORkTCYTBw8eNCtfs2YNDRs2pFSpUjg4OFCvXj0++OCDexLDwyokJITg4GB8fHyoXr06U6ZMwdHRkd27d2NpaUm5cuXMXmvXrqVHjx44OjoC8NFHH+Hr68v48ePx9vamZcuWvP3228ydO5e///4733OeP3+eJUuWMGPGDAICAmjQoAHLli1j586d7N69+35evoiIiIjIHVFyLvdUZmam2XZYWBi+vr4F1k9ISDAbVXV3d7/XIZpxcXFh7Nix7Nq1i++//55+/frRr18/vvjii/sax8Pi6tWrrFq1igsXLtCsWbM8+/fv38/BgwcJCwszyjIyMrC1tTWrZ2dnx+XLl9m/f3++59m/fz+ZmZm0bdvWKKtZsyaVK1dm165dd+lqRERERETunYc+OW/VqhVDhw5l1KhRuLi4UK5cOSIjI4H8R0/PnTuHyWRi69atwP9GdL/44gv8/Pyws7MjICCA1NRUNm7cSK1atXBycqJ3795cvHix0DENGTKEV155hdKlS1O2bFkWLVrEhQsX6NevHyVLlsTb25uNGzeaHffDDz/QoUMHHB0dKVu2LM899xx//vmnsf/ChQv06dMHR0dHypcvz/Tp0wv9Po0ZM4YmTZrkKa9bty5vvPEGAPv27aNdu3aUKVMGZ2dnWrZsyXfffWdW32QyMX/+fJ566ikcHByYMmWKsW/+/PmcO3eOESNGFBiHu7u72aiqhUXhuqinpyezZs0yK6tXr57xWd8o975nPz8/TCYTrVq1Aq59Np07d6ZWrVpUq1aNYcOG4evryzfffFOoOOSaw4cP4+joiI2NDYMGDWLt2rU89thjeeotWbKEWrVq0bx5c6MsMDCQnTt38uGHH3L16lVOnjxp9MGUlJR8z3f69GlKlChBqVKlzMrLli17z2ZfiIiIiIjcTY/EgnDLly8nPDycPXv2sGvXLvr27Yu/vz8+Pj6FbiMyMpI5c+Zgb29Pjx496NGjBzY2NqxcuZL09HQ6d+7M7NmzGT16dKFjGjVqFHv37uWjjz7ixRdfZO3atXTu3JkxY8Ywc+ZMnnvuOY4fP469vT3nzp0jICCAf/3rX8ycOZNLly4xevRoevTowZYtWwAYOXIk27Zt4z//+Q/u7u6MGTOG7777jnr16t0yntDQUKKiokhKSqJatWoAHDlyhO+//57Vq1cD8Pfff/P8888ze/ZscnJymD59OsHBwfz888+ULFnS7L2aOnUqs2bNMhbw+vHHH3njjTfYs2cPx44dKzCOevXqkZGRweOPP05kZCT+/v6Fej9v1969e2ncuDFfffUVtWvXpkSJEnnq5OTksGXLFhISEnjrrbcKbCsjI4OMjAxjOy0tDQAbixwsLXPufvDFWO5MiapVq7Jv3z7S0tJYvXo1zz//PF999ZVZgn7p0iVWrlzJmDFjzGZYtG7dmqlTpzJo0CCee+45bGxsGDNmDNu3byc7OzvPbAyArKwss/PnysnJ4erVq/ke86jIvfZH+T2Q4kP9UYoL9UUpTtQfH26387k+Esm5r68vEyZMAMDHx4c5c+awefPm20rOJ0+ebCSKYWFhREREkJSURNWqVQHo1q0b8fHxhU7O69aty7hx4wCIiIhg6tSplClThgEDBgAwfvx45s+fz/fff0/Tpk2ZM2cOfn5+vPnmm0YbS5cupVKlSvz3v//Fw8ODJUuW8O9//5s2bdoA174AqFixYqHiqV27NnXr1mXlypW8/vrrAMTExNCkSRO8vb0BCAgIMDtm4cKFlCpVim3bttGxY0ejvHfv3vTr18/YzsjIoFevXkybNo3KlSvnm5yXL1+eBQsW0LBhQzIyMli8eDGtWrViz5491K9fv1DXcDvc3NwAcHV1pVy5cmb7zp8/T4UKFcjIyMDS0pJ58+bRrl27AtuKiopi4sSJecrH+WVjb3/17gZezMXGxuYp8/f354svvmDUqFG89NJLRnl8fDwXLlygXLlyeY6rXr06y5cv5+zZszg4OJCamgpcGznP7xy//vorV65c4eOPPzbuXc8tP3v2bL7HPGri4uKKOgQRg/qjFBfqi1KcqD8+nAo7uxoeoeT8euXLlzf+Z/9O2ihbtiz29vZGYp5btnfv3jtqz9LSEldXV+rUqWPWHmDEeejQIeLj480Sj1xJSUlcunSJK1eumE1Nd3FxoUaNGoWOKTQ0lKVLl/L666+Tk5PDhx9+SHh4uLH/999/Z9y4cWzdupXU1FSuXr3KxYsXOX78uFk7DRs2NNuOiIigVq1aPPvsswWeu0aNGmaxNm/enKSkJGbOnHnfF2QrWbIkBw8eJD09nc2bNxMeHk7VqlWNqe83ioiIMHuf0tLSqFSpEpMPWJBlbXmfoi4efogMzLd81qxZlC1bluDgYKNsxowZhISE0KtXr1u2GxkZSaVKlRg8eDCWlnnfU39/fyZNmoSVlZVxjoSEBP744w/69euX7y0bj4rMzEzi4uJo164d1tbWRR2OPOLUH6W4UF+U4kT98eGWO6u2MB6J5PzGTm4ymcjOzjbuZ87J+d/U44KmHVzfhslkKrDNfxLTjecAjDbT09MJCQnJd3p1+fLlSUxMLPS5C9KrVy9Gjx7Nd999x6VLl/jtt9945plnjP3PP/88Z86c4Z133qFKlSrY2NjQrFkzrly5YtaOg4P5s723bNnC4cOH+fTTT4H/vd9lypRh7Nix+Y46AzRu3LjQ93pbWFiYfY5w51ODLCwsjNkC9erV46effiIqKqrA5NzGxgYbG5s85RnZJrKumu4ohgeVtbU1ERERdOjQgcqVK/P333+zcuVKtm3bxhdffGH08cTERLZv305sbGy+f4SmTZtGUFAQFhYWrFmzhmnTpvHxxx8bC8WdPHmSNm3asGLFCho3bkyZMmUICwtj1KhRuLu74+TkxJAhQ2jWrBktWrS4r+9BcWVtba0/+FJsqD9KcaG+KMWJ+uPD6XY+00ciOS9I7tTmlJQU/Pz8API8Wqu4qF+/PqtXr8bT09O4j/t61apVw9ramj179lC5cmUAzp49y3//+19atmxZqHNUrFiRli1bEhMTw6VLl2jXrp3Zauk7duxg3rx5xsjkb7/9ZrYgXUFWr17NpUuXjO19+/bRv39/tm/fbtzfnp+DBw9Svnz5QsXu5uZmtlhYWloav/zyS4H1c+8xv3r11tPOs7Ozze4pl5tLTU2lT58+pKSk4OzsjK+vL1988YXZrQFLly6lYsWKtG/fPt82Nm7cyJQpU8jIyKBu3br85z//MZ6DDte+eElISDCbJjRz5kwsLCzo2rUrGRkZBAYGMm/evHt3oSIiIiIid9EjnZzb2dnRtGlTpk6dipeXF6mpqcZ94MXNyy+/zKJFi+jVq5ex8nxiYiKrVq1i8eLFODo6EhYWxsiRI3F1dcXd3Z2xY8cWerXzXKGhoUyYMIErV64wc+ZMs30+Pj588MEHNGzYkLS0NEaOHImdfDlBHAAALChJREFUnd0t27wxAc9N6GvVqmWsrj1r1iy8vLyoXbs2ly9fZvHixWzZsoUvv/yyUHEHBATw/vvvExISQqlSpRg/fny+059zubu7Y2dnx6ZNm6hYsSK2trY4OzsTFRVFw4YNqVatGhkZGcTGxvLBBx8wf/78QsUh11Zgv5U333zTbP2EG+UuclgQT0/PPDMlbG1tmTt3LnPnzi1coCIiIiIixchD/yi1W1m6dClZWVk0aNCAV155hcmTJxd1SPny8PBgx44dXL16lfbt21OnTh1eeeUVSpUqZSTg06ZN44knniAkJIS2bdvSokULGjRocFvn6datG2fOnOHixYs8/fTTZvuWLFnC2bNnqV+/Ps899xxDhw69a88hv3LlCq+++v/au/e4mvL9f+CvXbv7nl0yFSFCQ4wSknKv6ILJTGMO+kou4zhKwnRkDtEYNGRSho45HHFkmgfDDKZB465JqSOXhmZCk8mlMVSKsqv1+8OvdewplVGtyuv5eOzHo/1Zn70+77X32/Z4789an7UQffr0wfDhw3HhwgV8//334uJ2dVm8eDGGDx+OsWPHYsyYMRg/fnyts/JyuRzR0dHYvHkzzM3N4eXlBeDp7ejmzJmD3r17Y/Dgwfjqq6+wc+dOzJw5s0GOk4iIiIiIqCYy4Y/TT0T0UoqKimBoaIh79+6hbdu2UodDrziVSoWEhAR4enryOjaSHPORmgvmIjUnzMfWrao2KCwshFKprLXvKz9zTkRERERERCQ1FucNLDc3FwqF4rmPP952rKmcPn261rias+b6nhIRERERETWUV3pBuMZgbm5e64rv5ubmTRfMMwYMGNBsV6KvS3N9T4mIiIiIiBoKi/MGJpfLxXtkNyd6enrNMq76aK7vKRERERERUUPhae1EREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxudQBELVWDquPolxuIHUYjS4nfIzUIRARERERtXicOf+DESNGICgoSOowqIH5+flh/PjxUofRqsXExMDGxgZKpRJKpRKOjo747rvv1PokJyfD2dkZBgYGUCqVGDZsGB4/fgwAyMnJwYwZM2BpaQk9PT1069YNy5Ytw5MnT2odt7S0FP7+/mjbti0UCgW8vb1x9+7dRjtOIiIiIqLGwOL8D/bu3YsVK1ZIHcZLOXHiBGQyGQoKCqQOBQCwcuVKODk5QV9fH0ZGRs/tFxsbCxsbG+jq6sLU1BT+/v6NFtPzfoQJDAxE//79oaOjg759+zba+K1Rx44dER4ejvT0dKSlpcHZ2RleXl7IzMwE8LQwd3d3x+jRo5Gamopz584hICAAGhpPv4auXr2KyspKbN68GZmZmYiMjMQ///lPfPjhh7WOO3/+fBw4cAC7d+/GyZMncevWLbzzzjuNfrxERERERA2Jp7X/gbGxsdQhtBpPnjyBtrY2njx5ggkTJsDR0RFbt26tse+nn36KdevWYe3atXBwcEBJSQlycnKaNuD/b/r06UhJScHFixclGb+lGjdunNrzlStXIiYmBmfPnkXv3r0xf/58BAYGIiQkROzTo0cP8W93d3e4u7uLz7t27YqsrCzExMQgIiKixjELCwuxdetW7Nq1C87OzgCAbdu2wdraGmfPnsWgQYMa8hCJiIiIiBoNZ87/4NkZ1S5duuDjjz+Gr68vFAoFOnfujP379+O3336Dl5cXFAoFbGxskJaWJr4+NjYWRkZG+Prrr2FlZQVdXV24ubnh5s2b9Y7hm2++Qb9+/aCrq4uuXbsiLCwM5eXl4naZTIYtW7bg7bffhr6+PqysrLB//34AT08NHjlyJACgTZs2kMlk8PPzq3W8zz//HObm5qisrFRr9/LywvTp0wEA165dg5eXF8zMzKBQKGBvb4/vv/9erX+XLl2wYsUK+Pr6QqlUYtasWQCAsLAwzJ8/H3369Klx/AcPHmDJkiXYsWMHJk+ejG7dusHGxgZvvfVWvd6v5cuXV5vlXr9+Pbp06VJjfz8/P5w8eRJRUVGQyWSQyWTiDwHR0dHw9/dH165d6zU21ayiogLx8fEoKSmBo6Mj8vPzkZKSAlNTUzg5OcHMzAzDhw/HmTNnat1PYWFhrT+YpaenQ6VSwdXVVWzr2bMnLCwskJyc3GDHQ0RERETU2DhzXofIyEisWrUKS5cuRWRkJKZMmQInJydMnz4da9euxaJFi+Dr64vMzEzIZDIAwKNHj7By5Urs2LED2tramDNnDiZOnIikpKQ6xzt9+jR8fX0RHR2NoUOH4tq1a2KRu2zZMrFfWFgY1qxZg7Vr12LDhg3w8fHBL7/8gk6dOuGrr76Ct7c3srKyoFQqoaenV+uYEyZMwNy5c3H8+HG4uLgAAO7fv49Dhw4hISEBAFBcXAxPT0+sXLkSOjo62LFjB8aNG4esrCxYWFiI+4qIiEBoaKharHVJTExEZWUl8vLyYG1tjYcPH8LJyQnr1q1Dp06d6r2f+oqKisJPP/2EN998Ex999BEAwMTE5E/vr6ysDGVlZeLzoqIiAICOhgBNTeHlgm0BVCqV+PelS5cwbNgwlJaWQqFQYPfu3bCyskJKSgqApz+kfPLJJ7CxsUFcXBxcXFxw/vx5WFlZVdtvdnY2NmzYgE8++URtjGf9+uuv0NbWhoGBgVofU1NT5OXlPfd1r5Kq94DvBTUHzEdqLpiL1JwwH1u3F/lcWZzXwdPTE3/9618BAKGhoYiJiYG9vT0mTJgAAFi0aBEcHR1x9+5dtGvXDsDTD+Czzz6Dg4MDAGD79u2wtrZGamoqBg4cWOt4YWFhCAkJwdSpUwE8PbV3xYoV+Pvf/65W8Pr5+WHSpEkAgFWrViE6Ohqpqalwd3cXZxpNTU1rvca7Sps2beDh4YFdu3aJxfmePXvw+uuvi7Pwtra2sLW1FV+zYsUK7Nu3D/v370dAQIDY7uzsjIULF9Y55rOuX7+OyspKrFq1ClFRUTA0NMSSJUswatQoXLx4Edra2i+0v7oYGhpCW1sb+vr64mf2MlavXo2wsLBq7UvsKqGvX/HS+2/uqn7AAZ7mfkREBEpKSpCcnIwpU6Zg5cqVKCkpAQCMHDkSJiYmuH37NpydnfHNN98gNDQUU6ZMUdvn77//jn/84x8YOHAg2rdvrzbGszIyMlBZWVlte2FhIa5fv/7c172KEhMTpQ6BSMR8pOaCuUjNCfOxdXr06FG9+7I4r4ONjY34t5mZGQConZ5d1Zafny8WenK5HPb29mKfnj17wsjICFeuXKmzOL9w4QKSkpKwcuVKsa2iogKlpaV49OgR9PX1q8VVtfJ1fn7+nz1M+Pj44P3338emTZugo6ODuLg4TJw4UVysq7i4GMuXL8e3336L27dvo7y8HI8fP0Zubq7afgYMGPDCY1dWVkKlUiE6OhqjR48GAHzxxRdo164djh8/Djc3tz99XE1h8eLFWLBggfi8qKgInTp1wsfnNVCupSlhZE3j8vKaP5/AwEC4u7vjwoULCA4ORkhICMaOHQtPT0+xz86dOyGXy9Xabt26BVdXV7i4uGDr1q1iDtZET08PkZGRcHJyUvshKjAwEE5OTmr7fVWpVCokJiZi1KhR0NLSkjocesUxH6m5YC5Sc8J8bN2qzqqtDxbndXj2H0jVaes1tf3xeu0/q7i4GGFhYTWuNq2rq1tjXFVxvEwM48aNgyAI+Pbbb2Fvb4/Tp08jMjJS3P7BBx8gMTERERER6N69O/T09PDuu+9Wu82VgcGL39e7ffv2AIBevXqJbSYmJnj99derFf810dDQgCConz7elKcF6ejoQEdHp1p7WaUM5RWyJotDKrX9JyIIAlQqFaysrGBubo5r166p9c/OzoaHh4fYlpeXh1GjRmHAgAHYvn07NDVr/3HDwcEBWlpaOHXqFLy9vQEAWVlZyM3NxZAhQ/gf3DO0tLT4flCzwXyk5oK5SM0J87F1epHPlMV5IygvL0daWpo4S56VlYWCggJYW1vX+dp+/fohKysL3bt3/9PjV50GXlFR/1OqdXV18c477yAuLg7Z2dno0aMH+vXrJ25PSkqCn58f3n77bQBPf0RoqNXUBw8eDODp+9SxY0cAT695v3fvHjp37lzn601MTHDnzh0IgiD+WJKRkVHra7S1tV/o/aG6LV68GB4eHrCwsMDDhw+xa9cunDhxAocPH4ZMJkNwcDCWLVsGW1tb9O3bF9u3b8fVq1exZ88eAE8L8xEjRqBz586IiIjAb7/9Ju676qyUvLw8uLi4YMeOHRg4cCAMDQ0xY8YMLFiwAMbGxlAqlZg7dy4cHR25UjsRERERtSgszhuBlpYW5s6di+joaMjlcgQEBGDQoEF1ntIOPL2ufezYsbCwsMC7774LDQ0NXLhwAZcvX8bHH39cr/E7d+4MmUyGgwcPwtPTE3p6elAoFHW+zsfHB2PHjkVmZib+7//+T22blZUV9u7di3HjxkEmk2Hp0qX1nqnPzc3F/fv3kZubi4qKCrFw7t69OxQKBd544w14eXlh3rx5+Pzzz6FUKrF48WL07NlTvOa9NiNGjMBvv/2GNWvW4N1338WhQ4fw3XffQalUPvc1Xbp0QUpKCnJycqBQKGBsbAwNDQ1kZ2ejuLgYd+7cwePHj8VYe/Xq1eDXvrc2+fn58PX1xe3bt2FoaAgbGxscPnwYo0aNAgAEBQWhtLQU8+fPx/3792Fra4vExER069YNwNPrrLKzs5GdnS3+SFOl6swIlUqFrKwstWt3IiMjoaGhAW9vb5SVlcHNzQ2bNm1qoqMmIiIiImoYvJVaI9DX18eiRYswefJkDB48GAqFAl9++WW9Xuvm5oaDBw/iyJEjsLe3x6BBgxAZGVmvGeQqHTp0EBeWMzMzU1uwrTbOzs4wNjZGVlYWJk+erLbt008/RZs2beDk5IRx48bBzc1NbWa9NqGhobCzs8OyZctQXFwMOzs72NnZqd2CbseOHXBwcMCYMWMwfPhwaGlp4dChQ/U6DcTa2hqbNm3Cxo0bYWtri9TUVHzwwQe1vuaDDz6ApqYmevXqBRMTE/H0+ZkzZ8LOzg6bN2/GTz/9JMZ669ateh3rq2zr1q3IyclBWVkZ8vPz8f3334uFeZWQkBDcvHkTJSUl+OGHHzBkyBBxm5+fHwRBqPFRpUuXLhAEASNGjBDbdHV1sXHjRty/fx8lJSXYu3dvgyz0R0RERETUlGTCHy/WpZcSGxuLoKAgFBQUSB0KSaSoqAiGhoa4d+8e2rZtK3U49IpTqVRISEiAp6cnr2MjyTEfqblgLlJzwnxs3apqg8LCwlrP7AU4c05EREREREQkORbnTax3795QKBQ1PuLi4hplzNzc3OeOqVAo6rUiupQ8PDyeG/uqVaukDo+IiIiIiOilcUG4Bubn5wc/P7/nbk9ISHjubb6q7pne0MzNzWtdvdzc3LxRxm0oW7ZswePHj2vcZmxs3MTREBERERERNTwW503sRRZ2ayhyufylbs0mtQ4dOkgdAhERERERUaPiae1EREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEpNLHQBRa+Ww+ijK5QZSh9HocsLHICYmBjExMcjJyQEA9O7dG6GhofDw8BD7JScn4x//+AdSUlKgqamJvn374vDhw9DT0wMA3L9/H3PnzsWBAwegoaEBb29vREVFQaFQPHfs0tJSLFy4EPHx8SgrK4Obmxs2bdoEMzOzRj1mIiIiIqKGxpnzehoxYgSCgoKkDoP+pJycHMhkMmRkZEgdSqvUsWNHhIeHIz09HWlpaXB2doaXlxcyMzMBPC3M3d3dMXr0aKSmpuLcuXMICAiAhsb/voJ8fHyQmZmJxMREHDx4EKdOncKsWbNqHXf+/Pk4cOAAdu/ejZMnT+LWrVt45513GvVYiYiIiIgaA4vzetq7dy9WrFghdRgtXlJSEuRyOfr27avWfurUKYwbNw7m5uaQyWT4+uuvGzWOEydOQCaToaCgQNI4Wotx48bB09MTVlZWeOONN7By5UooFAqcPXsWwNMiOjAwECEhIejduzd69OiB9957Dzo6OgCAK1eu4NChQ9iyZQscHBwwZMgQbNiwAfHx8bh161aNYxYWFmLr1q349NNP4ezsjP79+2Pbtm344YcfxHGJiIiIiFoKFuf1ZGxsjNdee03qMFoUQRBQXl4uPi8oKICvry9cXFyq9S0pKYGtrS02btzYlCE22zhasoqKCsTHx6OkpASOjo7Iz89HSkoKTE1N4eTkBDMzMwwfPhxnzpwRX5OcnAwjIyMMGDBAbHN1dYWGhgZSUlJqHCc9PR0qlQqurq5iW8+ePWFhYYHk5OTGO0AiIiIiokbAa87racSIEejbty/Wr1+PLl26YObMmfjpp5+wd+9etG3bFhs2bICjoyNmzpyJo0ePomvXrvj3v/8tFhuxsbEICgpCbGwsgoODcfPmTQwfPhxbtmxBp06d6hVDTEwMIiIicPPmTVhaWmLJkiWYMmWKuF0mk2HTpk3Yv38/Tpw4gfbt22PNmjV4991369y3k5MThg4dik8++URs++2332Bubo6jR49i2LBh+M9//oOoqChkZWXBwMAAzs7OWL9+PUxNTQE8nY0eOXIkEhISsGTJEly6dAlHjhzBiBEjAACzZ8/G5MmToampWW1G2sPDQ+365Bclk8mwb98+jB8/XmwzMjLC+vXr4efnp9Y3JycHI0eOBAC0adMGADB16lTExsb+qTjKyspQVlYmPi8qKgIA6GgI0NQU/sTRtCwqlQoAcOnSJQwbNgylpaVQKBTYvXs3rKysxOJ6+fLl+OSTT2BjY4O4uDi4uLjg/PnzsLKyQl5eHkxMTMR9VTE2NkZeXl61dgD49ddfoa2tDQMDA7Xtpqamz33Nq6jqfeD7Qc0B85GaC+YiNSfMx9btRT5XFud/UmRkJFatWoWlS5ciMjISU6ZMgZOTE6ZPn461a9di0aJF8PX1RWZmJmQyGQDg0aNHWLlyJXbs2AFtbW3MmTMHEydORFJSUp3j7du3D/PmzcP69evh6uqKgwcPYtq0aejYsaNYaALA0qVLER4ejqioKPznP//BxIkTcenSJVhbW9e6fx8fH6xZswbh4eFivF9++SXMzc0xdOhQAE8Ta8WKFejRowfy8/OxYMEC+Pn5ISEhQW1fISEhiIiIQNeuXcXid9u2bbh+/Tp27tyJjz/+uP5vdCPo1KkTvvrqK3h7eyMrKwtKpVJclOzPWL16NcLCwqq1L7GrhL5+xcuE2iJUff4qlQoREREoKSlBcnIypkyZgpUrV6KkpAQAMHLkSJiYmOD27dtwdnbGN998g9DQUEyZMgVZWVkoKSmplktPnjzB5cuXq7UDQEZGBiorK6ttKywsxPXr12t8zassMTFR6hCIRMxHai6Yi9ScMB9bp0ePHtW7L4vzP8nT0xN//etfAQChoaGIiYmBvb09JkyYAABYtGgRHB0dcffuXbRr1w7A0+Lls88+g4ODAwBg+/btsLa2RmpqKgYOHFjreBEREfDz88OcOXMAAAsWLMDZs2cRERGhVpxPmDABM2fOBACsWLECiYmJ2LBhAzZt2lTr/t977z0EBQXhzJkzYjG+a9cuTJo0SSzWp0+fLvbv2rUroqOjYW9vj+LiYrUVtT/66COMGjVKfP7zzz8jJCQEp0+fhlwufcppamrC2NgYwNNZViMjo5fa3+LFi7FgwQLxeVFRETp16oSPz2ugXEvzpfbdElxe7latLTAwEO7u7rhw4QKCg4MREhKCsWPHwtPTU+yzc+dOyOVyeHp6Ij8/H99++63a9vLychQXF8PFxUWtvYqenh4iIyPh5OSk9hkGBgbCycmpxte8ilQqFRITEzFq1ChoaWlJHQ694piP1FwwF6k5YT62blVn1daH9JVSC2VjYyP+XXXbpj59+lRry8/PF4tzuVwOe3t7sU/Pnj1hZGSEK1eu1FmcX7lypdrK1YMHD0ZUVJRam6OjY7Xn9Vmh3MTEBKNHj0ZcXByGDh2KGzduIDk5GZs3bxb7pKenY/ny5bhw4QIePHiAyspKAEBubi569eol9nv2uuGKigpMnjwZYWFheOONN+qMoyXS0dERFzZ7VlmlDOUVMgkialrP+09EEASoVCpYWVnB3Nwc165dU+ubnZ0NDw8PaGlpYciQISgoKMDFixfRv39/AMDx48dRWVmJwYMH1ziGg4MDtLS0cOrUKXh7ewMAsrKykJubiyFDhvA/tz/Q0tLie0LNBvORmgvmIjUnzMfW6UU+Uy4I9yc9+yZXzSzX1FZVwLYEPj4+2LNnD1QqFXbt2oU+ffqIPziUlJTAzc0NSqUScXFxOHfuHPbt2wfg6anHzzIw+N+9vR8+fIi0tDQEBARALpdDLpfjo48+woULFyCXy3Hs2LEGiV0mk0EQ1K/v5nU7TWfx4sU4deoUcnJycOnSJSxevBgnTpyAj48PZDIZgoODER0djT179iA7OxtLly7F1atXMWPGDACAtbU13N3d8f777yM1NRVJSUkICAjAxIkTYW5uDgDIy8tDz549kZqaCgAwNDTEjBkzsGDBAhw/fhzp6emYNm0aHB0dMWjQIMneCyIiIiKiP4Mz502ovLwcaWlp4ix5VlYWCgoK6rweHHhavCQlJWHq1KliW1JSktqMNQCcPXsWvr6+as/t7OzqFZ+XlxdmzZqFQ4cOYdeuXWr7uXr1Kn7//XeEh4eLC9ilpaXVuU+lUolLly6ptW3atAnHjh3Dnj17YGlpWa/Y6lJ1LXOVn3/+udbrO7S1tQE8ndmnl5efnw9fX1/cvn0bhoaGsLGxweHDh8XLG4KCglBaWor58+fj/v37sLW1RWJiIrp16ybuIy4uDgEBAXBxcYGGhga8vb0RHR0tblepVMjKylL7XCMjI8W+ZWVlcHNzq/MSDiIiIiKi5ojFeRPS0tLC3LlzER0dDblcjoCAAAwaNKjOU9oBIDg4GO+99x7s7Ozg6uqKAwcOYO/evfj+++/V+u3evRsDBgzAkCFDEBcXh9TUVGzdurVe8RkYGGD8+PFYunQprly5gkmTJonbLCwsoK2tjQ0bNmD27Nm4fPlyve77rqGhgTfffFOtzdTUFLq6umrtxcXFyM7OFp/fuHEDGRkZMDY2hoWFRZ3jODs747PPPoOjoyMqKiqwaNGiWk8h6dy5M2QyGQ4ePAhPT0/o6elBoVC8dByvqvrkWEhICEJCQp673djYGLt27Xru9i5dulQ7O0JXVxcbN27kre+IiIiIqMVjcd6E9PX1sWjRIkyePBl5eXkYOnRovQvn8ePHIyoqChEREZg3bx4sLS2xbds28TZlVcLCwhAfH485c+agffv2+OKLL6rNrtfGx8cHnp6eGDZsmFoxamJigtjYWHz44YeIjo5Gv379EBERgbfeeqve+65NWlqa2sJ2VQusVd3irC7r1q3DtGnTMHToUJibmyMqKgrp6enP7d+hQweEhYUhJCQE06ZNg6+vL2JjY186jmelLHZB27ZtX+g1RERERET0apIJf5yKokZRdZ/zgoKCRhujpnt9U9MrKiqCoaEh7t27x+KcJKdSqZCQkABPT08uMkOSYz5Sc8FcpOaE+di6VdUGhYWFUCqVtfblgnBEREREREREEmNx3kz07t0bCoWixkdcXNxL73/VqlXP3b+Hh0cDHEHjOX369HNjf/b+6kRERERERC0VrzlvIn5+fvDz83vu9oSEhOfe+qvqnul1qe0KhdmzZ+O9996rcZuenl699i+VAQMG1Ote7URERERERC0Vi/NmonPnzo26f2NjYxgbGzfqGI1FT08P3bt3lzoMIiIiIiKiRsPT2omIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkxuKciIiIiIiISGIszomIiIiIiIgkJpc6AKLWRhAEAMDDhw+hpaUlcTT0qlOpVHj06BGKioqYjyQ55iM1F8xFak6Yj61bUVERgP/VCLVhcU7UwH7//XcAgKWlpcSREBERERFRc/Dw4UMYGhrW2ofFOVEDMzY2BgDk5ubW+Q+QqLEVFRWhU6dOuHnzJpRKpdTh0CuO+UjNBXORmhPmY+smCAIePnwIc3PzOvuyOCdqYBoaT5dyMDQ05BcsNRtKpZL5SM0G85GaC+YiNSfMx9arvhN2XBCOiIiIiIiISGIszomIiIiIiIgkxuKcqIHp6Ohg2bJl0NHRkToUIuYjNSvMR2oumIvUnDAfqYpMqM+a7kRERERERETUaDhzTkRERERERCQxFudEREREREREEmNxTkRERERERCQxFudEREREREREEmNxTtTANm7ciC5dukBXVxcODg5ITU2VOiRq4U6dOoVx48bB3NwcMpkMX3/9tdp2QRAQGhqK9u3bQ09PD66urvj555/V+ty/fx8+Pj5QKpUwMjLCjBkzUFxcrNbn4sWLGDp0KHR1ddGpUyesWbOmsQ+NWpjVq1fD3t4er732GkxNTTF+/HhkZWWp9SktLYW/vz/atm0LhUIBb29v3L17V61Pbm4uxowZA319fZiamiI4OBjl5eVqfU6cOIF+/fpBR0cH3bt3R2xsbGMfHrUwMTExsLGxgVKphFKphKOjI7777jtxO3ORpBIeHg6ZTIagoCCxjflI9cHinKgBffnll1iwYAGWLVuG//73v7C1tYWbmxvy8/OlDo1asJKSEtja2mLjxo01bl+zZg2io6Pxz3/+EykpKTAwMICbmxtKS0vFPj4+PsjMzERiYiIOHjyIU6dOYdasWeL2oqIijB49Gp07d0Z6ejrWrl2L5cuX4/PPP2/046OW4+TJk/D398fZs2eRmJgIlUqF0aNHo6SkROwzf/58HDhwALt378bJkydx69YtvPPOO+L2iooKjBkzBk+ePMEPP/yA7du3IzY2FqGhoWKfGzduYMyYMRg5ciQyMjIQFBSEmTNn4vDhw016vNS8dezYEeHh4UhPT0daWhqcnZ3h5eWFzMxMAMxFksa5c+ewefNm2NjYqLUzH6leBCJqMAMHDhT8/f3F5xUVFYK5ubmwevVqCaOi1gSAsG/fPvF5ZWWl0K5dO2Ht2rViW0FBgaCjoyN88cUXgiAIwo8//igAEM6dOyf2+e677wSZTCbk5eUJgiAImzZtEtq0aSOUlZWJfRYtWiT06NGjkY+IWrL8/HwBgHDy5ElBEJ7mnpaWlrB7926xz5UrVwQAQnJysiAIgpCQkCBoaGgId+7cEfvExMQISqVSzL+///3vQu/evdXG+stf/iK4ubk19iFRC9emTRthy5YtzEWSxMOHDwUrKyshMTFRGD58uDBv3jxBEPjdSPXHmXOiBvLkyROkp6fD1dVVbNPQ0ICrqyuSk5MljIxasxs3buDOnTtqeWdoaAgHBwcx75KTk2FkZIQBAwaIfVxdXaGhoYGUlBSxz7Bhw6CtrS32cXNzQ1ZWFh48eNBER0MtTWFhIQDA2NgYAJCeng6VSqWWjz179oSFhYVaPvbp0wdmZmZiHzc3NxQVFYkznsnJyWr7qOrD71J6noqKCsTHx6OkpASOjo7MRZKEv78/xowZUy1nmI9UX3KpAyBqLe7du4eKigq1L1UAMDMzw9WrVyWKilq7O3fuAECNeVe17c6dOzA1NVXbLpfLYWxsrNbH0tKy2j6qtrVp06ZR4qeWq7KyEkFBQRg8eDDefPNNAE9zRVtbG0ZGRmp9/5iPNeVr1bba+hQVFeHx48fQ09NrjEOiFujSpUtwdHREaWkpFAoF9u3bh169eiEjI4O5SE0qPj4e//3vf3Hu3Llq2/jdSPXF4pyIiIhemL+/Py5fvowzZ85IHQq9wnr06IGMjAwUFhZiz549mDp1Kk6ePCl1WPSKuXnzJubNm4fExETo6upKHQ61YDytnaiBvP7669DU1Ky28ubdu3fRrl07iaKi1q4qt2rLu3bt2lVblLC8vBz3799X61PTPp4dg6hKQEAADh48iOPHj6Njx45ie7t27fDkyRMUFBSo9f9jPtaVa8/ro1QqOTNEarS1tdG9e3f0798fq1evhq2tLaKiopiL1KTS09ORn5+Pfv36QS6XQy6X4+TJk4iOjoZcLoeZmRnzkeqFxTlRA9HW1kb//v1x9OhRsa2yshJHjx6Fo6OjhJFRa2ZpaYl27dqp5V1RURFSUlLEvHN0dERBQQHS09PFPseOHUNlZSUcHBzEPqdOnYJKpRL7JCYmokePHjylnUSCICAgIAD79u3DsWPHql0K0b9/f2hpaanlY1ZWFnJzc9Xy8dKlS2o/GCUmJkKpVKJXr15in2f3UdWH36VUl8rKSpSVlTEXqUm5uLjg0qVLyMjIEB8DBgyAj4+P+DfzkepF6hXpiFqT+Ph4QUdHR4iNjRV+/PFHYdasWYKRkZHayptEL+rhw4fC+fPnhfPnzwsAhE8//VQ4f/688MsvvwiCIAjh4eGCkZGR8M033wgXL14UvLy8BEtLS+Hx48fiPtzd3QU7OzshJSVFOHPmjGBlZSVMmjRJ3F5QUCCYmZkJU6ZMES5fvizEx8cL+vr6wubNm5v8eKn5+tvf/iYYGhoKJ06cEG7fvi0+Hj16JPaZPXu2YGFhIRw7dkxIS0sTHB0dBUdHR3F7eXm58OabbwqjR48WMjIyhEOHDgkmJibC4sWLxT7Xr18X9PX1heDgYOHKlSvCxo0bBU1NTeHQoUNNerzUvIWEhAgnT54Ubty4IVy8eFEICQkRZDKZcOTIEUEQmIskrWdXaxcE5iPVD4tzoga2YcMGwcLCQtDW1hYGDhwonD17VuqQqIU7fvy4AKDaY+rUqYIgPL2d2tKlSwUzMzNBR0dHcHFxEbKystT28fvvvwuTJk0SFAqFoFQqhWnTpgkPHz5U63PhwgVhyJAhgo6OjtChQwchPDy8qQ6RWoia8hCAsG3bNrHP48ePhTlz5ght2rQR9PX1hbffflu4ffu22n5ycnIEDw8PQU9PT3j99deFhQsXCiqVSq3P8ePHhb59+wra2tpC165d1cYgEgRBmD59utC5c2dBW1tbMDExEVxcXMTCXBCYiyStPxbnzEeqD5kgCII0c/ZEREREREREBPCacyIiIiIiIiLJsTgnIiIiIiIikhiLcyIiIiIiIiKJsTgnIiIiIiIikhiLcyIiIiIiIiKJsTgnIiIiIiIikhiLcyIiIiIiIiKJsTgnIiIiIiIikhiLcyIiIiIiIiKJsTgnIiKiV5afnx9kMlm1R3Z2ttShERHRK0YudQBEREREUnJ3d8e2bdvU2kxMTCSKRp1KpYKWlpbUYRARURPgzDkRERG90nR0dNCuXTu1h6amZo19f/nlF4wbNw5t2rSBgYEBevfujYSEBHF7ZmYmxo4dC6VSiddeew1Dhw7FtWvXAACVlZX46KOP0LFjR+jo6KBv3744dOiQ+NqcnBzIZDJ8+eWXGD58OHR1dREXFwcA2LJlC6ytraGrq4uePXti06ZNjfiOEBGRFDhzTkRERFRP/v7+ePLkCU6dOgUDAwP8+OOPUCgUAIC8vDwMGzYMI0aMwLFjx6BUKpGUlITy8nIAQFRUFNatW4fNmzfDzs4O//73v/HWW28hMzMTVlZW4hghISFYt24d7OzsxAI9NDQUn332Gezs7HD+/Hm8//77MDAwwNSpUyV5H4iIqOHJBEEQpA6CiIiISAp+fn7YuXMndHV1xTYPDw/s3r27xv42Njbw9vbGsmXLqm378MMPER8fj6ysrBpPRe/QoQP8/f3x4Ycfim0DBw6Evb09Nm7ciJycHFhaWmL9+vWYN2+e2Kd79+5YsWIFJk2aJLZ9/PHHSEhIwA8//PCnjpuIiJofzpwTERHRK23kyJGIiYkRnxsYGDy3b2BgIP72t7/hyJEjcHV1hbe3N2xsbAAAGRkZGDp0aI2FeVFREW7duoXBgwertQ8ePBgXLlxQaxswYID4d0lJCa5du4YZM2bg/fffF9vLy8thaGj4YgdKRETNGotzIiIieqUZGBige/fu9eo7c+ZMuLm54dtvv8WRI0ewevVqrFu3DnPnzoWenl6DxVOluLgYAPCvf/0LDg4Oav2ed108ERG1TFwQjoiIiOgFdOrUCbNnz8bevXuxcOFC/Otf/wLw9JT306dPQ6VSVXuNUqmEubk5kpKS1NqTkpLQq1ev545lZmYGc3NzXL9+Hd27d1d7WFpaNuyBERGRpDhzTkRERFRPQUFB8PDwwBtvvIEHDx7g+PHjsLa2BgAEBARgw4YNmDhxIhYvXgxDQ0OcPXsWAwcORI8ePRAcHIxly5ahW7du6Nu3L7Zt24aMjAxxRfbnCQsLQ2BgIAwNDeHu7o6ysjKkpaXhwYMHWLBgQVMcNhERNQEW50RERET1VFFRAX9/f/z6669QKpVwd3dHZGQkAKBt27Y4duwYgoODMXz4cGhqaqJv377ideaBgYEoLCzEwoULkZ+fj169emH//v1qK7XXZObMmdDX18fatWsRHBwMAwMD9OnTB0FBQY19uERE1IS4WjsRERERERGRxHjNOREREREREZHEWJwTERERERERSYzFOREREREREZHEWJwTERERERERSYzFOREREREREZHEWJwTERERERERSYzFOREREREREZHEWJwTERERERERSYzFOREREREREZHEWJwTERERERERSYzFOREREREREZHE/h8dZF90NIxJBwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm==3.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0YFsj_1pJAL",
        "outputId": "6a16c4f8-e687-4aa7-b1c7-f04eaad39034"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm==3.3.2\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/2.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (0.41.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (1.11.2)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm==3.3.2) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm==3.3.2) (3.2.0)\n",
            "Installing collected packages: lightgbm\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 4.0.0\n",
            "    Uninstalling lightgbm-4.0.0:\n",
            "      Successfully uninstalled lightgbm-4.0.0\n",
            "Successfully installed lightgbm-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm\n",
        "print(lightgbm.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1NP3hnt-5mI",
        "outputId": "43542048-b1d6-43db-e8f5-65415d112fd3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm_clf = LGBMClassifier(n_estimators=500)\n",
        "\n",
        "eval_set = [(X_tr, y_tr),(X_val, y_val)]\n",
        "lgbm_clf.fit(X_tr, y_tr, early_stopping_rounds=100,\n",
        "            eval_metric=\"auc\", eval_set=eval_set)\n",
        "\n",
        "\n",
        "\n",
        "xgb_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:1])\n",
        "print('ROC AUC:{0:.4f}'.format(xgb_roc_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "APqDVvLkplT0",
        "outputId": "ae61bc87-5d41-4166-983f-75212da0f159"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's auc: 0.817384\tvalid_0's binary_logloss: 0.165046\n",
            "[2]\tvalid_0's auc: 0.818903\tvalid_0's binary_logloss: 0.160006\n",
            "[3]\tvalid_0's auc: 0.827707\tvalid_0's binary_logloss: 0.156323\n",
            "[4]\tvalid_0's auc: 0.832155\tvalid_0's binary_logloss: 0.153463\n",
            "[5]\tvalid_0's auc: 0.834677\tvalid_0's binary_logloss: 0.151256\n",
            "[6]\tvalid_0's auc: 0.834093\tvalid_0's binary_logloss: 0.149427\n",
            "[7]\tvalid_0's auc: 0.837046\tvalid_0's binary_logloss: 0.147961\n",
            "[8]\tvalid_0's auc: 0.837838\tvalid_0's binary_logloss: 0.146591\n",
            "[9]\tvalid_0's auc: 0.839435\tvalid_0's binary_logloss: 0.145455\n",
            "[10]\tvalid_0's auc: 0.83973\tvalid_0's binary_logloss: 0.144486\n",
            "[11]\tvalid_0's auc: 0.839799\tvalid_0's binary_logloss: 0.143769\n",
            "[12]\tvalid_0's auc: 0.840034\tvalid_0's binary_logloss: 0.143146\n",
            "[13]\tvalid_0's auc: 0.840271\tvalid_0's binary_logloss: 0.142533\n",
            "[14]\tvalid_0's auc: 0.840342\tvalid_0's binary_logloss: 0.142036\n",
            "[15]\tvalid_0's auc: 0.840928\tvalid_0's binary_logloss: 0.14161\n",
            "[16]\tvalid_0's auc: 0.840337\tvalid_0's binary_logloss: 0.141307\n",
            "[17]\tvalid_0's auc: 0.839901\tvalid_0's binary_logloss: 0.141152\n",
            "[18]\tvalid_0's auc: 0.839742\tvalid_0's binary_logloss: 0.141018\n",
            "[19]\tvalid_0's auc: 0.839818\tvalid_0's binary_logloss: 0.14068\n",
            "[20]\tvalid_0's auc: 0.839307\tvalid_0's binary_logloss: 0.140562\n",
            "[21]\tvalid_0's auc: 0.839662\tvalid_0's binary_logloss: 0.140353\n",
            "[22]\tvalid_0's auc: 0.840411\tvalid_0's binary_logloss: 0.140144\n",
            "[23]\tvalid_0's auc: 0.840522\tvalid_0's binary_logloss: 0.139983\n",
            "[24]\tvalid_0's auc: 0.840208\tvalid_0's binary_logloss: 0.139943\n",
            "[25]\tvalid_0's auc: 0.839578\tvalid_0's binary_logloss: 0.139898\n",
            "[26]\tvalid_0's auc: 0.83975\tvalid_0's binary_logloss: 0.139814\n",
            "[27]\tvalid_0's auc: 0.83988\tvalid_0's binary_logloss: 0.139711\n",
            "[28]\tvalid_0's auc: 0.839704\tvalid_0's binary_logloss: 0.139681\n",
            "[29]\tvalid_0's auc: 0.839432\tvalid_0's binary_logloss: 0.139662\n",
            "[30]\tvalid_0's auc: 0.839196\tvalid_0's binary_logloss: 0.139641\n",
            "[31]\tvalid_0's auc: 0.838891\tvalid_0's binary_logloss: 0.139654\n",
            "[32]\tvalid_0's auc: 0.838943\tvalid_0's binary_logloss: 0.1396\n",
            "[33]\tvalid_0's auc: 0.838632\tvalid_0's binary_logloss: 0.139642\n",
            "[34]\tvalid_0's auc: 0.838314\tvalid_0's binary_logloss: 0.139687\n",
            "[35]\tvalid_0's auc: 0.83844\tvalid_0's binary_logloss: 0.139668\n",
            "[36]\tvalid_0's auc: 0.839074\tvalid_0's binary_logloss: 0.139562\n",
            "[37]\tvalid_0's auc: 0.838806\tvalid_0's binary_logloss: 0.139594\n",
            "[38]\tvalid_0's auc: 0.839041\tvalid_0's binary_logloss: 0.139574\n",
            "[39]\tvalid_0's auc: 0.839081\tvalid_0's binary_logloss: 0.139587\n",
            "[40]\tvalid_0's auc: 0.839276\tvalid_0's binary_logloss: 0.139504\n",
            "[41]\tvalid_0's auc: 0.83951\tvalid_0's binary_logloss: 0.139481\n",
            "[42]\tvalid_0's auc: 0.839544\tvalid_0's binary_logloss: 0.139487\n",
            "[43]\tvalid_0's auc: 0.839673\tvalid_0's binary_logloss: 0.139478\n",
            "[44]\tvalid_0's auc: 0.839677\tvalid_0's binary_logloss: 0.139453\n",
            "[45]\tvalid_0's auc: 0.839703\tvalid_0's binary_logloss: 0.139445\n",
            "[46]\tvalid_0's auc: 0.839601\tvalid_0's binary_logloss: 0.139468\n",
            "[47]\tvalid_0's auc: 0.839318\tvalid_0's binary_logloss: 0.139529\n",
            "[48]\tvalid_0's auc: 0.839462\tvalid_0's binary_logloss: 0.139486\n",
            "[49]\tvalid_0's auc: 0.839288\tvalid_0's binary_logloss: 0.139492\n",
            "[50]\tvalid_0's auc: 0.838987\tvalid_0's binary_logloss: 0.139572\n",
            "[51]\tvalid_0's auc: 0.838845\tvalid_0's binary_logloss: 0.139603\n",
            "[52]\tvalid_0's auc: 0.838655\tvalid_0's binary_logloss: 0.139623\n",
            "[53]\tvalid_0's auc: 0.838783\tvalid_0's binary_logloss: 0.139609\n",
            "[54]\tvalid_0's auc: 0.838695\tvalid_0's binary_logloss: 0.139638\n",
            "[55]\tvalid_0's auc: 0.838868\tvalid_0's binary_logloss: 0.139625\n",
            "[56]\tvalid_0's auc: 0.838653\tvalid_0's binary_logloss: 0.139645\n",
            "[57]\tvalid_0's auc: 0.83856\tvalid_0's binary_logloss: 0.139688\n",
            "[58]\tvalid_0's auc: 0.838475\tvalid_0's binary_logloss: 0.139694\n",
            "[59]\tvalid_0's auc: 0.8384\tvalid_0's binary_logloss: 0.139682\n",
            "[60]\tvalid_0's auc: 0.838319\tvalid_0's binary_logloss: 0.13969\n",
            "[61]\tvalid_0's auc: 0.838209\tvalid_0's binary_logloss: 0.13973\n",
            "[62]\tvalid_0's auc: 0.83806\tvalid_0's binary_logloss: 0.139765\n",
            "[63]\tvalid_0's auc: 0.838096\tvalid_0's binary_logloss: 0.139749\n",
            "[64]\tvalid_0's auc: 0.838163\tvalid_0's binary_logloss: 0.139746\n",
            "[65]\tvalid_0's auc: 0.838183\tvalid_0's binary_logloss: 0.139805\n",
            "[66]\tvalid_0's auc: 0.838215\tvalid_0's binary_logloss: 0.139815\n",
            "[67]\tvalid_0's auc: 0.838268\tvalid_0's binary_logloss: 0.139822\n",
            "[68]\tvalid_0's auc: 0.83836\tvalid_0's binary_logloss: 0.139816\n",
            "[69]\tvalid_0's auc: 0.838114\tvalid_0's binary_logloss: 0.139874\n",
            "[70]\tvalid_0's auc: 0.83832\tvalid_0's binary_logloss: 0.139816\n",
            "[71]\tvalid_0's auc: 0.838256\tvalid_0's binary_logloss: 0.139818\n",
            "[72]\tvalid_0's auc: 0.838231\tvalid_0's binary_logloss: 0.139845\n",
            "[73]\tvalid_0's auc: 0.838028\tvalid_0's binary_logloss: 0.139888\n",
            "[74]\tvalid_0's auc: 0.837912\tvalid_0's binary_logloss: 0.139905\n",
            "[75]\tvalid_0's auc: 0.83772\tvalid_0's binary_logloss: 0.13992\n",
            "[76]\tvalid_0's auc: 0.837606\tvalid_0's binary_logloss: 0.139899\n",
            "[77]\tvalid_0's auc: 0.837521\tvalid_0's binary_logloss: 0.139925\n",
            "[78]\tvalid_0's auc: 0.837462\tvalid_0's binary_logloss: 0.139957\n",
            "[79]\tvalid_0's auc: 0.837541\tvalid_0's binary_logloss: 0.139944\n",
            "[80]\tvalid_0's auc: 0.838013\tvalid_0's binary_logloss: 0.13983\n",
            "[81]\tvalid_0's auc: 0.83789\tvalid_0's binary_logloss: 0.139874\n",
            "[82]\tvalid_0's auc: 0.837671\tvalid_0's binary_logloss: 0.139975\n",
            "[83]\tvalid_0's auc: 0.837707\tvalid_0's binary_logloss: 0.139972\n",
            "[84]\tvalid_0's auc: 0.837631\tvalid_0's binary_logloss: 0.140011\n",
            "[85]\tvalid_0's auc: 0.837496\tvalid_0's binary_logloss: 0.140023\n",
            "[86]\tvalid_0's auc: 0.83757\tvalid_0's binary_logloss: 0.140021\n",
            "[87]\tvalid_0's auc: 0.837284\tvalid_0's binary_logloss: 0.140099\n",
            "[88]\tvalid_0's auc: 0.837228\tvalid_0's binary_logloss: 0.140115\n",
            "[89]\tvalid_0's auc: 0.836964\tvalid_0's binary_logloss: 0.140172\n",
            "[90]\tvalid_0's auc: 0.836752\tvalid_0's binary_logloss: 0.140225\n",
            "[91]\tvalid_0's auc: 0.836833\tvalid_0's binary_logloss: 0.140221\n",
            "[92]\tvalid_0's auc: 0.836648\tvalid_0's binary_logloss: 0.140277\n",
            "[93]\tvalid_0's auc: 0.836648\tvalid_0's binary_logloss: 0.140315\n",
            "[94]\tvalid_0's auc: 0.836677\tvalid_0's binary_logloss: 0.140321\n",
            "[95]\tvalid_0's auc: 0.836729\tvalid_0's binary_logloss: 0.140307\n",
            "[96]\tvalid_0's auc: 0.8368\tvalid_0's binary_logloss: 0.140313\n",
            "[97]\tvalid_0's auc: 0.836797\tvalid_0's binary_logloss: 0.140331\n",
            "[98]\tvalid_0's auc: 0.836675\tvalid_0's binary_logloss: 0.140361\n",
            "[99]\tvalid_0's auc: 0.83655\tvalid_0's binary_logloss: 0.14039\n",
            "[100]\tvalid_0's auc: 0.836518\tvalid_0's binary_logloss: 0.1404\n",
            "[101]\tvalid_0's auc: 0.836998\tvalid_0's binary_logloss: 0.140294\n",
            "[102]\tvalid_0's auc: 0.836778\tvalid_0's binary_logloss: 0.140366\n",
            "[103]\tvalid_0's auc: 0.83694\tvalid_0's binary_logloss: 0.140333\n",
            "[104]\tvalid_0's auc: 0.836749\tvalid_0's binary_logloss: 0.14039\n",
            "[105]\tvalid_0's auc: 0.836752\tvalid_0's binary_logloss: 0.140391\n",
            "[106]\tvalid_0's auc: 0.837197\tvalid_0's binary_logloss: 0.140305\n",
            "[107]\tvalid_0's auc: 0.837141\tvalid_0's binary_logloss: 0.140329\n",
            "[108]\tvalid_0's auc: 0.8371\tvalid_0's binary_logloss: 0.140344\n",
            "[109]\tvalid_0's auc: 0.837136\tvalid_0's binary_logloss: 0.14033\n",
            "[110]\tvalid_0's auc: 0.837102\tvalid_0's binary_logloss: 0.140388\n",
            "[111]\tvalid_0's auc: 0.836957\tvalid_0's binary_logloss: 0.140426\n",
            "[112]\tvalid_0's auc: 0.836779\tvalid_0's binary_logloss: 0.14051\n",
            "[113]\tvalid_0's auc: 0.836831\tvalid_0's binary_logloss: 0.140526\n",
            "[114]\tvalid_0's auc: 0.836783\tvalid_0's binary_logloss: 0.14055\n",
            "[115]\tvalid_0's auc: 0.836672\tvalid_0's binary_logloss: 0.140585\n",
            "[116]\tvalid_0's auc: 0.836724\tvalid_0's binary_logloss: 0.140589\n",
            "[117]\tvalid_0's auc: 0.836767\tvalid_0's binary_logloss: 0.140567\n",
            "[118]\tvalid_0's auc: 0.836467\tvalid_0's binary_logloss: 0.140632\n",
            "[119]\tvalid_0's auc: 0.83652\tvalid_0's binary_logloss: 0.140598\n",
            "[120]\tvalid_0's auc: 0.836511\tvalid_0's binary_logloss: 0.14062\n",
            "[121]\tvalid_0's auc: 0.836562\tvalid_0's binary_logloss: 0.140599\n",
            "[122]\tvalid_0's auc: 0.836531\tvalid_0's binary_logloss: 0.140614\n",
            "[123]\tvalid_0's auc: 0.836683\tvalid_0's binary_logloss: 0.140588\n",
            "[124]\tvalid_0's auc: 0.836364\tvalid_0's binary_logloss: 0.140649\n",
            "[125]\tvalid_0's auc: 0.836269\tvalid_0's binary_logloss: 0.140672\n",
            "[126]\tvalid_0's auc: 0.836364\tvalid_0's binary_logloss: 0.140674\n",
            "[127]\tvalid_0's auc: 0.836299\tvalid_0's binary_logloss: 0.1407\n",
            "[128]\tvalid_0's auc: 0.836327\tvalid_0's binary_logloss: 0.14074\n",
            "[129]\tvalid_0's auc: 0.836109\tvalid_0's binary_logloss: 0.140798\n",
            "[130]\tvalid_0's auc: 0.836003\tvalid_0's binary_logloss: 0.140836\n",
            "[131]\tvalid_0's auc: 0.836012\tvalid_0's binary_logloss: 0.140834\n",
            "[132]\tvalid_0's auc: 0.836005\tvalid_0's binary_logloss: 0.140827\n",
            "[133]\tvalid_0's auc: 0.835753\tvalid_0's binary_logloss: 0.140876\n",
            "[134]\tvalid_0's auc: 0.835732\tvalid_0's binary_logloss: 0.14087\n",
            "[135]\tvalid_0's auc: 0.835679\tvalid_0's binary_logloss: 0.140901\n",
            "[136]\tvalid_0's auc: 0.835577\tvalid_0's binary_logloss: 0.140947\n",
            "[137]\tvalid_0's auc: 0.835408\tvalid_0's binary_logloss: 0.140986\n",
            "[138]\tvalid_0's auc: 0.83532\tvalid_0's binary_logloss: 0.141039\n",
            "[139]\tvalid_0's auc: 0.835139\tvalid_0's binary_logloss: 0.141118\n",
            "[140]\tvalid_0's auc: 0.835142\tvalid_0's binary_logloss: 0.141143\n",
            "[141]\tvalid_0's auc: 0.835196\tvalid_0's binary_logloss: 0.141144\n",
            "[142]\tvalid_0's auc: 0.835175\tvalid_0's binary_logloss: 0.141154\n",
            "[143]\tvalid_0's auc: 0.835202\tvalid_0's binary_logloss: 0.141159\n",
            "[144]\tvalid_0's auc: 0.835281\tvalid_0's binary_logloss: 0.141168\n",
            "[145]\tvalid_0's auc: 0.835105\tvalid_0's binary_logloss: 0.141234\n",
            "[146]\tvalid_0's auc: 0.835241\tvalid_0's binary_logloss: 0.14124\n",
            "[147]\tvalid_0's auc: 0.835166\tvalid_0's binary_logloss: 0.141259\n",
            "[148]\tvalid_0's auc: 0.835149\tvalid_0's binary_logloss: 0.141276\n",
            "[149]\tvalid_0's auc: 0.83511\tvalid_0's binary_logloss: 0.141313\n",
            "[150]\tvalid_0's auc: 0.835041\tvalid_0's binary_logloss: 0.141353\n",
            "[151]\tvalid_0's auc: 0.835166\tvalid_0's binary_logloss: 0.141366\n",
            "[152]\tvalid_0's auc: 0.835139\tvalid_0's binary_logloss: 0.14139\n",
            "[153]\tvalid_0's auc: 0.835041\tvalid_0's binary_logloss: 0.141416\n",
            "[154]\tvalid_0's auc: 0.834937\tvalid_0's binary_logloss: 0.14145\n",
            "[155]\tvalid_0's auc: 0.834743\tvalid_0's binary_logloss: 0.141496\n",
            "[156]\tvalid_0's auc: 0.83491\tvalid_0's binary_logloss: 0.141473\n",
            "[157]\tvalid_0's auc: 0.834922\tvalid_0's binary_logloss: 0.141499\n",
            "[158]\tvalid_0's auc: 0.834934\tvalid_0's binary_logloss: 0.141532\n",
            "[159]\tvalid_0's auc: 0.835064\tvalid_0's binary_logloss: 0.141515\n",
            "[160]\tvalid_0's auc: 0.835209\tvalid_0's binary_logloss: 0.141518\n",
            "[161]\tvalid_0's auc: 0.835224\tvalid_0's binary_logloss: 0.141557\n",
            "[162]\tvalid_0's auc: 0.835078\tvalid_0's binary_logloss: 0.141594\n",
            "[163]\tvalid_0's auc: 0.83489\tvalid_0's binary_logloss: 0.141653\n",
            "[164]\tvalid_0's auc: 0.834684\tvalid_0's binary_logloss: 0.141708\n",
            "[165]\tvalid_0's auc: 0.834549\tvalid_0's binary_logloss: 0.141768\n",
            "[166]\tvalid_0's auc: 0.834396\tvalid_0's binary_logloss: 0.141848\n",
            "[167]\tvalid_0's auc: 0.834196\tvalid_0's binary_logloss: 0.141917\n",
            "[168]\tvalid_0's auc: 0.834167\tvalid_0's binary_logloss: 0.141926\n",
            "[169]\tvalid_0's auc: 0.833961\tvalid_0's binary_logloss: 0.141982\n",
            "[170]\tvalid_0's auc: 0.834021\tvalid_0's binary_logloss: 0.141993\n",
            "[171]\tvalid_0's auc: 0.834074\tvalid_0's binary_logloss: 0.141971\n",
            "[172]\tvalid_0's auc: 0.833976\tvalid_0's binary_logloss: 0.141994\n",
            "[173]\tvalid_0's auc: 0.833946\tvalid_0's binary_logloss: 0.142021\n",
            "[174]\tvalid_0's auc: 0.833781\tvalid_0's binary_logloss: 0.142034\n",
            "[175]\tvalid_0's auc: 0.833777\tvalid_0's binary_logloss: 0.142048\n",
            "[176]\tvalid_0's auc: 0.83372\tvalid_0's binary_logloss: 0.142048\n",
            "[177]\tvalid_0's auc: 0.833537\tvalid_0's binary_logloss: 0.142123\n",
            "[178]\tvalid_0's auc: 0.833532\tvalid_0's binary_logloss: 0.142135\n",
            "[179]\tvalid_0's auc: 0.833461\tvalid_0's binary_logloss: 0.142201\n",
            "[180]\tvalid_0's auc: 0.833492\tvalid_0's binary_logloss: 0.142205\n",
            "[181]\tvalid_0's auc: 0.833504\tvalid_0's binary_logloss: 0.142228\n",
            "[182]\tvalid_0's auc: 0.833462\tvalid_0's binary_logloss: 0.142264\n",
            "[183]\tvalid_0's auc: 0.833551\tvalid_0's binary_logloss: 0.142274\n",
            "[184]\tvalid_0's auc: 0.833496\tvalid_0's binary_logloss: 0.142301\n",
            "[185]\tvalid_0's auc: 0.833386\tvalid_0's binary_logloss: 0.142309\n",
            "[186]\tvalid_0's auc: 0.833267\tvalid_0's binary_logloss: 0.142323\n",
            "[187]\tvalid_0's auc: 0.833328\tvalid_0's binary_logloss: 0.142352\n",
            "[188]\tvalid_0's auc: 0.833317\tvalid_0's binary_logloss: 0.142372\n",
            "[189]\tvalid_0's auc: 0.833382\tvalid_0's binary_logloss: 0.142398\n",
            "[190]\tvalid_0's auc: 0.833295\tvalid_0's binary_logloss: 0.142446\n",
            "[191]\tvalid_0's auc: 0.833187\tvalid_0's binary_logloss: 0.142473\n",
            "[192]\tvalid_0's auc: 0.833119\tvalid_0's binary_logloss: 0.142497\n",
            "[193]\tvalid_0's auc: 0.832997\tvalid_0's binary_logloss: 0.142567\n",
            "[194]\tvalid_0's auc: 0.833056\tvalid_0's binary_logloss: 0.142579\n",
            "[195]\tvalid_0's auc: 0.833103\tvalid_0's binary_logloss: 0.142599\n",
            "[196]\tvalid_0's auc: 0.832821\tvalid_0's binary_logloss: 0.142661\n",
            "[197]\tvalid_0's auc: 0.832785\tvalid_0's binary_logloss: 0.142692\n",
            "[198]\tvalid_0's auc: 0.832608\tvalid_0's binary_logloss: 0.142727\n",
            "[199]\tvalid_0's auc: 0.832287\tvalid_0's binary_logloss: 0.142814\n",
            "[200]\tvalid_0's auc: 0.83216\tvalid_0's binary_logloss: 0.142871\n",
            "[201]\tvalid_0's auc: 0.832008\tvalid_0's binary_logloss: 0.142889\n",
            "[202]\tvalid_0's auc: 0.832184\tvalid_0's binary_logloss: 0.142832\n",
            "[203]\tvalid_0's auc: 0.832197\tvalid_0's binary_logloss: 0.142852\n",
            "[204]\tvalid_0's auc: 0.832029\tvalid_0's binary_logloss: 0.142891\n",
            "[205]\tvalid_0's auc: 0.831858\tvalid_0's binary_logloss: 0.142942\n",
            "[206]\tvalid_0's auc: 0.831947\tvalid_0's binary_logloss: 0.14293\n",
            "[207]\tvalid_0's auc: 0.831845\tvalid_0's binary_logloss: 0.142964\n",
            "[208]\tvalid_0's auc: 0.831833\tvalid_0's binary_logloss: 0.142959\n",
            "[209]\tvalid_0's auc: 0.831828\tvalid_0's binary_logloss: 0.142952\n",
            "[210]\tvalid_0's auc: 0.831771\tvalid_0's binary_logloss: 0.142979\n",
            "[211]\tvalid_0's auc: 0.831834\tvalid_0's binary_logloss: 0.142988\n",
            "[212]\tvalid_0's auc: 0.831713\tvalid_0's binary_logloss: 0.143043\n",
            "[213]\tvalid_0's auc: 0.831697\tvalid_0's binary_logloss: 0.143066\n",
            "[214]\tvalid_0's auc: 0.831579\tvalid_0's binary_logloss: 0.143116\n",
            "[215]\tvalid_0's auc: 0.831322\tvalid_0's binary_logloss: 0.143179\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-15df5f4f3f79>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mxgb_roc_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC AUC:{0:.4f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_roc_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         return _average_binary_score(\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    342\u001b[0m         )\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [15204, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import hp\n",
        "\n",
        "lgbm_search_space = {\n",
        "    'num_leaves':hp.quniform('num_leaves',32, 64, 1),\n",
        "    'max_depth': hp.quniform(\"max_depth\", 100, 160,1),\n",
        "    'min_child_samples': hp.quniform(\"min_child_samples\", 60, 100,1),\n",
        "    'subsample': hp.uniform(\"subsample\", 0.7,1),\n",
        "    'learning_rate': hp.uniform(\"learning_rate\", 0.01,0.2),\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "5p0dTR2nXBFv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective_func(lgbm_search_space):\n",
        "    xgb_clf = LGBMClassifier(n_estimators = 800,\n",
        "\n",
        "                            # int type 필요\n",
        "                            max_depth = int(lgbm_search_space['max_depth']),\n",
        "                            min_child_sample = int(lgbm_search_space['min_child_samples']),\n",
        "                            learning_rate = lgbm_search_space['learning_rate'],\n",
        "                            subsample = lgbm_search_space['subsample'])\n",
        "\n",
        "    roc_auc_list = []\n",
        "\n",
        "    kf = KFold(n_splits=3)\n",
        "\n",
        "    for tr_index, val_index in kf.split(X_train):\n",
        "      X_tr, y_tr = X_train.iloc[tr_index], y_train.iloc[tr_index]\n",
        "      X_val, y_val = X_train.iloc[val_index], y_train.iloc[val_index]\n",
        "\n",
        "      xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=30, eval_metric=\"auc\",\n",
        "                  eval_set=[(X_tr, y_tr), (X_val, y_val)])\n",
        "\n",
        "      score = roc_auc_score(y_val, xgb_clf.predict_proba(X_val)[:,1])\n",
        "      roc_auc_list.append(score)\n",
        "\n",
        "\n",
        "    return -1 * np.mean(roc_auc_list)"
      ],
      "metadata": {
        "id": "akgQSRwSYTcL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, Trials\n",
        "\n",
        "trials = Trials()\n",
        "best = fmin(fn = objective_func,\n",
        "            space = lgbm_search_space,\n",
        "            algo = tpe.suggest,\n",
        "            max_evals=50,\n",
        "            trials = trials,\n",
        "            rstate = np.random.default_rng(seed = 30))\n",
        "print('best:', best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InZCY125Ye7m",
        "outputId": "bdb7ba93-e45c-48b9-ea5f-537851df4340"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.162225\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.163483\n",
            "[2]\ttraining's auc: 0.827172\ttraining's binary_logloss: 0.160137\tvalid_1's auc: 0.80445\tvalid_1's binary_logloss: 0.161786\n",
            "[3]\ttraining's auc: 0.833292\ttraining's binary_logloss: 0.15829\tvalid_1's auc: 0.807871\tvalid_1's binary_logloss: 0.160307\n",
            "[4]\ttraining's auc: 0.834189\ttraining's binary_logloss: 0.15663\tvalid_1's auc: 0.807478\tvalid_1's binary_logloss: 0.159032\n",
            "[5]\ttraining's auc: 0.835092\ttraining's binary_logloss: 0.155106\tvalid_1's auc: 0.808465\tvalid_1's binary_logloss: 0.157796\n",
            "[6]\ttraining's auc: 0.836472\ttraining's binary_logloss: 0.153704\tvalid_1's auc: 0.808726\tvalid_1's binary_logloss: 0.156695\n",
            "[7]\ttraining's auc: 0.836836\ttraining's binary_logloss: 0.152412\tvalid_1's auc: 0.808501\tvalid_1's binary_logloss: 0.155685\n",
            "[8]\ttraining's auc: 0.8385\ttraining's binary_logloss: 0.151219\tvalid_1's auc: 0.810052\tvalid_1's binary_logloss: 0.154734\n",
            "[9]\ttraining's auc: 0.841447\ttraining's binary_logloss: 0.150084\tvalid_1's auc: 0.812038\tvalid_1's binary_logloss: 0.153847\n",
            "[10]\ttraining's auc: 0.843681\ttraining's binary_logloss: 0.149007\tvalid_1's auc: 0.814405\tvalid_1's binary_logloss: 0.153021\n",
            "[11]\ttraining's auc: 0.845501\ttraining's binary_logloss: 0.148016\tvalid_1's auc: 0.814827\tvalid_1's binary_logloss: 0.152273\n",
            "[12]\ttraining's auc: 0.845942\ttraining's binary_logloss: 0.147065\tvalid_1's auc: 0.814798\tvalid_1's binary_logloss: 0.151587\n",
            "[13]\ttraining's auc: 0.847291\ttraining's binary_logloss: 0.146193\tvalid_1's auc: 0.816461\tvalid_1's binary_logloss: 0.150905\n",
            "[14]\ttraining's auc: 0.848091\ttraining's binary_logloss: 0.145344\tvalid_1's auc: 0.817571\tvalid_1's binary_logloss: 0.150268\n",
            "[15]\ttraining's auc: 0.849346\ttraining's binary_logloss: 0.144527\tvalid_1's auc: 0.818634\tvalid_1's binary_logloss: 0.149654\n",
            "[16]\ttraining's auc: 0.849828\ttraining's binary_logloss: 0.143725\tvalid_1's auc: 0.819125\tvalid_1's binary_logloss: 0.14906\n",
            "[17]\ttraining's auc: 0.850909\ttraining's binary_logloss: 0.142968\tvalid_1's auc: 0.819934\tvalid_1's binary_logloss: 0.148494\n",
            "[18]\ttraining's auc: 0.85148\ttraining's binary_logloss: 0.142263\tvalid_1's auc: 0.82059\tvalid_1's binary_logloss: 0.147974\n",
            "[19]\ttraining's auc: 0.852504\ttraining's binary_logloss: 0.141556\tvalid_1's auc: 0.820997\tvalid_1's binary_logloss: 0.147523\n",
            "[20]\ttraining's auc: 0.852747\ttraining's binary_logloss: 0.140912\tvalid_1's auc: 0.821091\tvalid_1's binary_logloss: 0.147056\n",
            "[21]\ttraining's auc: 0.853165\ttraining's binary_logloss: 0.140305\tvalid_1's auc: 0.821509\tvalid_1's binary_logloss: 0.146626\n",
            "[22]\ttraining's auc: 0.853357\ttraining's binary_logloss: 0.13972\tvalid_1's auc: 0.821429\tvalid_1's binary_logloss: 0.146197\n",
            "[23]\ttraining's auc: 0.853725\ttraining's binary_logloss: 0.139149\tvalid_1's auc: 0.821793\tvalid_1's binary_logloss: 0.145794\n",
            "[24]\ttraining's auc: 0.853992\ttraining's binary_logloss: 0.138608\tvalid_1's auc: 0.821954\tvalid_1's binary_logloss: 0.145408\n",
            "[25]\ttraining's auc: 0.854314\ttraining's binary_logloss: 0.1381\tvalid_1's auc: 0.822065\tvalid_1's binary_logloss: 0.145058\n",
            "[26]\ttraining's auc: 0.85674\ttraining's binary_logloss: 0.137583\tvalid_1's auc: 0.82238\tvalid_1's binary_logloss: 0.144701\n",
            "[27]\ttraining's auc: 0.85707\ttraining's binary_logloss: 0.137088\tvalid_1's auc: 0.82335\tvalid_1's binary_logloss: 0.14436\n",
            "[28]\ttraining's auc: 0.85744\ttraining's binary_logloss: 0.136606\tvalid_1's auc: 0.823514\tvalid_1's binary_logloss: 0.144032\n",
            "[29]\ttraining's auc: 0.857847\ttraining's binary_logloss: 0.136126\tvalid_1's auc: 0.823555\tvalid_1's binary_logloss: 0.143716\n",
            "[30]\ttraining's auc: 0.858164\ttraining's binary_logloss: 0.135693\tvalid_1's auc: 0.823764\tvalid_1's binary_logloss: 0.143407\n",
            "[31]\ttraining's auc: 0.859186\ttraining's binary_logloss: 0.135228\tvalid_1's auc: 0.823872\tvalid_1's binary_logloss: 0.143118\n",
            "[32]\ttraining's auc: 0.860009\ttraining's binary_logloss: 0.134833\tvalid_1's auc: 0.823834\tvalid_1's binary_logloss: 0.142843\n",
            "[33]\ttraining's auc: 0.861415\ttraining's binary_logloss: 0.134418\tvalid_1's auc: 0.824306\tvalid_1's binary_logloss: 0.142568\n",
            "[34]\ttraining's auc: 0.86228\ttraining's binary_logloss: 0.134017\tvalid_1's auc: 0.824476\tvalid_1's binary_logloss: 0.142314\n",
            "[35]\ttraining's auc: 0.863161\ttraining's binary_logloss: 0.133616\tvalid_1's auc: 0.824003\tvalid_1's binary_logloss: 0.1421\n",
            "[36]\ttraining's auc: 0.863513\ttraining's binary_logloss: 0.133256\tvalid_1's auc: 0.823995\tvalid_1's binary_logloss: 0.141871\n",
            "[37]\ttraining's auc: 0.864203\ttraining's binary_logloss: 0.132896\tvalid_1's auc: 0.824299\tvalid_1's binary_logloss: 0.141633\n",
            "[38]\ttraining's auc: 0.864699\ttraining's binary_logloss: 0.132548\tvalid_1's auc: 0.824747\tvalid_1's binary_logloss: 0.14144\n",
            "[39]\ttraining's auc: 0.865392\ttraining's binary_logloss: 0.132214\tvalid_1's auc: 0.82486\tvalid_1's binary_logloss: 0.141235\n",
            "[40]\ttraining's auc: 0.865687\ttraining's binary_logloss: 0.131905\tvalid_1's auc: 0.825381\tvalid_1's binary_logloss: 0.141021\n",
            "[41]\ttraining's auc: 0.866294\ttraining's binary_logloss: 0.131598\tvalid_1's auc: 0.825682\tvalid_1's binary_logloss: 0.140829\n",
            "[42]\ttraining's auc: 0.866706\ttraining's binary_logloss: 0.131286\tvalid_1's auc: 0.82599\tvalid_1's binary_logloss: 0.140635\n",
            "[43]\ttraining's auc: 0.867033\ttraining's binary_logloss: 0.130962\tvalid_1's auc: 0.826146\tvalid_1's binary_logloss: 0.140454\n",
            "[44]\ttraining's auc: 0.867911\ttraining's binary_logloss: 0.130666\tvalid_1's auc: 0.82667\tvalid_1's binary_logloss: 0.140278\n",
            "[45]\ttraining's auc: 0.868275\ttraining's binary_logloss: 0.130382\tvalid_1's auc: 0.826933\tvalid_1's binary_logloss: 0.140127\n",
            "[46]\ttraining's auc: 0.86877\ttraining's binary_logloss: 0.130116\tvalid_1's auc: 0.827143\tvalid_1's binary_logloss: 0.139975\n",
            "[47]\ttraining's auc: 0.869348\ttraining's binary_logloss: 0.129828\tvalid_1's auc: 0.827221\tvalid_1's binary_logloss: 0.139813\n",
            "[48]\ttraining's auc: 0.869746\ttraining's binary_logloss: 0.129558\tvalid_1's auc: 0.827306\tvalid_1's binary_logloss: 0.139693\n",
            "[49]\ttraining's auc: 0.870007\ttraining's binary_logloss: 0.129291\tvalid_1's auc: 0.827327\tvalid_1's binary_logloss: 0.139552\n",
            "[50]\ttraining's auc: 0.870337\ttraining's binary_logloss: 0.129039\tvalid_1's auc: 0.827474\tvalid_1's binary_logloss: 0.139404\n",
            "[51]\ttraining's auc: 0.870744\ttraining's binary_logloss: 0.128789\tvalid_1's auc: 0.827506\tvalid_1's binary_logloss: 0.139274\n",
            "[52]\ttraining's auc: 0.871141\ttraining's binary_logloss: 0.128558\tvalid_1's auc: 0.827578\tvalid_1's binary_logloss: 0.139155\n",
            "[53]\ttraining's auc: 0.871556\ttraining's binary_logloss: 0.128307\tvalid_1's auc: 0.827717\tvalid_1's binary_logloss: 0.139024\n",
            "[54]\ttraining's auc: 0.871833\ttraining's binary_logloss: 0.128088\tvalid_1's auc: 0.827692\tvalid_1's binary_logloss: 0.138902\n",
            "[55]\ttraining's auc: 0.872431\ttraining's binary_logloss: 0.127846\tvalid_1's auc: 0.827925\tvalid_1's binary_logloss: 0.138771\n",
            "[56]\ttraining's auc: 0.873173\ttraining's binary_logloss: 0.127612\tvalid_1's auc: 0.82786\tvalid_1's binary_logloss: 0.138685\n",
            "[57]\ttraining's auc: 0.873797\ttraining's binary_logloss: 0.127379\tvalid_1's auc: 0.827861\tvalid_1's binary_logloss: 0.138593\n",
            "[58]\ttraining's auc: 0.874076\ttraining's binary_logloss: 0.127169\tvalid_1's auc: 0.827837\tvalid_1's binary_logloss: 0.13851\n",
            "[59]\ttraining's auc: 0.874464\ttraining's binary_logloss: 0.126943\tvalid_1's auc: 0.82793\tvalid_1's binary_logloss: 0.138424\n",
            "[60]\ttraining's auc: 0.874903\ttraining's binary_logloss: 0.126722\tvalid_1's auc: 0.827833\tvalid_1's binary_logloss: 0.138339\n",
            "[61]\ttraining's auc: 0.875325\ttraining's binary_logloss: 0.126507\tvalid_1's auc: 0.827878\tvalid_1's binary_logloss: 0.138265\n",
            "[62]\ttraining's auc: 0.875588\ttraining's binary_logloss: 0.126297\tvalid_1's auc: 0.827875\tvalid_1's binary_logloss: 0.138188\n",
            "[63]\ttraining's auc: 0.876065\ttraining's binary_logloss: 0.126107\tvalid_1's auc: 0.828045\tvalid_1's binary_logloss: 0.138094\n",
            "[64]\ttraining's auc: 0.876485\ttraining's binary_logloss: 0.125904\tvalid_1's auc: 0.827934\tvalid_1's binary_logloss: 0.138016\n",
            "[65]\ttraining's auc: 0.877572\ttraining's binary_logloss: 0.125688\tvalid_1's auc: 0.828207\tvalid_1's binary_logloss: 0.137935\n",
            "[66]\ttraining's auc: 0.877783\ttraining's binary_logloss: 0.125504\tvalid_1's auc: 0.828159\tvalid_1's binary_logloss: 0.137856\n",
            "[67]\ttraining's auc: 0.878093\ttraining's binary_logloss: 0.125321\tvalid_1's auc: 0.828261\tvalid_1's binary_logloss: 0.137785\n",
            "[68]\ttraining's auc: 0.878717\ttraining's binary_logloss: 0.125126\tvalid_1's auc: 0.828288\tvalid_1's binary_logloss: 0.137711\n",
            "[69]\ttraining's auc: 0.879138\ttraining's binary_logloss: 0.124936\tvalid_1's auc: 0.828333\tvalid_1's binary_logloss: 0.137644\n",
            "[70]\ttraining's auc: 0.879463\ttraining's binary_logloss: 0.124767\tvalid_1's auc: 0.828405\tvalid_1's binary_logloss: 0.137582\n",
            "[71]\ttraining's auc: 0.879796\ttraining's binary_logloss: 0.124586\tvalid_1's auc: 0.828415\tvalid_1's binary_logloss: 0.137519\n",
            "[72]\ttraining's auc: 0.880089\ttraining's binary_logloss: 0.124416\tvalid_1's auc: 0.828335\tvalid_1's binary_logloss: 0.137455\n",
            "[73]\ttraining's auc: 0.880308\ttraining's binary_logloss: 0.124255\tvalid_1's auc: 0.828302\tvalid_1's binary_logloss: 0.137402\n",
            "[74]\ttraining's auc: 0.880909\ttraining's binary_logloss: 0.12408\tvalid_1's auc: 0.828339\tvalid_1's binary_logloss: 0.137323\n",
            "[75]\ttraining's auc: 0.881335\ttraining's binary_logloss: 0.123903\tvalid_1's auc: 0.828463\tvalid_1's binary_logloss: 0.13727\n",
            "[76]\ttraining's auc: 0.88188\ttraining's binary_logloss: 0.123721\tvalid_1's auc: 0.828458\tvalid_1's binary_logloss: 0.137219\n",
            "[77]\ttraining's auc: 0.882255\ttraining's binary_logloss: 0.123551\tvalid_1's auc: 0.828453\tvalid_1's binary_logloss: 0.137172\n",
            "[78]\ttraining's auc: 0.882818\ttraining's binary_logloss: 0.123374\tvalid_1's auc: 0.828507\tvalid_1's binary_logloss: 0.137127\n",
            "[79]\ttraining's auc: 0.883246\ttraining's binary_logloss: 0.12321\tvalid_1's auc: 0.828592\tvalid_1's binary_logloss: 0.137088\n",
            "[80]\ttraining's auc: 0.883415\ttraining's binary_logloss: 0.123054\tvalid_1's auc: 0.828617\tvalid_1's binary_logloss: 0.137071\n",
            "[81]\ttraining's auc: 0.883744\ttraining's binary_logloss: 0.122892\tvalid_1's auc: 0.828593\tvalid_1's binary_logloss: 0.137042\n",
            "[82]\ttraining's auc: 0.884045\ttraining's binary_logloss: 0.122745\tvalid_1's auc: 0.828601\tvalid_1's binary_logloss: 0.137001\n",
            "[83]\ttraining's auc: 0.884462\ttraining's binary_logloss: 0.122591\tvalid_1's auc: 0.828614\tvalid_1's binary_logloss: 0.136962\n",
            "[84]\ttraining's auc: 0.885066\ttraining's binary_logloss: 0.122423\tvalid_1's auc: 0.828879\tvalid_1's binary_logloss: 0.136898\n",
            "[85]\ttraining's auc: 0.88545\ttraining's binary_logloss: 0.122274\tvalid_1's auc: 0.828817\tvalid_1's binary_logloss: 0.136873\n",
            "[86]\ttraining's auc: 0.885826\ttraining's binary_logloss: 0.122117\tvalid_1's auc: 0.829077\tvalid_1's binary_logloss: 0.136806\n",
            "[87]\ttraining's auc: 0.886117\ttraining's binary_logloss: 0.121979\tvalid_1's auc: 0.829117\tvalid_1's binary_logloss: 0.13678\n",
            "[88]\ttraining's auc: 0.886633\ttraining's binary_logloss: 0.121824\tvalid_1's auc: 0.829239\tvalid_1's binary_logloss: 0.136731\n",
            "[89]\ttraining's auc: 0.886898\ttraining's binary_logloss: 0.121681\tvalid_1's auc: 0.829324\tvalid_1's binary_logloss: 0.136691\n",
            "[90]\ttraining's auc: 0.887372\ttraining's binary_logloss: 0.12153\tvalid_1's auc: 0.829241\tvalid_1's binary_logloss: 0.136654\n",
            "[91]\ttraining's auc: 0.887625\ttraining's binary_logloss: 0.121402\tvalid_1's auc: 0.829106\tvalid_1's binary_logloss: 0.136638\n",
            "[92]\ttraining's auc: 0.887973\ttraining's binary_logloss: 0.121254\tvalid_1's auc: 0.829182\tvalid_1's binary_logloss: 0.136605\n",
            "[93]\ttraining's auc: 0.888495\ttraining's binary_logloss: 0.121101\tvalid_1's auc: 0.829257\tvalid_1's binary_logloss: 0.136564\n",
            "[94]\ttraining's auc: 0.888832\ttraining's binary_logloss: 0.120933\tvalid_1's auc: 0.829217\tvalid_1's binary_logloss: 0.13655\n",
            "[95]\ttraining's auc: 0.889184\ttraining's binary_logloss: 0.120779\tvalid_1's auc: 0.829249\tvalid_1's binary_logloss: 0.136539\n",
            "[96]\ttraining's auc: 0.889779\ttraining's binary_logloss: 0.120629\tvalid_1's auc: 0.829312\tvalid_1's binary_logloss: 0.13651\n",
            "[97]\ttraining's auc: 0.890006\ttraining's binary_logloss: 0.120504\tvalid_1's auc: 0.829278\tvalid_1's binary_logloss: 0.136503\n",
            "[98]\ttraining's auc: 0.890389\ttraining's binary_logloss: 0.120371\tvalid_1's auc: 0.829227\tvalid_1's binary_logloss: 0.136476\n",
            "[99]\ttraining's auc: 0.890556\ttraining's binary_logloss: 0.120251\tvalid_1's auc: 0.829254\tvalid_1's binary_logloss: 0.136459\n",
            "[100]\ttraining's auc: 0.890858\ttraining's binary_logloss: 0.120119\tvalid_1's auc: 0.829263\tvalid_1's binary_logloss: 0.136442\n",
            "[101]\ttraining's auc: 0.89115\ttraining's binary_logloss: 0.119987\tvalid_1's auc: 0.829195\tvalid_1's binary_logloss: 0.136432\n",
            "[102]\ttraining's auc: 0.891448\ttraining's binary_logloss: 0.119862\tvalid_1's auc: 0.829489\tvalid_1's binary_logloss: 0.136398\n",
            "[103]\ttraining's auc: 0.891953\ttraining's binary_logloss: 0.119741\tvalid_1's auc: 0.829597\tvalid_1's binary_logloss: 0.136357\n",
            "[104]\ttraining's auc: 0.892234\ttraining's binary_logloss: 0.119632\tvalid_1's auc: 0.82955\tvalid_1's binary_logloss: 0.136356\n",
            "[105]\ttraining's auc: 0.892869\ttraining's binary_logloss: 0.119496\tvalid_1's auc: 0.829684\tvalid_1's binary_logloss: 0.136319\n",
            "[106]\ttraining's auc: 0.893231\ttraining's binary_logloss: 0.119376\tvalid_1's auc: 0.829559\tvalid_1's binary_logloss: 0.136311\n",
            "[107]\ttraining's auc: 0.893389\ttraining's binary_logloss: 0.119262\tvalid_1's auc: 0.829517\tvalid_1's binary_logloss: 0.136306\n",
            "[108]\ttraining's auc: 0.894005\ttraining's binary_logloss: 0.119111\tvalid_1's auc: 0.829773\tvalid_1's binary_logloss: 0.136244\n",
            "[109]\ttraining's auc: 0.894338\ttraining's binary_logloss: 0.118989\tvalid_1's auc: 0.829953\tvalid_1's binary_logloss: 0.136208\n",
            "[110]\ttraining's auc: 0.89484\ttraining's binary_logloss: 0.118853\tvalid_1's auc: 0.830174\tvalid_1's binary_logloss: 0.136153\n",
            "[111]\ttraining's auc: 0.895049\ttraining's binary_logloss: 0.118731\tvalid_1's auc: 0.830175\tvalid_1's binary_logloss: 0.136138\n",
            "[112]\ttraining's auc: 0.895279\ttraining's binary_logloss: 0.118617\tvalid_1's auc: 0.83023\tvalid_1's binary_logloss: 0.136117\n",
            "[113]\ttraining's auc: 0.895611\ttraining's binary_logloss: 0.118504\tvalid_1's auc: 0.830519\tvalid_1's binary_logloss: 0.136082\n",
            "[114]\ttraining's auc: 0.89592\ttraining's binary_logloss: 0.118395\tvalid_1's auc: 0.830522\tvalid_1's binary_logloss: 0.136061\n",
            "[115]\ttraining's auc: 0.896328\ttraining's binary_logloss: 0.11828\tvalid_1's auc: 0.830599\tvalid_1's binary_logloss: 0.136025\n",
            "[116]\ttraining's auc: 0.896459\ttraining's binary_logloss: 0.118179\tvalid_1's auc: 0.830605\tvalid_1's binary_logloss: 0.136006\n",
            "[117]\ttraining's auc: 0.896678\ttraining's binary_logloss: 0.118068\tvalid_1's auc: 0.830571\tvalid_1's binary_logloss: 0.135996\n",
            "[118]\ttraining's auc: 0.896937\ttraining's binary_logloss: 0.117951\tvalid_1's auc: 0.830562\tvalid_1's binary_logloss: 0.135982\n",
            "[119]\ttraining's auc: 0.897246\ttraining's binary_logloss: 0.117844\tvalid_1's auc: 0.830639\tvalid_1's binary_logloss: 0.135967\n",
            "[120]\ttraining's auc: 0.897471\ttraining's binary_logloss: 0.117728\tvalid_1's auc: 0.830614\tvalid_1's binary_logloss: 0.135964\n",
            "[121]\ttraining's auc: 0.897727\ttraining's binary_logloss: 0.117628\tvalid_1's auc: 0.830543\tvalid_1's binary_logloss: 0.135975\n",
            "[122]\ttraining's auc: 0.898275\ttraining's binary_logloss: 0.117506\tvalid_1's auc: 0.830809\tvalid_1's binary_logloss: 0.135932\n",
            "[123]\ttraining's auc: 0.898536\ttraining's binary_logloss: 0.117401\tvalid_1's auc: 0.830709\tvalid_1's binary_logloss: 0.13593\n",
            "[124]\ttraining's auc: 0.898779\ttraining's binary_logloss: 0.117293\tvalid_1's auc: 0.830628\tvalid_1's binary_logloss: 0.135936\n",
            "[125]\ttraining's auc: 0.899008\ttraining's binary_logloss: 0.117193\tvalid_1's auc: 0.830611\tvalid_1's binary_logloss: 0.135935\n",
            "[126]\ttraining's auc: 0.89927\ttraining's binary_logloss: 0.117094\tvalid_1's auc: 0.830613\tvalid_1's binary_logloss: 0.135939\n",
            "[127]\ttraining's auc: 0.899505\ttraining's binary_logloss: 0.116995\tvalid_1's auc: 0.830616\tvalid_1's binary_logloss: 0.135937\n",
            "[128]\ttraining's auc: 0.899802\ttraining's binary_logloss: 0.116894\tvalid_1's auc: 0.830774\tvalid_1's binary_logloss: 0.135905\n",
            "[129]\ttraining's auc: 0.900096\ttraining's binary_logloss: 0.116783\tvalid_1's auc: 0.830708\tvalid_1's binary_logloss: 0.135904\n",
            "[130]\ttraining's auc: 0.900391\ttraining's binary_logloss: 0.116679\tvalid_1's auc: 0.830725\tvalid_1's binary_logloss: 0.135903\n",
            "[131]\ttraining's auc: 0.900833\ttraining's binary_logloss: 0.116564\tvalid_1's auc: 0.831026\tvalid_1's binary_logloss: 0.135855\n",
            "[132]\ttraining's auc: 0.901015\ttraining's binary_logloss: 0.116471\tvalid_1's auc: 0.830998\tvalid_1's binary_logloss: 0.135859\n",
            "[133]\ttraining's auc: 0.901372\ttraining's binary_logloss: 0.116366\tvalid_1's auc: 0.831177\tvalid_1's binary_logloss: 0.135829\n",
            "[134]\ttraining's auc: 0.901648\ttraining's binary_logloss: 0.116262\tvalid_1's auc: 0.831131\tvalid_1's binary_logloss: 0.135831\n",
            "[135]\ttraining's auc: 0.902026\ttraining's binary_logloss: 0.116167\tvalid_1's auc: 0.831227\tvalid_1's binary_logloss: 0.135803\n",
            "[136]\ttraining's auc: 0.902279\ttraining's binary_logloss: 0.116079\tvalid_1's auc: 0.831328\tvalid_1's binary_logloss: 0.135779\n",
            "[137]\ttraining's auc: 0.902502\ttraining's binary_logloss: 0.115977\tvalid_1's auc: 0.831288\tvalid_1's binary_logloss: 0.135779\n",
            "[138]\ttraining's auc: 0.902738\ttraining's binary_logloss: 0.115887\tvalid_1's auc: 0.831366\tvalid_1's binary_logloss: 0.135764\n",
            "[139]\ttraining's auc: 0.902921\ttraining's binary_logloss: 0.115788\tvalid_1's auc: 0.831428\tvalid_1's binary_logloss: 0.135754\n",
            "[140]\ttraining's auc: 0.903086\ttraining's binary_logloss: 0.115686\tvalid_1's auc: 0.831478\tvalid_1's binary_logloss: 0.135743\n",
            "[141]\ttraining's auc: 0.903362\ttraining's binary_logloss: 0.115589\tvalid_1's auc: 0.831369\tvalid_1's binary_logloss: 0.135759\n",
            "[142]\ttraining's auc: 0.903531\ttraining's binary_logloss: 0.115503\tvalid_1's auc: 0.831334\tvalid_1's binary_logloss: 0.135773\n",
            "[143]\ttraining's auc: 0.903769\ttraining's binary_logloss: 0.115403\tvalid_1's auc: 0.831334\tvalid_1's binary_logloss: 0.135768\n",
            "[144]\ttraining's auc: 0.903966\ttraining's binary_logloss: 0.115321\tvalid_1's auc: 0.831377\tvalid_1's binary_logloss: 0.135758\n",
            "[145]\ttraining's auc: 0.904143\ttraining's binary_logloss: 0.115232\tvalid_1's auc: 0.831432\tvalid_1's binary_logloss: 0.135751\n",
            "[146]\ttraining's auc: 0.904318\ttraining's binary_logloss: 0.11514\tvalid_1's auc: 0.831479\tvalid_1's binary_logloss: 0.135749\n",
            "[147]\ttraining's auc: 0.904527\ttraining's binary_logloss: 0.115051\tvalid_1's auc: 0.831419\tvalid_1's binary_logloss: 0.135759\n",
            "[148]\ttraining's auc: 0.90484\ttraining's binary_logloss: 0.114965\tvalid_1's auc: 0.831373\tvalid_1's binary_logloss: 0.135763\n",
            "[149]\ttraining's auc: 0.905007\ttraining's binary_logloss: 0.114874\tvalid_1's auc: 0.831325\tvalid_1's binary_logloss: 0.13578\n",
            "[150]\ttraining's auc: 0.905168\ttraining's binary_logloss: 0.114791\tvalid_1's auc: 0.831296\tvalid_1's binary_logloss: 0.135789\n",
            "[151]\ttraining's auc: 0.905302\ttraining's binary_logloss: 0.114713\tvalid_1's auc: 0.831264\tvalid_1's binary_logloss: 0.135798\n",
            "[152]\ttraining's auc: 0.905463\ttraining's binary_logloss: 0.114631\tvalid_1's auc: 0.831287\tvalid_1's binary_logloss: 0.135801\n",
            "[153]\ttraining's auc: 0.905634\ttraining's binary_logloss: 0.11454\tvalid_1's auc: 0.831288\tvalid_1's binary_logloss: 0.135804\n",
            "[154]\ttraining's auc: 0.90591\ttraining's binary_logloss: 0.114457\tvalid_1's auc: 0.831304\tvalid_1's binary_logloss: 0.135806\n",
            "[155]\ttraining's auc: 0.906094\ttraining's binary_logloss: 0.114365\tvalid_1's auc: 0.831292\tvalid_1's binary_logloss: 0.135798\n",
            "[156]\ttraining's auc: 0.906197\ttraining's binary_logloss: 0.114292\tvalid_1's auc: 0.831357\tvalid_1's binary_logloss: 0.135793\n",
            "[157]\ttraining's auc: 0.906357\ttraining's binary_logloss: 0.114207\tvalid_1's auc: 0.831295\tvalid_1's binary_logloss: 0.135808\n",
            "[158]\ttraining's auc: 0.906576\ttraining's binary_logloss: 0.11412\tvalid_1's auc: 0.831279\tvalid_1's binary_logloss: 0.135806\n",
            "[159]\ttraining's auc: 0.906755\ttraining's binary_logloss: 0.114043\tvalid_1's auc: 0.831177\tvalid_1's binary_logloss: 0.13582\n",
            "[160]\ttraining's auc: 0.907003\ttraining's binary_logloss: 0.113946\tvalid_1's auc: 0.831186\tvalid_1's binary_logloss: 0.135819\n",
            "[161]\ttraining's auc: 0.907192\ttraining's binary_logloss: 0.113864\tvalid_1's auc: 0.831165\tvalid_1's binary_logloss: 0.135831\n",
            "[162]\ttraining's auc: 0.907496\ttraining's binary_logloss: 0.113789\tvalid_1's auc: 0.83122\tvalid_1's binary_logloss: 0.135835\n",
            "[163]\ttraining's auc: 0.907925\ttraining's binary_logloss: 0.113667\tvalid_1's auc: 0.831212\tvalid_1's binary_logloss: 0.135842\n",
            "[164]\ttraining's auc: 0.908151\ttraining's binary_logloss: 0.11357\tvalid_1's auc: 0.831247\tvalid_1's binary_logloss: 0.135838\n",
            "[165]\ttraining's auc: 0.908394\ttraining's binary_logloss: 0.113467\tvalid_1's auc: 0.831235\tvalid_1's binary_logloss: 0.135841\n",
            "[166]\ttraining's auc: 0.908802\ttraining's binary_logloss: 0.113362\tvalid_1's auc: 0.83121\tvalid_1's binary_logloss: 0.135839\n",
            "[167]\ttraining's auc: 0.908955\ttraining's binary_logloss: 0.113283\tvalid_1's auc: 0.831181\tvalid_1's binary_logloss: 0.135845\n",
            "[168]\ttraining's auc: 0.909031\ttraining's binary_logloss: 0.113216\tvalid_1's auc: 0.831141\tvalid_1's binary_logloss: 0.135861\n",
            "[169]\ttraining's auc: 0.909199\ttraining's binary_logloss: 0.113144\tvalid_1's auc: 0.831211\tvalid_1's binary_logloss: 0.135844\n",
            "[170]\ttraining's auc: 0.909423\ttraining's binary_logloss: 0.113045\tvalid_1's auc: 0.831234\tvalid_1's binary_logloss: 0.135837\n",
            "  0%|          | 0/50 [00:13<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.164603\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.158926\n",
            "[2]\ttraining's auc: 0.822077\ttraining's binary_logloss: 0.16258\tvalid_1's auc: 0.804437\tvalid_1's binary_logloss: 0.157266\n",
            "[3]\ttraining's auc: 0.823399\ttraining's binary_logloss: 0.160751\tvalid_1's auc: 0.804766\tvalid_1's binary_logloss: 0.155782\n",
            "[4]\ttraining's auc: 0.829662\ttraining's binary_logloss: 0.159068\tvalid_1's auc: 0.816987\tvalid_1's binary_logloss: 0.154404\n",
            "[5]\ttraining's auc: 0.832129\ttraining's binary_logloss: 0.157526\tvalid_1's auc: 0.818113\tvalid_1's binary_logloss: 0.153158\n",
            "[6]\ttraining's auc: 0.834178\ttraining's binary_logloss: 0.156085\tvalid_1's auc: 0.819082\tvalid_1's binary_logloss: 0.152026\n",
            "[7]\ttraining's auc: 0.834923\ttraining's binary_logloss: 0.154769\tvalid_1's auc: 0.819266\tvalid_1's binary_logloss: 0.150985\n",
            "[8]\ttraining's auc: 0.835542\ttraining's binary_logloss: 0.153532\tvalid_1's auc: 0.819521\tvalid_1's binary_logloss: 0.150009\n",
            "[9]\ttraining's auc: 0.836025\ttraining's binary_logloss: 0.152377\tvalid_1's auc: 0.81958\tvalid_1's binary_logloss: 0.149165\n",
            "[10]\ttraining's auc: 0.837365\ttraining's binary_logloss: 0.151298\tvalid_1's auc: 0.820182\tvalid_1's binary_logloss: 0.148324\n",
            "[11]\ttraining's auc: 0.838027\ttraining's binary_logloss: 0.150308\tvalid_1's auc: 0.821322\tvalid_1's binary_logloss: 0.14754\n",
            "[12]\ttraining's auc: 0.840497\ttraining's binary_logloss: 0.149365\tvalid_1's auc: 0.823649\tvalid_1's binary_logloss: 0.146836\n",
            "[13]\ttraining's auc: 0.841103\ttraining's binary_logloss: 0.148465\tvalid_1's auc: 0.823718\tvalid_1's binary_logloss: 0.146163\n",
            "[14]\ttraining's auc: 0.841583\ttraining's binary_logloss: 0.147601\tvalid_1's auc: 0.823989\tvalid_1's binary_logloss: 0.145518\n",
            "[15]\ttraining's auc: 0.843922\ttraining's binary_logloss: 0.146786\tvalid_1's auc: 0.825086\tvalid_1's binary_logloss: 0.144933\n",
            "[16]\ttraining's auc: 0.847191\ttraining's binary_logloss: 0.145987\tvalid_1's auc: 0.828221\tvalid_1's binary_logloss: 0.144355\n",
            "[17]\ttraining's auc: 0.848491\ttraining's binary_logloss: 0.145233\tvalid_1's auc: 0.828713\tvalid_1's binary_logloss: 0.143796\n",
            "[18]\ttraining's auc: 0.849086\ttraining's binary_logloss: 0.144522\tvalid_1's auc: 0.828826\tvalid_1's binary_logloss: 0.143278\n",
            "[19]\ttraining's auc: 0.850034\ttraining's binary_logloss: 0.143835\tvalid_1's auc: 0.829299\tvalid_1's binary_logloss: 0.142773\n",
            "[20]\ttraining's auc: 0.851109\ttraining's binary_logloss: 0.143165\tvalid_1's auc: 0.829137\tvalid_1's binary_logloss: 0.142313\n",
            "[21]\ttraining's auc: 0.85205\ttraining's binary_logloss: 0.142527\tvalid_1's auc: 0.829716\tvalid_1's binary_logloss: 0.141844\n",
            "[22]\ttraining's auc: 0.852396\ttraining's binary_logloss: 0.141941\tvalid_1's auc: 0.829681\tvalid_1's binary_logloss: 0.141404\n",
            "[23]\ttraining's auc: 0.853859\ttraining's binary_logloss: 0.141356\tvalid_1's auc: 0.829721\tvalid_1's binary_logloss: 0.140983\n",
            "[24]\ttraining's auc: 0.854359\ttraining's binary_logloss: 0.14078\tvalid_1's auc: 0.829985\tvalid_1's binary_logloss: 0.140592\n",
            "[25]\ttraining's auc: 0.855553\ttraining's binary_logloss: 0.140252\tvalid_1's auc: 0.83035\tvalid_1's binary_logloss: 0.140236\n",
            "[26]\ttraining's auc: 0.857294\ttraining's binary_logloss: 0.139734\tvalid_1's auc: 0.83236\tvalid_1's binary_logloss: 0.139856\n",
            "[27]\ttraining's auc: 0.857644\ttraining's binary_logloss: 0.139243\tvalid_1's auc: 0.832555\tvalid_1's binary_logloss: 0.139465\n",
            "[28]\ttraining's auc: 0.858239\ttraining's binary_logloss: 0.138763\tvalid_1's auc: 0.83288\tvalid_1's binary_logloss: 0.139111\n",
            "[29]\ttraining's auc: 0.858748\ttraining's binary_logloss: 0.138288\tvalid_1's auc: 0.832951\tvalid_1's binary_logloss: 0.138786\n",
            "[30]\ttraining's auc: 0.859345\ttraining's binary_logloss: 0.137826\tvalid_1's auc: 0.833108\tvalid_1's binary_logloss: 0.138482\n",
            "[31]\ttraining's auc: 0.859769\ttraining's binary_logloss: 0.137392\tvalid_1's auc: 0.833257\tvalid_1's binary_logloss: 0.138202\n",
            "[32]\ttraining's auc: 0.860145\ttraining's binary_logloss: 0.136977\tvalid_1's auc: 0.833367\tvalid_1's binary_logloss: 0.137907\n",
            "[33]\ttraining's auc: 0.860426\ttraining's binary_logloss: 0.136574\tvalid_1's auc: 0.833054\tvalid_1's binary_logloss: 0.137657\n",
            "[34]\ttraining's auc: 0.861861\ttraining's binary_logloss: 0.136179\tvalid_1's auc: 0.833741\tvalid_1's binary_logloss: 0.137382\n",
            "[35]\ttraining's auc: 0.86204\ttraining's binary_logloss: 0.135804\tvalid_1's auc: 0.833805\tvalid_1's binary_logloss: 0.137154\n",
            "[36]\ttraining's auc: 0.862949\ttraining's binary_logloss: 0.135434\tvalid_1's auc: 0.833877\tvalid_1's binary_logloss: 0.136896\n",
            "[37]\ttraining's auc: 0.86365\ttraining's binary_logloss: 0.135063\tvalid_1's auc: 0.833943\tvalid_1's binary_logloss: 0.136667\n",
            "[38]\ttraining's auc: 0.863945\ttraining's binary_logloss: 0.134706\tvalid_1's auc: 0.834023\tvalid_1's binary_logloss: 0.136442\n",
            "[39]\ttraining's auc: 0.864488\ttraining's binary_logloss: 0.134343\tvalid_1's auc: 0.834124\tvalid_1's binary_logloss: 0.136236\n",
            "[40]\ttraining's auc: 0.866092\ttraining's binary_logloss: 0.133985\tvalid_1's auc: 0.834249\tvalid_1's binary_logloss: 0.136045\n",
            "[41]\ttraining's auc: 0.866847\ttraining's binary_logloss: 0.133639\tvalid_1's auc: 0.834521\tvalid_1's binary_logloss: 0.135827\n",
            "[42]\ttraining's auc: 0.867553\ttraining's binary_logloss: 0.133307\tvalid_1's auc: 0.834589\tvalid_1's binary_logloss: 0.135659\n",
            "[43]\ttraining's auc: 0.868179\ttraining's binary_logloss: 0.132988\tvalid_1's auc: 0.834741\tvalid_1's binary_logloss: 0.135491\n",
            "[44]\ttraining's auc: 0.869087\ttraining's binary_logloss: 0.132672\tvalid_1's auc: 0.83528\tvalid_1's binary_logloss: 0.135332\n",
            "[45]\ttraining's auc: 0.869682\ttraining's binary_logloss: 0.132372\tvalid_1's auc: 0.835223\tvalid_1's binary_logloss: 0.135161\n",
            "[46]\ttraining's auc: 0.870126\ttraining's binary_logloss: 0.132071\tvalid_1's auc: 0.835067\tvalid_1's binary_logloss: 0.135004\n",
            "[47]\ttraining's auc: 0.870932\ttraining's binary_logloss: 0.131789\tvalid_1's auc: 0.834926\tvalid_1's binary_logloss: 0.134844\n",
            "[48]\ttraining's auc: 0.871385\ttraining's binary_logloss: 0.131506\tvalid_1's auc: 0.834833\tvalid_1's binary_logloss: 0.134713\n",
            "[49]\ttraining's auc: 0.871645\ttraining's binary_logloss: 0.131243\tvalid_1's auc: 0.83496\tvalid_1's binary_logloss: 0.134555\n",
            "[50]\ttraining's auc: 0.872052\ttraining's binary_logloss: 0.13099\tvalid_1's auc: 0.835103\tvalid_1's binary_logloss: 0.134429\n",
            "[51]\ttraining's auc: 0.872414\ttraining's binary_logloss: 0.130726\tvalid_1's auc: 0.835071\tvalid_1's binary_logloss: 0.134312\n",
            "[52]\ttraining's auc: 0.872842\ttraining's binary_logloss: 0.130466\tvalid_1's auc: 0.835109\tvalid_1's binary_logloss: 0.134187\n",
            "[53]\ttraining's auc: 0.873261\ttraining's binary_logloss: 0.130204\tvalid_1's auc: 0.835137\tvalid_1's binary_logloss: 0.134066\n",
            "[54]\ttraining's auc: 0.873634\ttraining's binary_logloss: 0.129951\tvalid_1's auc: 0.83495\tvalid_1's binary_logloss: 0.133977\n",
            "[55]\ttraining's auc: 0.874058\ttraining's binary_logloss: 0.129708\tvalid_1's auc: 0.834989\tvalid_1's binary_logloss: 0.133856\n",
            "[56]\ttraining's auc: 0.874243\ttraining's binary_logloss: 0.12949\tvalid_1's auc: 0.835017\tvalid_1's binary_logloss: 0.133761\n",
            "[57]\ttraining's auc: 0.874429\ttraining's binary_logloss: 0.12926\tvalid_1's auc: 0.834852\tvalid_1's binary_logloss: 0.133672\n",
            "[58]\ttraining's auc: 0.874877\ttraining's binary_logloss: 0.129022\tvalid_1's auc: 0.834725\tvalid_1's binary_logloss: 0.133582\n",
            "[59]\ttraining's auc: 0.875026\ttraining's binary_logloss: 0.128809\tvalid_1's auc: 0.834726\tvalid_1's binary_logloss: 0.133491\n",
            "[60]\ttraining's auc: 0.875368\ttraining's binary_logloss: 0.128588\tvalid_1's auc: 0.834767\tvalid_1's binary_logloss: 0.133403\n",
            "[61]\ttraining's auc: 0.875544\ttraining's binary_logloss: 0.128386\tvalid_1's auc: 0.834714\tvalid_1's binary_logloss: 0.133319\n",
            "[62]\ttraining's auc: 0.87581\ttraining's binary_logloss: 0.128189\tvalid_1's auc: 0.834692\tvalid_1's binary_logloss: 0.133239\n",
            "[63]\ttraining's auc: 0.876073\ttraining's binary_logloss: 0.127987\tvalid_1's auc: 0.834729\tvalid_1's binary_logloss: 0.133145\n",
            "[64]\ttraining's auc: 0.876264\ttraining's binary_logloss: 0.127799\tvalid_1's auc: 0.834835\tvalid_1's binary_logloss: 0.13306\n",
            "[65]\ttraining's auc: 0.876934\ttraining's binary_logloss: 0.127587\tvalid_1's auc: 0.834965\tvalid_1's binary_logloss: 0.132993\n",
            "[66]\ttraining's auc: 0.877237\ttraining's binary_logloss: 0.127388\tvalid_1's auc: 0.834935\tvalid_1's binary_logloss: 0.132918\n",
            "[67]\ttraining's auc: 0.877639\ttraining's binary_logloss: 0.127176\tvalid_1's auc: 0.834828\tvalid_1's binary_logloss: 0.132841\n",
            "[68]\ttraining's auc: 0.878215\ttraining's binary_logloss: 0.126958\tvalid_1's auc: 0.834942\tvalid_1's binary_logloss: 0.132779\n",
            "[69]\ttraining's auc: 0.878497\ttraining's binary_logloss: 0.126765\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.13271\n",
            "[70]\ttraining's auc: 0.87868\ttraining's binary_logloss: 0.126576\tvalid_1's auc: 0.834925\tvalid_1's binary_logloss: 0.13264\n",
            "[71]\ttraining's auc: 0.879201\ttraining's binary_logloss: 0.12639\tvalid_1's auc: 0.835056\tvalid_1's binary_logloss: 0.132565\n",
            "[72]\ttraining's auc: 0.87946\ttraining's binary_logloss: 0.126218\tvalid_1's auc: 0.835185\tvalid_1's binary_logloss: 0.132496\n",
            "[73]\ttraining's auc: 0.879914\ttraining's binary_logloss: 0.12604\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.132445\n",
            "[74]\ttraining's auc: 0.88022\ttraining's binary_logloss: 0.125869\tvalid_1's auc: 0.834842\tvalid_1's binary_logloss: 0.132404\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "  0%|          | 0/50 [00:18<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.160882\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.166494\n",
            "[2]\ttraining's auc: 0.830881\ttraining's binary_logloss: 0.158905\tvalid_1's auc: 0.816224\tvalid_1's binary_logloss: 0.164697\n",
            "[3]\ttraining's auc: 0.831547\ttraining's binary_logloss: 0.157153\tvalid_1's auc: 0.814456\tvalid_1's binary_logloss: 0.163161\n",
            "[4]\ttraining's auc: 0.832711\ttraining's binary_logloss: 0.155559\tvalid_1's auc: 0.815062\tvalid_1's binary_logloss: 0.161767\n",
            "[5]\ttraining's auc: 0.834715\ttraining's binary_logloss: 0.154087\tvalid_1's auc: 0.816516\tvalid_1's binary_logloss: 0.16041\n",
            "[6]\ttraining's auc: 0.835076\ttraining's binary_logloss: 0.152738\tvalid_1's auc: 0.816225\tvalid_1's binary_logloss: 0.159195\n",
            "[7]\ttraining's auc: 0.837302\ttraining's binary_logloss: 0.151486\tvalid_1's auc: 0.817675\tvalid_1's binary_logloss: 0.158109\n",
            "[8]\ttraining's auc: 0.838388\ttraining's binary_logloss: 0.150265\tvalid_1's auc: 0.818509\tvalid_1's binary_logloss: 0.157018\n",
            "[9]\ttraining's auc: 0.839798\ttraining's binary_logloss: 0.149145\tvalid_1's auc: 0.819136\tvalid_1's binary_logloss: 0.156031\n",
            "[10]\ttraining's auc: 0.841213\ttraining's binary_logloss: 0.148118\tvalid_1's auc: 0.819454\tvalid_1's binary_logloss: 0.15514\n",
            "[11]\ttraining's auc: 0.843734\ttraining's binary_logloss: 0.147146\tvalid_1's auc: 0.822747\tvalid_1's binary_logloss: 0.154281\n",
            "[12]\ttraining's auc: 0.846853\ttraining's binary_logloss: 0.1462\tvalid_1's auc: 0.825459\tvalid_1's binary_logloss: 0.153466\n",
            "[13]\ttraining's auc: 0.847936\ttraining's binary_logloss: 0.145295\tvalid_1's auc: 0.826202\tvalid_1's binary_logloss: 0.152679\n",
            "[14]\ttraining's auc: 0.849324\ttraining's binary_logloss: 0.144446\tvalid_1's auc: 0.827075\tvalid_1's binary_logloss: 0.151974\n",
            "[15]\ttraining's auc: 0.849168\ttraining's binary_logloss: 0.143659\tvalid_1's auc: 0.827568\tvalid_1's binary_logloss: 0.151314\n",
            "[16]\ttraining's auc: 0.849852\ttraining's binary_logloss: 0.142911\tvalid_1's auc: 0.827795\tvalid_1's binary_logloss: 0.15069\n",
            "[17]\ttraining's auc: 0.850025\ttraining's binary_logloss: 0.142198\tvalid_1's auc: 0.827788\tvalid_1's binary_logloss: 0.150084\n",
            "[18]\ttraining's auc: 0.850522\ttraining's binary_logloss: 0.141517\tvalid_1's auc: 0.82792\tvalid_1's binary_logloss: 0.14953\n",
            "[19]\ttraining's auc: 0.851494\ttraining's binary_logloss: 0.140844\tvalid_1's auc: 0.828474\tvalid_1's binary_logloss: 0.148977\n",
            "[20]\ttraining's auc: 0.852404\ttraining's binary_logloss: 0.140172\tvalid_1's auc: 0.828894\tvalid_1's binary_logloss: 0.148453\n",
            "[21]\ttraining's auc: 0.852851\ttraining's binary_logloss: 0.139564\tvalid_1's auc: 0.829132\tvalid_1's binary_logloss: 0.147935\n",
            "[22]\ttraining's auc: 0.852997\ttraining's binary_logloss: 0.138957\tvalid_1's auc: 0.829157\tvalid_1's binary_logloss: 0.147475\n",
            "[23]\ttraining's auc: 0.853262\ttraining's binary_logloss: 0.138379\tvalid_1's auc: 0.829189\tvalid_1's binary_logloss: 0.14704\n",
            "[24]\ttraining's auc: 0.854295\ttraining's binary_logloss: 0.137823\tvalid_1's auc: 0.829742\tvalid_1's binary_logloss: 0.146589\n",
            "[25]\ttraining's auc: 0.855321\ttraining's binary_logloss: 0.137293\tvalid_1's auc: 0.830266\tvalid_1's binary_logloss: 0.146185\n",
            "[26]\ttraining's auc: 0.85601\ttraining's binary_logloss: 0.136779\tvalid_1's auc: 0.830691\tvalid_1's binary_logloss: 0.145788\n",
            "[27]\ttraining's auc: 0.85632\ttraining's binary_logloss: 0.136292\tvalid_1's auc: 0.830769\tvalid_1's binary_logloss: 0.14541\n",
            "[28]\ttraining's auc: 0.857024\ttraining's binary_logloss: 0.135822\tvalid_1's auc: 0.830884\tvalid_1's binary_logloss: 0.145038\n",
            "[29]\ttraining's auc: 0.857791\ttraining's binary_logloss: 0.135387\tvalid_1's auc: 0.830943\tvalid_1's binary_logloss: 0.144696\n",
            "[30]\ttraining's auc: 0.857921\ttraining's binary_logloss: 0.134957\tvalid_1's auc: 0.831169\tvalid_1's binary_logloss: 0.144343\n",
            "[31]\ttraining's auc: 0.858257\ttraining's binary_logloss: 0.134533\tvalid_1's auc: 0.831416\tvalid_1's binary_logloss: 0.144013\n",
            "[32]\ttraining's auc: 0.858675\ttraining's binary_logloss: 0.134116\tvalid_1's auc: 0.831689\tvalid_1's binary_logloss: 0.143698\n",
            "[33]\ttraining's auc: 0.85936\ttraining's binary_logloss: 0.133714\tvalid_1's auc: 0.832107\tvalid_1's binary_logloss: 0.143393\n",
            "[34]\ttraining's auc: 0.859979\ttraining's binary_logloss: 0.13333\tvalid_1's auc: 0.832246\tvalid_1's binary_logloss: 0.143116\n",
            "[35]\ttraining's auc: 0.860768\ttraining's binary_logloss: 0.132964\tvalid_1's auc: 0.8322\tvalid_1's binary_logloss: 0.142838\n",
            "[36]\ttraining's auc: 0.861562\ttraining's binary_logloss: 0.132597\tvalid_1's auc: 0.832342\tvalid_1's binary_logloss: 0.142577\n",
            "[37]\ttraining's auc: 0.862594\ttraining's binary_logloss: 0.132258\tvalid_1's auc: 0.83225\tvalid_1's binary_logloss: 0.142342\n",
            "[38]\ttraining's auc: 0.86305\ttraining's binary_logloss: 0.131904\tvalid_1's auc: 0.832165\tvalid_1's binary_logloss: 0.142145\n",
            "[39]\ttraining's auc: 0.863402\ttraining's binary_logloss: 0.131571\tvalid_1's auc: 0.832129\tvalid_1's binary_logloss: 0.14192\n",
            "[40]\ttraining's auc: 0.863784\ttraining's binary_logloss: 0.131257\tvalid_1's auc: 0.832272\tvalid_1's binary_logloss: 0.141717\n",
            "[41]\ttraining's auc: 0.864336\ttraining's binary_logloss: 0.130935\tvalid_1's auc: 0.832198\tvalid_1's binary_logloss: 0.141522\n",
            "[42]\ttraining's auc: 0.864718\ttraining's binary_logloss: 0.130637\tvalid_1's auc: 0.832257\tvalid_1's binary_logloss: 0.141343\n",
            "[43]\ttraining's auc: 0.865027\ttraining's binary_logloss: 0.130351\tvalid_1's auc: 0.832156\tvalid_1's binary_logloss: 0.141165\n",
            "[44]\ttraining's auc: 0.865355\ttraining's binary_logloss: 0.130069\tvalid_1's auc: 0.832013\tvalid_1's binary_logloss: 0.141005\n",
            "[45]\ttraining's auc: 0.866872\ttraining's binary_logloss: 0.129772\tvalid_1's auc: 0.832483\tvalid_1's binary_logloss: 0.140816\n",
            "[46]\ttraining's auc: 0.867348\ttraining's binary_logloss: 0.129474\tvalid_1's auc: 0.832412\tvalid_1's binary_logloss: 0.140632\n",
            "[47]\ttraining's auc: 0.868381\ttraining's binary_logloss: 0.129174\tvalid_1's auc: 0.832393\tvalid_1's binary_logloss: 0.140478\n",
            "[48]\ttraining's auc: 0.868968\ttraining's binary_logloss: 0.128913\tvalid_1's auc: 0.832142\tvalid_1's binary_logloss: 0.14034\n",
            "[49]\ttraining's auc: 0.869436\ttraining's binary_logloss: 0.128655\tvalid_1's auc: 0.832167\tvalid_1's binary_logloss: 0.1402\n",
            "[50]\ttraining's auc: 0.870665\ttraining's binary_logloss: 0.128392\tvalid_1's auc: 0.834\tvalid_1's binary_logloss: 0.14005\n",
            "[51]\ttraining's auc: 0.870992\ttraining's binary_logloss: 0.128135\tvalid_1's auc: 0.833912\tvalid_1's binary_logloss: 0.13991\n",
            "[52]\ttraining's auc: 0.87162\ttraining's binary_logloss: 0.127866\tvalid_1's auc: 0.834275\tvalid_1's binary_logloss: 0.139751\n",
            "[53]\ttraining's auc: 0.872334\ttraining's binary_logloss: 0.127636\tvalid_1's auc: 0.834746\tvalid_1's binary_logloss: 0.139624\n",
            "[54]\ttraining's auc: 0.872764\ttraining's binary_logloss: 0.1274\tvalid_1's auc: 0.834585\tvalid_1's binary_logloss: 0.139517\n",
            "[55]\ttraining's auc: 0.873128\ttraining's binary_logloss: 0.127157\tvalid_1's auc: 0.834574\tvalid_1's binary_logloss: 0.139379\n",
            "[56]\ttraining's auc: 0.873674\ttraining's binary_logloss: 0.126908\tvalid_1's auc: 0.834875\tvalid_1's binary_logloss: 0.139267\n",
            "[57]\ttraining's auc: 0.874162\ttraining's binary_logloss: 0.126676\tvalid_1's auc: 0.834714\tvalid_1's binary_logloss: 0.13916\n",
            "[58]\ttraining's auc: 0.874617\ttraining's binary_logloss: 0.126459\tvalid_1's auc: 0.834868\tvalid_1's binary_logloss: 0.139046\n",
            "[59]\ttraining's auc: 0.875011\ttraining's binary_logloss: 0.126243\tvalid_1's auc: 0.835425\tvalid_1's binary_logloss: 0.138917\n",
            "[60]\ttraining's auc: 0.875567\ttraining's binary_logloss: 0.126027\tvalid_1's auc: 0.835725\tvalid_1's binary_logloss: 0.138798\n",
            "[61]\ttraining's auc: 0.876183\ttraining's binary_logloss: 0.125797\tvalid_1's auc: 0.835814\tvalid_1's binary_logloss: 0.138685\n",
            "[62]\ttraining's auc: 0.876562\ttraining's binary_logloss: 0.125597\tvalid_1's auc: 0.835692\tvalid_1's binary_logloss: 0.138596\n",
            "[63]\ttraining's auc: 0.876815\ttraining's binary_logloss: 0.125381\tvalid_1's auc: 0.835575\tvalid_1's binary_logloss: 0.138511\n",
            "[64]\ttraining's auc: 0.877341\ttraining's binary_logloss: 0.125188\tvalid_1's auc: 0.835643\tvalid_1's binary_logloss: 0.138417\n",
            "[65]\ttraining's auc: 0.878161\ttraining's binary_logloss: 0.12498\tvalid_1's auc: 0.835633\tvalid_1's binary_logloss: 0.138352\n",
            "[66]\ttraining's auc: 0.87862\ttraining's binary_logloss: 0.124787\tvalid_1's auc: 0.835556\tvalid_1's binary_logloss: 0.138275\n",
            "[67]\ttraining's auc: 0.879483\ttraining's binary_logloss: 0.124584\tvalid_1's auc: 0.836067\tvalid_1's binary_logloss: 0.13816\n",
            "[68]\ttraining's auc: 0.879892\ttraining's binary_logloss: 0.124388\tvalid_1's auc: 0.836113\tvalid_1's binary_logloss: 0.138079\n",
            "[69]\ttraining's auc: 0.880369\ttraining's binary_logloss: 0.124212\tvalid_1's auc: 0.83643\tvalid_1's binary_logloss: 0.137981\n",
            "[70]\ttraining's auc: 0.880802\ttraining's binary_logloss: 0.124032\tvalid_1's auc: 0.836607\tvalid_1's binary_logloss: 0.137917\n",
            "[71]\ttraining's auc: 0.881045\ttraining's binary_logloss: 0.123862\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.137841\n",
            "[72]\ttraining's auc: 0.881434\ttraining's binary_logloss: 0.12368\tvalid_1's auc: 0.836817\tvalid_1's binary_logloss: 0.137768\n",
            "[73]\ttraining's auc: 0.882182\ttraining's binary_logloss: 0.123475\tvalid_1's auc: 0.83685\tvalid_1's binary_logloss: 0.137693\n",
            "[74]\ttraining's auc: 0.882377\ttraining's binary_logloss: 0.123304\tvalid_1's auc: 0.83692\tvalid_1's binary_logloss: 0.137631\n",
            "[75]\ttraining's auc: 0.883065\ttraining's binary_logloss: 0.123114\tvalid_1's auc: 0.836902\tvalid_1's binary_logloss: 0.137592\n",
            "[76]\ttraining's auc: 0.883371\ttraining's binary_logloss: 0.122957\tvalid_1's auc: 0.83678\tvalid_1's binary_logloss: 0.137536\n",
            "[77]\ttraining's auc: 0.884052\ttraining's binary_logloss: 0.122775\tvalid_1's auc: 0.83655\tvalid_1's binary_logloss: 0.137475\n",
            "[78]\ttraining's auc: 0.884337\ttraining's binary_logloss: 0.122611\tvalid_1's auc: 0.83665\tvalid_1's binary_logloss: 0.137405\n",
            "[79]\ttraining's auc: 0.88466\ttraining's binary_logloss: 0.122452\tvalid_1's auc: 0.836751\tvalid_1's binary_logloss: 0.137341\n",
            "[80]\ttraining's auc: 0.885027\ttraining's binary_logloss: 0.122288\tvalid_1's auc: 0.836649\tvalid_1's binary_logloss: 0.137318\n",
            "[81]\ttraining's auc: 0.885563\ttraining's binary_logloss: 0.122127\tvalid_1's auc: 0.83672\tvalid_1's binary_logloss: 0.137274\n",
            "[82]\ttraining's auc: 0.88594\ttraining's binary_logloss: 0.121965\tvalid_1's auc: 0.836833\tvalid_1's binary_logloss: 0.137228\n",
            "[83]\ttraining's auc: 0.88657\ttraining's binary_logloss: 0.121799\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.137187\n",
            "[84]\ttraining's auc: 0.887003\ttraining's binary_logloss: 0.121637\tvalid_1's auc: 0.836988\tvalid_1's binary_logloss: 0.137144\n",
            "[85]\ttraining's auc: 0.887426\ttraining's binary_logloss: 0.121482\tvalid_1's auc: 0.836958\tvalid_1's binary_logloss: 0.137107\n",
            "[86]\ttraining's auc: 0.887933\ttraining's binary_logloss: 0.121319\tvalid_1's auc: 0.836879\tvalid_1's binary_logloss: 0.137063\n",
            "[87]\ttraining's auc: 0.888254\ttraining's binary_logloss: 0.121177\tvalid_1's auc: 0.836838\tvalid_1's binary_logloss: 0.137025\n",
            "[88]\ttraining's auc: 0.888612\ttraining's binary_logloss: 0.121021\tvalid_1's auc: 0.836645\tvalid_1's binary_logloss: 0.137002\n",
            "[89]\ttraining's auc: 0.888867\ttraining's binary_logloss: 0.120888\tvalid_1's auc: 0.836899\tvalid_1's binary_logloss: 0.13693\n",
            "[90]\ttraining's auc: 0.889086\ttraining's binary_logloss: 0.120747\tvalid_1's auc: 0.836783\tvalid_1's binary_logloss: 0.136902\n",
            "[91]\ttraining's auc: 0.889318\ttraining's binary_logloss: 0.120623\tvalid_1's auc: 0.836788\tvalid_1's binary_logloss: 0.136872\n",
            "[92]\ttraining's auc: 0.889558\ttraining's binary_logloss: 0.12049\tvalid_1's auc: 0.836694\tvalid_1's binary_logloss: 0.136853\n",
            "[93]\ttraining's auc: 0.889861\ttraining's binary_logloss: 0.120369\tvalid_1's auc: 0.836621\tvalid_1's binary_logloss: 0.13682\n",
            "[94]\ttraining's auc: 0.890112\ttraining's binary_logloss: 0.120236\tvalid_1's auc: 0.836551\tvalid_1's binary_logloss: 0.136796\n",
            "[95]\ttraining's auc: 0.890452\ttraining's binary_logloss: 0.120098\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.136768\n",
            "[96]\ttraining's auc: 0.890819\ttraining's binary_logloss: 0.119965\tvalid_1's auc: 0.836588\tvalid_1's binary_logloss: 0.136739\n",
            "[97]\ttraining's auc: 0.891143\ttraining's binary_logloss: 0.119833\tvalid_1's auc: 0.836566\tvalid_1's binary_logloss: 0.136724\n",
            "[98]\ttraining's auc: 0.891441\ttraining's binary_logloss: 0.119697\tvalid_1's auc: 0.836657\tvalid_1's binary_logloss: 0.136684\n",
            "[99]\ttraining's auc: 0.891682\ttraining's binary_logloss: 0.11957\tvalid_1's auc: 0.836704\tvalid_1's binary_logloss: 0.13666\n",
            "[100]\ttraining's auc: 0.892043\ttraining's binary_logloss: 0.119437\tvalid_1's auc: 0.836619\tvalid_1's binary_logloss: 0.136641\n",
            "[101]\ttraining's auc: 0.892392\ttraining's binary_logloss: 0.119304\tvalid_1's auc: 0.836615\tvalid_1's binary_logloss: 0.136622\n",
            "[102]\ttraining's auc: 0.892715\ttraining's binary_logloss: 0.119191\tvalid_1's auc: 0.836595\tvalid_1's binary_logloss: 0.136599\n",
            "[103]\ttraining's auc: 0.893046\ttraining's binary_logloss: 0.119057\tvalid_1's auc: 0.836613\tvalid_1's binary_logloss: 0.13658\n",
            "[104]\ttraining's auc: 0.893258\ttraining's binary_logloss: 0.11894\tvalid_1's auc: 0.836524\tvalid_1's binary_logloss: 0.136565\n",
            "[105]\ttraining's auc: 0.893679\ttraining's binary_logloss: 0.118831\tvalid_1's auc: 0.836487\tvalid_1's binary_logloss: 0.136548\n",
            "[106]\ttraining's auc: 0.894026\ttraining's binary_logloss: 0.118707\tvalid_1's auc: 0.836425\tvalid_1's binary_logloss: 0.136541\n",
            "[107]\ttraining's auc: 0.894179\ttraining's binary_logloss: 0.118609\tvalid_1's auc: 0.836453\tvalid_1's binary_logloss: 0.136518\n",
            "[108]\ttraining's auc: 0.894549\ttraining's binary_logloss: 0.118493\tvalid_1's auc: 0.836375\tvalid_1's binary_logloss: 0.136517\n",
            "[109]\ttraining's auc: 0.894932\ttraining's binary_logloss: 0.118363\tvalid_1's auc: 0.836433\tvalid_1's binary_logloss: 0.136498\n",
            "[110]\ttraining's auc: 0.89509\ttraining's binary_logloss: 0.11826\tvalid_1's auc: 0.836574\tvalid_1's binary_logloss: 0.136476\n",
            "[111]\ttraining's auc: 0.895366\ttraining's binary_logloss: 0.118154\tvalid_1's auc: 0.836551\tvalid_1's binary_logloss: 0.136462\n",
            "[112]\ttraining's auc: 0.895597\ttraining's binary_logloss: 0.118049\tvalid_1's auc: 0.836641\tvalid_1's binary_logloss: 0.136433\n",
            "[113]\ttraining's auc: 0.895965\ttraining's binary_logloss: 0.117928\tvalid_1's auc: 0.836567\tvalid_1's binary_logloss: 0.13643\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "  2%|▏         | 1/50 [00:27<21:59, 26.92s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.152632\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.155643\n",
            "[2]\ttraining's auc: 0.835655\ttraining's binary_logloss: 0.146378\tvalid_1's auc: 0.810709\tvalid_1's binary_logloss: 0.150721\n",
            "[3]\ttraining's auc: 0.843487\ttraining's binary_logloss: 0.142105\tvalid_1's auc: 0.815487\tvalid_1's binary_logloss: 0.14759\n",
            "[4]\ttraining's auc: 0.848066\ttraining's binary_logloss: 0.138728\tvalid_1's auc: 0.817807\tvalid_1's binary_logloss: 0.14523\n",
            "[5]\ttraining's auc: 0.851086\ttraining's binary_logloss: 0.135942\tvalid_1's auc: 0.818983\tvalid_1's binary_logloss: 0.14344\n",
            "[6]\ttraining's auc: 0.853672\ttraining's binary_logloss: 0.133666\tvalid_1's auc: 0.820991\tvalid_1's binary_logloss: 0.141887\n",
            "[7]\ttraining's auc: 0.856665\ttraining's binary_logloss: 0.131688\tvalid_1's auc: 0.821538\tvalid_1's binary_logloss: 0.14078\n",
            "[8]\ttraining's auc: 0.861054\ttraining's binary_logloss: 0.130002\tvalid_1's auc: 0.822465\tvalid_1's binary_logloss: 0.139893\n",
            "[9]\ttraining's auc: 0.865236\ttraining's binary_logloss: 0.128561\tvalid_1's auc: 0.823489\tvalid_1's binary_logloss: 0.139252\n",
            "[10]\ttraining's auc: 0.868596\ttraining's binary_logloss: 0.127189\tvalid_1's auc: 0.823886\tvalid_1's binary_logloss: 0.138748\n",
            "[11]\ttraining's auc: 0.871095\ttraining's binary_logloss: 0.126066\tvalid_1's auc: 0.823768\tvalid_1's binary_logloss: 0.138403\n",
            "[12]\ttraining's auc: 0.873704\ttraining's binary_logloss: 0.124944\tvalid_1's auc: 0.823133\tvalid_1's binary_logloss: 0.138082\n",
            "[13]\ttraining's auc: 0.876828\ttraining's binary_logloss: 0.124004\tvalid_1's auc: 0.823979\tvalid_1's binary_logloss: 0.137767\n",
            "[14]\ttraining's auc: 0.878777\ttraining's binary_logloss: 0.123154\tvalid_1's auc: 0.825658\tvalid_1's binary_logloss: 0.137392\n",
            "[15]\ttraining's auc: 0.881164\ttraining's binary_logloss: 0.12224\tvalid_1's auc: 0.826537\tvalid_1's binary_logloss: 0.137177\n",
            "[16]\ttraining's auc: 0.885034\ttraining's binary_logloss: 0.121287\tvalid_1's auc: 0.825968\tvalid_1's binary_logloss: 0.137079\n",
            "[17]\ttraining's auc: 0.886263\ttraining's binary_logloss: 0.120608\tvalid_1's auc: 0.826837\tvalid_1's binary_logloss: 0.136877\n",
            "[18]\ttraining's auc: 0.887831\ttraining's binary_logloss: 0.119935\tvalid_1's auc: 0.826605\tvalid_1's binary_logloss: 0.136832\n",
            "[19]\ttraining's auc: 0.891153\ttraining's binary_logloss: 0.119154\tvalid_1's auc: 0.827504\tvalid_1's binary_logloss: 0.136626\n",
            "[20]\ttraining's auc: 0.892097\ttraining's binary_logloss: 0.118607\tvalid_1's auc: 0.827547\tvalid_1's binary_logloss: 0.136607\n",
            "[21]\ttraining's auc: 0.894666\ttraining's binary_logloss: 0.11786\tvalid_1's auc: 0.826439\tvalid_1's binary_logloss: 0.136749\n",
            "[22]\ttraining's auc: 0.896155\ttraining's binary_logloss: 0.117279\tvalid_1's auc: 0.827116\tvalid_1's binary_logloss: 0.136635\n",
            "[23]\ttraining's auc: 0.898394\ttraining's binary_logloss: 0.116592\tvalid_1's auc: 0.826904\tvalid_1's binary_logloss: 0.136615\n",
            "[24]\ttraining's auc: 0.899788\ttraining's binary_logloss: 0.115989\tvalid_1's auc: 0.827454\tvalid_1's binary_logloss: 0.136496\n",
            "[25]\ttraining's auc: 0.901352\ttraining's binary_logloss: 0.115464\tvalid_1's auc: 0.827986\tvalid_1's binary_logloss: 0.13642\n",
            "[26]\ttraining's auc: 0.902774\ttraining's binary_logloss: 0.114951\tvalid_1's auc: 0.828499\tvalid_1's binary_logloss: 0.13631\n",
            "[27]\ttraining's auc: 0.903814\ttraining's binary_logloss: 0.114413\tvalid_1's auc: 0.82899\tvalid_1's binary_logloss: 0.136239\n",
            "[28]\ttraining's auc: 0.905837\ttraining's binary_logloss: 0.113895\tvalid_1's auc: 0.828497\tvalid_1's binary_logloss: 0.136344\n",
            "[29]\ttraining's auc: 0.906601\ttraining's binary_logloss: 0.113453\tvalid_1's auc: 0.828437\tvalid_1's binary_logloss: 0.136368\n",
            "[30]\ttraining's auc: 0.907608\ttraining's binary_logloss: 0.113004\tvalid_1's auc: 0.828006\tvalid_1's binary_logloss: 0.136489\n",
            "[31]\ttraining's auc: 0.909004\ttraining's binary_logloss: 0.11253\tvalid_1's auc: 0.827605\tvalid_1's binary_logloss: 0.136609\n",
            "[32]\ttraining's auc: 0.910431\ttraining's binary_logloss: 0.11206\tvalid_1's auc: 0.827422\tvalid_1's binary_logloss: 0.136662\n",
            "[33]\ttraining's auc: 0.911504\ttraining's binary_logloss: 0.111629\tvalid_1's auc: 0.827239\tvalid_1's binary_logloss: 0.136685\n",
            "[34]\ttraining's auc: 0.912788\ttraining's binary_logloss: 0.11126\tvalid_1's auc: 0.827074\tvalid_1's binary_logloss: 0.136706\n",
            "[35]\ttraining's auc: 0.913737\ttraining's binary_logloss: 0.110862\tvalid_1's auc: 0.826807\tvalid_1's binary_logloss: 0.136781\n",
            "[36]\ttraining's auc: 0.914542\ttraining's binary_logloss: 0.110489\tvalid_1's auc: 0.82693\tvalid_1's binary_logloss: 0.136831\n",
            "[37]\ttraining's auc: 0.915175\ttraining's binary_logloss: 0.110225\tvalid_1's auc: 0.826729\tvalid_1's binary_logloss: 0.136865\n",
            "[38]\ttraining's auc: 0.916517\ttraining's binary_logloss: 0.109793\tvalid_1's auc: 0.826795\tvalid_1's binary_logloss: 0.136893\n",
            "[39]\ttraining's auc: 0.917285\ttraining's binary_logloss: 0.109404\tvalid_1's auc: 0.826521\tvalid_1's binary_logloss: 0.136968\n",
            "[40]\ttraining's auc: 0.91759\ttraining's binary_logloss: 0.109106\tvalid_1's auc: 0.8258\tvalid_1's binary_logloss: 0.137119\n",
            "[41]\ttraining's auc: 0.918172\ttraining's binary_logloss: 0.108773\tvalid_1's auc: 0.825392\tvalid_1's binary_logloss: 0.137218\n",
            "[42]\ttraining's auc: 0.918886\ttraining's binary_logloss: 0.108416\tvalid_1's auc: 0.825236\tvalid_1's binary_logloss: 0.137286\n",
            "[43]\ttraining's auc: 0.919591\ttraining's binary_logloss: 0.108045\tvalid_1's auc: 0.825052\tvalid_1's binary_logloss: 0.137324\n",
            "[44]\ttraining's auc: 0.920305\ttraining's binary_logloss: 0.107703\tvalid_1's auc: 0.824445\tvalid_1's binary_logloss: 0.137455\n",
            "[45]\ttraining's auc: 0.920771\ttraining's binary_logloss: 0.107432\tvalid_1's auc: 0.824075\tvalid_1's binary_logloss: 0.137541\n",
            "[46]\ttraining's auc: 0.922608\ttraining's binary_logloss: 0.106769\tvalid_1's auc: 0.823654\tvalid_1's binary_logloss: 0.137673\n",
            "[47]\ttraining's auc: 0.923667\ttraining's binary_logloss: 0.10636\tvalid_1's auc: 0.823895\tvalid_1's binary_logloss: 0.137668\n",
            "[48]\ttraining's auc: 0.924386\ttraining's binary_logloss: 0.10603\tvalid_1's auc: 0.823752\tvalid_1's binary_logloss: 0.137761\n",
            "[49]\ttraining's auc: 0.924735\ttraining's binary_logloss: 0.105766\tvalid_1's auc: 0.823796\tvalid_1's binary_logloss: 0.137826\n",
            "[50]\ttraining's auc: 0.925132\ttraining's binary_logloss: 0.105544\tvalid_1's auc: 0.823378\tvalid_1's binary_logloss: 0.13789\n",
            "[51]\ttraining's auc: 0.92545\ttraining's binary_logloss: 0.10532\tvalid_1's auc: 0.823107\tvalid_1's binary_logloss: 0.13798\n",
            "[52]\ttraining's auc: 0.925648\ttraining's binary_logloss: 0.105155\tvalid_1's auc: 0.822447\tvalid_1's binary_logloss: 0.13812\n",
            "[53]\ttraining's auc: 0.926542\ttraining's binary_logloss: 0.104742\tvalid_1's auc: 0.822347\tvalid_1's binary_logloss: 0.138159\n",
            "[54]\ttraining's auc: 0.927336\ttraining's binary_logloss: 0.104477\tvalid_1's auc: 0.822293\tvalid_1's binary_logloss: 0.138167\n",
            "[55]\ttraining's auc: 0.928415\ttraining's binary_logloss: 0.104139\tvalid_1's auc: 0.822065\tvalid_1's binary_logloss: 0.138224\n",
            "[56]\ttraining's auc: 0.929323\ttraining's binary_logloss: 0.103849\tvalid_1's auc: 0.822097\tvalid_1's binary_logloss: 0.138239\n",
            "[57]\ttraining's auc: 0.929893\ttraining's binary_logloss: 0.103565\tvalid_1's auc: 0.821787\tvalid_1's binary_logloss: 0.138305\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "  2%|▏         | 1/50 [00:30<21:59, 26.92s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.155074\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.151771\n",
            "[2]\ttraining's auc: 0.831744\ttraining's binary_logloss: 0.148708\tvalid_1's auc: 0.816738\tvalid_1's binary_logloss: 0.146873\n",
            "[3]\ttraining's auc: 0.840903\ttraining's binary_logloss: 0.144317\tvalid_1's auc: 0.821302\tvalid_1's binary_logloss: 0.143494\n",
            "[4]\ttraining's auc: 0.848686\ttraining's binary_logloss: 0.140966\tvalid_1's auc: 0.825786\tvalid_1's binary_logloss: 0.141184\n",
            "[5]\ttraining's auc: 0.853093\ttraining's binary_logloss: 0.138159\tvalid_1's auc: 0.827844\tvalid_1's binary_logloss: 0.139373\n",
            "[6]\ttraining's auc: 0.854863\ttraining's binary_logloss: 0.135853\tvalid_1's auc: 0.82877\tvalid_1's binary_logloss: 0.137919\n",
            "[7]\ttraining's auc: 0.859923\ttraining's binary_logloss: 0.134011\tvalid_1's auc: 0.829261\tvalid_1's binary_logloss: 0.136736\n",
            "[8]\ttraining's auc: 0.86384\ttraining's binary_logloss: 0.132327\tvalid_1's auc: 0.830807\tvalid_1's binary_logloss: 0.135863\n",
            "[9]\ttraining's auc: 0.868566\ttraining's binary_logloss: 0.13072\tvalid_1's auc: 0.831064\tvalid_1's binary_logloss: 0.13507\n",
            "[10]\ttraining's auc: 0.870781\ttraining's binary_logloss: 0.129347\tvalid_1's auc: 0.830776\tvalid_1's binary_logloss: 0.134571\n",
            "[11]\ttraining's auc: 0.872881\ttraining's binary_logloss: 0.128125\tvalid_1's auc: 0.830564\tvalid_1's binary_logloss: 0.134139\n",
            "[12]\ttraining's auc: 0.874513\ttraining's binary_logloss: 0.127093\tvalid_1's auc: 0.83136\tvalid_1's binary_logloss: 0.133622\n",
            "[13]\ttraining's auc: 0.876341\ttraining's binary_logloss: 0.12607\tvalid_1's auc: 0.831223\tvalid_1's binary_logloss: 0.133291\n",
            "[14]\ttraining's auc: 0.878574\ttraining's binary_logloss: 0.125186\tvalid_1's auc: 0.83166\tvalid_1's binary_logloss: 0.132982\n",
            "[15]\ttraining's auc: 0.880916\ttraining's binary_logloss: 0.124237\tvalid_1's auc: 0.831474\tvalid_1's binary_logloss: 0.132678\n",
            "[16]\ttraining's auc: 0.883339\ttraining's binary_logloss: 0.123363\tvalid_1's auc: 0.83145\tvalid_1's binary_logloss: 0.132509\n",
            "[17]\ttraining's auc: 0.884698\ttraining's binary_logloss: 0.122636\tvalid_1's auc: 0.832021\tvalid_1's binary_logloss: 0.132355\n",
            "[18]\ttraining's auc: 0.886017\ttraining's binary_logloss: 0.121906\tvalid_1's auc: 0.831877\tvalid_1's binary_logloss: 0.132278\n",
            "[19]\ttraining's auc: 0.887772\ttraining's binary_logloss: 0.121251\tvalid_1's auc: 0.832238\tvalid_1's binary_logloss: 0.132197\n",
            "[20]\ttraining's auc: 0.889657\ttraining's binary_logloss: 0.120622\tvalid_1's auc: 0.831772\tvalid_1's binary_logloss: 0.132143\n",
            "[21]\ttraining's auc: 0.891653\ttraining's binary_logloss: 0.120009\tvalid_1's auc: 0.831295\tvalid_1's binary_logloss: 0.132102\n",
            "[22]\ttraining's auc: 0.893238\ttraining's binary_logloss: 0.119385\tvalid_1's auc: 0.83119\tvalid_1's binary_logloss: 0.132061\n",
            "[23]\ttraining's auc: 0.895067\ttraining's binary_logloss: 0.118763\tvalid_1's auc: 0.832496\tvalid_1's binary_logloss: 0.131913\n",
            "[24]\ttraining's auc: 0.895958\ttraining's binary_logloss: 0.118255\tvalid_1's auc: 0.832749\tvalid_1's binary_logloss: 0.131895\n",
            "[25]\ttraining's auc: 0.89772\ttraining's binary_logloss: 0.117719\tvalid_1's auc: 0.832831\tvalid_1's binary_logloss: 0.131847\n",
            "[26]\ttraining's auc: 0.899262\ttraining's binary_logloss: 0.117214\tvalid_1's auc: 0.832553\tvalid_1's binary_logloss: 0.131864\n",
            "[27]\ttraining's auc: 0.900194\ttraining's binary_logloss: 0.116708\tvalid_1's auc: 0.832763\tvalid_1's binary_logloss: 0.131821\n",
            "[28]\ttraining's auc: 0.901701\ttraining's binary_logloss: 0.116124\tvalid_1's auc: 0.832665\tvalid_1's binary_logloss: 0.131881\n",
            "[29]\ttraining's auc: 0.902613\ttraining's binary_logloss: 0.115624\tvalid_1's auc: 0.832878\tvalid_1's binary_logloss: 0.131901\n",
            "[30]\ttraining's auc: 0.904474\ttraining's binary_logloss: 0.114959\tvalid_1's auc: 0.832592\tvalid_1's binary_logloss: 0.131916\n",
            "[31]\ttraining's auc: 0.905599\ttraining's binary_logloss: 0.114547\tvalid_1's auc: 0.832336\tvalid_1's binary_logloss: 0.131943\n",
            "[32]\ttraining's auc: 0.906462\ttraining's binary_logloss: 0.114107\tvalid_1's auc: 0.83237\tvalid_1's binary_logloss: 0.131947\n",
            "[33]\ttraining's auc: 0.907031\ttraining's binary_logloss: 0.113746\tvalid_1's auc: 0.832717\tvalid_1's binary_logloss: 0.131901\n",
            "[34]\ttraining's auc: 0.907491\ttraining's binary_logloss: 0.113436\tvalid_1's auc: 0.83292\tvalid_1's binary_logloss: 0.131872\n",
            "[35]\ttraining's auc: 0.908753\ttraining's binary_logloss: 0.112947\tvalid_1's auc: 0.833256\tvalid_1's binary_logloss: 0.131801\n",
            "[36]\ttraining's auc: 0.909517\ttraining's binary_logloss: 0.112635\tvalid_1's auc: 0.833504\tvalid_1's binary_logloss: 0.131775\n",
            "[37]\ttraining's auc: 0.910824\ttraining's binary_logloss: 0.112149\tvalid_1's auc: 0.833913\tvalid_1's binary_logloss: 0.131676\n",
            "[38]\ttraining's auc: 0.91228\ttraining's binary_logloss: 0.111621\tvalid_1's auc: 0.834221\tvalid_1's binary_logloss: 0.131621\n",
            "[39]\ttraining's auc: 0.913034\ttraining's binary_logloss: 0.111236\tvalid_1's auc: 0.834621\tvalid_1's binary_logloss: 0.131567\n",
            "[40]\ttraining's auc: 0.913868\ttraining's binary_logloss: 0.110844\tvalid_1's auc: 0.834749\tvalid_1's binary_logloss: 0.13159\n",
            "[41]\ttraining's auc: 0.914772\ttraining's binary_logloss: 0.110382\tvalid_1's auc: 0.834467\tvalid_1's binary_logloss: 0.131656\n",
            "[42]\ttraining's auc: 0.915569\ttraining's binary_logloss: 0.110004\tvalid_1's auc: 0.834499\tvalid_1's binary_logloss: 0.13159\n",
            "[43]\ttraining's auc: 0.915995\ttraining's binary_logloss: 0.109748\tvalid_1's auc: 0.83452\tvalid_1's binary_logloss: 0.131624\n",
            "[44]\ttraining's auc: 0.916855\ttraining's binary_logloss: 0.109457\tvalid_1's auc: 0.83408\tvalid_1's binary_logloss: 0.131694\n",
            "[45]\ttraining's auc: 0.917173\ttraining's binary_logloss: 0.109225\tvalid_1's auc: 0.833868\tvalid_1's binary_logloss: 0.131727\n",
            "[46]\ttraining's auc: 0.918391\ttraining's binary_logloss: 0.108788\tvalid_1's auc: 0.833936\tvalid_1's binary_logloss: 0.131722\n",
            "[47]\ttraining's auc: 0.91907\ttraining's binary_logloss: 0.108428\tvalid_1's auc: 0.833666\tvalid_1's binary_logloss: 0.131792\n",
            "[48]\ttraining's auc: 0.91957\ttraining's binary_logloss: 0.108155\tvalid_1's auc: 0.833786\tvalid_1's binary_logloss: 0.131781\n",
            "[49]\ttraining's auc: 0.920142\ttraining's binary_logloss: 0.107856\tvalid_1's auc: 0.83355\tvalid_1's binary_logloss: 0.131792\n",
            "[50]\ttraining's auc: 0.920502\ttraining's binary_logloss: 0.10764\tvalid_1's auc: 0.833417\tvalid_1's binary_logloss: 0.131825\n",
            "[51]\ttraining's auc: 0.921256\ttraining's binary_logloss: 0.10733\tvalid_1's auc: 0.833111\tvalid_1's binary_logloss: 0.131865\n",
            "[52]\ttraining's auc: 0.922072\ttraining's binary_logloss: 0.10706\tvalid_1's auc: 0.833084\tvalid_1's binary_logloss: 0.131915\n",
            "[53]\ttraining's auc: 0.922396\ttraining's binary_logloss: 0.106833\tvalid_1's auc: 0.832862\tvalid_1's binary_logloss: 0.13196\n",
            "[54]\ttraining's auc: 0.922649\ttraining's binary_logloss: 0.106604\tvalid_1's auc: 0.832934\tvalid_1's binary_logloss: 0.131923\n",
            "[55]\ttraining's auc: 0.92317\ttraining's binary_logloss: 0.106344\tvalid_1's auc: 0.832533\tvalid_1's binary_logloss: 0.132021\n",
            "[56]\ttraining's auc: 0.923786\ttraining's binary_logloss: 0.106054\tvalid_1's auc: 0.83244\tvalid_1's binary_logloss: 0.132054\n",
            "[57]\ttraining's auc: 0.924695\ttraining's binary_logloss: 0.10562\tvalid_1's auc: 0.832354\tvalid_1's binary_logloss: 0.132062\n",
            "[58]\ttraining's auc: 0.926351\ttraining's binary_logloss: 0.105144\tvalid_1's auc: 0.832167\tvalid_1's binary_logloss: 0.132156\n",
            "[59]\ttraining's auc: 0.927109\ttraining's binary_logloss: 0.104882\tvalid_1's auc: 0.831738\tvalid_1's binary_logloss: 0.132209\n",
            "[60]\ttraining's auc: 0.927562\ttraining's binary_logloss: 0.104664\tvalid_1's auc: 0.831455\tvalid_1's binary_logloss: 0.132259\n",
            "[61]\ttraining's auc: 0.929158\ttraining's binary_logloss: 0.104105\tvalid_1's auc: 0.831009\tvalid_1's binary_logloss: 0.132414\n",
            "[62]\ttraining's auc: 0.929585\ttraining's binary_logloss: 0.103833\tvalid_1's auc: 0.830741\tvalid_1's binary_logloss: 0.132506\n",
            "[63]\ttraining's auc: 0.929916\ttraining's binary_logloss: 0.103589\tvalid_1's auc: 0.830761\tvalid_1's binary_logloss: 0.132498\n",
            "[64]\ttraining's auc: 0.930215\ttraining's binary_logloss: 0.103372\tvalid_1's auc: 0.830684\tvalid_1's binary_logloss: 0.132534\n",
            "[65]\ttraining's auc: 0.930739\ttraining's binary_logloss: 0.103083\tvalid_1's auc: 0.83083\tvalid_1's binary_logloss: 0.132495\n",
            "[66]\ttraining's auc: 0.931334\ttraining's binary_logloss: 0.102764\tvalid_1's auc: 0.831017\tvalid_1's binary_logloss: 0.132485\n",
            "[67]\ttraining's auc: 0.931577\ttraining's binary_logloss: 0.102564\tvalid_1's auc: 0.830493\tvalid_1's binary_logloss: 0.13259\n",
            "[68]\ttraining's auc: 0.931899\ttraining's binary_logloss: 0.102321\tvalid_1's auc: 0.830268\tvalid_1's binary_logloss: 0.132649\n",
            "[69]\ttraining's auc: 0.932058\ttraining's binary_logloss: 0.102153\tvalid_1's auc: 0.830457\tvalid_1's binary_logloss: 0.132622\n",
            "  2%|▏         | 1/50 [00:34<21:59, 26.92s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.15192\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.158508\n",
            "[2]\ttraining's auc: 0.834616\ttraining's binary_logloss: 0.145893\tvalid_1's auc: 0.817234\tvalid_1's binary_logloss: 0.153133\n",
            "[3]\ttraining's auc: 0.842027\ttraining's binary_logloss: 0.141587\tvalid_1's auc: 0.821318\tvalid_1's binary_logloss: 0.14958\n",
            "[4]\ttraining's auc: 0.847326\ttraining's binary_logloss: 0.13807\tvalid_1's auc: 0.82381\tvalid_1's binary_logloss: 0.147014\n",
            "[5]\ttraining's auc: 0.851652\ttraining's binary_logloss: 0.135356\tvalid_1's auc: 0.826052\tvalid_1's binary_logloss: 0.145076\n",
            "[6]\ttraining's auc: 0.854525\ttraining's binary_logloss: 0.133106\tvalid_1's auc: 0.827495\tvalid_1's binary_logloss: 0.14344\n",
            "[7]\ttraining's auc: 0.859561\ttraining's binary_logloss: 0.131213\tvalid_1's auc: 0.827983\tvalid_1's binary_logloss: 0.142234\n",
            "[8]\ttraining's auc: 0.862367\ttraining's binary_logloss: 0.129664\tvalid_1's auc: 0.828946\tvalid_1's binary_logloss: 0.141178\n",
            "[9]\ttraining's auc: 0.867756\ttraining's binary_logloss: 0.128148\tvalid_1's auc: 0.82999\tvalid_1's binary_logloss: 0.140304\n",
            "[10]\ttraining's auc: 0.870766\ttraining's binary_logloss: 0.126892\tvalid_1's auc: 0.833342\tvalid_1's binary_logloss: 0.139594\n",
            "[11]\ttraining's auc: 0.873453\ttraining's binary_logloss: 0.125641\tvalid_1's auc: 0.834918\tvalid_1's binary_logloss: 0.138931\n",
            "[12]\ttraining's auc: 0.876418\ttraining's binary_logloss: 0.124456\tvalid_1's auc: 0.833896\tvalid_1's binary_logloss: 0.138629\n",
            "[13]\ttraining's auc: 0.879681\ttraining's binary_logloss: 0.123277\tvalid_1's auc: 0.832893\tvalid_1's binary_logloss: 0.138511\n",
            "[14]\ttraining's auc: 0.881817\ttraining's binary_logloss: 0.122435\tvalid_1's auc: 0.832931\tvalid_1's binary_logloss: 0.138285\n",
            "[15]\ttraining's auc: 0.884\ttraining's binary_logloss: 0.12163\tvalid_1's auc: 0.833307\tvalid_1's binary_logloss: 0.138009\n",
            "[16]\ttraining's auc: 0.885276\ttraining's binary_logloss: 0.120848\tvalid_1's auc: 0.834043\tvalid_1's binary_logloss: 0.137787\n",
            "[17]\ttraining's auc: 0.88683\ttraining's binary_logloss: 0.120183\tvalid_1's auc: 0.834055\tvalid_1's binary_logloss: 0.137656\n",
            "[18]\ttraining's auc: 0.888989\ttraining's binary_logloss: 0.119422\tvalid_1's auc: 0.833954\tvalid_1's binary_logloss: 0.137576\n",
            "[19]\ttraining's auc: 0.891577\ttraining's binary_logloss: 0.118675\tvalid_1's auc: 0.833497\tvalid_1's binary_logloss: 0.137577\n",
            "[20]\ttraining's auc: 0.893167\ttraining's binary_logloss: 0.11799\tvalid_1's auc: 0.834048\tvalid_1's binary_logloss: 0.137379\n",
            "[21]\ttraining's auc: 0.894323\ttraining's binary_logloss: 0.11741\tvalid_1's auc: 0.834233\tvalid_1's binary_logloss: 0.137287\n",
            "[22]\ttraining's auc: 0.895363\ttraining's binary_logloss: 0.11683\tvalid_1's auc: 0.834323\tvalid_1's binary_logloss: 0.137162\n",
            "[23]\ttraining's auc: 0.896384\ttraining's binary_logloss: 0.116376\tvalid_1's auc: 0.834236\tvalid_1's binary_logloss: 0.13714\n",
            "[24]\ttraining's auc: 0.897399\ttraining's binary_logloss: 0.11581\tvalid_1's auc: 0.834345\tvalid_1's binary_logloss: 0.137054\n",
            "[25]\ttraining's auc: 0.898111\ttraining's binary_logloss: 0.115354\tvalid_1's auc: 0.834411\tvalid_1's binary_logloss: 0.13702\n",
            "[26]\ttraining's auc: 0.899927\ttraining's binary_logloss: 0.114818\tvalid_1's auc: 0.833544\tvalid_1's binary_logloss: 0.137112\n",
            "[27]\ttraining's auc: 0.901343\ttraining's binary_logloss: 0.114205\tvalid_1's auc: 0.833313\tvalid_1's binary_logloss: 0.137173\n",
            "[28]\ttraining's auc: 0.903702\ttraining's binary_logloss: 0.11357\tvalid_1's auc: 0.833374\tvalid_1's binary_logloss: 0.137153\n",
            "[29]\ttraining's auc: 0.905116\ttraining's binary_logloss: 0.113086\tvalid_1's auc: 0.833078\tvalid_1's binary_logloss: 0.137208\n",
            "[30]\ttraining's auc: 0.906776\ttraining's binary_logloss: 0.112539\tvalid_1's auc: 0.833267\tvalid_1's binary_logloss: 0.137219\n",
            "[31]\ttraining's auc: 0.907819\ttraining's binary_logloss: 0.112184\tvalid_1's auc: 0.833803\tvalid_1's binary_logloss: 0.137131\n",
            "[32]\ttraining's auc: 0.909268\ttraining's binary_logloss: 0.111649\tvalid_1's auc: 0.833726\tvalid_1's binary_logloss: 0.137146\n",
            "[33]\ttraining's auc: 0.910453\ttraining's binary_logloss: 0.111169\tvalid_1's auc: 0.833732\tvalid_1's binary_logloss: 0.137143\n",
            "[34]\ttraining's auc: 0.911234\ttraining's binary_logloss: 0.110819\tvalid_1's auc: 0.833727\tvalid_1's binary_logloss: 0.137153\n",
            "[35]\ttraining's auc: 0.91187\ttraining's binary_logloss: 0.11048\tvalid_1's auc: 0.833706\tvalid_1's binary_logloss: 0.137165\n",
            "[36]\ttraining's auc: 0.912549\ttraining's binary_logloss: 0.110118\tvalid_1's auc: 0.833491\tvalid_1's binary_logloss: 0.137176\n",
            "[37]\ttraining's auc: 0.913189\ttraining's binary_logloss: 0.109767\tvalid_1's auc: 0.833635\tvalid_1's binary_logloss: 0.137183\n",
            "[38]\ttraining's auc: 0.914596\ttraining's binary_logloss: 0.109229\tvalid_1's auc: 0.833523\tvalid_1's binary_logloss: 0.137217\n",
            "[39]\ttraining's auc: 0.915801\ttraining's binary_logloss: 0.108735\tvalid_1's auc: 0.833764\tvalid_1's binary_logloss: 0.137204\n",
            "[40]\ttraining's auc: 0.916941\ttraining's binary_logloss: 0.108262\tvalid_1's auc: 0.833729\tvalid_1's binary_logloss: 0.137208\n",
            "[41]\ttraining's auc: 0.918133\ttraining's binary_logloss: 0.10794\tvalid_1's auc: 0.834374\tvalid_1's binary_logloss: 0.137112\n",
            "  4%|▍         | 2/50 [00:44<16:59, 21.24s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.158481\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.160385\n",
            "[2]\ttraining's auc: 0.832841\ttraining's binary_logloss: 0.154109\tvalid_1's auc: 0.806025\tvalid_1's binary_logloss: 0.156946\n",
            "[3]\ttraining's auc: 0.83452\ttraining's binary_logloss: 0.150687\tvalid_1's auc: 0.806743\tvalid_1's binary_logloss: 0.154386\n",
            "[4]\ttraining's auc: 0.84218\ttraining's binary_logloss: 0.147864\tvalid_1's auc: 0.813882\tvalid_1's binary_logloss: 0.152155\n",
            "[5]\ttraining's auc: 0.846269\ttraining's binary_logloss: 0.145434\tvalid_1's auc: 0.815739\tvalid_1's binary_logloss: 0.150376\n",
            "[6]\ttraining's auc: 0.848139\ttraining's binary_logloss: 0.143361\tvalid_1's auc: 0.81484\tvalid_1's binary_logloss: 0.148883\n",
            "[7]\ttraining's auc: 0.850617\ttraining's binary_logloss: 0.141451\tvalid_1's auc: 0.817476\tvalid_1's binary_logloss: 0.147474\n",
            "[8]\ttraining's auc: 0.852441\ttraining's binary_logloss: 0.139786\tvalid_1's auc: 0.819033\tvalid_1's binary_logloss: 0.146258\n",
            "[9]\ttraining's auc: 0.853282\ttraining's binary_logloss: 0.138325\tvalid_1's auc: 0.819664\tvalid_1's binary_logloss: 0.145234\n",
            "[10]\ttraining's auc: 0.854425\ttraining's binary_logloss: 0.136965\tvalid_1's auc: 0.820409\tvalid_1's binary_logloss: 0.144295\n",
            "[11]\ttraining's auc: 0.855366\ttraining's binary_logloss: 0.135716\tvalid_1's auc: 0.820805\tvalid_1's binary_logloss: 0.143492\n",
            "[12]\ttraining's auc: 0.85752\ttraining's binary_logloss: 0.134608\tvalid_1's auc: 0.821511\tvalid_1's binary_logloss: 0.142731\n",
            "[13]\ttraining's auc: 0.858324\ttraining's binary_logloss: 0.133638\tvalid_1's auc: 0.821789\tvalid_1's binary_logloss: 0.142013\n",
            "[14]\ttraining's auc: 0.860935\ttraining's binary_logloss: 0.132578\tvalid_1's auc: 0.821873\tvalid_1's binary_logloss: 0.141456\n",
            "[15]\ttraining's auc: 0.863041\ttraining's binary_logloss: 0.131658\tvalid_1's auc: 0.823468\tvalid_1's binary_logloss: 0.140944\n",
            "[16]\ttraining's auc: 0.864583\ttraining's binary_logloss: 0.130766\tvalid_1's auc: 0.823902\tvalid_1's binary_logloss: 0.140441\n",
            "[17]\ttraining's auc: 0.86751\ttraining's binary_logloss: 0.129965\tvalid_1's auc: 0.824809\tvalid_1's binary_logloss: 0.140072\n",
            "[18]\ttraining's auc: 0.868881\ttraining's binary_logloss: 0.129222\tvalid_1's auc: 0.825018\tvalid_1's binary_logloss: 0.13974\n",
            "[19]\ttraining's auc: 0.869832\ttraining's binary_logloss: 0.128592\tvalid_1's auc: 0.825234\tvalid_1's binary_logloss: 0.139443\n",
            "[20]\ttraining's auc: 0.87134\ttraining's binary_logloss: 0.127929\tvalid_1's auc: 0.825535\tvalid_1's binary_logloss: 0.1391\n",
            "[21]\ttraining's auc: 0.871988\ttraining's binary_logloss: 0.127373\tvalid_1's auc: 0.825683\tvalid_1's binary_logloss: 0.13881\n",
            "[22]\ttraining's auc: 0.873444\ttraining's binary_logloss: 0.126805\tvalid_1's auc: 0.825442\tvalid_1's binary_logloss: 0.138612\n",
            "[23]\ttraining's auc: 0.874607\ttraining's binary_logloss: 0.126233\tvalid_1's auc: 0.825396\tvalid_1's binary_logloss: 0.13843\n",
            "[24]\ttraining's auc: 0.875579\ttraining's binary_logloss: 0.125687\tvalid_1's auc: 0.825717\tvalid_1's binary_logloss: 0.138191\n",
            "[25]\ttraining's auc: 0.878088\ttraining's binary_logloss: 0.125134\tvalid_1's auc: 0.826128\tvalid_1's binary_logloss: 0.137998\n",
            "[26]\ttraining's auc: 0.87894\ttraining's binary_logloss: 0.124606\tvalid_1's auc: 0.826478\tvalid_1's binary_logloss: 0.137817\n",
            "[27]\ttraining's auc: 0.879728\ttraining's binary_logloss: 0.124146\tvalid_1's auc: 0.826385\tvalid_1's binary_logloss: 0.137709\n",
            "[28]\ttraining's auc: 0.88095\ttraining's binary_logloss: 0.123631\tvalid_1's auc: 0.826937\tvalid_1's binary_logloss: 0.137551\n",
            "[29]\ttraining's auc: 0.881909\ttraining's binary_logloss: 0.123196\tvalid_1's auc: 0.8274\tvalid_1's binary_logloss: 0.137372\n",
            "[30]\ttraining's auc: 0.882344\ttraining's binary_logloss: 0.122809\tvalid_1's auc: 0.827944\tvalid_1's binary_logloss: 0.137211\n",
            "[31]\ttraining's auc: 0.883768\ttraining's binary_logloss: 0.122388\tvalid_1's auc: 0.827886\tvalid_1's binary_logloss: 0.13711\n",
            "[32]\ttraining's auc: 0.885325\ttraining's binary_logloss: 0.121894\tvalid_1's auc: 0.827835\tvalid_1's binary_logloss: 0.137051\n",
            "[33]\ttraining's auc: 0.886278\ttraining's binary_logloss: 0.121487\tvalid_1's auc: 0.827852\tvalid_1's binary_logloss: 0.136994\n",
            "[34]\ttraining's auc: 0.887106\ttraining's binary_logloss: 0.121122\tvalid_1's auc: 0.827714\tvalid_1's binary_logloss: 0.136954\n",
            "[35]\ttraining's auc: 0.888662\ttraining's binary_logloss: 0.120716\tvalid_1's auc: 0.828537\tvalid_1's binary_logloss: 0.136804\n",
            "[36]\ttraining's auc: 0.889517\ttraining's binary_logloss: 0.120376\tvalid_1's auc: 0.828577\tvalid_1's binary_logloss: 0.136777\n",
            "[37]\ttraining's auc: 0.890601\ttraining's binary_logloss: 0.120012\tvalid_1's auc: 0.828331\tvalid_1's binary_logloss: 0.136751\n",
            "[38]\ttraining's auc: 0.892084\ttraining's binary_logloss: 0.119599\tvalid_1's auc: 0.829071\tvalid_1's binary_logloss: 0.136575\n",
            "[39]\ttraining's auc: 0.892762\ttraining's binary_logloss: 0.119296\tvalid_1's auc: 0.828956\tvalid_1's binary_logloss: 0.136552\n",
            "[40]\ttraining's auc: 0.893332\ttraining's binary_logloss: 0.119011\tvalid_1's auc: 0.828893\tvalid_1's binary_logloss: 0.136514\n",
            "[41]\ttraining's auc: 0.894109\ttraining's binary_logloss: 0.118702\tvalid_1's auc: 0.829135\tvalid_1's binary_logloss: 0.136455\n",
            "[42]\ttraining's auc: 0.894707\ttraining's binary_logloss: 0.118414\tvalid_1's auc: 0.828815\tvalid_1's binary_logloss: 0.136487\n",
            "[43]\ttraining's auc: 0.895304\ttraining's binary_logloss: 0.118104\tvalid_1's auc: 0.828589\tvalid_1's binary_logloss: 0.136478\n",
            "[44]\ttraining's auc: 0.895935\ttraining's binary_logloss: 0.117805\tvalid_1's auc: 0.828864\tvalid_1's binary_logloss: 0.136408\n",
            "[45]\ttraining's auc: 0.896637\ttraining's binary_logloss: 0.11753\tvalid_1's auc: 0.828827\tvalid_1's binary_logloss: 0.136385\n",
            "[46]\ttraining's auc: 0.897705\ttraining's binary_logloss: 0.117229\tvalid_1's auc: 0.828792\tvalid_1's binary_logloss: 0.136391\n",
            "[47]\ttraining's auc: 0.89866\ttraining's binary_logloss: 0.11692\tvalid_1's auc: 0.829133\tvalid_1's binary_logloss: 0.136354\n",
            "[48]\ttraining's auc: 0.899549\ttraining's binary_logloss: 0.116641\tvalid_1's auc: 0.829025\tvalid_1's binary_logloss: 0.136386\n",
            "[49]\ttraining's auc: 0.900291\ttraining's binary_logloss: 0.116362\tvalid_1's auc: 0.829002\tvalid_1's binary_logloss: 0.136375\n",
            "[50]\ttraining's auc: 0.900717\ttraining's binary_logloss: 0.116125\tvalid_1's auc: 0.829127\tvalid_1's binary_logloss: 0.136371\n",
            "[51]\ttraining's auc: 0.901103\ttraining's binary_logloss: 0.115902\tvalid_1's auc: 0.829033\tvalid_1's binary_logloss: 0.136381\n",
            "[52]\ttraining's auc: 0.901682\ttraining's binary_logloss: 0.115664\tvalid_1's auc: 0.828686\tvalid_1's binary_logloss: 0.136432\n",
            "[53]\ttraining's auc: 0.902869\ttraining's binary_logloss: 0.115376\tvalid_1's auc: 0.829263\tvalid_1's binary_logloss: 0.136339\n",
            "[54]\ttraining's auc: 0.903343\ttraining's binary_logloss: 0.115106\tvalid_1's auc: 0.828994\tvalid_1's binary_logloss: 0.136367\n",
            "[55]\ttraining's auc: 0.903757\ttraining's binary_logloss: 0.114874\tvalid_1's auc: 0.829243\tvalid_1's binary_logloss: 0.136345\n",
            "[56]\ttraining's auc: 0.904523\ttraining's binary_logloss: 0.114659\tvalid_1's auc: 0.829142\tvalid_1's binary_logloss: 0.136359\n",
            "[57]\ttraining's auc: 0.904962\ttraining's binary_logloss: 0.114401\tvalid_1's auc: 0.829092\tvalid_1's binary_logloss: 0.136372\n",
            "[58]\ttraining's auc: 0.905373\ttraining's binary_logloss: 0.114189\tvalid_1's auc: 0.828884\tvalid_1's binary_logloss: 0.136417\n",
            "[59]\ttraining's auc: 0.905952\ttraining's binary_logloss: 0.113962\tvalid_1's auc: 0.829013\tvalid_1's binary_logloss: 0.136385\n",
            "[60]\ttraining's auc: 0.906418\ttraining's binary_logloss: 0.113722\tvalid_1's auc: 0.82927\tvalid_1's binary_logloss: 0.13635\n",
            "[61]\ttraining's auc: 0.906888\ttraining's binary_logloss: 0.113497\tvalid_1's auc: 0.829198\tvalid_1's binary_logloss: 0.136362\n",
            "[62]\ttraining's auc: 0.907464\ttraining's binary_logloss: 0.113231\tvalid_1's auc: 0.82929\tvalid_1's binary_logloss: 0.136325\n",
            "[63]\ttraining's auc: 0.908182\ttraining's binary_logloss: 0.11298\tvalid_1's auc: 0.829123\tvalid_1's binary_logloss: 0.136374\n",
            "[64]\ttraining's auc: 0.908665\ttraining's binary_logloss: 0.112765\tvalid_1's auc: 0.828971\tvalid_1's binary_logloss: 0.136378\n",
            "[65]\ttraining's auc: 0.909363\ttraining's binary_logloss: 0.112586\tvalid_1's auc: 0.828906\tvalid_1's binary_logloss: 0.136395\n",
            "[66]\ttraining's auc: 0.909862\ttraining's binary_logloss: 0.112413\tvalid_1's auc: 0.828649\tvalid_1's binary_logloss: 0.136426\n",
            "[67]\ttraining's auc: 0.911056\ttraining's binary_logloss: 0.112198\tvalid_1's auc: 0.828552\tvalid_1's binary_logloss: 0.136431\n",
            "[68]\ttraining's auc: 0.911474\ttraining's binary_logloss: 0.111975\tvalid_1's auc: 0.828458\tvalid_1's binary_logloss: 0.136457\n",
            "[69]\ttraining's auc: 0.911963\ttraining's binary_logloss: 0.111769\tvalid_1's auc: 0.828207\tvalid_1's binary_logloss: 0.136516\n",
            "[70]\ttraining's auc: 0.912396\ttraining's binary_logloss: 0.111576\tvalid_1's auc: 0.828047\tvalid_1's binary_logloss: 0.136537\n",
            "[71]\ttraining's auc: 0.912894\ttraining's binary_logloss: 0.111351\tvalid_1's auc: 0.827867\tvalid_1's binary_logloss: 0.13657\n",
            "[72]\ttraining's auc: 0.913392\ttraining's binary_logloss: 0.111124\tvalid_1's auc: 0.827689\tvalid_1's binary_logloss: 0.136615\n",
            "[73]\ttraining's auc: 0.913667\ttraining's binary_logloss: 0.110979\tvalid_1's auc: 0.827612\tvalid_1's binary_logloss: 0.136621\n",
            "[74]\ttraining's auc: 0.914176\ttraining's binary_logloss: 0.110745\tvalid_1's auc: 0.827473\tvalid_1's binary_logloss: 0.136666\n",
            "[75]\ttraining's auc: 0.914528\ttraining's binary_logloss: 0.110543\tvalid_1's auc: 0.82746\tvalid_1's binary_logloss: 0.13668\n",
            "[76]\ttraining's auc: 0.914907\ttraining's binary_logloss: 0.110345\tvalid_1's auc: 0.827697\tvalid_1's binary_logloss: 0.136646\n",
            "[77]\ttraining's auc: 0.915588\ttraining's binary_logloss: 0.110156\tvalid_1's auc: 0.827767\tvalid_1's binary_logloss: 0.13665\n",
            "[78]\ttraining's auc: 0.915777\ttraining's binary_logloss: 0.110023\tvalid_1's auc: 0.827757\tvalid_1's binary_logloss: 0.136647\n",
            "[79]\ttraining's auc: 0.916079\ttraining's binary_logloss: 0.109851\tvalid_1's auc: 0.82743\tvalid_1's binary_logloss: 0.1367\n",
            "[80]\ttraining's auc: 0.916282\ttraining's binary_logloss: 0.109729\tvalid_1's auc: 0.82734\tvalid_1's binary_logloss: 0.13673\n",
            "[81]\ttraining's auc: 0.916736\ttraining's binary_logloss: 0.109569\tvalid_1's auc: 0.827333\tvalid_1's binary_logloss: 0.136752\n",
            "[82]\ttraining's auc: 0.917052\ttraining's binary_logloss: 0.109418\tvalid_1's auc: 0.827017\tvalid_1's binary_logloss: 0.136804\n",
            "[83]\ttraining's auc: 0.917444\ttraining's binary_logloss: 0.109246\tvalid_1's auc: 0.826965\tvalid_1's binary_logloss: 0.136818\n",
            "[84]\ttraining's auc: 0.917618\ttraining's binary_logloss: 0.109127\tvalid_1's auc: 0.826655\tvalid_1's binary_logloss: 0.136883\n",
            "[85]\ttraining's auc: 0.917888\ttraining's binary_logloss: 0.108989\tvalid_1's auc: 0.826429\tvalid_1's binary_logloss: 0.136942\n",
            "[86]\ttraining's auc: 0.91835\ttraining's binary_logloss: 0.108786\tvalid_1's auc: 0.826151\tvalid_1's binary_logloss: 0.136997\n",
            "[87]\ttraining's auc: 0.919027\ttraining's binary_logloss: 0.10855\tvalid_1's auc: 0.826234\tvalid_1's binary_logloss: 0.136975\n",
            "[88]\ttraining's auc: 0.919275\ttraining's binary_logloss: 0.108425\tvalid_1's auc: 0.826329\tvalid_1's binary_logloss: 0.136976\n",
            "[89]\ttraining's auc: 0.919666\ttraining's binary_logloss: 0.108229\tvalid_1's auc: 0.82629\tvalid_1's binary_logloss: 0.136976\n",
            "[90]\ttraining's auc: 0.919851\ttraining's binary_logloss: 0.108106\tvalid_1's auc: 0.826115\tvalid_1's binary_logloss: 0.137026\n",
            "[91]\ttraining's auc: 0.920024\ttraining's binary_logloss: 0.108001\tvalid_1's auc: 0.826083\tvalid_1's binary_logloss: 0.137035\n",
            "[92]\ttraining's auc: 0.920324\ttraining's binary_logloss: 0.107859\tvalid_1's auc: 0.826095\tvalid_1's binary_logloss: 0.137054\n",
            "  4%|▍         | 2/50 [00:49<16:59, 21.24s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.160883\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156084\n",
            "[2]\ttraining's auc: 0.82636\ttraining's binary_logloss: 0.156451\tvalid_1's auc: 0.816021\tvalid_1's binary_logloss: 0.152656\n",
            "[3]\ttraining's auc: 0.832599\ttraining's binary_logloss: 0.152875\tvalid_1's auc: 0.817747\tvalid_1's binary_logloss: 0.149917\n",
            "[4]\ttraining's auc: 0.834846\ttraining's binary_logloss: 0.150018\tvalid_1's auc: 0.819921\tvalid_1's binary_logloss: 0.147631\n",
            "[5]\ttraining's auc: 0.84034\ttraining's binary_logloss: 0.147577\tvalid_1's auc: 0.823207\tvalid_1's binary_logloss: 0.145793\n",
            "[6]\ttraining's auc: 0.845638\ttraining's binary_logloss: 0.145482\tvalid_1's auc: 0.826213\tvalid_1's binary_logloss: 0.144183\n",
            "[7]\ttraining's auc: 0.850039\ttraining's binary_logloss: 0.143554\tvalid_1's auc: 0.827939\tvalid_1's binary_logloss: 0.142789\n",
            "[8]\ttraining's auc: 0.851849\ttraining's binary_logloss: 0.141916\tvalid_1's auc: 0.828996\tvalid_1's binary_logloss: 0.141535\n",
            "[9]\ttraining's auc: 0.853382\ttraining's binary_logloss: 0.140447\tvalid_1's auc: 0.829796\tvalid_1's binary_logloss: 0.140503\n",
            "[10]\ttraining's auc: 0.855417\ttraining's binary_logloss: 0.139095\tvalid_1's auc: 0.832833\tvalid_1's binary_logloss: 0.139467\n",
            "[11]\ttraining's auc: 0.857579\ttraining's binary_logloss: 0.137853\tvalid_1's auc: 0.833768\tvalid_1's binary_logloss: 0.138597\n",
            "[12]\ttraining's auc: 0.858811\ttraining's binary_logloss: 0.136718\tvalid_1's auc: 0.833326\tvalid_1's binary_logloss: 0.137848\n",
            "[13]\ttraining's auc: 0.860032\ttraining's binary_logloss: 0.135712\tvalid_1's auc: 0.833335\tvalid_1's binary_logloss: 0.13714\n",
            "[14]\ttraining's auc: 0.862098\ttraining's binary_logloss: 0.1348\tvalid_1's auc: 0.834391\tvalid_1's binary_logloss: 0.136532\n",
            "[15]\ttraining's auc: 0.863141\ttraining's binary_logloss: 0.13384\tvalid_1's auc: 0.834512\tvalid_1's binary_logloss: 0.135964\n",
            "[16]\ttraining's auc: 0.865737\ttraining's binary_logloss: 0.132976\tvalid_1's auc: 0.834841\tvalid_1's binary_logloss: 0.13551\n",
            "[17]\ttraining's auc: 0.868278\ttraining's binary_logloss: 0.132174\tvalid_1's auc: 0.83505\tvalid_1's binary_logloss: 0.135099\n",
            "[18]\ttraining's auc: 0.869509\ttraining's binary_logloss: 0.131399\tvalid_1's auc: 0.835177\tvalid_1's binary_logloss: 0.134743\n",
            "[19]\ttraining's auc: 0.870671\ttraining's binary_logloss: 0.130673\tvalid_1's auc: 0.835195\tvalid_1's binary_logloss: 0.134351\n",
            "[20]\ttraining's auc: 0.872186\ttraining's binary_logloss: 0.12999\tvalid_1's auc: 0.834863\tvalid_1's binary_logloss: 0.134056\n",
            "[21]\ttraining's auc: 0.872954\ttraining's binary_logloss: 0.129348\tvalid_1's auc: 0.8344\tvalid_1's binary_logloss: 0.133836\n",
            "[22]\ttraining's auc: 0.873821\ttraining's binary_logloss: 0.128672\tvalid_1's auc: 0.834574\tvalid_1's binary_logloss: 0.133571\n",
            "[23]\ttraining's auc: 0.87471\ttraining's binary_logloss: 0.128101\tvalid_1's auc: 0.834356\tvalid_1's binary_logloss: 0.133364\n",
            "[24]\ttraining's auc: 0.875384\ttraining's binary_logloss: 0.127548\tvalid_1's auc: 0.834215\tvalid_1's binary_logloss: 0.133192\n",
            "[25]\ttraining's auc: 0.87652\ttraining's binary_logloss: 0.126998\tvalid_1's auc: 0.83425\tvalid_1's binary_logloss: 0.133008\n",
            "[26]\ttraining's auc: 0.877412\ttraining's binary_logloss: 0.126519\tvalid_1's auc: 0.834476\tvalid_1's binary_logloss: 0.132812\n",
            "[27]\ttraining's auc: 0.878531\ttraining's binary_logloss: 0.126007\tvalid_1's auc: 0.834957\tvalid_1's binary_logloss: 0.132613\n",
            "[28]\ttraining's auc: 0.879038\ttraining's binary_logloss: 0.125567\tvalid_1's auc: 0.834944\tvalid_1's binary_logloss: 0.132466\n",
            "[29]\ttraining's auc: 0.879891\ttraining's binary_logloss: 0.125075\tvalid_1's auc: 0.834606\tvalid_1's binary_logloss: 0.132352\n",
            "[30]\ttraining's auc: 0.880743\ttraining's binary_logloss: 0.12467\tvalid_1's auc: 0.834608\tvalid_1's binary_logloss: 0.13222\n",
            "[31]\ttraining's auc: 0.881576\ttraining's binary_logloss: 0.124256\tvalid_1's auc: 0.834651\tvalid_1's binary_logloss: 0.132088\n",
            "[32]\ttraining's auc: 0.882817\ttraining's binary_logloss: 0.123866\tvalid_1's auc: 0.834758\tvalid_1's binary_logloss: 0.132001\n",
            "[33]\ttraining's auc: 0.883982\ttraining's binary_logloss: 0.123473\tvalid_1's auc: 0.834519\tvalid_1's binary_logloss: 0.131887\n",
            "[34]\ttraining's auc: 0.885157\ttraining's binary_logloss: 0.123043\tvalid_1's auc: 0.834586\tvalid_1's binary_logloss: 0.131813\n",
            "[35]\ttraining's auc: 0.886476\ttraining's binary_logloss: 0.122685\tvalid_1's auc: 0.834754\tvalid_1's binary_logloss: 0.131735\n",
            "[36]\ttraining's auc: 0.888194\ttraining's binary_logloss: 0.122273\tvalid_1's auc: 0.83531\tvalid_1's binary_logloss: 0.131623\n",
            "[37]\ttraining's auc: 0.889008\ttraining's binary_logloss: 0.121891\tvalid_1's auc: 0.835468\tvalid_1's binary_logloss: 0.131535\n",
            "[38]\ttraining's auc: 0.889595\ttraining's binary_logloss: 0.121565\tvalid_1's auc: 0.835677\tvalid_1's binary_logloss: 0.131455\n",
            "[39]\ttraining's auc: 0.89079\ttraining's binary_logloss: 0.121219\tvalid_1's auc: 0.836186\tvalid_1's binary_logloss: 0.131332\n",
            "[40]\ttraining's auc: 0.891622\ttraining's binary_logloss: 0.120878\tvalid_1's auc: 0.836203\tvalid_1's binary_logloss: 0.13126\n",
            "[41]\ttraining's auc: 0.892421\ttraining's binary_logloss: 0.120556\tvalid_1's auc: 0.836155\tvalid_1's binary_logloss: 0.13123\n",
            "[42]\ttraining's auc: 0.893007\ttraining's binary_logloss: 0.120277\tvalid_1's auc: 0.836352\tvalid_1's binary_logloss: 0.131167\n",
            "[43]\ttraining's auc: 0.893423\ttraining's binary_logloss: 0.12\tvalid_1's auc: 0.836056\tvalid_1's binary_logloss: 0.131159\n",
            "[44]\ttraining's auc: 0.894242\ttraining's binary_logloss: 0.119701\tvalid_1's auc: 0.836074\tvalid_1's binary_logloss: 0.131113\n",
            "[45]\ttraining's auc: 0.895004\ttraining's binary_logloss: 0.119417\tvalid_1's auc: 0.836126\tvalid_1's binary_logloss: 0.131076\n",
            "[46]\ttraining's auc: 0.895526\ttraining's binary_logloss: 0.119155\tvalid_1's auc: 0.836368\tvalid_1's binary_logloss: 0.13102\n",
            "[47]\ttraining's auc: 0.89615\ttraining's binary_logloss: 0.118888\tvalid_1's auc: 0.836498\tvalid_1's binary_logloss: 0.130957\n",
            "[48]\ttraining's auc: 0.896502\ttraining's binary_logloss: 0.118641\tvalid_1's auc: 0.836471\tvalid_1's binary_logloss: 0.130949\n",
            "[49]\ttraining's auc: 0.897682\ttraining's binary_logloss: 0.118323\tvalid_1's auc: 0.836658\tvalid_1's binary_logloss: 0.130908\n",
            "[50]\ttraining's auc: 0.898725\ttraining's binary_logloss: 0.118062\tvalid_1's auc: 0.836671\tvalid_1's binary_logloss: 0.130888\n",
            "[51]\ttraining's auc: 0.89958\ttraining's binary_logloss: 0.117827\tvalid_1's auc: 0.836544\tvalid_1's binary_logloss: 0.130885\n",
            "[52]\ttraining's auc: 0.900339\ttraining's binary_logloss: 0.117541\tvalid_1's auc: 0.836585\tvalid_1's binary_logloss: 0.130867\n",
            "[53]\ttraining's auc: 0.901041\ttraining's binary_logloss: 0.117306\tvalid_1's auc: 0.836559\tvalid_1's binary_logloss: 0.130857\n",
            "[54]\ttraining's auc: 0.901593\ttraining's binary_logloss: 0.117083\tvalid_1's auc: 0.836781\tvalid_1's binary_logloss: 0.130824\n",
            "[55]\ttraining's auc: 0.90247\ttraining's binary_logloss: 0.116831\tvalid_1's auc: 0.836602\tvalid_1's binary_logloss: 0.13082\n",
            "[56]\ttraining's auc: 0.90306\ttraining's binary_logloss: 0.116578\tvalid_1's auc: 0.836831\tvalid_1's binary_logloss: 0.130754\n",
            "[57]\ttraining's auc: 0.90385\ttraining's binary_logloss: 0.116349\tvalid_1's auc: 0.836708\tvalid_1's binary_logloss: 0.130763\n",
            "[58]\ttraining's auc: 0.904285\ttraining's binary_logloss: 0.116138\tvalid_1's auc: 0.836803\tvalid_1's binary_logloss: 0.130752\n",
            "[59]\ttraining's auc: 0.904735\ttraining's binary_logloss: 0.115894\tvalid_1's auc: 0.83696\tvalid_1's binary_logloss: 0.130724\n",
            "[60]\ttraining's auc: 0.905209\ttraining's binary_logloss: 0.115646\tvalid_1's auc: 0.836918\tvalid_1's binary_logloss: 0.130725\n",
            "[61]\ttraining's auc: 0.90558\ttraining's binary_logloss: 0.115472\tvalid_1's auc: 0.836818\tvalid_1's binary_logloss: 0.130735\n",
            "[62]\ttraining's auc: 0.906064\ttraining's binary_logloss: 0.115269\tvalid_1's auc: 0.836812\tvalid_1's binary_logloss: 0.130729\n",
            "[63]\ttraining's auc: 0.906642\ttraining's binary_logloss: 0.115004\tvalid_1's auc: 0.837095\tvalid_1's binary_logloss: 0.130677\n",
            "[64]\ttraining's auc: 0.906971\ttraining's binary_logloss: 0.114844\tvalid_1's auc: 0.837043\tvalid_1's binary_logloss: 0.130676\n",
            "[65]\ttraining's auc: 0.907421\ttraining's binary_logloss: 0.11462\tvalid_1's auc: 0.837008\tvalid_1's binary_logloss: 0.130697\n",
            "[66]\ttraining's auc: 0.907982\ttraining's binary_logloss: 0.114388\tvalid_1's auc: 0.836976\tvalid_1's binary_logloss: 0.13071\n",
            "[67]\ttraining's auc: 0.908659\ttraining's binary_logloss: 0.114124\tvalid_1's auc: 0.836964\tvalid_1's binary_logloss: 0.130731\n",
            "[68]\ttraining's auc: 0.909412\ttraining's binary_logloss: 0.113867\tvalid_1's auc: 0.836725\tvalid_1's binary_logloss: 0.130747\n",
            "[69]\ttraining's auc: 0.909793\ttraining's binary_logloss: 0.113674\tvalid_1's auc: 0.836632\tvalid_1's binary_logloss: 0.130766\n",
            "[70]\ttraining's auc: 0.910277\ttraining's binary_logloss: 0.113459\tvalid_1's auc: 0.836793\tvalid_1's binary_logloss: 0.130763\n",
            "[71]\ttraining's auc: 0.910596\ttraining's binary_logloss: 0.113257\tvalid_1's auc: 0.83679\tvalid_1's binary_logloss: 0.130753\n",
            "[72]\ttraining's auc: 0.911055\ttraining's binary_logloss: 0.113053\tvalid_1's auc: 0.836737\tvalid_1's binary_logloss: 0.130755\n",
            "[73]\ttraining's auc: 0.911407\ttraining's binary_logloss: 0.112864\tvalid_1's auc: 0.836868\tvalid_1's binary_logloss: 0.130728\n",
            "[74]\ttraining's auc: 0.911705\ttraining's binary_logloss: 0.11271\tvalid_1's auc: 0.836816\tvalid_1's binary_logloss: 0.13074\n",
            "[75]\ttraining's auc: 0.912228\ttraining's binary_logloss: 0.112474\tvalid_1's auc: 0.83661\tvalid_1's binary_logloss: 0.130766\n",
            "[76]\ttraining's auc: 0.91256\ttraining's binary_logloss: 0.112293\tvalid_1's auc: 0.836648\tvalid_1's binary_logloss: 0.130756\n",
            "[77]\ttraining's auc: 0.913037\ttraining's binary_logloss: 0.112082\tvalid_1's auc: 0.836482\tvalid_1's binary_logloss: 0.130776\n",
            "[78]\ttraining's auc: 0.913261\ttraining's binary_logloss: 0.111927\tvalid_1's auc: 0.836603\tvalid_1's binary_logloss: 0.130741\n",
            "[79]\ttraining's auc: 0.913837\ttraining's binary_logloss: 0.111709\tvalid_1's auc: 0.836816\tvalid_1's binary_logloss: 0.130723\n",
            "[80]\ttraining's auc: 0.914019\ttraining's binary_logloss: 0.111568\tvalid_1's auc: 0.836694\tvalid_1's binary_logloss: 0.13074\n",
            "[81]\ttraining's auc: 0.914327\ttraining's binary_logloss: 0.111401\tvalid_1's auc: 0.83682\tvalid_1's binary_logloss: 0.13071\n",
            "[82]\ttraining's auc: 0.914509\ttraining's binary_logloss: 0.11128\tvalid_1's auc: 0.83668\tvalid_1's binary_logloss: 0.130734\n",
            "[83]\ttraining's auc: 0.914803\ttraining's binary_logloss: 0.11113\tvalid_1's auc: 0.836433\tvalid_1's binary_logloss: 0.130786\n",
            "[84]\ttraining's auc: 0.915201\ttraining's binary_logloss: 0.110934\tvalid_1's auc: 0.836356\tvalid_1's binary_logloss: 0.130809\n",
            "[85]\ttraining's auc: 0.91563\ttraining's binary_logloss: 0.110728\tvalid_1's auc: 0.836276\tvalid_1's binary_logloss: 0.130805\n",
            "[86]\ttraining's auc: 0.916034\ttraining's binary_logloss: 0.110549\tvalid_1's auc: 0.83603\tvalid_1's binary_logloss: 0.13084\n",
            "[87]\ttraining's auc: 0.916482\ttraining's binary_logloss: 0.110334\tvalid_1's auc: 0.836185\tvalid_1's binary_logloss: 0.130803\n",
            "[88]\ttraining's auc: 0.916789\ttraining's binary_logloss: 0.110187\tvalid_1's auc: 0.836165\tvalid_1's binary_logloss: 0.130808\n",
            "[89]\ttraining's auc: 0.917294\ttraining's binary_logloss: 0.110004\tvalid_1's auc: 0.836128\tvalid_1's binary_logloss: 0.130822\n",
            "[90]\ttraining's auc: 0.91742\ttraining's binary_logloss: 0.1099\tvalid_1's auc: 0.835977\tvalid_1's binary_logloss: 0.130844\n",
            "[91]\ttraining's auc: 0.917596\ttraining's binary_logloss: 0.109787\tvalid_1's auc: 0.835922\tvalid_1's binary_logloss: 0.130858\n",
            "[92]\ttraining's auc: 0.917762\ttraining's binary_logloss: 0.10967\tvalid_1's auc: 0.835949\tvalid_1's binary_logloss: 0.130858\n",
            "[93]\ttraining's auc: 0.918275\ttraining's binary_logloss: 0.109518\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.130861\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "  4%|▍         | 2/50 [00:59<16:59, 21.24s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.157395\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.163363\n",
            "[2]\ttraining's auc: 0.831489\ttraining's binary_logloss: 0.153162\tvalid_1's auc: 0.814459\tvalid_1's binary_logloss: 0.159568\n",
            "[3]\ttraining's auc: 0.83599\ttraining's binary_logloss: 0.149765\tvalid_1's auc: 0.817084\tvalid_1's binary_logloss: 0.156677\n",
            "[4]\ttraining's auc: 0.838096\ttraining's binary_logloss: 0.147028\tvalid_1's auc: 0.818544\tvalid_1's binary_logloss: 0.154282\n",
            "[5]\ttraining's auc: 0.84429\ttraining's binary_logloss: 0.144559\tvalid_1's auc: 0.823355\tvalid_1's binary_logloss: 0.152204\n",
            "[6]\ttraining's auc: 0.847642\ttraining's binary_logloss: 0.142442\tvalid_1's auc: 0.824572\tvalid_1's binary_logloss: 0.150489\n",
            "[7]\ttraining's auc: 0.850389\ttraining's binary_logloss: 0.140628\tvalid_1's auc: 0.826549\tvalid_1's binary_logloss: 0.148923\n",
            "[8]\ttraining's auc: 0.851664\ttraining's binary_logloss: 0.138914\tvalid_1's auc: 0.827511\tvalid_1's binary_logloss: 0.147643\n",
            "[9]\ttraining's auc: 0.852481\ttraining's binary_logloss: 0.137429\tvalid_1's auc: 0.827884\tvalid_1's binary_logloss: 0.146446\n",
            "[10]\ttraining's auc: 0.854265\ttraining's binary_logloss: 0.136096\tvalid_1's auc: 0.828665\tvalid_1's binary_logloss: 0.145468\n",
            "[11]\ttraining's auc: 0.856384\ttraining's binary_logloss: 0.134902\tvalid_1's auc: 0.829607\tvalid_1's binary_logloss: 0.144537\n",
            "[12]\ttraining's auc: 0.857295\ttraining's binary_logloss: 0.133824\tvalid_1's auc: 0.829961\tvalid_1's binary_logloss: 0.143679\n",
            "[13]\ttraining's auc: 0.858847\ttraining's binary_logloss: 0.132805\tvalid_1's auc: 0.830364\tvalid_1's binary_logloss: 0.142922\n",
            "[14]\ttraining's auc: 0.860908\ttraining's binary_logloss: 0.131866\tvalid_1's auc: 0.830559\tvalid_1's binary_logloss: 0.142279\n",
            "[15]\ttraining's auc: 0.863638\ttraining's binary_logloss: 0.131006\tvalid_1's auc: 0.830515\tvalid_1's binary_logloss: 0.141707\n",
            "[16]\ttraining's auc: 0.864443\ttraining's binary_logloss: 0.130213\tvalid_1's auc: 0.8306\tvalid_1's binary_logloss: 0.141215\n",
            "[17]\ttraining's auc: 0.866833\ttraining's binary_logloss: 0.129424\tvalid_1's auc: 0.830938\tvalid_1's binary_logloss: 0.140744\n",
            "[18]\ttraining's auc: 0.868563\ttraining's binary_logloss: 0.128694\tvalid_1's auc: 0.83102\tvalid_1's binary_logloss: 0.1403\n",
            "[19]\ttraining's auc: 0.869828\ttraining's binary_logloss: 0.128012\tvalid_1's auc: 0.831056\tvalid_1's binary_logloss: 0.139942\n",
            "[20]\ttraining's auc: 0.872372\ttraining's binary_logloss: 0.127319\tvalid_1's auc: 0.833366\tvalid_1's binary_logloss: 0.139586\n",
            "[21]\ttraining's auc: 0.87295\ttraining's binary_logloss: 0.126728\tvalid_1's auc: 0.833628\tvalid_1's binary_logloss: 0.139268\n",
            "[22]\ttraining's auc: 0.874673\ttraining's binary_logloss: 0.126114\tvalid_1's auc: 0.834244\tvalid_1's binary_logloss: 0.138993\n",
            "[23]\ttraining's auc: 0.875759\ttraining's binary_logloss: 0.125548\tvalid_1's auc: 0.834477\tvalid_1's binary_logloss: 0.138718\n",
            "[24]\ttraining's auc: 0.87717\ttraining's binary_logloss: 0.125026\tvalid_1's auc: 0.834817\tvalid_1's binary_logloss: 0.138437\n",
            "[25]\ttraining's auc: 0.878418\ttraining's binary_logloss: 0.124488\tvalid_1's auc: 0.835016\tvalid_1's binary_logloss: 0.138225\n",
            "[26]\ttraining's auc: 0.879913\ttraining's binary_logloss: 0.123944\tvalid_1's auc: 0.835142\tvalid_1's binary_logloss: 0.138015\n",
            "[27]\ttraining's auc: 0.881383\ttraining's binary_logloss: 0.123487\tvalid_1's auc: 0.835335\tvalid_1's binary_logloss: 0.137831\n",
            "[28]\ttraining's auc: 0.882757\ttraining's binary_logloss: 0.122959\tvalid_1's auc: 0.835177\tvalid_1's binary_logloss: 0.137697\n",
            "[29]\ttraining's auc: 0.884088\ttraining's binary_logloss: 0.122548\tvalid_1's auc: 0.835071\tvalid_1's binary_logloss: 0.137568\n",
            "[30]\ttraining's auc: 0.885258\ttraining's binary_logloss: 0.122119\tvalid_1's auc: 0.834625\tvalid_1's binary_logloss: 0.137478\n",
            "[31]\ttraining's auc: 0.886244\ttraining's binary_logloss: 0.121655\tvalid_1's auc: 0.834821\tvalid_1's binary_logloss: 0.137356\n",
            "[32]\ttraining's auc: 0.88788\ttraining's binary_logloss: 0.121197\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.13726\n",
            "[33]\ttraining's auc: 0.888961\ttraining's binary_logloss: 0.120798\tvalid_1's auc: 0.835499\tvalid_1's binary_logloss: 0.137116\n",
            "[34]\ttraining's auc: 0.889903\ttraining's binary_logloss: 0.120392\tvalid_1's auc: 0.835376\tvalid_1's binary_logloss: 0.137018\n",
            "[35]\ttraining's auc: 0.89063\ttraining's binary_logloss: 0.120017\tvalid_1's auc: 0.835252\tvalid_1's binary_logloss: 0.136956\n",
            "[36]\ttraining's auc: 0.891759\ttraining's binary_logloss: 0.119614\tvalid_1's auc: 0.834967\tvalid_1's binary_logloss: 0.136927\n",
            "[37]\ttraining's auc: 0.892178\ttraining's binary_logloss: 0.119307\tvalid_1's auc: 0.835026\tvalid_1's binary_logloss: 0.136871\n",
            "[38]\ttraining's auc: 0.893236\ttraining's binary_logloss: 0.118959\tvalid_1's auc: 0.835011\tvalid_1's binary_logloss: 0.136795\n",
            "[39]\ttraining's auc: 0.894208\ttraining's binary_logloss: 0.118597\tvalid_1's auc: 0.834989\tvalid_1's binary_logloss: 0.136759\n",
            "[40]\ttraining's auc: 0.894718\ttraining's binary_logloss: 0.118321\tvalid_1's auc: 0.834912\tvalid_1's binary_logloss: 0.136738\n",
            "[41]\ttraining's auc: 0.895612\ttraining's binary_logloss: 0.11799\tvalid_1's auc: 0.834906\tvalid_1's binary_logloss: 0.136677\n",
            "[42]\ttraining's auc: 0.896453\ttraining's binary_logloss: 0.117655\tvalid_1's auc: 0.834883\tvalid_1's binary_logloss: 0.136643\n",
            "[43]\ttraining's auc: 0.89684\ttraining's binary_logloss: 0.117392\tvalid_1's auc: 0.834997\tvalid_1's binary_logloss: 0.136591\n",
            "[44]\ttraining's auc: 0.897783\ttraining's binary_logloss: 0.117103\tvalid_1's auc: 0.834712\tvalid_1's binary_logloss: 0.136622\n",
            "[45]\ttraining's auc: 0.898436\ttraining's binary_logloss: 0.116835\tvalid_1's auc: 0.834532\tvalid_1's binary_logloss: 0.136627\n",
            "[46]\ttraining's auc: 0.89956\ttraining's binary_logloss: 0.116499\tvalid_1's auc: 0.834596\tvalid_1's binary_logloss: 0.136582\n",
            "[47]\ttraining's auc: 0.900108\ttraining's binary_logloss: 0.116231\tvalid_1's auc: 0.834411\tvalid_1's binary_logloss: 0.136583\n",
            "[48]\ttraining's auc: 0.900642\ttraining's binary_logloss: 0.115972\tvalid_1's auc: 0.834476\tvalid_1's binary_logloss: 0.136554\n",
            "[49]\ttraining's auc: 0.901071\ttraining's binary_logloss: 0.115771\tvalid_1's auc: 0.834047\tvalid_1's binary_logloss: 0.136558\n",
            "[50]\ttraining's auc: 0.901764\ttraining's binary_logloss: 0.115546\tvalid_1's auc: 0.833999\tvalid_1's binary_logloss: 0.136556\n",
            "[51]\ttraining's auc: 0.902398\ttraining's binary_logloss: 0.115289\tvalid_1's auc: 0.833798\tvalid_1's binary_logloss: 0.136576\n",
            "[52]\ttraining's auc: 0.903093\ttraining's binary_logloss: 0.115036\tvalid_1's auc: 0.833714\tvalid_1's binary_logloss: 0.13659\n",
            "[53]\ttraining's auc: 0.903551\ttraining's binary_logloss: 0.114828\tvalid_1's auc: 0.833972\tvalid_1's binary_logloss: 0.136557\n",
            "[54]\ttraining's auc: 0.904404\ttraining's binary_logloss: 0.114585\tvalid_1's auc: 0.833961\tvalid_1's binary_logloss: 0.136555\n",
            "[55]\ttraining's auc: 0.905074\ttraining's binary_logloss: 0.114318\tvalid_1's auc: 0.833811\tvalid_1's binary_logloss: 0.136601\n",
            "[56]\ttraining's auc: 0.905517\ttraining's binary_logloss: 0.114096\tvalid_1's auc: 0.833857\tvalid_1's binary_logloss: 0.136608\n",
            "[57]\ttraining's auc: 0.90623\ttraining's binary_logloss: 0.113815\tvalid_1's auc: 0.833916\tvalid_1's binary_logloss: 0.136593\n",
            "[58]\ttraining's auc: 0.906833\ttraining's binary_logloss: 0.113544\tvalid_1's auc: 0.834209\tvalid_1's binary_logloss: 0.136565\n",
            "[59]\ttraining's auc: 0.907573\ttraining's binary_logloss: 0.113282\tvalid_1's auc: 0.834154\tvalid_1's binary_logloss: 0.136597\n",
            "[60]\ttraining's auc: 0.908146\ttraining's binary_logloss: 0.113\tvalid_1's auc: 0.834427\tvalid_1's binary_logloss: 0.136555\n",
            "[61]\ttraining's auc: 0.908689\ttraining's binary_logloss: 0.112822\tvalid_1's auc: 0.834726\tvalid_1's binary_logloss: 0.136513\n",
            "[62]\ttraining's auc: 0.909199\ttraining's binary_logloss: 0.11258\tvalid_1's auc: 0.834682\tvalid_1's binary_logloss: 0.136532\n",
            "[63]\ttraining's auc: 0.909472\ttraining's binary_logloss: 0.112377\tvalid_1's auc: 0.834904\tvalid_1's binary_logloss: 0.136502\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "  6%|▌         | 3/50 [01:16<20:25, 26.07s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.15504\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.157575\n",
            "[2]\ttraining's auc: 0.834033\ttraining's binary_logloss: 0.149344\tvalid_1's auc: 0.808708\tvalid_1's binary_logloss: 0.153043\n",
            "[3]\ttraining's auc: 0.842615\ttraining's binary_logloss: 0.145265\tvalid_1's auc: 0.815718\tvalid_1's binary_logloss: 0.149908\n",
            "[4]\ttraining's auc: 0.847162\ttraining's binary_logloss: 0.142006\tvalid_1's auc: 0.817273\tvalid_1's binary_logloss: 0.147594\n",
            "[5]\ttraining's auc: 0.850571\ttraining's binary_logloss: 0.139292\tvalid_1's auc: 0.81865\tvalid_1's binary_logloss: 0.145714\n",
            "[6]\ttraining's auc: 0.852997\ttraining's binary_logloss: 0.137036\tvalid_1's auc: 0.819578\tvalid_1's binary_logloss: 0.14419\n",
            "[7]\ttraining's auc: 0.857308\ttraining's binary_logloss: 0.135137\tvalid_1's auc: 0.820111\tvalid_1's binary_logloss: 0.142893\n",
            "[8]\ttraining's auc: 0.859915\ttraining's binary_logloss: 0.133353\tvalid_1's auc: 0.82164\tvalid_1's binary_logloss: 0.141734\n",
            "[9]\ttraining's auc: 0.863044\ttraining's binary_logloss: 0.131907\tvalid_1's auc: 0.823657\tvalid_1's binary_logloss: 0.140798\n",
            "[10]\ttraining's auc: 0.864786\ttraining's binary_logloss: 0.130612\tvalid_1's auc: 0.82509\tvalid_1's binary_logloss: 0.13995\n",
            "[11]\ttraining's auc: 0.867452\ttraining's binary_logloss: 0.129447\tvalid_1's auc: 0.825704\tvalid_1's binary_logloss: 0.139384\n",
            "[12]\ttraining's auc: 0.870206\ttraining's binary_logloss: 0.128366\tvalid_1's auc: 0.826127\tvalid_1's binary_logloss: 0.138922\n",
            "[13]\ttraining's auc: 0.871961\ttraining's binary_logloss: 0.127369\tvalid_1's auc: 0.826038\tvalid_1's binary_logloss: 0.138548\n",
            "[14]\ttraining's auc: 0.873416\ttraining's binary_logloss: 0.126535\tvalid_1's auc: 0.826119\tvalid_1's binary_logloss: 0.138171\n",
            "[15]\ttraining's auc: 0.875118\ttraining's binary_logloss: 0.125647\tvalid_1's auc: 0.826846\tvalid_1's binary_logloss: 0.137713\n",
            "[16]\ttraining's auc: 0.876275\ttraining's binary_logloss: 0.124899\tvalid_1's auc: 0.82739\tvalid_1's binary_logloss: 0.137397\n",
            "[17]\ttraining's auc: 0.878002\ttraining's binary_logloss: 0.124162\tvalid_1's auc: 0.828347\tvalid_1's binary_logloss: 0.137181\n",
            "[18]\ttraining's auc: 0.881899\ttraining's binary_logloss: 0.123291\tvalid_1's auc: 0.828323\tvalid_1's binary_logloss: 0.136974\n",
            "[19]\ttraining's auc: 0.883398\ttraining's binary_logloss: 0.122657\tvalid_1's auc: 0.828149\tvalid_1's binary_logloss: 0.136884\n",
            "[20]\ttraining's auc: 0.884823\ttraining's binary_logloss: 0.122038\tvalid_1's auc: 0.828303\tvalid_1's binary_logloss: 0.136739\n",
            "[21]\ttraining's auc: 0.885973\ttraining's binary_logloss: 0.121432\tvalid_1's auc: 0.827872\tvalid_1's binary_logloss: 0.136724\n",
            "[22]\ttraining's auc: 0.887881\ttraining's binary_logloss: 0.120753\tvalid_1's auc: 0.82805\tvalid_1's binary_logloss: 0.136678\n",
            "[23]\ttraining's auc: 0.889328\ttraining's binary_logloss: 0.120146\tvalid_1's auc: 0.827727\tvalid_1's binary_logloss: 0.136633\n",
            "[24]\ttraining's auc: 0.890302\ttraining's binary_logloss: 0.11965\tvalid_1's auc: 0.827938\tvalid_1's binary_logloss: 0.13657\n",
            "[25]\ttraining's auc: 0.8914\ttraining's binary_logloss: 0.119182\tvalid_1's auc: 0.827662\tvalid_1's binary_logloss: 0.136548\n",
            "[26]\ttraining's auc: 0.893563\ttraining's binary_logloss: 0.118601\tvalid_1's auc: 0.82806\tvalid_1's binary_logloss: 0.136448\n",
            "[27]\ttraining's auc: 0.895503\ttraining's binary_logloss: 0.118153\tvalid_1's auc: 0.828086\tvalid_1's binary_logloss: 0.136416\n",
            "[28]\ttraining's auc: 0.896659\ttraining's binary_logloss: 0.117678\tvalid_1's auc: 0.827695\tvalid_1's binary_logloss: 0.13648\n",
            "[29]\ttraining's auc: 0.897793\ttraining's binary_logloss: 0.11719\tvalid_1's auc: 0.827761\tvalid_1's binary_logloss: 0.136475\n",
            "[30]\ttraining's auc: 0.899143\ttraining's binary_logloss: 0.116718\tvalid_1's auc: 0.828225\tvalid_1's binary_logloss: 0.136353\n",
            "[31]\ttraining's auc: 0.900162\ttraining's binary_logloss: 0.116337\tvalid_1's auc: 0.828501\tvalid_1's binary_logloss: 0.136316\n",
            "[32]\ttraining's auc: 0.901985\ttraining's binary_logloss: 0.115849\tvalid_1's auc: 0.829103\tvalid_1's binary_logloss: 0.136182\n",
            "[33]\ttraining's auc: 0.903018\ttraining's binary_logloss: 0.115417\tvalid_1's auc: 0.828836\tvalid_1's binary_logloss: 0.136236\n",
            "[34]\ttraining's auc: 0.903799\ttraining's binary_logloss: 0.115043\tvalid_1's auc: 0.828498\tvalid_1's binary_logloss: 0.136283\n",
            "[35]\ttraining's auc: 0.905179\ttraining's binary_logloss: 0.114639\tvalid_1's auc: 0.828356\tvalid_1's binary_logloss: 0.136315\n",
            "[36]\ttraining's auc: 0.905981\ttraining's binary_logloss: 0.114233\tvalid_1's auc: 0.828362\tvalid_1's binary_logloss: 0.136319\n",
            "[37]\ttraining's auc: 0.906801\ttraining's binary_logloss: 0.113912\tvalid_1's auc: 0.828273\tvalid_1's binary_logloss: 0.136335\n",
            "[38]\ttraining's auc: 0.907411\ttraining's binary_logloss: 0.113585\tvalid_1's auc: 0.828485\tvalid_1's binary_logloss: 0.136338\n",
            "[39]\ttraining's auc: 0.908211\ttraining's binary_logloss: 0.113184\tvalid_1's auc: 0.828682\tvalid_1's binary_logloss: 0.136307\n",
            "[40]\ttraining's auc: 0.908823\ttraining's binary_logloss: 0.112881\tvalid_1's auc: 0.82848\tvalid_1's binary_logloss: 0.13637\n",
            "[41]\ttraining's auc: 0.909625\ttraining's binary_logloss: 0.112524\tvalid_1's auc: 0.828555\tvalid_1's binary_logloss: 0.136369\n",
            "[42]\ttraining's auc: 0.910213\ttraining's binary_logloss: 0.112288\tvalid_1's auc: 0.828354\tvalid_1's binary_logloss: 0.136385\n",
            "[43]\ttraining's auc: 0.910921\ttraining's binary_logloss: 0.111945\tvalid_1's auc: 0.828138\tvalid_1's binary_logloss: 0.136439\n",
            "[44]\ttraining's auc: 0.911594\ttraining's binary_logloss: 0.111655\tvalid_1's auc: 0.828079\tvalid_1's binary_logloss: 0.136486\n",
            "[45]\ttraining's auc: 0.912326\ttraining's binary_logloss: 0.111353\tvalid_1's auc: 0.827917\tvalid_1's binary_logloss: 0.136506\n",
            "[46]\ttraining's auc: 0.913175\ttraining's binary_logloss: 0.110979\tvalid_1's auc: 0.82754\tvalid_1's binary_logloss: 0.136601\n",
            "[47]\ttraining's auc: 0.914158\ttraining's binary_logloss: 0.110583\tvalid_1's auc: 0.827197\tvalid_1's binary_logloss: 0.136687\n",
            "[48]\ttraining's auc: 0.9146\ttraining's binary_logloss: 0.110356\tvalid_1's auc: 0.827079\tvalid_1's binary_logloss: 0.13671\n",
            "[49]\ttraining's auc: 0.915489\ttraining's binary_logloss: 0.110093\tvalid_1's auc: 0.826995\tvalid_1's binary_logloss: 0.136745\n",
            "[50]\ttraining's auc: 0.916025\ttraining's binary_logloss: 0.109819\tvalid_1's auc: 0.826809\tvalid_1's binary_logloss: 0.136781\n",
            "[51]\ttraining's auc: 0.91693\ttraining's binary_logloss: 0.109431\tvalid_1's auc: 0.82623\tvalid_1's binary_logloss: 0.136929\n",
            "[52]\ttraining's auc: 0.917476\ttraining's binary_logloss: 0.109122\tvalid_1's auc: 0.826181\tvalid_1's binary_logloss: 0.136945\n",
            "[53]\ttraining's auc: 0.917953\ttraining's binary_logloss: 0.108874\tvalid_1's auc: 0.825844\tvalid_1's binary_logloss: 0.137058\n",
            "[54]\ttraining's auc: 0.91824\ttraining's binary_logloss: 0.108692\tvalid_1's auc: 0.825589\tvalid_1's binary_logloss: 0.13712\n",
            "[55]\ttraining's auc: 0.91846\ttraining's binary_logloss: 0.108509\tvalid_1's auc: 0.825347\tvalid_1's binary_logloss: 0.137168\n",
            "[56]\ttraining's auc: 0.918662\ttraining's binary_logloss: 0.10835\tvalid_1's auc: 0.825154\tvalid_1's binary_logloss: 0.137214\n",
            "[57]\ttraining's auc: 0.919017\ttraining's binary_logloss: 0.108117\tvalid_1's auc: 0.824664\tvalid_1's binary_logloss: 0.137311\n",
            "[58]\ttraining's auc: 0.919608\ttraining's binary_logloss: 0.107839\tvalid_1's auc: 0.824523\tvalid_1's binary_logloss: 0.137318\n",
            "[59]\ttraining's auc: 0.91991\ttraining's binary_logloss: 0.107665\tvalid_1's auc: 0.824349\tvalid_1's binary_logloss: 0.137354\n",
            "[60]\ttraining's auc: 0.920179\ttraining's binary_logloss: 0.107504\tvalid_1's auc: 0.824099\tvalid_1's binary_logloss: 0.137444\n",
            "[61]\ttraining's auc: 0.92034\ttraining's binary_logloss: 0.107359\tvalid_1's auc: 0.823799\tvalid_1's binary_logloss: 0.137543\n",
            "[62]\ttraining's auc: 0.920947\ttraining's binary_logloss: 0.107061\tvalid_1's auc: 0.823716\tvalid_1's binary_logloss: 0.137567\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "  6%|▌         | 3/50 [01:34<20:25, 26.07s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.157464\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.153521\n",
            "[2]\ttraining's auc: 0.828301\ttraining's binary_logloss: 0.15177\tvalid_1's auc: 0.814899\tvalid_1's binary_logloss: 0.149171\n",
            "[3]\ttraining's auc: 0.83779\ttraining's binary_logloss: 0.147519\tvalid_1's auc: 0.818762\tvalid_1's binary_logloss: 0.146029\n",
            "[4]\ttraining's auc: 0.844309\ttraining's binary_logloss: 0.144222\tvalid_1's auc: 0.824382\tvalid_1's binary_logloss: 0.143608\n",
            "[5]\ttraining's auc: 0.848846\ttraining's binary_logloss: 0.141489\tvalid_1's auc: 0.826658\tvalid_1's binary_logloss: 0.141624\n",
            "[6]\ttraining's auc: 0.852026\ttraining's binary_logloss: 0.139151\tvalid_1's auc: 0.829266\tvalid_1's binary_logloss: 0.140002\n",
            "[7]\ttraining's auc: 0.854508\ttraining's binary_logloss: 0.137169\tvalid_1's auc: 0.83065\tvalid_1's binary_logloss: 0.138684\n",
            "[8]\ttraining's auc: 0.857838\ttraining's binary_logloss: 0.135445\tvalid_1's auc: 0.830431\tvalid_1's binary_logloss: 0.137699\n",
            "[9]\ttraining's auc: 0.860259\ttraining's binary_logloss: 0.133889\tvalid_1's auc: 0.830167\tvalid_1's binary_logloss: 0.136821\n",
            "[10]\ttraining's auc: 0.864926\ttraining's binary_logloss: 0.132463\tvalid_1's auc: 0.831906\tvalid_1's binary_logloss: 0.136013\n",
            "[11]\ttraining's auc: 0.868162\ttraining's binary_logloss: 0.131233\tvalid_1's auc: 0.832224\tvalid_1's binary_logloss: 0.13536\n",
            "[12]\ttraining's auc: 0.870715\ttraining's binary_logloss: 0.130102\tvalid_1's auc: 0.832057\tvalid_1's binary_logloss: 0.134898\n",
            "[13]\ttraining's auc: 0.871751\ttraining's binary_logloss: 0.129099\tvalid_1's auc: 0.832518\tvalid_1's binary_logloss: 0.134388\n",
            "[14]\ttraining's auc: 0.872617\ttraining's binary_logloss: 0.1282\tvalid_1's auc: 0.832183\tvalid_1's binary_logloss: 0.134027\n",
            "[15]\ttraining's auc: 0.874484\ttraining's binary_logloss: 0.127318\tvalid_1's auc: 0.832189\tvalid_1's binary_logloss: 0.133689\n",
            "[16]\ttraining's auc: 0.876711\ttraining's binary_logloss: 0.126517\tvalid_1's auc: 0.833106\tvalid_1's binary_logloss: 0.1334\n",
            "[17]\ttraining's auc: 0.879009\ttraining's binary_logloss: 0.125708\tvalid_1's auc: 0.832909\tvalid_1's binary_logloss: 0.13309\n",
            "[18]\ttraining's auc: 0.879756\ttraining's binary_logloss: 0.12501\tvalid_1's auc: 0.832981\tvalid_1's binary_logloss: 0.132867\n",
            "[19]\ttraining's auc: 0.881992\ttraining's binary_logloss: 0.12428\tvalid_1's auc: 0.832712\tvalid_1's binary_logloss: 0.132741\n",
            "[20]\ttraining's auc: 0.883669\ttraining's binary_logloss: 0.123686\tvalid_1's auc: 0.832674\tvalid_1's binary_logloss: 0.13261\n",
            "[21]\ttraining's auc: 0.885177\ttraining's binary_logloss: 0.12309\tvalid_1's auc: 0.832395\tvalid_1's binary_logloss: 0.132507\n",
            "[22]\ttraining's auc: 0.886178\ttraining's binary_logloss: 0.122511\tvalid_1's auc: 0.832972\tvalid_1's binary_logloss: 0.132354\n",
            "[23]\ttraining's auc: 0.887543\ttraining's binary_logloss: 0.121991\tvalid_1's auc: 0.832676\tvalid_1's binary_logloss: 0.132307\n",
            "[24]\ttraining's auc: 0.888861\ttraining's binary_logloss: 0.121469\tvalid_1's auc: 0.832962\tvalid_1's binary_logloss: 0.132221\n",
            "[25]\ttraining's auc: 0.890202\ttraining's binary_logloss: 0.120954\tvalid_1's auc: 0.83354\tvalid_1's binary_logloss: 0.132081\n",
            "[26]\ttraining's auc: 0.89174\ttraining's binary_logloss: 0.120418\tvalid_1's auc: 0.833177\tvalid_1's binary_logloss: 0.13203\n",
            "[27]\ttraining's auc: 0.892602\ttraining's binary_logloss: 0.119972\tvalid_1's auc: 0.832926\tvalid_1's binary_logloss: 0.132007\n",
            "[28]\ttraining's auc: 0.893242\ttraining's binary_logloss: 0.119558\tvalid_1's auc: 0.8336\tvalid_1's binary_logloss: 0.131854\n",
            "[29]\ttraining's auc: 0.894756\ttraining's binary_logloss: 0.119139\tvalid_1's auc: 0.833506\tvalid_1's binary_logloss: 0.131815\n",
            "[30]\ttraining's auc: 0.89631\ttraining's binary_logloss: 0.118697\tvalid_1's auc: 0.833729\tvalid_1's binary_logloss: 0.131774\n",
            "[31]\ttraining's auc: 0.897805\ttraining's binary_logloss: 0.118242\tvalid_1's auc: 0.833756\tvalid_1's binary_logloss: 0.131703\n",
            "[32]\ttraining's auc: 0.898408\ttraining's binary_logloss: 0.117872\tvalid_1's auc: 0.833686\tvalid_1's binary_logloss: 0.131676\n",
            "[33]\ttraining's auc: 0.900049\ttraining's binary_logloss: 0.11746\tvalid_1's auc: 0.833321\tvalid_1's binary_logloss: 0.131705\n",
            "[34]\ttraining's auc: 0.901777\ttraining's binary_logloss: 0.116991\tvalid_1's auc: 0.833435\tvalid_1's binary_logloss: 0.131692\n",
            "[35]\ttraining's auc: 0.902515\ttraining's binary_logloss: 0.116629\tvalid_1's auc: 0.833441\tvalid_1's binary_logloss: 0.131673\n",
            "[36]\ttraining's auc: 0.903943\ttraining's binary_logloss: 0.116144\tvalid_1's auc: 0.833644\tvalid_1's binary_logloss: 0.131628\n",
            "[37]\ttraining's auc: 0.904704\ttraining's binary_logloss: 0.115736\tvalid_1's auc: 0.833422\tvalid_1's binary_logloss: 0.131651\n",
            "[38]\ttraining's auc: 0.905771\ttraining's binary_logloss: 0.115269\tvalid_1's auc: 0.833545\tvalid_1's binary_logloss: 0.131658\n",
            "[39]\ttraining's auc: 0.906695\ttraining's binary_logloss: 0.114854\tvalid_1's auc: 0.833354\tvalid_1's binary_logloss: 0.131692\n",
            "[40]\ttraining's auc: 0.908005\ttraining's binary_logloss: 0.114469\tvalid_1's auc: 0.833598\tvalid_1's binary_logloss: 0.131661\n",
            "[41]\ttraining's auc: 0.908739\ttraining's binary_logloss: 0.114141\tvalid_1's auc: 0.833284\tvalid_1's binary_logloss: 0.131712\n",
            "[42]\ttraining's auc: 0.909321\ttraining's binary_logloss: 0.113802\tvalid_1's auc: 0.83321\tvalid_1's binary_logloss: 0.131725\n",
            "[43]\ttraining's auc: 0.910072\ttraining's binary_logloss: 0.113447\tvalid_1's auc: 0.833308\tvalid_1's binary_logloss: 0.1317\n",
            "[44]\ttraining's auc: 0.91058\ttraining's binary_logloss: 0.113147\tvalid_1's auc: 0.833473\tvalid_1's binary_logloss: 0.131681\n",
            "[45]\ttraining's auc: 0.911355\ttraining's binary_logloss: 0.112849\tvalid_1's auc: 0.833499\tvalid_1's binary_logloss: 0.131673\n",
            "[46]\ttraining's auc: 0.912393\ttraining's binary_logloss: 0.112419\tvalid_1's auc: 0.833258\tvalid_1's binary_logloss: 0.131687\n",
            "[47]\ttraining's auc: 0.91292\ttraining's binary_logloss: 0.112125\tvalid_1's auc: 0.833318\tvalid_1's binary_logloss: 0.131664\n",
            "[48]\ttraining's auc: 0.913379\ttraining's binary_logloss: 0.111857\tvalid_1's auc: 0.833583\tvalid_1's binary_logloss: 0.131622\n",
            "[49]\ttraining's auc: 0.914191\ttraining's binary_logloss: 0.111568\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.131628\n",
            "[50]\ttraining's auc: 0.914491\ttraining's binary_logloss: 0.111319\tvalid_1's auc: 0.833633\tvalid_1's binary_logloss: 0.131607\n",
            "[51]\ttraining's auc: 0.915363\ttraining's binary_logloss: 0.110967\tvalid_1's auc: 0.833838\tvalid_1's binary_logloss: 0.131518\n",
            "[52]\ttraining's auc: 0.915926\ttraining's binary_logloss: 0.110726\tvalid_1's auc: 0.833642\tvalid_1's binary_logloss: 0.131557\n",
            "[53]\ttraining's auc: 0.916238\ttraining's binary_logloss: 0.110516\tvalid_1's auc: 0.833345\tvalid_1's binary_logloss: 0.131618\n",
            "[54]\ttraining's auc: 0.916797\ttraining's binary_logloss: 0.110276\tvalid_1's auc: 0.833534\tvalid_1's binary_logloss: 0.131578\n",
            "[55]\ttraining's auc: 0.917382\ttraining's binary_logloss: 0.109993\tvalid_1's auc: 0.833438\tvalid_1's binary_logloss: 0.131585\n",
            "[56]\ttraining's auc: 0.917848\ttraining's binary_logloss: 0.10975\tvalid_1's auc: 0.833292\tvalid_1's binary_logloss: 0.131608\n",
            "[57]\ttraining's auc: 0.91834\ttraining's binary_logloss: 0.109478\tvalid_1's auc: 0.833468\tvalid_1's binary_logloss: 0.131611\n",
            "[58]\ttraining's auc: 0.918855\ttraining's binary_logloss: 0.10917\tvalid_1's auc: 0.833281\tvalid_1's binary_logloss: 0.131651\n",
            "[59]\ttraining's auc: 0.919172\ttraining's binary_logloss: 0.108966\tvalid_1's auc: 0.833356\tvalid_1's binary_logloss: 0.131609\n",
            "[60]\ttraining's auc: 0.919359\ttraining's binary_logloss: 0.108814\tvalid_1's auc: 0.833266\tvalid_1's binary_logloss: 0.131621\n",
            "[61]\ttraining's auc: 0.919918\ttraining's binary_logloss: 0.10862\tvalid_1's auc: 0.833417\tvalid_1's binary_logloss: 0.131604\n",
            "[62]\ttraining's auc: 0.92042\ttraining's binary_logloss: 0.10838\tvalid_1's auc: 0.833179\tvalid_1's binary_logloss: 0.131611\n",
            "[63]\ttraining's auc: 0.920883\ttraining's binary_logloss: 0.108145\tvalid_1's auc: 0.832917\tvalid_1's binary_logloss: 0.131648\n",
            "[64]\ttraining's auc: 0.921666\ttraining's binary_logloss: 0.107922\tvalid_1's auc: 0.832758\tvalid_1's binary_logloss: 0.131697\n",
            "[65]\ttraining's auc: 0.922209\ttraining's binary_logloss: 0.107726\tvalid_1's auc: 0.832649\tvalid_1's binary_logloss: 0.131728\n",
            "[66]\ttraining's auc: 0.922614\ttraining's binary_logloss: 0.107479\tvalid_1's auc: 0.832506\tvalid_1's binary_logloss: 0.131759\n",
            "[67]\ttraining's auc: 0.922876\ttraining's binary_logloss: 0.107293\tvalid_1's auc: 0.832492\tvalid_1's binary_logloss: 0.131772\n",
            "[68]\ttraining's auc: 0.923233\ttraining's binary_logloss: 0.107057\tvalid_1's auc: 0.832379\tvalid_1's binary_logloss: 0.131809\n",
            "[69]\ttraining's auc: 0.923531\ttraining's binary_logloss: 0.106852\tvalid_1's auc: 0.832477\tvalid_1's binary_logloss: 0.131811\n",
            "[70]\ttraining's auc: 0.923768\ttraining's binary_logloss: 0.106651\tvalid_1's auc: 0.832147\tvalid_1's binary_logloss: 0.131854\n",
            "[71]\ttraining's auc: 0.924491\ttraining's binary_logloss: 0.106381\tvalid_1's auc: 0.83208\tvalid_1's binary_logloss: 0.13189\n",
            "[72]\ttraining's auc: 0.924722\ttraining's binary_logloss: 0.106226\tvalid_1's auc: 0.832154\tvalid_1's binary_logloss: 0.131894\n",
            "[73]\ttraining's auc: 0.925297\ttraining's binary_logloss: 0.105995\tvalid_1's auc: 0.831875\tvalid_1's binary_logloss: 0.131937\n",
            "[74]\ttraining's auc: 0.925508\ttraining's binary_logloss: 0.105856\tvalid_1's auc: 0.831949\tvalid_1's binary_logloss: 0.131936\n",
            "[75]\ttraining's auc: 0.926556\ttraining's binary_logloss: 0.10555\tvalid_1's auc: 0.831928\tvalid_1's binary_logloss: 0.131928\n",
            "[76]\ttraining's auc: 0.926937\ttraining's binary_logloss: 0.105332\tvalid_1's auc: 0.831754\tvalid_1's binary_logloss: 0.131992\n",
            "[77]\ttraining's auc: 0.927139\ttraining's binary_logloss: 0.105174\tvalid_1's auc: 0.831694\tvalid_1's binary_logloss: 0.132005\n",
            "[78]\ttraining's auc: 0.927763\ttraining's binary_logloss: 0.104878\tvalid_1's auc: 0.831154\tvalid_1's binary_logloss: 0.132123\n",
            "[79]\ttraining's auc: 0.928208\ttraining's binary_logloss: 0.104574\tvalid_1's auc: 0.83119\tvalid_1's binary_logloss: 0.132132\n",
            "[80]\ttraining's auc: 0.928649\ttraining's binary_logloss: 0.104366\tvalid_1's auc: 0.831288\tvalid_1's binary_logloss: 0.13211\n",
            "[81]\ttraining's auc: 0.928945\ttraining's binary_logloss: 0.104186\tvalid_1's auc: 0.831164\tvalid_1's binary_logloss: 0.132147\n",
            "  6%|▌         | 3/50 [01:45<20:25, 26.07s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.15418\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.160501\n",
            "[2]\ttraining's auc: 0.832651\ttraining's binary_logloss: 0.148603\tvalid_1's auc: 0.815296\tvalid_1's binary_logloss: 0.155501\n",
            "[3]\ttraining's auc: 0.840128\ttraining's binary_logloss: 0.144513\tvalid_1's auc: 0.820937\tvalid_1's binary_logloss: 0.152\n",
            "[4]\ttraining's auc: 0.844863\ttraining's binary_logloss: 0.141344\tvalid_1's auc: 0.822708\tvalid_1's binary_logloss: 0.149417\n",
            "[5]\ttraining's auc: 0.849989\ttraining's binary_logloss: 0.138588\tvalid_1's auc: 0.826011\tvalid_1's binary_logloss: 0.147283\n",
            "[6]\ttraining's auc: 0.852259\ttraining's binary_logloss: 0.13633\tvalid_1's auc: 0.827622\tvalid_1's binary_logloss: 0.145579\n",
            "[7]\ttraining's auc: 0.854795\ttraining's binary_logloss: 0.134474\tvalid_1's auc: 0.829108\tvalid_1's binary_logloss: 0.144171\n",
            "[8]\ttraining's auc: 0.857144\ttraining's binary_logloss: 0.13281\tvalid_1's auc: 0.829819\tvalid_1's binary_logloss: 0.143019\n",
            "[9]\ttraining's auc: 0.860313\ttraining's binary_logloss: 0.131294\tvalid_1's auc: 0.830712\tvalid_1's binary_logloss: 0.142039\n",
            "[10]\ttraining's auc: 0.862724\ttraining's binary_logloss: 0.130006\tvalid_1's auc: 0.830942\tvalid_1's binary_logloss: 0.141217\n",
            "[11]\ttraining's auc: 0.866753\ttraining's binary_logloss: 0.128781\tvalid_1's auc: 0.831874\tvalid_1's binary_logloss: 0.140417\n",
            "[12]\ttraining's auc: 0.869292\ttraining's binary_logloss: 0.127708\tvalid_1's auc: 0.83411\tvalid_1's binary_logloss: 0.139793\n",
            "[13]\ttraining's auc: 0.871186\ttraining's binary_logloss: 0.126737\tvalid_1's auc: 0.833584\tvalid_1's binary_logloss: 0.139384\n",
            "[14]\ttraining's auc: 0.873017\ttraining's binary_logloss: 0.12586\tvalid_1's auc: 0.834185\tvalid_1's binary_logloss: 0.138921\n",
            "[15]\ttraining's auc: 0.87419\ttraining's binary_logloss: 0.125096\tvalid_1's auc: 0.835067\tvalid_1's binary_logloss: 0.138567\n",
            "[16]\ttraining's auc: 0.876839\ttraining's binary_logloss: 0.124224\tvalid_1's auc: 0.835247\tvalid_1's binary_logloss: 0.138256\n",
            "[17]\ttraining's auc: 0.878967\ttraining's binary_logloss: 0.123465\tvalid_1's auc: 0.835124\tvalid_1's binary_logloss: 0.138103\n",
            "[18]\ttraining's auc: 0.880887\ttraining's binary_logloss: 0.122781\tvalid_1's auc: 0.835466\tvalid_1's binary_logloss: 0.137808\n",
            "[19]\ttraining's auc: 0.882929\ttraining's binary_logloss: 0.122075\tvalid_1's auc: 0.835255\tvalid_1's binary_logloss: 0.137542\n",
            "[20]\ttraining's auc: 0.884898\ttraining's binary_logloss: 0.121329\tvalid_1's auc: 0.834851\tvalid_1's binary_logloss: 0.137489\n",
            "[21]\ttraining's auc: 0.886867\ttraining's binary_logloss: 0.12066\tvalid_1's auc: 0.835163\tvalid_1's binary_logloss: 0.13731\n",
            "[22]\ttraining's auc: 0.88793\ttraining's binary_logloss: 0.120103\tvalid_1's auc: 0.83567\tvalid_1's binary_logloss: 0.137095\n",
            "[23]\ttraining's auc: 0.88917\ttraining's binary_logloss: 0.119562\tvalid_1's auc: 0.835311\tvalid_1's binary_logloss: 0.137028\n",
            "[24]\ttraining's auc: 0.891127\ttraining's binary_logloss: 0.118892\tvalid_1's auc: 0.835379\tvalid_1's binary_logloss: 0.136985\n",
            "[25]\ttraining's auc: 0.892921\ttraining's binary_logloss: 0.118364\tvalid_1's auc: 0.835097\tvalid_1's binary_logloss: 0.136933\n",
            "[26]\ttraining's auc: 0.893714\ttraining's binary_logloss: 0.117947\tvalid_1's auc: 0.834813\tvalid_1's binary_logloss: 0.136901\n",
            "[27]\ttraining's auc: 0.895523\ttraining's binary_logloss: 0.117419\tvalid_1's auc: 0.834498\tvalid_1's binary_logloss: 0.136874\n",
            "[28]\ttraining's auc: 0.896344\ttraining's binary_logloss: 0.116932\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.13673\n",
            "[29]\ttraining's auc: 0.897387\ttraining's binary_logloss: 0.116488\tvalid_1's auc: 0.834441\tvalid_1's binary_logloss: 0.136736\n",
            "[30]\ttraining's auc: 0.898545\ttraining's binary_logloss: 0.116074\tvalid_1's auc: 0.834645\tvalid_1's binary_logloss: 0.136698\n",
            "[31]\ttraining's auc: 0.900011\ttraining's binary_logloss: 0.115546\tvalid_1's auc: 0.834427\tvalid_1's binary_logloss: 0.136705\n",
            "[32]\ttraining's auc: 0.900994\ttraining's binary_logloss: 0.115131\tvalid_1's auc: 0.834092\tvalid_1's binary_logloss: 0.136758\n",
            "[33]\ttraining's auc: 0.90236\ttraining's binary_logloss: 0.114736\tvalid_1's auc: 0.834195\tvalid_1's binary_logloss: 0.136742\n",
            "[34]\ttraining's auc: 0.903225\ttraining's binary_logloss: 0.114306\tvalid_1's auc: 0.834325\tvalid_1's binary_logloss: 0.136684\n",
            "[35]\ttraining's auc: 0.904529\ttraining's binary_logloss: 0.113813\tvalid_1's auc: 0.834295\tvalid_1's binary_logloss: 0.13665\n",
            "[36]\ttraining's auc: 0.905653\ttraining's binary_logloss: 0.113402\tvalid_1's auc: 0.834424\tvalid_1's binary_logloss: 0.136644\n",
            "[37]\ttraining's auc: 0.906595\ttraining's binary_logloss: 0.113087\tvalid_1's auc: 0.834384\tvalid_1's binary_logloss: 0.136625\n",
            "[38]\ttraining's auc: 0.907558\ttraining's binary_logloss: 0.112723\tvalid_1's auc: 0.834511\tvalid_1's binary_logloss: 0.136626\n",
            "[39]\ttraining's auc: 0.90894\ttraining's binary_logloss: 0.112247\tvalid_1's auc: 0.834493\tvalid_1's binary_logloss: 0.136671\n",
            "[40]\ttraining's auc: 0.909718\ttraining's binary_logloss: 0.111918\tvalid_1's auc: 0.834513\tvalid_1's binary_logloss: 0.136716\n",
            "[41]\ttraining's auc: 0.910256\ttraining's binary_logloss: 0.111619\tvalid_1's auc: 0.834638\tvalid_1's binary_logloss: 0.136709\n",
            "[42]\ttraining's auc: 0.911049\ttraining's binary_logloss: 0.111255\tvalid_1's auc: 0.835153\tvalid_1's binary_logloss: 0.136647\n",
            "[43]\ttraining's auc: 0.911656\ttraining's binary_logloss: 0.110915\tvalid_1's auc: 0.835464\tvalid_1's binary_logloss: 0.136643\n",
            "[44]\ttraining's auc: 0.912393\ttraining's binary_logloss: 0.110601\tvalid_1's auc: 0.835702\tvalid_1's binary_logloss: 0.136604\n",
            "[45]\ttraining's auc: 0.913234\ttraining's binary_logloss: 0.110255\tvalid_1's auc: 0.835733\tvalid_1's binary_logloss: 0.136668\n",
            "[46]\ttraining's auc: 0.913652\ttraining's binary_logloss: 0.109993\tvalid_1's auc: 0.835347\tvalid_1's binary_logloss: 0.136736\n",
            "[47]\ttraining's auc: 0.914051\ttraining's binary_logloss: 0.109723\tvalid_1's auc: 0.835142\tvalid_1's binary_logloss: 0.136793\n",
            "[48]\ttraining's auc: 0.915259\ttraining's binary_logloss: 0.109298\tvalid_1's auc: 0.835072\tvalid_1's binary_logloss: 0.136822\n",
            "[49]\ttraining's auc: 0.915912\ttraining's binary_logloss: 0.109024\tvalid_1's auc: 0.834983\tvalid_1's binary_logloss: 0.13686\n",
            "[50]\ttraining's auc: 0.916668\ttraining's binary_logloss: 0.108688\tvalid_1's auc: 0.835038\tvalid_1's binary_logloss: 0.136843\n",
            "[51]\ttraining's auc: 0.917539\ttraining's binary_logloss: 0.108414\tvalid_1's auc: 0.835107\tvalid_1's binary_logloss: 0.136834\n",
            "[52]\ttraining's auc: 0.917741\ttraining's binary_logloss: 0.108234\tvalid_1's auc: 0.835066\tvalid_1's binary_logloss: 0.136845\n",
            "[53]\ttraining's auc: 0.918367\ttraining's binary_logloss: 0.107909\tvalid_1's auc: 0.835009\tvalid_1's binary_logloss: 0.13686\n",
            "[54]\ttraining's auc: 0.919029\ttraining's binary_logloss: 0.107617\tvalid_1's auc: 0.834957\tvalid_1's binary_logloss: 0.136888\n",
            "[55]\ttraining's auc: 0.919516\ttraining's binary_logloss: 0.107415\tvalid_1's auc: 0.83487\tvalid_1's binary_logloss: 0.136945\n",
            "[56]\ttraining's auc: 0.920246\ttraining's binary_logloss: 0.10709\tvalid_1's auc: 0.835156\tvalid_1's binary_logloss: 0.136915\n",
            "[57]\ttraining's auc: 0.920612\ttraining's binary_logloss: 0.106871\tvalid_1's auc: 0.835077\tvalid_1's binary_logloss: 0.136911\n",
            "[58]\ttraining's auc: 0.920985\ttraining's binary_logloss: 0.106629\tvalid_1's auc: 0.834943\tvalid_1's binary_logloss: 0.136931\n",
            "[59]\ttraining's auc: 0.921758\ttraining's binary_logloss: 0.106283\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.137017\n",
            "[60]\ttraining's auc: 0.922041\ttraining's binary_logloss: 0.106063\tvalid_1's auc: 0.83467\tvalid_1's binary_logloss: 0.137043\n",
            "[61]\ttraining's auc: 0.922298\ttraining's binary_logloss: 0.105873\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.137046\n",
            "[62]\ttraining's auc: 0.922576\ttraining's binary_logloss: 0.105662\tvalid_1's auc: 0.834597\tvalid_1's binary_logloss: 0.137113\n",
            "[63]\ttraining's auc: 0.923285\ttraining's binary_logloss: 0.105322\tvalid_1's auc: 0.834441\tvalid_1's binary_logloss: 0.13719\n",
            "[64]\ttraining's auc: 0.924224\ttraining's binary_logloss: 0.104989\tvalid_1's auc: 0.834488\tvalid_1's binary_logloss: 0.137189\n",
            "[65]\ttraining's auc: 0.924605\ttraining's binary_logloss: 0.104759\tvalid_1's auc: 0.834626\tvalid_1's binary_logloss: 0.137174\n",
            "[66]\ttraining's auc: 0.925556\ttraining's binary_logloss: 0.104423\tvalid_1's auc: 0.834747\tvalid_1's binary_logloss: 0.137135\n",
            "[67]\ttraining's auc: 0.926143\ttraining's binary_logloss: 0.104173\tvalid_1's auc: 0.834488\tvalid_1's binary_logloss: 0.137163\n",
            "[68]\ttraining's auc: 0.926674\ttraining's binary_logloss: 0.103859\tvalid_1's auc: 0.834267\tvalid_1's binary_logloss: 0.137194\n",
            "[69]\ttraining's auc: 0.926864\ttraining's binary_logloss: 0.103711\tvalid_1's auc: 0.834129\tvalid_1's binary_logloss: 0.137244\n",
            "[70]\ttraining's auc: 0.927237\ttraining's binary_logloss: 0.103503\tvalid_1's auc: 0.833773\tvalid_1's binary_logloss: 0.137314\n",
            "[71]\ttraining's auc: 0.927873\ttraining's binary_logloss: 0.103208\tvalid_1's auc: 0.833671\tvalid_1's binary_logloss: 0.137364\n",
            "[72]\ttraining's auc: 0.928423\ttraining's binary_logloss: 0.102913\tvalid_1's auc: 0.833701\tvalid_1's binary_logloss: 0.137339\n",
            "[73]\ttraining's auc: 0.928651\ttraining's binary_logloss: 0.102745\tvalid_1's auc: 0.8336\tvalid_1's binary_logloss: 0.137391\n",
            "[74]\ttraining's auc: 0.928874\ttraining's binary_logloss: 0.102591\tvalid_1's auc: 0.833481\tvalid_1's binary_logloss: 0.137399\n",
            "  8%|▊         | 4/50 [01:50<22:23, 29.20s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.159015\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.160824\n",
            "[2]\ttraining's auc: 0.832674\ttraining's binary_logloss: 0.154901\tvalid_1's auc: 0.805912\tvalid_1's binary_logloss: 0.157638\n",
            "[3]\ttraining's auc: 0.834009\ttraining's binary_logloss: 0.151623\tvalid_1's auc: 0.806799\tvalid_1's binary_logloss: 0.155131\n",
            "[4]\ttraining's auc: 0.839352\ttraining's binary_logloss: 0.148835\tvalid_1's auc: 0.810761\tvalid_1's binary_logloss: 0.152909\n",
            "[5]\ttraining's auc: 0.844423\ttraining's binary_logloss: 0.14647\tvalid_1's auc: 0.813451\tvalid_1's binary_logloss: 0.151058\n",
            "[6]\ttraining's auc: 0.847033\ttraining's binary_logloss: 0.144412\tvalid_1's auc: 0.816639\tvalid_1's binary_logloss: 0.149503\n",
            "[7]\ttraining's auc: 0.84792\ttraining's binary_logloss: 0.14261\tvalid_1's auc: 0.818159\tvalid_1's binary_logloss: 0.148088\n",
            "[8]\ttraining's auc: 0.850782\ttraining's binary_logloss: 0.140949\tvalid_1's auc: 0.82017\tvalid_1's binary_logloss: 0.146897\n",
            "[9]\ttraining's auc: 0.85176\ttraining's binary_logloss: 0.139521\tvalid_1's auc: 0.821391\tvalid_1's binary_logloss: 0.145823\n",
            "[10]\ttraining's auc: 0.852617\ttraining's binary_logloss: 0.138158\tvalid_1's auc: 0.821442\tvalid_1's binary_logloss: 0.14493\n",
            "[11]\ttraining's auc: 0.85408\ttraining's binary_logloss: 0.13691\tvalid_1's auc: 0.821736\tvalid_1's binary_logloss: 0.144071\n",
            "[12]\ttraining's auc: 0.856712\ttraining's binary_logloss: 0.135797\tvalid_1's auc: 0.822249\tvalid_1's binary_logloss: 0.14328\n",
            "[13]\ttraining's auc: 0.859586\ttraining's binary_logloss: 0.13472\tvalid_1's auc: 0.823116\tvalid_1's binary_logloss: 0.142579\n",
            "[14]\ttraining's auc: 0.861224\ttraining's binary_logloss: 0.133725\tvalid_1's auc: 0.823381\tvalid_1's binary_logloss: 0.141974\n",
            "[15]\ttraining's auc: 0.861832\ttraining's binary_logloss: 0.132856\tvalid_1's auc: 0.823941\tvalid_1's binary_logloss: 0.141351\n",
            "[16]\ttraining's auc: 0.864411\ttraining's binary_logloss: 0.132033\tvalid_1's auc: 0.825357\tvalid_1's binary_logloss: 0.140802\n",
            "[17]\ttraining's auc: 0.865451\ttraining's binary_logloss: 0.13127\tvalid_1's auc: 0.826354\tvalid_1's binary_logloss: 0.14038\n",
            "[18]\ttraining's auc: 0.867066\ttraining's binary_logloss: 0.130542\tvalid_1's auc: 0.826792\tvalid_1's binary_logloss: 0.14002\n",
            "[19]\ttraining's auc: 0.868033\ttraining's binary_logloss: 0.129855\tvalid_1's auc: 0.826811\tvalid_1's binary_logloss: 0.139681\n",
            "[20]\ttraining's auc: 0.869453\ttraining's binary_logloss: 0.12914\tvalid_1's auc: 0.827143\tvalid_1's binary_logloss: 0.139334\n",
            "[21]\ttraining's auc: 0.870802\ttraining's binary_logloss: 0.128524\tvalid_1's auc: 0.827243\tvalid_1's binary_logloss: 0.13904\n",
            "[22]\ttraining's auc: 0.871843\ttraining's binary_logloss: 0.127923\tvalid_1's auc: 0.827928\tvalid_1's binary_logloss: 0.138668\n",
            "[23]\ttraining's auc: 0.872591\ttraining's binary_logloss: 0.127418\tvalid_1's auc: 0.827928\tvalid_1's binary_logloss: 0.138405\n",
            "[24]\ttraining's auc: 0.873687\ttraining's binary_logloss: 0.126845\tvalid_1's auc: 0.828215\tvalid_1's binary_logloss: 0.138156\n",
            "[25]\ttraining's auc: 0.874911\ttraining's binary_logloss: 0.126301\tvalid_1's auc: 0.828526\tvalid_1's binary_logloss: 0.137914\n",
            "[26]\ttraining's auc: 0.876232\ttraining's binary_logloss: 0.125787\tvalid_1's auc: 0.828715\tvalid_1's binary_logloss: 0.137753\n",
            "[27]\ttraining's auc: 0.878061\ttraining's binary_logloss: 0.125307\tvalid_1's auc: 0.828498\tvalid_1's binary_logloss: 0.137599\n",
            "[28]\ttraining's auc: 0.878517\ttraining's binary_logloss: 0.124888\tvalid_1's auc: 0.828669\tvalid_1's binary_logloss: 0.137438\n",
            "[29]\ttraining's auc: 0.87932\ttraining's binary_logloss: 0.124458\tvalid_1's auc: 0.829337\tvalid_1's binary_logloss: 0.137268\n",
            "[30]\ttraining's auc: 0.87997\ttraining's binary_logloss: 0.124039\tvalid_1's auc: 0.829496\tvalid_1's binary_logloss: 0.137103\n",
            "[31]\ttraining's auc: 0.881229\ttraining's binary_logloss: 0.123596\tvalid_1's auc: 0.829444\tvalid_1's binary_logloss: 0.136979\n",
            "[32]\ttraining's auc: 0.882086\ttraining's binary_logloss: 0.123199\tvalid_1's auc: 0.829708\tvalid_1's binary_logloss: 0.136856\n",
            "[33]\ttraining's auc: 0.88333\ttraining's binary_logloss: 0.122787\tvalid_1's auc: 0.829556\tvalid_1's binary_logloss: 0.136767\n",
            "[34]\ttraining's auc: 0.884361\ttraining's binary_logloss: 0.122404\tvalid_1's auc: 0.829445\tvalid_1's binary_logloss: 0.136712\n",
            "[35]\ttraining's auc: 0.884707\ttraining's binary_logloss: 0.122077\tvalid_1's auc: 0.829701\tvalid_1's binary_logloss: 0.136619\n",
            "[36]\ttraining's auc: 0.885334\ttraining's binary_logloss: 0.121739\tvalid_1's auc: 0.829562\tvalid_1's binary_logloss: 0.136559\n",
            "[37]\ttraining's auc: 0.886631\ttraining's binary_logloss: 0.121311\tvalid_1's auc: 0.82968\tvalid_1's binary_logloss: 0.136508\n",
            "[38]\ttraining's auc: 0.887985\ttraining's binary_logloss: 0.120939\tvalid_1's auc: 0.830314\tvalid_1's binary_logloss: 0.136367\n",
            "[39]\ttraining's auc: 0.888805\ttraining's binary_logloss: 0.120593\tvalid_1's auc: 0.830249\tvalid_1's binary_logloss: 0.136341\n",
            "[40]\ttraining's auc: 0.890256\ttraining's binary_logloss: 0.120207\tvalid_1's auc: 0.830203\tvalid_1's binary_logloss: 0.136298\n",
            "[41]\ttraining's auc: 0.890825\ttraining's binary_logloss: 0.119928\tvalid_1's auc: 0.830174\tvalid_1's binary_logloss: 0.136242\n",
            "[42]\ttraining's auc: 0.891412\ttraining's binary_logloss: 0.119646\tvalid_1's auc: 0.829788\tvalid_1's binary_logloss: 0.136265\n",
            "[43]\ttraining's auc: 0.892441\ttraining's binary_logloss: 0.119314\tvalid_1's auc: 0.83008\tvalid_1's binary_logloss: 0.136181\n",
            "[44]\ttraining's auc: 0.893271\ttraining's binary_logloss: 0.119015\tvalid_1's auc: 0.830065\tvalid_1's binary_logloss: 0.136126\n",
            "[45]\ttraining's auc: 0.893905\ttraining's binary_logloss: 0.118733\tvalid_1's auc: 0.830027\tvalid_1's binary_logloss: 0.136067\n",
            "[46]\ttraining's auc: 0.894603\ttraining's binary_logloss: 0.118469\tvalid_1's auc: 0.830426\tvalid_1's binary_logloss: 0.135985\n",
            "[47]\ttraining's auc: 0.895652\ttraining's binary_logloss: 0.11817\tvalid_1's auc: 0.83053\tvalid_1's binary_logloss: 0.135989\n",
            "[48]\ttraining's auc: 0.897245\ttraining's binary_logloss: 0.117831\tvalid_1's auc: 0.831105\tvalid_1's binary_logloss: 0.135879\n",
            "[49]\ttraining's auc: 0.897732\ttraining's binary_logloss: 0.117576\tvalid_1's auc: 0.831143\tvalid_1's binary_logloss: 0.135866\n",
            "[50]\ttraining's auc: 0.898694\ttraining's binary_logloss: 0.117307\tvalid_1's auc: 0.831566\tvalid_1's binary_logloss: 0.135771\n",
            "[51]\ttraining's auc: 0.899247\ttraining's binary_logloss: 0.117058\tvalid_1's auc: 0.831348\tvalid_1's binary_logloss: 0.135792\n",
            "[52]\ttraining's auc: 0.899689\ttraining's binary_logloss: 0.116811\tvalid_1's auc: 0.831319\tvalid_1's binary_logloss: 0.135788\n",
            "[53]\ttraining's auc: 0.900232\ttraining's binary_logloss: 0.116572\tvalid_1's auc: 0.831289\tvalid_1's binary_logloss: 0.135762\n",
            "[54]\ttraining's auc: 0.900993\ttraining's binary_logloss: 0.116313\tvalid_1's auc: 0.830989\tvalid_1's binary_logloss: 0.13579\n",
            "[55]\ttraining's auc: 0.901696\ttraining's binary_logloss: 0.116079\tvalid_1's auc: 0.83134\tvalid_1's binary_logloss: 0.13571\n",
            "[56]\ttraining's auc: 0.902187\ttraining's binary_logloss: 0.115855\tvalid_1's auc: 0.831328\tvalid_1's binary_logloss: 0.135695\n",
            "[57]\ttraining's auc: 0.902712\ttraining's binary_logloss: 0.115629\tvalid_1's auc: 0.831548\tvalid_1's binary_logloss: 0.135685\n",
            "[58]\ttraining's auc: 0.903177\ttraining's binary_logloss: 0.115403\tvalid_1's auc: 0.831705\tvalid_1's binary_logloss: 0.135641\n",
            "[59]\ttraining's auc: 0.904069\ttraining's binary_logloss: 0.115194\tvalid_1's auc: 0.831555\tvalid_1's binary_logloss: 0.135651\n",
            "[60]\ttraining's auc: 0.904428\ttraining's binary_logloss: 0.114963\tvalid_1's auc: 0.83168\tvalid_1's binary_logloss: 0.13565\n",
            "[61]\ttraining's auc: 0.904936\ttraining's binary_logloss: 0.114772\tvalid_1's auc: 0.831804\tvalid_1's binary_logloss: 0.135639\n",
            "[62]\ttraining's auc: 0.905342\ttraining's binary_logloss: 0.114545\tvalid_1's auc: 0.831793\tvalid_1's binary_logloss: 0.135639\n",
            "[63]\ttraining's auc: 0.906043\ttraining's binary_logloss: 0.114288\tvalid_1's auc: 0.831665\tvalid_1's binary_logloss: 0.135648\n",
            "[64]\ttraining's auc: 0.906508\ttraining's binary_logloss: 0.114092\tvalid_1's auc: 0.831737\tvalid_1's binary_logloss: 0.135657\n",
            "[65]\ttraining's auc: 0.907102\ttraining's binary_logloss: 0.113879\tvalid_1's auc: 0.831562\tvalid_1's binary_logloss: 0.135677\n",
            "[66]\ttraining's auc: 0.907532\ttraining's binary_logloss: 0.113669\tvalid_1's auc: 0.831583\tvalid_1's binary_logloss: 0.135669\n",
            "[67]\ttraining's auc: 0.908318\ttraining's binary_logloss: 0.113438\tvalid_1's auc: 0.831443\tvalid_1's binary_logloss: 0.135699\n",
            "[68]\ttraining's auc: 0.908913\ttraining's binary_logloss: 0.113209\tvalid_1's auc: 0.831547\tvalid_1's binary_logloss: 0.135716\n",
            "[69]\ttraining's auc: 0.909358\ttraining's binary_logloss: 0.113013\tvalid_1's auc: 0.831629\tvalid_1's binary_logloss: 0.135692\n",
            "[70]\ttraining's auc: 0.909772\ttraining's binary_logloss: 0.112822\tvalid_1's auc: 0.831639\tvalid_1's binary_logloss: 0.135697\n",
            "[71]\ttraining's auc: 0.910263\ttraining's binary_logloss: 0.112602\tvalid_1's auc: 0.831487\tvalid_1's binary_logloss: 0.135728\n",
            "[72]\ttraining's auc: 0.910683\ttraining's binary_logloss: 0.112376\tvalid_1's auc: 0.831317\tvalid_1's binary_logloss: 0.135785\n",
            "[73]\ttraining's auc: 0.911062\ttraining's binary_logloss: 0.112184\tvalid_1's auc: 0.831315\tvalid_1's binary_logloss: 0.135781\n",
            "[74]\ttraining's auc: 0.911643\ttraining's binary_logloss: 0.112022\tvalid_1's auc: 0.83137\tvalid_1's binary_logloss: 0.135775\n",
            "[75]\ttraining's auc: 0.912073\ttraining's binary_logloss: 0.111823\tvalid_1's auc: 0.83132\tvalid_1's binary_logloss: 0.135785\n",
            "[76]\ttraining's auc: 0.912599\ttraining's binary_logloss: 0.111626\tvalid_1's auc: 0.831205\tvalid_1's binary_logloss: 0.135794\n",
            "[77]\ttraining's auc: 0.913216\ttraining's binary_logloss: 0.111396\tvalid_1's auc: 0.830948\tvalid_1's binary_logloss: 0.135861\n",
            "[78]\ttraining's auc: 0.913501\ttraining's binary_logloss: 0.111234\tvalid_1's auc: 0.830887\tvalid_1's binary_logloss: 0.135896\n",
            "[79]\ttraining's auc: 0.913687\ttraining's binary_logloss: 0.111107\tvalid_1's auc: 0.830782\tvalid_1's binary_logloss: 0.135925\n",
            "[80]\ttraining's auc: 0.914566\ttraining's binary_logloss: 0.110933\tvalid_1's auc: 0.830731\tvalid_1's binary_logloss: 0.135933\n",
            "[81]\ttraining's auc: 0.914834\ttraining's binary_logloss: 0.110787\tvalid_1's auc: 0.830613\tvalid_1's binary_logloss: 0.13597\n",
            "[82]\ttraining's auc: 0.915127\ttraining's binary_logloss: 0.110642\tvalid_1's auc: 0.8305\tvalid_1's binary_logloss: 0.135999\n",
            "[83]\ttraining's auc: 0.915512\ttraining's binary_logloss: 0.110475\tvalid_1's auc: 0.83053\tvalid_1's binary_logloss: 0.136003\n",
            "[84]\ttraining's auc: 0.91598\ttraining's binary_logloss: 0.110264\tvalid_1's auc: 0.830301\tvalid_1's binary_logloss: 0.136038\n",
            "[85]\ttraining's auc: 0.91657\ttraining's binary_logloss: 0.110102\tvalid_1's auc: 0.830222\tvalid_1's binary_logloss: 0.136066\n",
            "[86]\ttraining's auc: 0.916829\ttraining's binary_logloss: 0.109934\tvalid_1's auc: 0.829962\tvalid_1's binary_logloss: 0.1361\n",
            "[87]\ttraining's auc: 0.917069\ttraining's binary_logloss: 0.109813\tvalid_1's auc: 0.829799\tvalid_1's binary_logloss: 0.136136\n",
            "[88]\ttraining's auc: 0.917394\ttraining's binary_logloss: 0.109656\tvalid_1's auc: 0.829903\tvalid_1's binary_logloss: 0.136139\n",
            "[89]\ttraining's auc: 0.917791\ttraining's binary_logloss: 0.109485\tvalid_1's auc: 0.830026\tvalid_1's binary_logloss: 0.136133\n",
            "[90]\ttraining's auc: 0.918177\ttraining's binary_logloss: 0.109322\tvalid_1's auc: 0.830022\tvalid_1's binary_logloss: 0.136162\n",
            "[91]\ttraining's auc: 0.918286\ttraining's binary_logloss: 0.109211\tvalid_1's auc: 0.829786\tvalid_1's binary_logloss: 0.136222\n",
            "  8%|▊         | 4/50 [02:12<22:23, 29.20s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.161413\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156486\n",
            "[2]\ttraining's auc: 0.826862\ttraining's binary_logloss: 0.157304\tvalid_1's auc: 0.817438\tvalid_1's binary_logloss: 0.153101\n",
            "[3]\ttraining's auc: 0.833105\ttraining's binary_logloss: 0.15392\tvalid_1's auc: 0.819611\tvalid_1's binary_logloss: 0.150461\n",
            "[4]\ttraining's auc: 0.835151\ttraining's binary_logloss: 0.151175\tvalid_1's auc: 0.820014\tvalid_1's binary_logloss: 0.148294\n",
            "[5]\ttraining's auc: 0.840137\ttraining's binary_logloss: 0.148814\tvalid_1's auc: 0.823417\tvalid_1's binary_logloss: 0.146516\n",
            "[6]\ttraining's auc: 0.84506\ttraining's binary_logloss: 0.146764\tvalid_1's auc: 0.825862\tvalid_1's binary_logloss: 0.144973\n",
            "[7]\ttraining's auc: 0.849207\ttraining's binary_logloss: 0.144882\tvalid_1's auc: 0.828393\tvalid_1's binary_logloss: 0.143654\n",
            "[8]\ttraining's auc: 0.850137\ttraining's binary_logloss: 0.143217\tvalid_1's auc: 0.828328\tvalid_1's binary_logloss: 0.142435\n",
            "[9]\ttraining's auc: 0.85294\ttraining's binary_logloss: 0.141727\tvalid_1's auc: 0.82913\tvalid_1's binary_logloss: 0.141359\n",
            "[10]\ttraining's auc: 0.854626\ttraining's binary_logloss: 0.140359\tvalid_1's auc: 0.829661\tvalid_1's binary_logloss: 0.140399\n",
            "[11]\ttraining's auc: 0.857329\ttraining's binary_logloss: 0.139117\tvalid_1's auc: 0.831591\tvalid_1's binary_logloss: 0.139515\n",
            "[12]\ttraining's auc: 0.857831\ttraining's binary_logloss: 0.138007\tvalid_1's auc: 0.832778\tvalid_1's binary_logloss: 0.138665\n",
            "[13]\ttraining's auc: 0.858695\ttraining's binary_logloss: 0.136967\tvalid_1's auc: 0.832874\tvalid_1's binary_logloss: 0.137954\n",
            "[14]\ttraining's auc: 0.860296\ttraining's binary_logloss: 0.13597\tvalid_1's auc: 0.832656\tvalid_1's binary_logloss: 0.137366\n",
            "[15]\ttraining's auc: 0.861286\ttraining's binary_logloss: 0.135\tvalid_1's auc: 0.832906\tvalid_1's binary_logloss: 0.136799\n",
            "[16]\ttraining's auc: 0.863071\ttraining's binary_logloss: 0.134197\tvalid_1's auc: 0.83392\tvalid_1's binary_logloss: 0.13628\n",
            "[17]\ttraining's auc: 0.865557\ttraining's binary_logloss: 0.133387\tvalid_1's auc: 0.834539\tvalid_1's binary_logloss: 0.13582\n",
            "[18]\ttraining's auc: 0.867331\ttraining's binary_logloss: 0.132634\tvalid_1's auc: 0.83488\tvalid_1's binary_logloss: 0.13547\n",
            "[19]\ttraining's auc: 0.868828\ttraining's binary_logloss: 0.131908\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.135063\n",
            "[20]\ttraining's auc: 0.870522\ttraining's binary_logloss: 0.13121\tvalid_1's auc: 0.835349\tvalid_1's binary_logloss: 0.134746\n",
            "[21]\ttraining's auc: 0.871215\ttraining's binary_logloss: 0.130595\tvalid_1's auc: 0.835264\tvalid_1's binary_logloss: 0.134423\n",
            "[22]\ttraining's auc: 0.872484\ttraining's binary_logloss: 0.129965\tvalid_1's auc: 0.835023\tvalid_1's binary_logloss: 0.134133\n",
            "[23]\ttraining's auc: 0.873125\ttraining's binary_logloss: 0.129395\tvalid_1's auc: 0.834758\tvalid_1's binary_logloss: 0.133847\n",
            "[24]\ttraining's auc: 0.873907\ttraining's binary_logloss: 0.128883\tvalid_1's auc: 0.834692\tvalid_1's binary_logloss: 0.133629\n",
            "[25]\ttraining's auc: 0.874484\ttraining's binary_logloss: 0.128351\tvalid_1's auc: 0.834158\tvalid_1's binary_logloss: 0.133429\n",
            "[26]\ttraining's auc: 0.87549\ttraining's binary_logloss: 0.127814\tvalid_1's auc: 0.834041\tvalid_1's binary_logloss: 0.133248\n",
            "[27]\ttraining's auc: 0.876546\ttraining's binary_logloss: 0.127352\tvalid_1's auc: 0.834037\tvalid_1's binary_logloss: 0.13307\n",
            "[28]\ttraining's auc: 0.877426\ttraining's binary_logloss: 0.126883\tvalid_1's auc: 0.833933\tvalid_1's binary_logloss: 0.132899\n",
            "[29]\ttraining's auc: 0.878261\ttraining's binary_logloss: 0.126429\tvalid_1's auc: 0.834018\tvalid_1's binary_logloss: 0.132722\n",
            "[30]\ttraining's auc: 0.878584\ttraining's binary_logloss: 0.126033\tvalid_1's auc: 0.834275\tvalid_1's binary_logloss: 0.132564\n",
            "[31]\ttraining's auc: 0.879313\ttraining's binary_logloss: 0.125616\tvalid_1's auc: 0.834351\tvalid_1's binary_logloss: 0.132412\n",
            "[32]\ttraining's auc: 0.880136\ttraining's binary_logloss: 0.125208\tvalid_1's auc: 0.83403\tvalid_1's binary_logloss: 0.132313\n",
            "[33]\ttraining's auc: 0.880987\ttraining's binary_logloss: 0.124805\tvalid_1's auc: 0.834654\tvalid_1's binary_logloss: 0.132167\n",
            "[34]\ttraining's auc: 0.882025\ttraining's binary_logloss: 0.124426\tvalid_1's auc: 0.834664\tvalid_1's binary_logloss: 0.132087\n",
            "[35]\ttraining's auc: 0.882818\ttraining's binary_logloss: 0.124074\tvalid_1's auc: 0.834642\tvalid_1's binary_logloss: 0.132\n",
            "[36]\ttraining's auc: 0.883733\ttraining's binary_logloss: 0.123762\tvalid_1's auc: 0.834743\tvalid_1's binary_logloss: 0.131928\n",
            "[37]\ttraining's auc: 0.884313\ttraining's binary_logloss: 0.123442\tvalid_1's auc: 0.835047\tvalid_1's binary_logloss: 0.131843\n",
            "[38]\ttraining's auc: 0.885144\ttraining's binary_logloss: 0.123108\tvalid_1's auc: 0.834849\tvalid_1's binary_logloss: 0.131773\n",
            "[39]\ttraining's auc: 0.8856\ttraining's binary_logloss: 0.122813\tvalid_1's auc: 0.835157\tvalid_1's binary_logloss: 0.131686\n",
            "[40]\ttraining's auc: 0.886088\ttraining's binary_logloss: 0.122485\tvalid_1's auc: 0.835147\tvalid_1's binary_logloss: 0.131629\n",
            "[41]\ttraining's auc: 0.887303\ttraining's binary_logloss: 0.122148\tvalid_1's auc: 0.835188\tvalid_1's binary_logloss: 0.131558\n",
            "[42]\ttraining's auc: 0.88822\ttraining's binary_logloss: 0.121835\tvalid_1's auc: 0.835186\tvalid_1's binary_logloss: 0.131495\n",
            "[43]\ttraining's auc: 0.888806\ttraining's binary_logloss: 0.121525\tvalid_1's auc: 0.835443\tvalid_1's binary_logloss: 0.131422\n",
            "[44]\ttraining's auc: 0.889759\ttraining's binary_logloss: 0.12124\tvalid_1's auc: 0.835634\tvalid_1's binary_logloss: 0.131343\n",
            "[45]\ttraining's auc: 0.890367\ttraining's binary_logloss: 0.120993\tvalid_1's auc: 0.835656\tvalid_1's binary_logloss: 0.131284\n",
            "[46]\ttraining's auc: 0.890833\ttraining's binary_logloss: 0.120741\tvalid_1's auc: 0.83551\tvalid_1's binary_logloss: 0.13127\n",
            "[47]\ttraining's auc: 0.891662\ttraining's binary_logloss: 0.120469\tvalid_1's auc: 0.83551\tvalid_1's binary_logloss: 0.131253\n",
            "[48]\ttraining's auc: 0.891941\ttraining's binary_logloss: 0.120234\tvalid_1's auc: 0.835358\tvalid_1's binary_logloss: 0.131229\n",
            "[49]\ttraining's auc: 0.892379\ttraining's binary_logloss: 0.120004\tvalid_1's auc: 0.835402\tvalid_1's binary_logloss: 0.131179\n",
            "  8%|▊         | 4/50 [02:21<22:23, 29.20s/trial, best loss: -0.8345991277002364]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.157893\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.163808\n",
            "[2]\ttraining's auc: 0.831466\ttraining's binary_logloss: 0.153922\tvalid_1's auc: 0.814406\tvalid_1's binary_logloss: 0.16024\n",
            "[3]\ttraining's auc: 0.834655\ttraining's binary_logloss: 0.150782\tvalid_1's auc: 0.816009\tvalid_1's binary_logloss: 0.157411\n",
            "[4]\ttraining's auc: 0.838788\ttraining's binary_logloss: 0.148159\tvalid_1's auc: 0.819092\tvalid_1's binary_logloss: 0.15506\n",
            "[5]\ttraining's auc: 0.842444\ttraining's binary_logloss: 0.145867\tvalid_1's auc: 0.820523\tvalid_1's binary_logloss: 0.153014\n",
            "[6]\ttraining's auc: 0.848455\ttraining's binary_logloss: 0.143741\tvalid_1's auc: 0.825186\tvalid_1's binary_logloss: 0.151322\n",
            "[7]\ttraining's auc: 0.85077\ttraining's binary_logloss: 0.141974\tvalid_1's auc: 0.826415\tvalid_1's binary_logloss: 0.14984\n",
            "[8]\ttraining's auc: 0.852624\ttraining's binary_logloss: 0.140266\tvalid_1's auc: 0.827403\tvalid_1's binary_logloss: 0.14854\n",
            "[9]\ttraining's auc: 0.853633\ttraining's binary_logloss: 0.13882\tvalid_1's auc: 0.827724\tvalid_1's binary_logloss: 0.147335\n",
            "[10]\ttraining's auc: 0.85434\ttraining's binary_logloss: 0.137481\tvalid_1's auc: 0.829004\tvalid_1's binary_logloss: 0.146335\n",
            "[11]\ttraining's auc: 0.855254\ttraining's binary_logloss: 0.136281\tvalid_1's auc: 0.829401\tvalid_1's binary_logloss: 0.145424\n",
            "[12]\ttraining's auc: 0.856774\ttraining's binary_logloss: 0.135195\tvalid_1's auc: 0.830874\tvalid_1's binary_logloss: 0.144584\n",
            "[13]\ttraining's auc: 0.858926\ttraining's binary_logloss: 0.134159\tvalid_1's auc: 0.830947\tvalid_1's binary_logloss: 0.143862\n",
            "[14]\ttraining's auc: 0.859179\ttraining's binary_logloss: 0.13324\tvalid_1's auc: 0.831602\tvalid_1's binary_logloss: 0.143169\n",
            "[15]\ttraining's auc: 0.859845\ttraining's binary_logloss: 0.132366\tvalid_1's auc: 0.831711\tvalid_1's binary_logloss: 0.142618\n",
            "[16]\ttraining's auc: 0.862232\ttraining's binary_logloss: 0.131533\tvalid_1's auc: 0.831865\tvalid_1's binary_logloss: 0.142085\n",
            "[17]\ttraining's auc: 0.863627\ttraining's binary_logloss: 0.130738\tvalid_1's auc: 0.831829\tvalid_1's binary_logloss: 0.141591\n",
            "[18]\ttraining's auc: 0.865027\ttraining's binary_logloss: 0.130041\tvalid_1's auc: 0.832029\tvalid_1's binary_logloss: 0.14113\n",
            "[19]\ttraining's auc: 0.867229\ttraining's binary_logloss: 0.129331\tvalid_1's auc: 0.832427\tvalid_1's binary_logloss: 0.140699\n",
            "[20]\ttraining's auc: 0.868663\ttraining's binary_logloss: 0.128674\tvalid_1's auc: 0.832285\tvalid_1's binary_logloss: 0.140375\n",
            "[21]\ttraining's auc: 0.87081\ttraining's binary_logloss: 0.127992\tvalid_1's auc: 0.833543\tvalid_1's binary_logloss: 0.140011\n",
            "[22]\ttraining's auc: 0.871788\ttraining's binary_logloss: 0.127432\tvalid_1's auc: 0.834328\tvalid_1's binary_logloss: 0.139684\n",
            "[23]\ttraining's auc: 0.873325\ttraining's binary_logloss: 0.12685\tvalid_1's auc: 0.834542\tvalid_1's binary_logloss: 0.139378\n",
            "[24]\ttraining's auc: 0.874644\ttraining's binary_logloss: 0.126349\tvalid_1's auc: 0.835167\tvalid_1's binary_logloss: 0.13909\n",
            "[25]\ttraining's auc: 0.875113\ttraining's binary_logloss: 0.125837\tvalid_1's auc: 0.835365\tvalid_1's binary_logloss: 0.138832\n",
            "[26]\ttraining's auc: 0.876409\ttraining's binary_logloss: 0.125331\tvalid_1's auc: 0.835742\tvalid_1's binary_logloss: 0.138604\n",
            "[27]\ttraining's auc: 0.877773\ttraining's binary_logloss: 0.124818\tvalid_1's auc: 0.835958\tvalid_1's binary_logloss: 0.138402\n",
            "[28]\ttraining's auc: 0.87959\ttraining's binary_logloss: 0.124299\tvalid_1's auc: 0.836128\tvalid_1's binary_logloss: 0.138201\n",
            "[29]\ttraining's auc: 0.880536\ttraining's binary_logloss: 0.123838\tvalid_1's auc: 0.83622\tvalid_1's binary_logloss: 0.138017\n",
            "[30]\ttraining's auc: 0.882081\ttraining's binary_logloss: 0.12337\tvalid_1's auc: 0.836257\tvalid_1's binary_logloss: 0.137875\n",
            "[31]\ttraining's auc: 0.882753\ttraining's binary_logloss: 0.122956\tvalid_1's auc: 0.836212\tvalid_1's binary_logloss: 0.137726\n",
            "[32]\ttraining's auc: 0.88453\ttraining's binary_logloss: 0.122486\tvalid_1's auc: 0.835907\tvalid_1's binary_logloss: 0.137605\n",
            "[33]\ttraining's auc: 0.885035\ttraining's binary_logloss: 0.12211\tvalid_1's auc: 0.835962\tvalid_1's binary_logloss: 0.137503\n",
            "[34]\ttraining's auc: 0.886076\ttraining's binary_logloss: 0.121714\tvalid_1's auc: 0.835921\tvalid_1's binary_logloss: 0.137399\n",
            "[35]\ttraining's auc: 0.887161\ttraining's binary_logloss: 0.121288\tvalid_1's auc: 0.836106\tvalid_1's binary_logloss: 0.137346\n",
            "[36]\ttraining's auc: 0.887917\ttraining's binary_logloss: 0.120937\tvalid_1's auc: 0.836304\tvalid_1's binary_logloss: 0.137255\n",
            "[37]\ttraining's auc: 0.88846\ttraining's binary_logloss: 0.120599\tvalid_1's auc: 0.835854\tvalid_1's binary_logloss: 0.137209\n",
            "[38]\ttraining's auc: 0.889551\ttraining's binary_logloss: 0.120243\tvalid_1's auc: 0.835899\tvalid_1's binary_logloss: 0.137146\n",
            "[39]\ttraining's auc: 0.890188\ttraining's binary_logloss: 0.119946\tvalid_1's auc: 0.835714\tvalid_1's binary_logloss: 0.137086\n",
            "[40]\ttraining's auc: 0.890883\ttraining's binary_logloss: 0.119645\tvalid_1's auc: 0.835598\tvalid_1's binary_logloss: 0.137027\n",
            "[41]\ttraining's auc: 0.89158\ttraining's binary_logloss: 0.119311\tvalid_1's auc: 0.835725\tvalid_1's binary_logloss: 0.136972\n",
            "[42]\ttraining's auc: 0.892384\ttraining's binary_logloss: 0.118998\tvalid_1's auc: 0.83581\tvalid_1's binary_logloss: 0.136933\n",
            "[43]\ttraining's auc: 0.893132\ttraining's binary_logloss: 0.118718\tvalid_1's auc: 0.835925\tvalid_1's binary_logloss: 0.136892\n",
            "[44]\ttraining's auc: 0.893979\ttraining's binary_logloss: 0.118393\tvalid_1's auc: 0.835748\tvalid_1's binary_logloss: 0.136858\n",
            "[45]\ttraining's auc: 0.895162\ttraining's binary_logloss: 0.11807\tvalid_1's auc: 0.835883\tvalid_1's binary_logloss: 0.136805\n",
            "[46]\ttraining's auc: 0.895506\ttraining's binary_logloss: 0.11784\tvalid_1's auc: 0.835943\tvalid_1's binary_logloss: 0.136793\n",
            "[47]\ttraining's auc: 0.896175\ttraining's binary_logloss: 0.117615\tvalid_1's auc: 0.835721\tvalid_1's binary_logloss: 0.136787\n",
            "[48]\ttraining's auc: 0.896766\ttraining's binary_logloss: 0.11736\tvalid_1's auc: 0.835737\tvalid_1's binary_logloss: 0.13676\n",
            "[49]\ttraining's auc: 0.89752\ttraining's binary_logloss: 0.117051\tvalid_1's auc: 0.835668\tvalid_1's binary_logloss: 0.136745\n",
            "[50]\ttraining's auc: 0.898373\ttraining's binary_logloss: 0.116806\tvalid_1's auc: 0.835482\tvalid_1's binary_logloss: 0.136728\n",
            "[51]\ttraining's auc: 0.899131\ttraining's binary_logloss: 0.11652\tvalid_1's auc: 0.835345\tvalid_1's binary_logloss: 0.136696\n",
            "[52]\ttraining's auc: 0.899809\ttraining's binary_logloss: 0.116248\tvalid_1's auc: 0.835185\tvalid_1's binary_logloss: 0.136679\n",
            "[53]\ttraining's auc: 0.900413\ttraining's binary_logloss: 0.116024\tvalid_1's auc: 0.83499\tvalid_1's binary_logloss: 0.136676\n",
            "[54]\ttraining's auc: 0.901203\ttraining's binary_logloss: 0.115753\tvalid_1's auc: 0.834773\tvalid_1's binary_logloss: 0.136699\n",
            "[55]\ttraining's auc: 0.901837\ttraining's binary_logloss: 0.115542\tvalid_1's auc: 0.834904\tvalid_1's binary_logloss: 0.136668\n",
            "[56]\ttraining's auc: 0.902332\ttraining's binary_logloss: 0.115316\tvalid_1's auc: 0.834821\tvalid_1's binary_logloss: 0.13667\n",
            "[57]\ttraining's auc: 0.902865\ttraining's binary_logloss: 0.115052\tvalid_1's auc: 0.834887\tvalid_1's binary_logloss: 0.13664\n",
            "[58]\ttraining's auc: 0.903596\ttraining's binary_logloss: 0.114813\tvalid_1's auc: 0.834809\tvalid_1's binary_logloss: 0.136629\n",
            "[59]\ttraining's auc: 0.90412\ttraining's binary_logloss: 0.114569\tvalid_1's auc: 0.834839\tvalid_1's binary_logloss: 0.136602\n",
            "[60]\ttraining's auc: 0.904752\ttraining's binary_logloss: 0.1143\tvalid_1's auc: 0.834549\tvalid_1's binary_logloss: 0.136655\n",
            "[61]\ttraining's auc: 0.90505\ttraining's binary_logloss: 0.114106\tvalid_1's auc: 0.834688\tvalid_1's binary_logloss: 0.136632\n",
            "[62]\ttraining's auc: 0.905521\ttraining's binary_logloss: 0.113863\tvalid_1's auc: 0.834707\tvalid_1's binary_logloss: 0.13661\n",
            "[63]\ttraining's auc: 0.905992\ttraining's binary_logloss: 0.113631\tvalid_1's auc: 0.834926\tvalid_1's binary_logloss: 0.136591\n",
            "[64]\ttraining's auc: 0.906294\ttraining's binary_logloss: 0.113475\tvalid_1's auc: 0.83495\tvalid_1's binary_logloss: 0.136585\n",
            "[65]\ttraining's auc: 0.90677\ttraining's binary_logloss: 0.113264\tvalid_1's auc: 0.834913\tvalid_1's binary_logloss: 0.136601\n",
            "[66]\ttraining's auc: 0.907385\ttraining's binary_logloss: 0.113048\tvalid_1's auc: 0.834856\tvalid_1's binary_logloss: 0.136606\n",
            " 10%|█         | 5/50 [02:31<25:11, 33.58s/trial, best loss: -0.8346327164689749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.163215\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.164309\n",
            "[2]\ttraining's auc: 0.827206\ttraining's binary_logloss: 0.161949\tvalid_1's auc: 0.805069\tvalid_1's binary_logloss: 0.163251\n",
            "[3]\ttraining's auc: 0.827629\ttraining's binary_logloss: 0.160774\tvalid_1's auc: 0.804855\tvalid_1's binary_logloss: 0.162305\n",
            "[4]\ttraining's auc: 0.832975\ttraining's binary_logloss: 0.159659\tvalid_1's auc: 0.807973\tvalid_1's binary_logloss: 0.161424\n",
            "[5]\ttraining's auc: 0.833743\ttraining's binary_logloss: 0.158609\tvalid_1's auc: 0.807907\tvalid_1's binary_logloss: 0.160612\n",
            "[6]\ttraining's auc: 0.834124\ttraining's binary_logloss: 0.157626\tvalid_1's auc: 0.80801\tvalid_1's binary_logloss: 0.15982\n",
            "[7]\ttraining's auc: 0.834845\ttraining's binary_logloss: 0.156693\tvalid_1's auc: 0.80816\tvalid_1's binary_logloss: 0.159067\n",
            "[8]\ttraining's auc: 0.836129\ttraining's binary_logloss: 0.155807\tvalid_1's auc: 0.808958\tvalid_1's binary_logloss: 0.158383\n",
            "[9]\ttraining's auc: 0.836268\ttraining's binary_logloss: 0.154955\tvalid_1's auc: 0.808638\tvalid_1's binary_logloss: 0.157734\n",
            "[10]\ttraining's auc: 0.836481\ttraining's binary_logloss: 0.154158\tvalid_1's auc: 0.808494\tvalid_1's binary_logloss: 0.157122\n",
            "[11]\ttraining's auc: 0.836748\ttraining's binary_logloss: 0.153398\tvalid_1's auc: 0.808246\tvalid_1's binary_logloss: 0.156518\n",
            "[12]\ttraining's auc: 0.83859\ttraining's binary_logloss: 0.152641\tvalid_1's auc: 0.809995\tvalid_1's binary_logloss: 0.155926\n",
            "[13]\ttraining's auc: 0.838589\ttraining's binary_logloss: 0.151939\tvalid_1's auc: 0.810436\tvalid_1's binary_logloss: 0.155349\n",
            "[14]\ttraining's auc: 0.839235\ttraining's binary_logloss: 0.151246\tvalid_1's auc: 0.810898\tvalid_1's binary_logloss: 0.154798\n",
            "[15]\ttraining's auc: 0.841886\ttraining's binary_logloss: 0.15059\tvalid_1's auc: 0.81226\tvalid_1's binary_logloss: 0.154287\n",
            "[16]\ttraining's auc: 0.843764\ttraining's binary_logloss: 0.149953\tvalid_1's auc: 0.814026\tvalid_1's binary_logloss: 0.153778\n",
            "[17]\ttraining's auc: 0.845211\ttraining's binary_logloss: 0.14934\tvalid_1's auc: 0.815196\tvalid_1's binary_logloss: 0.153317\n",
            "[18]\ttraining's auc: 0.84553\ttraining's binary_logloss: 0.148754\tvalid_1's auc: 0.81537\tvalid_1's binary_logloss: 0.152863\n",
            "[19]\ttraining's auc: 0.845977\ttraining's binary_logloss: 0.148196\tvalid_1's auc: 0.81548\tvalid_1's binary_logloss: 0.152429\n",
            "[20]\ttraining's auc: 0.846597\ttraining's binary_logloss: 0.147651\tvalid_1's auc: 0.816278\tvalid_1's binary_logloss: 0.152017\n",
            "[21]\ttraining's auc: 0.847643\ttraining's binary_logloss: 0.147127\tvalid_1's auc: 0.817236\tvalid_1's binary_logloss: 0.151602\n",
            "[22]\ttraining's auc: 0.848147\ttraining's binary_logloss: 0.146611\tvalid_1's auc: 0.817391\tvalid_1's binary_logloss: 0.151223\n",
            "[23]\ttraining's auc: 0.848416\ttraining's binary_logloss: 0.14612\tvalid_1's auc: 0.817451\tvalid_1's binary_logloss: 0.150856\n",
            "[24]\ttraining's auc: 0.848663\ttraining's binary_logloss: 0.145631\tvalid_1's auc: 0.81795\tvalid_1's binary_logloss: 0.150489\n",
            "[25]\ttraining's auc: 0.849\ttraining's binary_logloss: 0.145163\tvalid_1's auc: 0.818181\tvalid_1's binary_logloss: 0.150119\n",
            "[26]\ttraining's auc: 0.849598\ttraining's binary_logloss: 0.1447\tvalid_1's auc: 0.818667\tvalid_1's binary_logloss: 0.149769\n",
            "[27]\ttraining's auc: 0.849791\ttraining's binary_logloss: 0.144231\tvalid_1's auc: 0.819022\tvalid_1's binary_logloss: 0.149415\n",
            "[28]\ttraining's auc: 0.850445\ttraining's binary_logloss: 0.14378\tvalid_1's auc: 0.819406\tvalid_1's binary_logloss: 0.149082\n",
            "[29]\ttraining's auc: 0.850943\ttraining's binary_logloss: 0.143342\tvalid_1's auc: 0.819854\tvalid_1's binary_logloss: 0.148758\n",
            "[30]\ttraining's auc: 0.851171\ttraining's binary_logloss: 0.142918\tvalid_1's auc: 0.82006\tvalid_1's binary_logloss: 0.148439\n",
            "[31]\ttraining's auc: 0.851618\ttraining's binary_logloss: 0.14251\tvalid_1's auc: 0.820677\tvalid_1's binary_logloss: 0.148144\n",
            "[32]\ttraining's auc: 0.852463\ttraining's binary_logloss: 0.142114\tvalid_1's auc: 0.82104\tvalid_1's binary_logloss: 0.147848\n",
            "[33]\ttraining's auc: 0.853082\ttraining's binary_logloss: 0.141723\tvalid_1's auc: 0.821131\tvalid_1's binary_logloss: 0.147582\n",
            "[34]\ttraining's auc: 0.853547\ttraining's binary_logloss: 0.14135\tvalid_1's auc: 0.821512\tvalid_1's binary_logloss: 0.147296\n",
            "[35]\ttraining's auc: 0.853563\ttraining's binary_logloss: 0.140982\tvalid_1's auc: 0.821824\tvalid_1's binary_logloss: 0.147024\n",
            "[36]\ttraining's auc: 0.854716\ttraining's binary_logloss: 0.140622\tvalid_1's auc: 0.822909\tvalid_1's binary_logloss: 0.146763\n",
            "[37]\ttraining's auc: 0.854851\ttraining's binary_logloss: 0.140279\tvalid_1's auc: 0.822997\tvalid_1's binary_logloss: 0.146519\n",
            "[38]\ttraining's auc: 0.855016\ttraining's binary_logloss: 0.139937\tvalid_1's auc: 0.822916\tvalid_1's binary_logloss: 0.146282\n",
            "[39]\ttraining's auc: 0.855185\ttraining's binary_logloss: 0.139606\tvalid_1's auc: 0.822646\tvalid_1's binary_logloss: 0.146048\n",
            "[40]\ttraining's auc: 0.855265\ttraining's binary_logloss: 0.139289\tvalid_1's auc: 0.822626\tvalid_1's binary_logloss: 0.145823\n",
            "[41]\ttraining's auc: 0.855489\ttraining's binary_logloss: 0.138975\tvalid_1's auc: 0.822916\tvalid_1's binary_logloss: 0.145579\n",
            "[42]\ttraining's auc: 0.855845\ttraining's binary_logloss: 0.13866\tvalid_1's auc: 0.822904\tvalid_1's binary_logloss: 0.145372\n",
            "[43]\ttraining's auc: 0.85752\ttraining's binary_logloss: 0.138363\tvalid_1's auc: 0.824161\tvalid_1's binary_logloss: 0.145147\n",
            "[44]\ttraining's auc: 0.857759\ttraining's binary_logloss: 0.138056\tvalid_1's auc: 0.824267\tvalid_1's binary_logloss: 0.144934\n",
            "[45]\ttraining's auc: 0.858037\ttraining's binary_logloss: 0.137757\tvalid_1's auc: 0.824009\tvalid_1's binary_logloss: 0.144722\n",
            "[46]\ttraining's auc: 0.858478\ttraining's binary_logloss: 0.137461\tvalid_1's auc: 0.824078\tvalid_1's binary_logloss: 0.144532\n",
            "[47]\ttraining's auc: 0.85879\ttraining's binary_logloss: 0.137176\tvalid_1's auc: 0.824072\tvalid_1's binary_logloss: 0.144339\n",
            "[48]\ttraining's auc: 0.859148\ttraining's binary_logloss: 0.136895\tvalid_1's auc: 0.824216\tvalid_1's binary_logloss: 0.144142\n",
            "[49]\ttraining's auc: 0.859333\ttraining's binary_logloss: 0.136627\tvalid_1's auc: 0.824032\tvalid_1's binary_logloss: 0.143966\n",
            "[50]\ttraining's auc: 0.859491\ttraining's binary_logloss: 0.136362\tvalid_1's auc: 0.823882\tvalid_1's binary_logloss: 0.143799\n",
            "[51]\ttraining's auc: 0.859712\ttraining's binary_logloss: 0.136097\tvalid_1's auc: 0.823852\tvalid_1's binary_logloss: 0.143632\n",
            "[52]\ttraining's auc: 0.85994\ttraining's binary_logloss: 0.135838\tvalid_1's auc: 0.823929\tvalid_1's binary_logloss: 0.143474\n",
            "[53]\ttraining's auc: 0.85997\ttraining's binary_logloss: 0.135589\tvalid_1's auc: 0.824209\tvalid_1's binary_logloss: 0.143305\n",
            "[54]\ttraining's auc: 0.860662\ttraining's binary_logloss: 0.135321\tvalid_1's auc: 0.824406\tvalid_1's binary_logloss: 0.143136\n",
            "[55]\ttraining's auc: 0.861259\ttraining's binary_logloss: 0.135088\tvalid_1's auc: 0.8247\tvalid_1's binary_logloss: 0.142967\n",
            "[56]\ttraining's auc: 0.86173\ttraining's binary_logloss: 0.134847\tvalid_1's auc: 0.824642\tvalid_1's binary_logloss: 0.142803\n",
            "[57]\ttraining's auc: 0.86215\ttraining's binary_logloss: 0.13461\tvalid_1's auc: 0.824822\tvalid_1's binary_logloss: 0.14265\n",
            "[58]\ttraining's auc: 0.862373\ttraining's binary_logloss: 0.134389\tvalid_1's auc: 0.824994\tvalid_1's binary_logloss: 0.14249\n",
            "[59]\ttraining's auc: 0.862463\ttraining's binary_logloss: 0.134168\tvalid_1's auc: 0.824956\tvalid_1's binary_logloss: 0.142343\n",
            "[60]\ttraining's auc: 0.862545\ttraining's binary_logloss: 0.133953\tvalid_1's auc: 0.825024\tvalid_1's binary_logloss: 0.142203\n",
            "[61]\ttraining's auc: 0.863106\ttraining's binary_logloss: 0.133738\tvalid_1's auc: 0.825234\tvalid_1's binary_logloss: 0.142049\n",
            "[62]\ttraining's auc: 0.863403\ttraining's binary_logloss: 0.133526\tvalid_1's auc: 0.825243\tvalid_1's binary_logloss: 0.141904\n",
            "[63]\ttraining's auc: 0.863622\ttraining's binary_logloss: 0.133321\tvalid_1's auc: 0.825399\tvalid_1's binary_logloss: 0.141768\n",
            "[64]\ttraining's auc: 0.864142\ttraining's binary_logloss: 0.133116\tvalid_1's auc: 0.825585\tvalid_1's binary_logloss: 0.141637\n",
            "[65]\ttraining's auc: 0.86456\ttraining's binary_logloss: 0.132911\tvalid_1's auc: 0.825708\tvalid_1's binary_logloss: 0.141512\n",
            "[66]\ttraining's auc: 0.864936\ttraining's binary_logloss: 0.13269\tvalid_1's auc: 0.825671\tvalid_1's binary_logloss: 0.141374\n",
            "[67]\ttraining's auc: 0.865086\ttraining's binary_logloss: 0.132485\tvalid_1's auc: 0.825961\tvalid_1's binary_logloss: 0.141262\n",
            "[68]\ttraining's auc: 0.865446\ttraining's binary_logloss: 0.132294\tvalid_1's auc: 0.826145\tvalid_1's binary_logloss: 0.141134\n",
            "[69]\ttraining's auc: 0.86585\ttraining's binary_logloss: 0.132105\tvalid_1's auc: 0.826154\tvalid_1's binary_logloss: 0.141014\n",
            "[70]\ttraining's auc: 0.866133\ttraining's binary_logloss: 0.131922\tvalid_1's auc: 0.82637\tvalid_1's binary_logloss: 0.1409\n",
            "[71]\ttraining's auc: 0.86635\ttraining's binary_logloss: 0.131734\tvalid_1's auc: 0.826481\tvalid_1's binary_logloss: 0.140791\n",
            "[72]\ttraining's auc: 0.86644\ttraining's binary_logloss: 0.131553\tvalid_1's auc: 0.826504\tvalid_1's binary_logloss: 0.140693\n",
            "[73]\ttraining's auc: 0.866636\ttraining's binary_logloss: 0.131363\tvalid_1's auc: 0.826686\tvalid_1's binary_logloss: 0.140574\n",
            "[74]\ttraining's auc: 0.867185\ttraining's binary_logloss: 0.131185\tvalid_1's auc: 0.826859\tvalid_1's binary_logloss: 0.140458\n",
            "[75]\ttraining's auc: 0.867354\ttraining's binary_logloss: 0.13101\tvalid_1's auc: 0.827018\tvalid_1's binary_logloss: 0.140361\n",
            "[76]\ttraining's auc: 0.867671\ttraining's binary_logloss: 0.130828\tvalid_1's auc: 0.826972\tvalid_1's binary_logloss: 0.140255\n",
            "[77]\ttraining's auc: 0.868234\ttraining's binary_logloss: 0.13066\tvalid_1's auc: 0.827342\tvalid_1's binary_logloss: 0.14016\n",
            "[78]\ttraining's auc: 0.868539\ttraining's binary_logloss: 0.130495\tvalid_1's auc: 0.827486\tvalid_1's binary_logloss: 0.140075\n",
            "[79]\ttraining's auc: 0.86891\ttraining's binary_logloss: 0.130324\tvalid_1's auc: 0.827595\tvalid_1's binary_logloss: 0.139988\n",
            "[80]\ttraining's auc: 0.869256\ttraining's binary_logloss: 0.13016\tvalid_1's auc: 0.8276\tvalid_1's binary_logloss: 0.139909\n",
            "[81]\ttraining's auc: 0.869485\ttraining's binary_logloss: 0.129989\tvalid_1's auc: 0.827668\tvalid_1's binary_logloss: 0.139821\n",
            "[82]\ttraining's auc: 0.869621\ttraining's binary_logloss: 0.129838\tvalid_1's auc: 0.827726\tvalid_1's binary_logloss: 0.13974\n",
            "[83]\ttraining's auc: 0.869935\ttraining's binary_logloss: 0.129684\tvalid_1's auc: 0.827844\tvalid_1's binary_logloss: 0.13966\n",
            "[84]\ttraining's auc: 0.870114\ttraining's binary_logloss: 0.129526\tvalid_1's auc: 0.827921\tvalid_1's binary_logloss: 0.139583\n",
            "[85]\ttraining's auc: 0.870327\ttraining's binary_logloss: 0.129374\tvalid_1's auc: 0.827981\tvalid_1's binary_logloss: 0.139516\n",
            "[86]\ttraining's auc: 0.870567\ttraining's binary_logloss: 0.129223\tvalid_1's auc: 0.827946\tvalid_1's binary_logloss: 0.139438\n",
            "[87]\ttraining's auc: 0.870782\ttraining's binary_logloss: 0.129079\tvalid_1's auc: 0.828079\tvalid_1's binary_logloss: 0.139363\n",
            "[88]\ttraining's auc: 0.870991\ttraining's binary_logloss: 0.128935\tvalid_1's auc: 0.828178\tvalid_1's binary_logloss: 0.139281\n",
            "[89]\ttraining's auc: 0.871162\ttraining's binary_logloss: 0.128796\tvalid_1's auc: 0.828194\tvalid_1's binary_logloss: 0.139209\n",
            "[90]\ttraining's auc: 0.871472\ttraining's binary_logloss: 0.128649\tvalid_1's auc: 0.828498\tvalid_1's binary_logloss: 0.139127\n",
            "[91]\ttraining's auc: 0.871757\ttraining's binary_logloss: 0.128511\tvalid_1's auc: 0.828459\tvalid_1's binary_logloss: 0.13906\n",
            "[92]\ttraining's auc: 0.871876\ttraining's binary_logloss: 0.12837\tvalid_1's auc: 0.828492\tvalid_1's binary_logloss: 0.138988\n",
            "[93]\ttraining's auc: 0.872052\ttraining's binary_logloss: 0.128237\tvalid_1's auc: 0.828679\tvalid_1's binary_logloss: 0.138918\n",
            "[94]\ttraining's auc: 0.872413\ttraining's binary_logloss: 0.128093\tvalid_1's auc: 0.828703\tvalid_1's binary_logloss: 0.138846\n",
            "[95]\ttraining's auc: 0.872537\ttraining's binary_logloss: 0.127968\tvalid_1's auc: 0.828879\tvalid_1's binary_logloss: 0.138779\n",
            "[96]\ttraining's auc: 0.872801\ttraining's binary_logloss: 0.12783\tvalid_1's auc: 0.828937\tvalid_1's binary_logloss: 0.138711\n",
            "[97]\ttraining's auc: 0.873144\ttraining's binary_logloss: 0.127699\tvalid_1's auc: 0.828874\tvalid_1's binary_logloss: 0.13866\n",
            "[98]\ttraining's auc: 0.873358\ttraining's binary_logloss: 0.127563\tvalid_1's auc: 0.828921\tvalid_1's binary_logloss: 0.1386\n",
            "[99]\ttraining's auc: 0.873619\ttraining's binary_logloss: 0.12742\tvalid_1's auc: 0.82895\tvalid_1's binary_logloss: 0.138542\n",
            "[100]\ttraining's auc: 0.873875\ttraining's binary_logloss: 0.127297\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.138496\n",
            "[101]\ttraining's auc: 0.87414\ttraining's binary_logloss: 0.127165\tvalid_1's auc: 0.828732\tvalid_1's binary_logloss: 0.138442\n",
            "[102]\ttraining's auc: 0.874378\ttraining's binary_logloss: 0.127036\tvalid_1's auc: 0.828649\tvalid_1's binary_logloss: 0.138394\n",
            "[103]\ttraining's auc: 0.87482\ttraining's binary_logloss: 0.126906\tvalid_1's auc: 0.828607\tvalid_1's binary_logloss: 0.138343\n",
            "[104]\ttraining's auc: 0.875123\ttraining's binary_logloss: 0.126778\tvalid_1's auc: 0.82856\tvalid_1's binary_logloss: 0.138288\n",
            "[105]\ttraining's auc: 0.875328\ttraining's binary_logloss: 0.126656\tvalid_1's auc: 0.828582\tvalid_1's binary_logloss: 0.138242\n",
            "[106]\ttraining's auc: 0.875561\ttraining's binary_logloss: 0.126536\tvalid_1's auc: 0.828527\tvalid_1's binary_logloss: 0.138199\n",
            "[107]\ttraining's auc: 0.875842\ttraining's binary_logloss: 0.126418\tvalid_1's auc: 0.828541\tvalid_1's binary_logloss: 0.138155\n",
            "[108]\ttraining's auc: 0.876022\ttraining's binary_logloss: 0.126303\tvalid_1's auc: 0.828524\tvalid_1's binary_logloss: 0.138108\n",
            "[109]\ttraining's auc: 0.876202\ttraining's binary_logloss: 0.126179\tvalid_1's auc: 0.828608\tvalid_1's binary_logloss: 0.138062\n",
            "[110]\ttraining's auc: 0.876335\ttraining's binary_logloss: 0.126067\tvalid_1's auc: 0.828639\tvalid_1's binary_logloss: 0.138007\n",
            "[111]\ttraining's auc: 0.876987\ttraining's binary_logloss: 0.125934\tvalid_1's auc: 0.828761\tvalid_1's binary_logloss: 0.137963\n",
            "[112]\ttraining's auc: 0.877138\ttraining's binary_logloss: 0.125824\tvalid_1's auc: 0.828796\tvalid_1's binary_logloss: 0.137921\n",
            "[113]\ttraining's auc: 0.877313\ttraining's binary_logloss: 0.125715\tvalid_1's auc: 0.828762\tvalid_1's binary_logloss: 0.13788\n",
            "[114]\ttraining's auc: 0.877797\ttraining's binary_logloss: 0.125592\tvalid_1's auc: 0.828831\tvalid_1's binary_logloss: 0.137839\n",
            "[115]\ttraining's auc: 0.877969\ttraining's binary_logloss: 0.125486\tvalid_1's auc: 0.828889\tvalid_1's binary_logloss: 0.137797\n",
            "[116]\ttraining's auc: 0.87818\ttraining's binary_logloss: 0.125384\tvalid_1's auc: 0.828776\tvalid_1's binary_logloss: 0.137762\n",
            "[117]\ttraining's auc: 0.878285\ttraining's binary_logloss: 0.125283\tvalid_1's auc: 0.828789\tvalid_1's binary_logloss: 0.137725\n",
            "[118]\ttraining's auc: 0.878472\ttraining's binary_logloss: 0.125172\tvalid_1's auc: 0.82869\tvalid_1's binary_logloss: 0.137697\n",
            "[119]\ttraining's auc: 0.878663\ttraining's binary_logloss: 0.125071\tvalid_1's auc: 0.828769\tvalid_1's binary_logloss: 0.137662\n",
            "[120]\ttraining's auc: 0.879161\ttraining's binary_logloss: 0.124948\tvalid_1's auc: 0.828881\tvalid_1's binary_logloss: 0.137611\n",
            "[121]\ttraining's auc: 0.87926\ttraining's binary_logloss: 0.12485\tvalid_1's auc: 0.828868\tvalid_1's binary_logloss: 0.137572\n",
            "[122]\ttraining's auc: 0.879518\ttraining's binary_logloss: 0.124735\tvalid_1's auc: 0.828846\tvalid_1's binary_logloss: 0.137546\n",
            "[123]\ttraining's auc: 0.879675\ttraining's binary_logloss: 0.124637\tvalid_1's auc: 0.829008\tvalid_1's binary_logloss: 0.137508\n",
            "[124]\ttraining's auc: 0.87983\ttraining's binary_logloss: 0.124543\tvalid_1's auc: 0.829065\tvalid_1's binary_logloss: 0.137469\n",
            "[125]\ttraining's auc: 0.880032\ttraining's binary_logloss: 0.124438\tvalid_1's auc: 0.829144\tvalid_1's binary_logloss: 0.137436\n",
            "[126]\ttraining's auc: 0.880233\ttraining's binary_logloss: 0.124339\tvalid_1's auc: 0.829141\tvalid_1's binary_logloss: 0.137399\n",
            "[127]\ttraining's auc: 0.880521\ttraining's binary_logloss: 0.124238\tvalid_1's auc: 0.82923\tvalid_1's binary_logloss: 0.137352\n",
            "[128]\ttraining's auc: 0.880802\ttraining's binary_logloss: 0.124132\tvalid_1's auc: 0.829135\tvalid_1's binary_logloss: 0.13732\n",
            "[129]\ttraining's auc: 0.881125\ttraining's binary_logloss: 0.124028\tvalid_1's auc: 0.829079\tvalid_1's binary_logloss: 0.13729\n",
            "[130]\ttraining's auc: 0.881314\ttraining's binary_logloss: 0.123932\tvalid_1's auc: 0.829385\tvalid_1's binary_logloss: 0.137248\n",
            "[131]\ttraining's auc: 0.881685\ttraining's binary_logloss: 0.123829\tvalid_1's auc: 0.829341\tvalid_1's binary_logloss: 0.137217\n",
            "[132]\ttraining's auc: 0.88184\ttraining's binary_logloss: 0.123735\tvalid_1's auc: 0.829393\tvalid_1's binary_logloss: 0.137185\n",
            "[133]\ttraining's auc: 0.882073\ttraining's binary_logloss: 0.123635\tvalid_1's auc: 0.829325\tvalid_1's binary_logloss: 0.13716\n",
            "[134]\ttraining's auc: 0.882598\ttraining's binary_logloss: 0.123527\tvalid_1's auc: 0.829352\tvalid_1's binary_logloss: 0.137124\n",
            "[135]\ttraining's auc: 0.88281\ttraining's binary_logloss: 0.123432\tvalid_1's auc: 0.82922\tvalid_1's binary_logloss: 0.1371\n",
            "[136]\ttraining's auc: 0.882973\ttraining's binary_logloss: 0.123341\tvalid_1's auc: 0.829361\tvalid_1's binary_logloss: 0.137088\n",
            "[137]\ttraining's auc: 0.88313\ttraining's binary_logloss: 0.123251\tvalid_1's auc: 0.829285\tvalid_1's binary_logloss: 0.13707\n",
            "[138]\ttraining's auc: 0.883299\ttraining's binary_logloss: 0.123163\tvalid_1's auc: 0.82926\tvalid_1's binary_logloss: 0.137048\n",
            "[139]\ttraining's auc: 0.883613\ttraining's binary_logloss: 0.123062\tvalid_1's auc: 0.829313\tvalid_1's binary_logloss: 0.137027\n",
            "[140]\ttraining's auc: 0.884046\ttraining's binary_logloss: 0.12296\tvalid_1's auc: 0.829479\tvalid_1's binary_logloss: 0.136983\n",
            "[141]\ttraining's auc: 0.884365\ttraining's binary_logloss: 0.122863\tvalid_1's auc: 0.82944\tvalid_1's binary_logloss: 0.136964\n",
            "[142]\ttraining's auc: 0.884629\ttraining's binary_logloss: 0.122766\tvalid_1's auc: 0.829557\tvalid_1's binary_logloss: 0.136923\n",
            "[143]\ttraining's auc: 0.884899\ttraining's binary_logloss: 0.122673\tvalid_1's auc: 0.829686\tvalid_1's binary_logloss: 0.136895\n",
            "[144]\ttraining's auc: 0.88513\ttraining's binary_logloss: 0.122587\tvalid_1's auc: 0.829667\tvalid_1's binary_logloss: 0.136882\n",
            "[145]\ttraining's auc: 0.885367\ttraining's binary_logloss: 0.122497\tvalid_1's auc: 0.829754\tvalid_1's binary_logloss: 0.136847\n",
            "[146]\ttraining's auc: 0.88558\ttraining's binary_logloss: 0.122411\tvalid_1's auc: 0.829688\tvalid_1's binary_logloss: 0.136836\n",
            "[147]\ttraining's auc: 0.88588\ttraining's binary_logloss: 0.122317\tvalid_1's auc: 0.82983\tvalid_1's binary_logloss: 0.136799\n",
            "[148]\ttraining's auc: 0.886246\ttraining's binary_logloss: 0.122218\tvalid_1's auc: 0.829688\tvalid_1's binary_logloss: 0.136783\n",
            "[149]\ttraining's auc: 0.886416\ttraining's binary_logloss: 0.122139\tvalid_1's auc: 0.829624\tvalid_1's binary_logloss: 0.136771\n",
            "[150]\ttraining's auc: 0.886584\ttraining's binary_logloss: 0.122057\tvalid_1's auc: 0.829614\tvalid_1's binary_logloss: 0.136755\n",
            "[151]\ttraining's auc: 0.886774\ttraining's binary_logloss: 0.121961\tvalid_1's auc: 0.829751\tvalid_1's binary_logloss: 0.136728\n",
            "[152]\ttraining's auc: 0.887039\ttraining's binary_logloss: 0.121869\tvalid_1's auc: 0.82984\tvalid_1's binary_logloss: 0.136704\n",
            "[153]\ttraining's auc: 0.887259\ttraining's binary_logloss: 0.121788\tvalid_1's auc: 0.829778\tvalid_1's binary_logloss: 0.136672\n",
            "[154]\ttraining's auc: 0.887434\ttraining's binary_logloss: 0.121707\tvalid_1's auc: 0.829811\tvalid_1's binary_logloss: 0.136649\n",
            "[155]\ttraining's auc: 0.887694\ttraining's binary_logloss: 0.121613\tvalid_1's auc: 0.829906\tvalid_1's binary_logloss: 0.136628\n",
            "[156]\ttraining's auc: 0.88801\ttraining's binary_logloss: 0.121507\tvalid_1's auc: 0.829913\tvalid_1's binary_logloss: 0.136614\n",
            "[157]\ttraining's auc: 0.888232\ttraining's binary_logloss: 0.121421\tvalid_1's auc: 0.829843\tvalid_1's binary_logloss: 0.136597\n",
            "[158]\ttraining's auc: 0.88835\ttraining's binary_logloss: 0.121346\tvalid_1's auc: 0.829818\tvalid_1's binary_logloss: 0.136588\n",
            "[159]\ttraining's auc: 0.888736\ttraining's binary_logloss: 0.121256\tvalid_1's auc: 0.829902\tvalid_1's binary_logloss: 0.136557\n",
            "[160]\ttraining's auc: 0.888954\ttraining's binary_logloss: 0.121163\tvalid_1's auc: 0.829987\tvalid_1's binary_logloss: 0.136548\n",
            "[161]\ttraining's auc: 0.889176\ttraining's binary_logloss: 0.121074\tvalid_1's auc: 0.829932\tvalid_1's binary_logloss: 0.136536\n",
            "[162]\ttraining's auc: 0.889328\ttraining's binary_logloss: 0.120992\tvalid_1's auc: 0.830071\tvalid_1's binary_logloss: 0.136508\n",
            "[163]\ttraining's auc: 0.88946\ttraining's binary_logloss: 0.12091\tvalid_1's auc: 0.830055\tvalid_1's binary_logloss: 0.136492\n",
            "[164]\ttraining's auc: 0.889898\ttraining's binary_logloss: 0.120809\tvalid_1's auc: 0.830209\tvalid_1's binary_logloss: 0.136451\n",
            "[165]\ttraining's auc: 0.890027\ttraining's binary_logloss: 0.120735\tvalid_1's auc: 0.830098\tvalid_1's binary_logloss: 0.136448\n",
            "[166]\ttraining's auc: 0.890209\ttraining's binary_logloss: 0.12065\tvalid_1's auc: 0.830056\tvalid_1's binary_logloss: 0.136442\n",
            "[167]\ttraining's auc: 0.890587\ttraining's binary_logloss: 0.120556\tvalid_1's auc: 0.830139\tvalid_1's binary_logloss: 0.136408\n",
            "[168]\ttraining's auc: 0.890681\ttraining's binary_logloss: 0.120484\tvalid_1's auc: 0.830204\tvalid_1's binary_logloss: 0.136387\n",
            "[169]\ttraining's auc: 0.89084\ttraining's binary_logloss: 0.120406\tvalid_1's auc: 0.830209\tvalid_1's binary_logloss: 0.13638\n",
            "[170]\ttraining's auc: 0.890954\ttraining's binary_logloss: 0.120334\tvalid_1's auc: 0.830166\tvalid_1's binary_logloss: 0.136373\n",
            "[171]\ttraining's auc: 0.891054\ttraining's binary_logloss: 0.120265\tvalid_1's auc: 0.830171\tvalid_1's binary_logloss: 0.13636\n",
            "[172]\ttraining's auc: 0.891309\ttraining's binary_logloss: 0.120182\tvalid_1's auc: 0.830073\tvalid_1's binary_logloss: 0.136354\n",
            "[173]\ttraining's auc: 0.891407\ttraining's binary_logloss: 0.120107\tvalid_1's auc: 0.830101\tvalid_1's binary_logloss: 0.13635\n",
            "[174]\ttraining's auc: 0.891609\ttraining's binary_logloss: 0.120037\tvalid_1's auc: 0.83012\tvalid_1's binary_logloss: 0.136342\n",
            "[175]\ttraining's auc: 0.891948\ttraining's binary_logloss: 0.119953\tvalid_1's auc: 0.830142\tvalid_1's binary_logloss: 0.136313\n",
            "[176]\ttraining's auc: 0.892118\ttraining's binary_logloss: 0.119878\tvalid_1's auc: 0.830158\tvalid_1's binary_logloss: 0.136296\n",
            "[177]\ttraining's auc: 0.892201\ttraining's binary_logloss: 0.11981\tvalid_1's auc: 0.830186\tvalid_1's binary_logloss: 0.136284\n",
            "[178]\ttraining's auc: 0.892341\ttraining's binary_logloss: 0.119739\tvalid_1's auc: 0.830247\tvalid_1's binary_logloss: 0.136267\n",
            "[179]\ttraining's auc: 0.892589\ttraining's binary_logloss: 0.119674\tvalid_1's auc: 0.830222\tvalid_1's binary_logloss: 0.136264\n",
            "[180]\ttraining's auc: 0.892778\ttraining's binary_logloss: 0.119606\tvalid_1's auc: 0.830215\tvalid_1's binary_logloss: 0.136245\n",
            "[181]\ttraining's auc: 0.893022\ttraining's binary_logloss: 0.119526\tvalid_1's auc: 0.83038\tvalid_1's binary_logloss: 0.136218\n",
            "[182]\ttraining's auc: 0.893128\ttraining's binary_logloss: 0.119462\tvalid_1's auc: 0.830393\tvalid_1's binary_logloss: 0.136206\n",
            "[183]\ttraining's auc: 0.893294\ttraining's binary_logloss: 0.11939\tvalid_1's auc: 0.83041\tvalid_1's binary_logloss: 0.136191\n",
            "[184]\ttraining's auc: 0.893696\ttraining's binary_logloss: 0.119309\tvalid_1's auc: 0.830607\tvalid_1's binary_logloss: 0.136156\n",
            "[185]\ttraining's auc: 0.893797\ttraining's binary_logloss: 0.119243\tvalid_1's auc: 0.83062\tvalid_1's binary_logloss: 0.136146\n",
            "[186]\ttraining's auc: 0.893951\ttraining's binary_logloss: 0.119177\tvalid_1's auc: 0.830632\tvalid_1's binary_logloss: 0.136136\n",
            "[187]\ttraining's auc: 0.894172\ttraining's binary_logloss: 0.119105\tvalid_1's auc: 0.830763\tvalid_1's binary_logloss: 0.136114\n",
            "[188]\ttraining's auc: 0.894296\ttraining's binary_logloss: 0.119035\tvalid_1's auc: 0.830846\tvalid_1's binary_logloss: 0.136092\n",
            "[189]\ttraining's auc: 0.894471\ttraining's binary_logloss: 0.118964\tvalid_1's auc: 0.830844\tvalid_1's binary_logloss: 0.136087\n",
            "[190]\ttraining's auc: 0.894596\ttraining's binary_logloss: 0.118906\tvalid_1's auc: 0.830881\tvalid_1's binary_logloss: 0.136076\n",
            "[191]\ttraining's auc: 0.89467\ttraining's binary_logloss: 0.118849\tvalid_1's auc: 0.830895\tvalid_1's binary_logloss: 0.136068\n",
            "[192]\ttraining's auc: 0.894854\ttraining's binary_logloss: 0.118776\tvalid_1's auc: 0.831009\tvalid_1's binary_logloss: 0.136045\n",
            "[193]\ttraining's auc: 0.8951\ttraining's binary_logloss: 0.118706\tvalid_1's auc: 0.830983\tvalid_1's binary_logloss: 0.136035\n",
            "[194]\ttraining's auc: 0.895238\ttraining's binary_logloss: 0.118645\tvalid_1's auc: 0.831013\tvalid_1's binary_logloss: 0.136023\n",
            "[195]\ttraining's auc: 0.895592\ttraining's binary_logloss: 0.118567\tvalid_1's auc: 0.831244\tvalid_1's binary_logloss: 0.135984\n",
            "[196]\ttraining's auc: 0.895695\ttraining's binary_logloss: 0.118512\tvalid_1's auc: 0.831212\tvalid_1's binary_logloss: 0.135978\n",
            "[197]\ttraining's auc: 0.895861\ttraining's binary_logloss: 0.118448\tvalid_1's auc: 0.831263\tvalid_1's binary_logloss: 0.135959\n",
            "[198]\ttraining's auc: 0.896071\ttraining's binary_logloss: 0.118376\tvalid_1's auc: 0.831319\tvalid_1's binary_logloss: 0.135944\n",
            "[199]\ttraining's auc: 0.896242\ttraining's binary_logloss: 0.118307\tvalid_1's auc: 0.831379\tvalid_1's binary_logloss: 0.13593\n",
            "[200]\ttraining's auc: 0.896418\ttraining's binary_logloss: 0.118245\tvalid_1's auc: 0.831382\tvalid_1's binary_logloss: 0.135925\n",
            "[201]\ttraining's auc: 0.896496\ttraining's binary_logloss: 0.118187\tvalid_1's auc: 0.831372\tvalid_1's binary_logloss: 0.135915\n",
            "[202]\ttraining's auc: 0.896745\ttraining's binary_logloss: 0.118115\tvalid_1's auc: 0.831487\tvalid_1's binary_logloss: 0.13589\n",
            "[203]\ttraining's auc: 0.896906\ttraining's binary_logloss: 0.11805\tvalid_1's auc: 0.831506\tvalid_1's binary_logloss: 0.135878\n",
            "[204]\ttraining's auc: 0.897192\ttraining's binary_logloss: 0.11798\tvalid_1's auc: 0.83158\tvalid_1's binary_logloss: 0.135864\n",
            "[205]\ttraining's auc: 0.8973\ttraining's binary_logloss: 0.117923\tvalid_1's auc: 0.831539\tvalid_1's binary_logloss: 0.135855\n",
            "[206]\ttraining's auc: 0.897429\ttraining's binary_logloss: 0.117862\tvalid_1's auc: 0.831641\tvalid_1's binary_logloss: 0.13584\n",
            "[207]\ttraining's auc: 0.897699\ttraining's binary_logloss: 0.117797\tvalid_1's auc: 0.831806\tvalid_1's binary_logloss: 0.135815\n",
            "[208]\ttraining's auc: 0.897872\ttraining's binary_logloss: 0.11773\tvalid_1's auc: 0.831759\tvalid_1's binary_logloss: 0.135817\n",
            "[209]\ttraining's auc: 0.898086\ttraining's binary_logloss: 0.117667\tvalid_1's auc: 0.831809\tvalid_1's binary_logloss: 0.135801\n",
            "[210]\ttraining's auc: 0.898208\ttraining's binary_logloss: 0.117607\tvalid_1's auc: 0.831826\tvalid_1's binary_logloss: 0.135789\n",
            "[211]\ttraining's auc: 0.898368\ttraining's binary_logloss: 0.11755\tvalid_1's auc: 0.831904\tvalid_1's binary_logloss: 0.135776\n",
            "[212]\ttraining's auc: 0.898513\ttraining's binary_logloss: 0.117485\tvalid_1's auc: 0.83185\tvalid_1's binary_logloss: 0.135778\n",
            "[213]\ttraining's auc: 0.898605\ttraining's binary_logloss: 0.117426\tvalid_1's auc: 0.831858\tvalid_1's binary_logloss: 0.135774\n",
            "[214]\ttraining's auc: 0.898745\ttraining's binary_logloss: 0.11736\tvalid_1's auc: 0.831831\tvalid_1's binary_logloss: 0.135776\n",
            "[215]\ttraining's auc: 0.898878\ttraining's binary_logloss: 0.117296\tvalid_1's auc: 0.831817\tvalid_1's binary_logloss: 0.135777\n",
            "[216]\ttraining's auc: 0.899013\ttraining's binary_logloss: 0.117232\tvalid_1's auc: 0.831787\tvalid_1's binary_logloss: 0.135775\n",
            "[217]\ttraining's auc: 0.899137\ttraining's binary_logloss: 0.117176\tvalid_1's auc: 0.83177\tvalid_1's binary_logloss: 0.135769\n",
            "[218]\ttraining's auc: 0.899307\ttraining's binary_logloss: 0.11711\tvalid_1's auc: 0.831769\tvalid_1's binary_logloss: 0.135773\n",
            "[219]\ttraining's auc: 0.899432\ttraining's binary_logloss: 0.117053\tvalid_1's auc: 0.831759\tvalid_1's binary_logloss: 0.135769\n",
            "[220]\ttraining's auc: 0.899585\ttraining's binary_logloss: 0.116994\tvalid_1's auc: 0.831783\tvalid_1's binary_logloss: 0.135768\n",
            "[221]\ttraining's auc: 0.899702\ttraining's binary_logloss: 0.116936\tvalid_1's auc: 0.831798\tvalid_1's binary_logloss: 0.135763\n",
            "[222]\ttraining's auc: 0.899849\ttraining's binary_logloss: 0.116879\tvalid_1's auc: 0.831751\tvalid_1's binary_logloss: 0.135768\n",
            "[223]\ttraining's auc: 0.90005\ttraining's binary_logloss: 0.116817\tvalid_1's auc: 0.831786\tvalid_1's binary_logloss: 0.135757\n",
            "[224]\ttraining's auc: 0.900213\ttraining's binary_logloss: 0.116765\tvalid_1's auc: 0.831767\tvalid_1's binary_logloss: 0.135748\n",
            "[225]\ttraining's auc: 0.90032\ttraining's binary_logloss: 0.116712\tvalid_1's auc: 0.831752\tvalid_1's binary_logloss: 0.135751\n",
            "[226]\ttraining's auc: 0.900416\ttraining's binary_logloss: 0.116659\tvalid_1's auc: 0.831754\tvalid_1's binary_logloss: 0.135747\n",
            "[227]\ttraining's auc: 0.900557\ttraining's binary_logloss: 0.116594\tvalid_1's auc: 0.831715\tvalid_1's binary_logloss: 0.135759\n",
            "[228]\ttraining's auc: 0.900684\ttraining's binary_logloss: 0.116537\tvalid_1's auc: 0.831695\tvalid_1's binary_logloss: 0.135759\n",
            "[229]\ttraining's auc: 0.900797\ttraining's binary_logloss: 0.11647\tvalid_1's auc: 0.831675\tvalid_1's binary_logloss: 0.135759\n",
            "[230]\ttraining's auc: 0.901005\ttraining's binary_logloss: 0.116417\tvalid_1's auc: 0.831719\tvalid_1's binary_logloss: 0.135751\n",
            "[231]\ttraining's auc: 0.901143\ttraining's binary_logloss: 0.116358\tvalid_1's auc: 0.831656\tvalid_1's binary_logloss: 0.135749\n",
            "[232]\ttraining's auc: 0.90135\ttraining's binary_logloss: 0.116299\tvalid_1's auc: 0.831682\tvalid_1's binary_logloss: 0.135746\n",
            "[233]\ttraining's auc: 0.901448\ttraining's binary_logloss: 0.116248\tvalid_1's auc: 0.831645\tvalid_1's binary_logloss: 0.135754\n",
            "[234]\ttraining's auc: 0.901646\ttraining's binary_logloss: 0.116189\tvalid_1's auc: 0.831678\tvalid_1's binary_logloss: 0.135745\n",
            "[235]\ttraining's auc: 0.901846\ttraining's binary_logloss: 0.116131\tvalid_1's auc: 0.831808\tvalid_1's binary_logloss: 0.135726\n",
            "[236]\ttraining's auc: 0.902025\ttraining's binary_logloss: 0.116081\tvalid_1's auc: 0.831824\tvalid_1's binary_logloss: 0.135723\n",
            "[237]\ttraining's auc: 0.902115\ttraining's binary_logloss: 0.116024\tvalid_1's auc: 0.831752\tvalid_1's binary_logloss: 0.135731\n",
            "[238]\ttraining's auc: 0.902271\ttraining's binary_logloss: 0.115976\tvalid_1's auc: 0.831665\tvalid_1's binary_logloss: 0.135737\n",
            "[239]\ttraining's auc: 0.902389\ttraining's binary_logloss: 0.115917\tvalid_1's auc: 0.831743\tvalid_1's binary_logloss: 0.135729\n",
            "[240]\ttraining's auc: 0.902496\ttraining's binary_logloss: 0.115861\tvalid_1's auc: 0.831809\tvalid_1's binary_logloss: 0.135724\n",
            "[241]\ttraining's auc: 0.902679\ttraining's binary_logloss: 0.115809\tvalid_1's auc: 0.83182\tvalid_1's binary_logloss: 0.135719\n",
            " 10%|█         | 5/50 [03:34<25:11, 33.58s/trial, best loss: -0.8346327164689749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.165588\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.159686\n",
            "[2]\ttraining's auc: 0.819273\ttraining's binary_logloss: 0.164347\tvalid_1's auc: 0.802595\tvalid_1's binary_logloss: 0.158692\n",
            "[3]\ttraining's auc: 0.821869\ttraining's binary_logloss: 0.163188\tvalid_1's auc: 0.804867\tvalid_1's binary_logloss: 0.157742\n",
            "[4]\ttraining's auc: 0.823216\ttraining's binary_logloss: 0.162095\tvalid_1's auc: 0.805384\tvalid_1's binary_logloss: 0.156856\n",
            "[5]\ttraining's auc: 0.823975\ttraining's binary_logloss: 0.161069\tvalid_1's auc: 0.805689\tvalid_1's binary_logloss: 0.156025\n",
            "[6]\ttraining's auc: 0.829149\ttraining's binary_logloss: 0.160077\tvalid_1's auc: 0.816338\tvalid_1's binary_logloss: 0.155206\n",
            "[7]\ttraining's auc: 0.830356\ttraining's binary_logloss: 0.159137\tvalid_1's auc: 0.816995\tvalid_1's binary_logloss: 0.154438\n",
            "[8]\ttraining's auc: 0.831969\ttraining's binary_logloss: 0.158237\tvalid_1's auc: 0.818011\tvalid_1's binary_logloss: 0.15371\n",
            "[9]\ttraining's auc: 0.833489\ttraining's binary_logloss: 0.157368\tvalid_1's auc: 0.818772\tvalid_1's binary_logloss: 0.153022\n",
            "[10]\ttraining's auc: 0.834281\ttraining's binary_logloss: 0.156553\tvalid_1's auc: 0.819705\tvalid_1's binary_logloss: 0.152363\n",
            "[11]\ttraining's auc: 0.834528\ttraining's binary_logloss: 0.15578\tvalid_1's auc: 0.819579\tvalid_1's binary_logloss: 0.151736\n",
            "[12]\ttraining's auc: 0.8347\ttraining's binary_logloss: 0.155031\tvalid_1's auc: 0.819801\tvalid_1's binary_logloss: 0.151153\n",
            "[13]\ttraining's auc: 0.835072\ttraining's binary_logloss: 0.154313\tvalid_1's auc: 0.819869\tvalid_1's binary_logloss: 0.150586\n",
            "[14]\ttraining's auc: 0.835441\ttraining's binary_logloss: 0.153619\tvalid_1's auc: 0.819946\tvalid_1's binary_logloss: 0.150031\n",
            "[15]\ttraining's auc: 0.83589\ttraining's binary_logloss: 0.152957\tvalid_1's auc: 0.82037\tvalid_1's binary_logloss: 0.149524\n",
            "[16]\ttraining's auc: 0.836947\ttraining's binary_logloss: 0.152322\tvalid_1's auc: 0.821293\tvalid_1's binary_logloss: 0.149016\n",
            "[17]\ttraining's auc: 0.837346\ttraining's binary_logloss: 0.151695\tvalid_1's auc: 0.821244\tvalid_1's binary_logloss: 0.14856\n",
            "[18]\ttraining's auc: 0.837695\ttraining's binary_logloss: 0.151103\tvalid_1's auc: 0.82122\tvalid_1's binary_logloss: 0.148105\n",
            "[19]\ttraining's auc: 0.840533\ttraining's binary_logloss: 0.150517\tvalid_1's auc: 0.82383\tvalid_1's binary_logloss: 0.147666\n",
            "[20]\ttraining's auc: 0.840666\ttraining's binary_logloss: 0.149955\tvalid_1's auc: 0.823862\tvalid_1's binary_logloss: 0.147241\n",
            "[21]\ttraining's auc: 0.840935\ttraining's binary_logloss: 0.149422\tvalid_1's auc: 0.82377\tvalid_1's binary_logloss: 0.146847\n",
            "[22]\ttraining's auc: 0.842323\ttraining's binary_logloss: 0.148909\tvalid_1's auc: 0.824111\tvalid_1's binary_logloss: 0.14646\n",
            "[23]\ttraining's auc: 0.842578\ttraining's binary_logloss: 0.148401\tvalid_1's auc: 0.824436\tvalid_1's binary_logloss: 0.146066\n",
            "[24]\ttraining's auc: 0.843755\ttraining's binary_logloss: 0.147904\tvalid_1's auc: 0.824981\tvalid_1's binary_logloss: 0.145689\n",
            "[25]\ttraining's auc: 0.844021\ttraining's binary_logloss: 0.147428\tvalid_1's auc: 0.825061\tvalid_1's binary_logloss: 0.145328\n",
            "[26]\ttraining's auc: 0.844881\ttraining's binary_logloss: 0.146969\tvalid_1's auc: 0.825597\tvalid_1's binary_logloss: 0.144968\n",
            "[27]\ttraining's auc: 0.84754\ttraining's binary_logloss: 0.146502\tvalid_1's auc: 0.828176\tvalid_1's binary_logloss: 0.144631\n",
            "[28]\ttraining's auc: 0.84848\ttraining's binary_logloss: 0.14605\tvalid_1's auc: 0.828448\tvalid_1's binary_logloss: 0.144306\n",
            "[29]\ttraining's auc: 0.849244\ttraining's binary_logloss: 0.145615\tvalid_1's auc: 0.8288\tvalid_1's binary_logloss: 0.143982\n",
            "[30]\ttraining's auc: 0.849383\ttraining's binary_logloss: 0.145187\tvalid_1's auc: 0.829109\tvalid_1's binary_logloss: 0.143674\n",
            "[31]\ttraining's auc: 0.849759\ttraining's binary_logloss: 0.144776\tvalid_1's auc: 0.829156\tvalid_1's binary_logloss: 0.143372\n",
            "[32]\ttraining's auc: 0.849943\ttraining's binary_logloss: 0.14438\tvalid_1's auc: 0.82953\tvalid_1's binary_logloss: 0.143083\n",
            "[33]\ttraining's auc: 0.850477\ttraining's binary_logloss: 0.14399\tvalid_1's auc: 0.829363\tvalid_1's binary_logloss: 0.142788\n",
            "[34]\ttraining's auc: 0.850837\ttraining's binary_logloss: 0.143615\tvalid_1's auc: 0.829282\tvalid_1's binary_logloss: 0.142515\n",
            "[35]\ttraining's auc: 0.851407\ttraining's binary_logloss: 0.143251\tvalid_1's auc: 0.829946\tvalid_1's binary_logloss: 0.142244\n",
            "[36]\ttraining's auc: 0.851681\ttraining's binary_logloss: 0.142894\tvalid_1's auc: 0.829997\tvalid_1's binary_logloss: 0.14198\n",
            "[37]\ttraining's auc: 0.85233\ttraining's binary_logloss: 0.142552\tvalid_1's auc: 0.829812\tvalid_1's binary_logloss: 0.141727\n",
            "[38]\ttraining's auc: 0.85275\ttraining's binary_logloss: 0.142202\tvalid_1's auc: 0.829996\tvalid_1's binary_logloss: 0.141469\n",
            "[39]\ttraining's auc: 0.853095\ttraining's binary_logloss: 0.141862\tvalid_1's auc: 0.830157\tvalid_1's binary_logloss: 0.141214\n",
            "[40]\ttraining's auc: 0.853528\ttraining's binary_logloss: 0.141528\tvalid_1's auc: 0.830304\tvalid_1's binary_logloss: 0.140966\n",
            "[41]\ttraining's auc: 0.854056\ttraining's binary_logloss: 0.141205\tvalid_1's auc: 0.830365\tvalid_1's binary_logloss: 0.140712\n",
            "[42]\ttraining's auc: 0.854477\ttraining's binary_logloss: 0.140883\tvalid_1's auc: 0.830328\tvalid_1's binary_logloss: 0.140465\n",
            "[43]\ttraining's auc: 0.855352\ttraining's binary_logloss: 0.140571\tvalid_1's auc: 0.83126\tvalid_1's binary_logloss: 0.14023\n",
            "[44]\ttraining's auc: 0.856081\ttraining's binary_logloss: 0.140275\tvalid_1's auc: 0.832706\tvalid_1's binary_logloss: 0.14001\n",
            "[45]\ttraining's auc: 0.856405\ttraining's binary_logloss: 0.139982\tvalid_1's auc: 0.83255\tvalid_1's binary_logloss: 0.139807\n",
            "[46]\ttraining's auc: 0.856637\ttraining's binary_logloss: 0.139692\tvalid_1's auc: 0.832791\tvalid_1's binary_logloss: 0.139593\n",
            "[47]\ttraining's auc: 0.857309\ttraining's binary_logloss: 0.13941\tvalid_1's auc: 0.832842\tvalid_1's binary_logloss: 0.139407\n",
            "[48]\ttraining's auc: 0.857595\ttraining's binary_logloss: 0.139136\tvalid_1's auc: 0.832942\tvalid_1's binary_logloss: 0.139202\n",
            "[49]\ttraining's auc: 0.857855\ttraining's binary_logloss: 0.13886\tvalid_1's auc: 0.832999\tvalid_1's binary_logloss: 0.138999\n",
            "[50]\ttraining's auc: 0.858253\ttraining's binary_logloss: 0.138591\tvalid_1's auc: 0.832946\tvalid_1's binary_logloss: 0.13882\n",
            "[51]\ttraining's auc: 0.858696\ttraining's binary_logloss: 0.138322\tvalid_1's auc: 0.833106\tvalid_1's binary_logloss: 0.138638\n",
            "[52]\ttraining's auc: 0.859038\ttraining's binary_logloss: 0.138057\tvalid_1's auc: 0.83318\tvalid_1's binary_logloss: 0.138465\n",
            "[53]\ttraining's auc: 0.859135\ttraining's binary_logloss: 0.137796\tvalid_1's auc: 0.832908\tvalid_1's binary_logloss: 0.138296\n",
            "[54]\ttraining's auc: 0.859398\ttraining's binary_logloss: 0.137547\tvalid_1's auc: 0.832766\tvalid_1's binary_logloss: 0.138135\n",
            "[55]\ttraining's auc: 0.859778\ttraining's binary_logloss: 0.137308\tvalid_1's auc: 0.832937\tvalid_1's binary_logloss: 0.137963\n",
            "[56]\ttraining's auc: 0.859929\ttraining's binary_logloss: 0.137071\tvalid_1's auc: 0.832892\tvalid_1's binary_logloss: 0.137813\n",
            "[57]\ttraining's auc: 0.860215\ttraining's binary_logloss: 0.13683\tvalid_1's auc: 0.832997\tvalid_1's binary_logloss: 0.13765\n",
            "[58]\ttraining's auc: 0.860468\ttraining's binary_logloss: 0.136597\tvalid_1's auc: 0.832969\tvalid_1's binary_logloss: 0.137505\n",
            "[59]\ttraining's auc: 0.860603\ttraining's binary_logloss: 0.136373\tvalid_1's auc: 0.832994\tvalid_1's binary_logloss: 0.137353\n",
            "[60]\ttraining's auc: 0.861036\ttraining's binary_logloss: 0.136149\tvalid_1's auc: 0.833033\tvalid_1's binary_logloss: 0.137208\n",
            "[61]\ttraining's auc: 0.861219\ttraining's binary_logloss: 0.135922\tvalid_1's auc: 0.833163\tvalid_1's binary_logloss: 0.137055\n",
            "[62]\ttraining's auc: 0.861917\ttraining's binary_logloss: 0.135708\tvalid_1's auc: 0.833432\tvalid_1's binary_logloss: 0.136922\n",
            "[63]\ttraining's auc: 0.86301\ttraining's binary_logloss: 0.135501\tvalid_1's auc: 0.833984\tvalid_1's binary_logloss: 0.136784\n",
            "[64]\ttraining's auc: 0.863062\ttraining's binary_logloss: 0.135289\tvalid_1's auc: 0.833965\tvalid_1's binary_logloss: 0.136665\n",
            "[65]\ttraining's auc: 0.863309\ttraining's binary_logloss: 0.135086\tvalid_1's auc: 0.834102\tvalid_1's binary_logloss: 0.136523\n",
            "[66]\ttraining's auc: 0.863668\ttraining's binary_logloss: 0.134873\tvalid_1's auc: 0.834178\tvalid_1's binary_logloss: 0.136399\n",
            "[67]\ttraining's auc: 0.863909\ttraining's binary_logloss: 0.13467\tvalid_1's auc: 0.834218\tvalid_1's binary_logloss: 0.136275\n",
            "[68]\ttraining's auc: 0.864736\ttraining's binary_logloss: 0.13446\tvalid_1's auc: 0.83439\tvalid_1's binary_logloss: 0.136154\n",
            "[69]\ttraining's auc: 0.865626\ttraining's binary_logloss: 0.134251\tvalid_1's auc: 0.834492\tvalid_1's binary_logloss: 0.136041\n",
            "[70]\ttraining's auc: 0.866165\ttraining's binary_logloss: 0.134056\tvalid_1's auc: 0.834428\tvalid_1's binary_logloss: 0.135939\n",
            "[71]\ttraining's auc: 0.866718\ttraining's binary_logloss: 0.133851\tvalid_1's auc: 0.834542\tvalid_1's binary_logloss: 0.135831\n",
            "[72]\ttraining's auc: 0.866905\ttraining's binary_logloss: 0.133665\tvalid_1's auc: 0.834485\tvalid_1's binary_logloss: 0.135731\n",
            "[73]\ttraining's auc: 0.867267\ttraining's binary_logloss: 0.133477\tvalid_1's auc: 0.834543\tvalid_1's binary_logloss: 0.135621\n",
            "[74]\ttraining's auc: 0.867674\ttraining's binary_logloss: 0.133293\tvalid_1's auc: 0.834608\tvalid_1's binary_logloss: 0.135518\n",
            "[75]\ttraining's auc: 0.868091\ttraining's binary_logloss: 0.133106\tvalid_1's auc: 0.834596\tvalid_1's binary_logloss: 0.135435\n",
            "[76]\ttraining's auc: 0.868407\ttraining's binary_logloss: 0.132922\tvalid_1's auc: 0.834897\tvalid_1's binary_logloss: 0.13533\n",
            "[77]\ttraining's auc: 0.868903\ttraining's binary_logloss: 0.132742\tvalid_1's auc: 0.835107\tvalid_1's binary_logloss: 0.135243\n",
            "[78]\ttraining's auc: 0.869142\ttraining's binary_logloss: 0.13257\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.13515\n",
            "[79]\ttraining's auc: 0.869706\ttraining's binary_logloss: 0.132401\tvalid_1's auc: 0.835017\tvalid_1's binary_logloss: 0.135062\n",
            "[80]\ttraining's auc: 0.870047\ttraining's binary_logloss: 0.132236\tvalid_1's auc: 0.835051\tvalid_1's binary_logloss: 0.134983\n",
            "[81]\ttraining's auc: 0.870329\ttraining's binary_logloss: 0.13207\tvalid_1's auc: 0.834903\tvalid_1's binary_logloss: 0.134895\n",
            "[82]\ttraining's auc: 0.870842\ttraining's binary_logloss: 0.131898\tvalid_1's auc: 0.834877\tvalid_1's binary_logloss: 0.134809\n",
            "[83]\ttraining's auc: 0.871021\ttraining's binary_logloss: 0.131735\tvalid_1's auc: 0.83481\tvalid_1's binary_logloss: 0.134732\n",
            "[84]\ttraining's auc: 0.871257\ttraining's binary_logloss: 0.13158\tvalid_1's auc: 0.834806\tvalid_1's binary_logloss: 0.134647\n",
            "[85]\ttraining's auc: 0.871445\ttraining's binary_logloss: 0.131423\tvalid_1's auc: 0.834783\tvalid_1's binary_logloss: 0.134573\n",
            "[86]\ttraining's auc: 0.871662\ttraining's binary_logloss: 0.13127\tvalid_1's auc: 0.834783\tvalid_1's binary_logloss: 0.134491\n",
            "[87]\ttraining's auc: 0.871862\ttraining's binary_logloss: 0.131119\tvalid_1's auc: 0.834711\tvalid_1's binary_logloss: 0.134408\n",
            "[88]\ttraining's auc: 0.872104\ttraining's binary_logloss: 0.130958\tvalid_1's auc: 0.834735\tvalid_1's binary_logloss: 0.134333\n",
            "[89]\ttraining's auc: 0.872316\ttraining's binary_logloss: 0.130816\tvalid_1's auc: 0.834845\tvalid_1's binary_logloss: 0.13425\n",
            "[90]\ttraining's auc: 0.872541\ttraining's binary_logloss: 0.130672\tvalid_1's auc: 0.834891\tvalid_1's binary_logloss: 0.134177\n",
            "[91]\ttraining's auc: 0.872669\ttraining's binary_logloss: 0.130533\tvalid_1's auc: 0.834905\tvalid_1's binary_logloss: 0.134112\n",
            "[92]\ttraining's auc: 0.872861\ttraining's binary_logloss: 0.130385\tvalid_1's auc: 0.834956\tvalid_1's binary_logloss: 0.134049\n",
            "[93]\ttraining's auc: 0.873126\ttraining's binary_logloss: 0.130246\tvalid_1's auc: 0.834897\tvalid_1's binary_logloss: 0.13399\n",
            "[94]\ttraining's auc: 0.873274\ttraining's binary_logloss: 0.1301\tvalid_1's auc: 0.834962\tvalid_1's binary_logloss: 0.133923\n",
            "[95]\ttraining's auc: 0.873467\ttraining's binary_logloss: 0.12997\tvalid_1's auc: 0.834862\tvalid_1's binary_logloss: 0.133865\n",
            "[96]\ttraining's auc: 0.873597\ttraining's binary_logloss: 0.129834\tvalid_1's auc: 0.834782\tvalid_1's binary_logloss: 0.133806\n",
            "[97]\ttraining's auc: 0.873782\ttraining's binary_logloss: 0.1297\tvalid_1's auc: 0.834805\tvalid_1's binary_logloss: 0.133736\n",
            "[98]\ttraining's auc: 0.873902\ttraining's binary_logloss: 0.129567\tvalid_1's auc: 0.83478\tvalid_1's binary_logloss: 0.133681\n",
            "[99]\ttraining's auc: 0.874104\ttraining's binary_logloss: 0.129447\tvalid_1's auc: 0.834825\tvalid_1's binary_logloss: 0.133615\n",
            "[100]\ttraining's auc: 0.874215\ttraining's binary_logloss: 0.129321\tvalid_1's auc: 0.834651\tvalid_1's binary_logloss: 0.133561\n",
            "[101]\ttraining's auc: 0.874426\ttraining's binary_logloss: 0.129185\tvalid_1's auc: 0.834674\tvalid_1's binary_logloss: 0.133508\n",
            "[102]\ttraining's auc: 0.874585\ttraining's binary_logloss: 0.129055\tvalid_1's auc: 0.834602\tvalid_1's binary_logloss: 0.133459\n",
            "[103]\ttraining's auc: 0.874795\ttraining's binary_logloss: 0.128932\tvalid_1's auc: 0.834529\tvalid_1's binary_logloss: 0.133408\n",
            "[104]\ttraining's auc: 0.874964\ttraining's binary_logloss: 0.128805\tvalid_1's auc: 0.834707\tvalid_1's binary_logloss: 0.133351\n",
            "[105]\ttraining's auc: 0.875116\ttraining's binary_logloss: 0.128683\tvalid_1's auc: 0.834705\tvalid_1's binary_logloss: 0.133297\n",
            "[106]\ttraining's auc: 0.875152\ttraining's binary_logloss: 0.128567\tvalid_1's auc: 0.834704\tvalid_1's binary_logloss: 0.133243\n",
            "[107]\ttraining's auc: 0.875346\ttraining's binary_logloss: 0.128446\tvalid_1's auc: 0.83469\tvalid_1's binary_logloss: 0.133192\n",
            " 10%|█         | 5/50 [03:59<25:11, 33.58s/trial, best loss: -0.8346327164689749]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.161804\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.167325\n",
            "[2]\ttraining's auc: 0.827205\ttraining's binary_logloss: 0.160622\tvalid_1's auc: 0.811332\tvalid_1's binary_logloss: 0.16623\n",
            "[3]\ttraining's auc: 0.83112\ttraining's binary_logloss: 0.159495\tvalid_1's auc: 0.815259\tvalid_1's binary_logloss: 0.165195\n",
            "[4]\ttraining's auc: 0.831115\ttraining's binary_logloss: 0.158445\tvalid_1's auc: 0.815382\tvalid_1's binary_logloss: 0.164239\n",
            "[5]\ttraining's auc: 0.831981\ttraining's binary_logloss: 0.157462\tvalid_1's auc: 0.816051\tvalid_1's binary_logloss: 0.163355\n",
            "[6]\ttraining's auc: 0.832262\ttraining's binary_logloss: 0.156536\tvalid_1's auc: 0.816114\tvalid_1's binary_logloss: 0.162518\n",
            "[7]\ttraining's auc: 0.832843\ttraining's binary_logloss: 0.155643\tvalid_1's auc: 0.816153\tvalid_1's binary_logloss: 0.161701\n",
            "[8]\ttraining's auc: 0.834159\ttraining's binary_logloss: 0.154782\tvalid_1's auc: 0.816527\tvalid_1's binary_logloss: 0.160916\n",
            "[9]\ttraining's auc: 0.834835\ttraining's binary_logloss: 0.153975\tvalid_1's auc: 0.817579\tvalid_1's binary_logloss: 0.160204\n",
            "[10]\ttraining's auc: 0.835262\ttraining's binary_logloss: 0.153192\tvalid_1's auc: 0.817477\tvalid_1's binary_logloss: 0.159511\n",
            "[11]\ttraining's auc: 0.835482\ttraining's binary_logloss: 0.152462\tvalid_1's auc: 0.816967\tvalid_1's binary_logloss: 0.158857\n",
            "[12]\ttraining's auc: 0.837285\ttraining's binary_logloss: 0.151745\tvalid_1's auc: 0.818443\tvalid_1's binary_logloss: 0.158215\n",
            "[13]\ttraining's auc: 0.8381\ttraining's binary_logloss: 0.151062\tvalid_1's auc: 0.81868\tvalid_1's binary_logloss: 0.157622\n",
            "[14]\ttraining's auc: 0.838939\ttraining's binary_logloss: 0.15041\tvalid_1's auc: 0.818782\tvalid_1's binary_logloss: 0.157042\n",
            "[15]\ttraining's auc: 0.839012\ttraining's binary_logloss: 0.149747\tvalid_1's auc: 0.819121\tvalid_1's binary_logloss: 0.156445\n",
            "[16]\ttraining's auc: 0.839465\ttraining's binary_logloss: 0.149138\tvalid_1's auc: 0.819268\tvalid_1's binary_logloss: 0.15589\n",
            "[17]\ttraining's auc: 0.840924\ttraining's binary_logloss: 0.148537\tvalid_1's auc: 0.819503\tvalid_1's binary_logloss: 0.155381\n",
            "[18]\ttraining's auc: 0.841191\ttraining's binary_logloss: 0.147967\tvalid_1's auc: 0.81969\tvalid_1's binary_logloss: 0.154887\n",
            "[19]\ttraining's auc: 0.842995\ttraining's binary_logloss: 0.147403\tvalid_1's auc: 0.821569\tvalid_1's binary_logloss: 0.154396\n",
            "[20]\ttraining's auc: 0.844699\ttraining's binary_logloss: 0.14686\tvalid_1's auc: 0.822553\tvalid_1's binary_logloss: 0.153932\n",
            "[21]\ttraining's auc: 0.847201\ttraining's binary_logloss: 0.146312\tvalid_1's auc: 0.825496\tvalid_1's binary_logloss: 0.153467\n",
            "[22]\ttraining's auc: 0.847942\ttraining's binary_logloss: 0.145794\tvalid_1's auc: 0.825976\tvalid_1's binary_logloss: 0.153026\n",
            "[23]\ttraining's auc: 0.848545\ttraining's binary_logloss: 0.145281\tvalid_1's auc: 0.826264\tvalid_1's binary_logloss: 0.152585\n",
            "[24]\ttraining's auc: 0.849663\ttraining's binary_logloss: 0.144788\tvalid_1's auc: 0.826975\tvalid_1's binary_logloss: 0.152173\n",
            "[25]\ttraining's auc: 0.850153\ttraining's binary_logloss: 0.144322\tvalid_1's auc: 0.827578\tvalid_1's binary_logloss: 0.151783\n",
            "[26]\ttraining's auc: 0.85058\ttraining's binary_logloss: 0.143868\tvalid_1's auc: 0.82758\tvalid_1's binary_logloss: 0.151407\n",
            "[27]\ttraining's auc: 0.851015\ttraining's binary_logloss: 0.143433\tvalid_1's auc: 0.827493\tvalid_1's binary_logloss: 0.15102\n",
            "[28]\ttraining's auc: 0.850358\ttraining's binary_logloss: 0.143013\tvalid_1's auc: 0.827726\tvalid_1's binary_logloss: 0.150655\n",
            "[29]\ttraining's auc: 0.850448\ttraining's binary_logloss: 0.142601\tvalid_1's auc: 0.827936\tvalid_1's binary_logloss: 0.150307\n",
            "[30]\ttraining's auc: 0.850666\ttraining's binary_logloss: 0.142201\tvalid_1's auc: 0.827864\tvalid_1's binary_logloss: 0.149985\n",
            "[31]\ttraining's auc: 0.850885\ttraining's binary_logloss: 0.141808\tvalid_1's auc: 0.828057\tvalid_1's binary_logloss: 0.149661\n",
            "[32]\ttraining's auc: 0.851154\ttraining's binary_logloss: 0.141414\tvalid_1's auc: 0.828685\tvalid_1's binary_logloss: 0.149335\n",
            "[33]\ttraining's auc: 0.851876\ttraining's binary_logloss: 0.141039\tvalid_1's auc: 0.828859\tvalid_1's binary_logloss: 0.149019\n",
            "[34]\ttraining's auc: 0.852567\ttraining's binary_logloss: 0.140664\tvalid_1's auc: 0.828998\tvalid_1's binary_logloss: 0.148715\n",
            "[35]\ttraining's auc: 0.852917\ttraining's binary_logloss: 0.140297\tvalid_1's auc: 0.828722\tvalid_1's binary_logloss: 0.148424\n",
            "[36]\ttraining's auc: 0.852938\ttraining's binary_logloss: 0.139943\tvalid_1's auc: 0.829006\tvalid_1's binary_logloss: 0.148125\n",
            "[37]\ttraining's auc: 0.853107\ttraining's binary_logloss: 0.13958\tvalid_1's auc: 0.829049\tvalid_1's binary_logloss: 0.147847\n",
            "[38]\ttraining's auc: 0.853349\ttraining's binary_logloss: 0.139247\tvalid_1's auc: 0.829034\tvalid_1's binary_logloss: 0.147577\n",
            "[39]\ttraining's auc: 0.853522\ttraining's binary_logloss: 0.138906\tvalid_1's auc: 0.829012\tvalid_1's binary_logloss: 0.147307\n",
            "[40]\ttraining's auc: 0.853785\ttraining's binary_logloss: 0.138573\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.147059\n",
            "[41]\ttraining's auc: 0.854153\ttraining's binary_logloss: 0.138259\tvalid_1's auc: 0.829353\tvalid_1's binary_logloss: 0.146814\n",
            "[42]\ttraining's auc: 0.854818\ttraining's binary_logloss: 0.137947\tvalid_1's auc: 0.829802\tvalid_1's binary_logloss: 0.146566\n",
            "[43]\ttraining's auc: 0.855417\ttraining's binary_logloss: 0.137641\tvalid_1's auc: 0.829985\tvalid_1's binary_logloss: 0.146329\n",
            "[44]\ttraining's auc: 0.855407\ttraining's binary_logloss: 0.13734\tvalid_1's auc: 0.830123\tvalid_1's binary_logloss: 0.146095\n",
            "[45]\ttraining's auc: 0.855968\ttraining's binary_logloss: 0.137045\tvalid_1's auc: 0.830448\tvalid_1's binary_logloss: 0.145867\n",
            "[46]\ttraining's auc: 0.85605\ttraining's binary_logloss: 0.136759\tvalid_1's auc: 0.830556\tvalid_1's binary_logloss: 0.145657\n",
            "[47]\ttraining's auc: 0.85628\ttraining's binary_logloss: 0.136485\tvalid_1's auc: 0.830768\tvalid_1's binary_logloss: 0.145448\n",
            "[48]\ttraining's auc: 0.85647\ttraining's binary_logloss: 0.13621\tvalid_1's auc: 0.830858\tvalid_1's binary_logloss: 0.145241\n",
            "[49]\ttraining's auc: 0.856707\ttraining's binary_logloss: 0.135944\tvalid_1's auc: 0.831079\tvalid_1's binary_logloss: 0.145035\n",
            "[50]\ttraining's auc: 0.857116\ttraining's binary_logloss: 0.13567\tvalid_1's auc: 0.831065\tvalid_1's binary_logloss: 0.144831\n",
            "[51]\ttraining's auc: 0.857332\ttraining's binary_logloss: 0.135411\tvalid_1's auc: 0.831177\tvalid_1's binary_logloss: 0.144628\n",
            "[52]\ttraining's auc: 0.857592\ttraining's binary_logloss: 0.135162\tvalid_1's auc: 0.831199\tvalid_1's binary_logloss: 0.144437\n",
            "[53]\ttraining's auc: 0.857921\ttraining's binary_logloss: 0.134918\tvalid_1's auc: 0.83147\tvalid_1's binary_logloss: 0.144244\n",
            "[54]\ttraining's auc: 0.858202\ttraining's binary_logloss: 0.13467\tvalid_1's auc: 0.831594\tvalid_1's binary_logloss: 0.144062\n",
            "[55]\ttraining's auc: 0.85842\ttraining's binary_logloss: 0.13443\tvalid_1's auc: 0.831689\tvalid_1's binary_logloss: 0.143873\n",
            "[56]\ttraining's auc: 0.85868\ttraining's binary_logloss: 0.134194\tvalid_1's auc: 0.831795\tvalid_1's binary_logloss: 0.143698\n",
            "[57]\ttraining's auc: 0.859367\ttraining's binary_logloss: 0.13396\tvalid_1's auc: 0.831725\tvalid_1's binary_logloss: 0.143534\n",
            "[58]\ttraining's auc: 0.859715\ttraining's binary_logloss: 0.133738\tvalid_1's auc: 0.831891\tvalid_1's binary_logloss: 0.143373\n",
            "[59]\ttraining's auc: 0.860025\ttraining's binary_logloss: 0.133515\tvalid_1's auc: 0.832065\tvalid_1's binary_logloss: 0.143214\n",
            "[60]\ttraining's auc: 0.860284\ttraining's binary_logloss: 0.133298\tvalid_1's auc: 0.832058\tvalid_1's binary_logloss: 0.143054\n",
            "[61]\ttraining's auc: 0.860903\ttraining's binary_logloss: 0.133091\tvalid_1's auc: 0.832164\tvalid_1's binary_logloss: 0.142897\n",
            "[62]\ttraining's auc: 0.861343\ttraining's binary_logloss: 0.13287\tvalid_1's auc: 0.832367\tvalid_1's binary_logloss: 0.142744\n",
            "[63]\ttraining's auc: 0.861576\ttraining's binary_logloss: 0.132673\tvalid_1's auc: 0.83244\tvalid_1's binary_logloss: 0.1426\n",
            "[64]\ttraining's auc: 0.861938\ttraining's binary_logloss: 0.13247\tvalid_1's auc: 0.832402\tvalid_1's binary_logloss: 0.142462\n",
            "[65]\ttraining's auc: 0.862363\ttraining's binary_logloss: 0.132267\tvalid_1's auc: 0.832476\tvalid_1's binary_logloss: 0.142324\n",
            "[66]\ttraining's auc: 0.862644\ttraining's binary_logloss: 0.132076\tvalid_1's auc: 0.832578\tvalid_1's binary_logloss: 0.142184\n",
            "[67]\ttraining's auc: 0.862945\ttraining's binary_logloss: 0.131884\tvalid_1's auc: 0.832592\tvalid_1's binary_logloss: 0.142055\n",
            "[68]\ttraining's auc: 0.863323\ttraining's binary_logloss: 0.131694\tvalid_1's auc: 0.832515\tvalid_1's binary_logloss: 0.14193\n",
            "[69]\ttraining's auc: 0.863914\ttraining's binary_logloss: 0.131505\tvalid_1's auc: 0.832682\tvalid_1's binary_logloss: 0.141812\n",
            "[70]\ttraining's auc: 0.864217\ttraining's binary_logloss: 0.131321\tvalid_1's auc: 0.832662\tvalid_1's binary_logloss: 0.1417\n",
            "[71]\ttraining's auc: 0.864427\ttraining's binary_logloss: 0.131143\tvalid_1's auc: 0.832607\tvalid_1's binary_logloss: 0.141586\n",
            "[72]\ttraining's auc: 0.864685\ttraining's binary_logloss: 0.130966\tvalid_1's auc: 0.832549\tvalid_1's binary_logloss: 0.141482\n",
            "[73]\ttraining's auc: 0.864892\ttraining's binary_logloss: 0.130794\tvalid_1's auc: 0.8325\tvalid_1's binary_logloss: 0.141374\n",
            "[74]\ttraining's auc: 0.865079\ttraining's binary_logloss: 0.130627\tvalid_1's auc: 0.83258\tvalid_1's binary_logloss: 0.141272\n",
            "[75]\ttraining's auc: 0.865865\ttraining's binary_logloss: 0.130446\tvalid_1's auc: 0.832746\tvalid_1's binary_logloss: 0.141156\n",
            "[76]\ttraining's auc: 0.866154\ttraining's binary_logloss: 0.130276\tvalid_1's auc: 0.832683\tvalid_1's binary_logloss: 0.141059\n",
            "[77]\ttraining's auc: 0.866637\ttraining's binary_logloss: 0.130104\tvalid_1's auc: 0.832693\tvalid_1's binary_logloss: 0.140958\n",
            "[78]\ttraining's auc: 0.866993\ttraining's binary_logloss: 0.129942\tvalid_1's auc: 0.832759\tvalid_1's binary_logloss: 0.140862\n",
            "[79]\ttraining's auc: 0.867655\ttraining's binary_logloss: 0.129776\tvalid_1's auc: 0.832787\tvalid_1's binary_logloss: 0.140758\n",
            "[80]\ttraining's auc: 0.867888\ttraining's binary_logloss: 0.129608\tvalid_1's auc: 0.832884\tvalid_1's binary_logloss: 0.140655\n",
            "[81]\ttraining's auc: 0.868305\ttraining's binary_logloss: 0.12945\tvalid_1's auc: 0.832874\tvalid_1's binary_logloss: 0.140575\n",
            "[82]\ttraining's auc: 0.868674\ttraining's binary_logloss: 0.129288\tvalid_1's auc: 0.832754\tvalid_1's binary_logloss: 0.140495\n",
            "[83]\ttraining's auc: 0.869016\ttraining's binary_logloss: 0.129122\tvalid_1's auc: 0.83275\tvalid_1's binary_logloss: 0.140412\n",
            "[84]\ttraining's auc: 0.869316\ttraining's binary_logloss: 0.12897\tvalid_1's auc: 0.832811\tvalid_1's binary_logloss: 0.140325\n",
            "[85]\ttraining's auc: 0.86958\ttraining's binary_logloss: 0.12882\tvalid_1's auc: 0.832772\tvalid_1's binary_logloss: 0.140248\n",
            "[86]\ttraining's auc: 0.870579\ttraining's binary_logloss: 0.128672\tvalid_1's auc: 0.834352\tvalid_1's binary_logloss: 0.14017\n",
            "[87]\ttraining's auc: 0.870767\ttraining's binary_logloss: 0.128531\tvalid_1's auc: 0.834261\tvalid_1's binary_logloss: 0.140093\n",
            "[88]\ttraining's auc: 0.870933\ttraining's binary_logloss: 0.128392\tvalid_1's auc: 0.834321\tvalid_1's binary_logloss: 0.140018\n",
            "[89]\ttraining's auc: 0.871589\ttraining's binary_logloss: 0.128244\tvalid_1's auc: 0.834739\tvalid_1's binary_logloss: 0.139927\n",
            "[90]\ttraining's auc: 0.871869\ttraining's binary_logloss: 0.1281\tvalid_1's auc: 0.834811\tvalid_1's binary_logloss: 0.139855\n",
            "[91]\ttraining's auc: 0.871959\ttraining's binary_logloss: 0.127959\tvalid_1's auc: 0.834928\tvalid_1's binary_logloss: 0.139759\n",
            "[92]\ttraining's auc: 0.872289\ttraining's binary_logloss: 0.127816\tvalid_1's auc: 0.834906\tvalid_1's binary_logloss: 0.139689\n",
            "[93]\ttraining's auc: 0.872587\ttraining's binary_logloss: 0.127671\tvalid_1's auc: 0.835124\tvalid_1's binary_logloss: 0.1396\n",
            "[94]\ttraining's auc: 0.872922\ttraining's binary_logloss: 0.127529\tvalid_1's auc: 0.83515\tvalid_1's binary_logloss: 0.139527\n",
            "[95]\ttraining's auc: 0.873029\ttraining's binary_logloss: 0.127393\tvalid_1's auc: 0.835213\tvalid_1's binary_logloss: 0.139453\n",
            "[96]\ttraining's auc: 0.873364\ttraining's binary_logloss: 0.127253\tvalid_1's auc: 0.835188\tvalid_1's binary_logloss: 0.139383\n",
            "[97]\ttraining's auc: 0.873547\ttraining's binary_logloss: 0.127122\tvalid_1's auc: 0.835269\tvalid_1's binary_logloss: 0.139313\n",
            "[98]\ttraining's auc: 0.874102\ttraining's binary_logloss: 0.126981\tvalid_1's auc: 0.835457\tvalid_1's binary_logloss: 0.139242\n",
            "[99]\ttraining's auc: 0.874415\ttraining's binary_logloss: 0.126858\tvalid_1's auc: 0.835568\tvalid_1's binary_logloss: 0.13918\n",
            "[100]\ttraining's auc: 0.874781\ttraining's binary_logloss: 0.126725\tvalid_1's auc: 0.835872\tvalid_1's binary_logloss: 0.139118\n",
            "[101]\ttraining's auc: 0.875069\ttraining's binary_logloss: 0.126593\tvalid_1's auc: 0.835814\tvalid_1's binary_logloss: 0.139058\n",
            "[102]\ttraining's auc: 0.875301\ttraining's binary_logloss: 0.12647\tvalid_1's auc: 0.835787\tvalid_1's binary_logloss: 0.138994\n",
            "[103]\ttraining's auc: 0.875553\ttraining's binary_logloss: 0.126344\tvalid_1's auc: 0.835923\tvalid_1's binary_logloss: 0.138923\n",
            "[104]\ttraining's auc: 0.875694\ttraining's binary_logloss: 0.126224\tvalid_1's auc: 0.836004\tvalid_1's binary_logloss: 0.138864\n",
            "[105]\ttraining's auc: 0.87584\ttraining's binary_logloss: 0.126108\tvalid_1's auc: 0.83599\tvalid_1's binary_logloss: 0.138809\n",
            "[106]\ttraining's auc: 0.876122\ttraining's binary_logloss: 0.125973\tvalid_1's auc: 0.836038\tvalid_1's binary_logloss: 0.138749\n",
            "[107]\ttraining's auc: 0.876411\ttraining's binary_logloss: 0.12585\tvalid_1's auc: 0.836155\tvalid_1's binary_logloss: 0.138693\n",
            "[108]\ttraining's auc: 0.877018\ttraining's binary_logloss: 0.125724\tvalid_1's auc: 0.836002\tvalid_1's binary_logloss: 0.138642\n",
            "[109]\ttraining's auc: 0.877404\ttraining's binary_logloss: 0.125594\tvalid_1's auc: 0.836014\tvalid_1's binary_logloss: 0.138586\n",
            "[110]\ttraining's auc: 0.8777\ttraining's binary_logloss: 0.125463\tvalid_1's auc: 0.835956\tvalid_1's binary_logloss: 0.138531\n",
            "[111]\ttraining's auc: 0.878031\ttraining's binary_logloss: 0.125335\tvalid_1's auc: 0.836005\tvalid_1's binary_logloss: 0.138477\n",
            "[112]\ttraining's auc: 0.878517\ttraining's binary_logloss: 0.125209\tvalid_1's auc: 0.836017\tvalid_1's binary_logloss: 0.138419\n",
            "[113]\ttraining's auc: 0.878941\ttraining's binary_logloss: 0.125085\tvalid_1's auc: 0.836218\tvalid_1's binary_logloss: 0.138354\n",
            "[114]\ttraining's auc: 0.879092\ttraining's binary_logloss: 0.124974\tvalid_1's auc: 0.836197\tvalid_1's binary_logloss: 0.138299\n",
            "[115]\ttraining's auc: 0.879306\ttraining's binary_logloss: 0.124854\tvalid_1's auc: 0.836228\tvalid_1's binary_logloss: 0.138249\n",
            "[116]\ttraining's auc: 0.879459\ttraining's binary_logloss: 0.124746\tvalid_1's auc: 0.836421\tvalid_1's binary_logloss: 0.138192\n",
            "[117]\ttraining's auc: 0.879657\ttraining's binary_logloss: 0.124636\tvalid_1's auc: 0.836484\tvalid_1's binary_logloss: 0.138144\n",
            "[118]\ttraining's auc: 0.880138\ttraining's binary_logloss: 0.124524\tvalid_1's auc: 0.8365\tvalid_1's binary_logloss: 0.138096\n",
            "[119]\ttraining's auc: 0.880365\ttraining's binary_logloss: 0.124419\tvalid_1's auc: 0.836592\tvalid_1's binary_logloss: 0.138045\n",
            "[120]\ttraining's auc: 0.880793\ttraining's binary_logloss: 0.124317\tvalid_1's auc: 0.836826\tvalid_1's binary_logloss: 0.138002\n",
            "[121]\ttraining's auc: 0.880991\ttraining's binary_logloss: 0.124212\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.137958\n",
            "[122]\ttraining's auc: 0.881239\ttraining's binary_logloss: 0.124092\tvalid_1's auc: 0.836782\tvalid_1's binary_logloss: 0.137922\n",
            "[123]\ttraining's auc: 0.881479\ttraining's binary_logloss: 0.123994\tvalid_1's auc: 0.836716\tvalid_1's binary_logloss: 0.137878\n",
            "[124]\ttraining's auc: 0.881834\ttraining's binary_logloss: 0.123879\tvalid_1's auc: 0.83667\tvalid_1's binary_logloss: 0.137845\n",
            "[125]\ttraining's auc: 0.881969\ttraining's binary_logloss: 0.123778\tvalid_1's auc: 0.836646\tvalid_1's binary_logloss: 0.137809\n",
            "[126]\ttraining's auc: 0.882178\ttraining's binary_logloss: 0.123682\tvalid_1's auc: 0.836582\tvalid_1's binary_logloss: 0.137773\n",
            "[127]\ttraining's auc: 0.882472\ttraining's binary_logloss: 0.123574\tvalid_1's auc: 0.836548\tvalid_1's binary_logloss: 0.137744\n",
            "[128]\ttraining's auc: 0.882575\ttraining's binary_logloss: 0.123478\tvalid_1's auc: 0.836613\tvalid_1's binary_logloss: 0.137703\n",
            "[129]\ttraining's auc: 0.882913\ttraining's binary_logloss: 0.123373\tvalid_1's auc: 0.836664\tvalid_1's binary_logloss: 0.137671\n",
            "[130]\ttraining's auc: 0.883054\ttraining's binary_logloss: 0.123281\tvalid_1's auc: 0.836719\tvalid_1's binary_logloss: 0.137628\n",
            "[131]\ttraining's auc: 0.883157\ttraining's binary_logloss: 0.123184\tvalid_1's auc: 0.83664\tvalid_1's binary_logloss: 0.137594\n",
            "[132]\ttraining's auc: 0.883353\ttraining's binary_logloss: 0.123088\tvalid_1's auc: 0.836746\tvalid_1's binary_logloss: 0.137556\n",
            "[133]\ttraining's auc: 0.883566\ttraining's binary_logloss: 0.123\tvalid_1's auc: 0.836761\tvalid_1's binary_logloss: 0.137529\n",
            "[134]\ttraining's auc: 0.883841\ttraining's binary_logloss: 0.122907\tvalid_1's auc: 0.836783\tvalid_1's binary_logloss: 0.137495\n",
            "[135]\ttraining's auc: 0.884161\ttraining's binary_logloss: 0.12281\tvalid_1's auc: 0.836705\tvalid_1's binary_logloss: 0.137455\n",
            "[136]\ttraining's auc: 0.884419\ttraining's binary_logloss: 0.122708\tvalid_1's auc: 0.836682\tvalid_1's binary_logloss: 0.137429\n",
            "[137]\ttraining's auc: 0.88467\ttraining's binary_logloss: 0.122612\tvalid_1's auc: 0.836682\tvalid_1's binary_logloss: 0.137394\n",
            "[138]\ttraining's auc: 0.884927\ttraining's binary_logloss: 0.122512\tvalid_1's auc: 0.836725\tvalid_1's binary_logloss: 0.137359\n",
            "[139]\ttraining's auc: 0.885127\ttraining's binary_logloss: 0.122424\tvalid_1's auc: 0.836759\tvalid_1's binary_logloss: 0.13732\n",
            "[140]\ttraining's auc: 0.88535\ttraining's binary_logloss: 0.12233\tvalid_1's auc: 0.836755\tvalid_1's binary_logloss: 0.137282\n",
            "[141]\ttraining's auc: 0.885558\ttraining's binary_logloss: 0.122233\tvalid_1's auc: 0.83681\tvalid_1's binary_logloss: 0.137254\n",
            "[142]\ttraining's auc: 0.885827\ttraining's binary_logloss: 0.12214\tvalid_1's auc: 0.836774\tvalid_1's binary_logloss: 0.137232\n",
            "[143]\ttraining's auc: 0.886013\ttraining's binary_logloss: 0.122052\tvalid_1's auc: 0.836742\tvalid_1's binary_logloss: 0.137202\n",
            "[144]\ttraining's auc: 0.886319\ttraining's binary_logloss: 0.121962\tvalid_1's auc: 0.837038\tvalid_1's binary_logloss: 0.137171\n",
            "[145]\ttraining's auc: 0.88654\ttraining's binary_logloss: 0.121873\tvalid_1's auc: 0.837078\tvalid_1's binary_logloss: 0.137141\n",
            "[146]\ttraining's auc: 0.88676\ttraining's binary_logloss: 0.121787\tvalid_1's auc: 0.837144\tvalid_1's binary_logloss: 0.137112\n",
            "[147]\ttraining's auc: 0.886994\ttraining's binary_logloss: 0.121698\tvalid_1's auc: 0.837163\tvalid_1's binary_logloss: 0.137079\n",
            "[148]\ttraining's auc: 0.887136\ttraining's binary_logloss: 0.121611\tvalid_1's auc: 0.837213\tvalid_1's binary_logloss: 0.137046\n",
            "[149]\ttraining's auc: 0.88746\ttraining's binary_logloss: 0.121515\tvalid_1's auc: 0.837245\tvalid_1's binary_logloss: 0.137018\n",
            "[150]\ttraining's auc: 0.887677\ttraining's binary_logloss: 0.121431\tvalid_1's auc: 0.837233\tvalid_1's binary_logloss: 0.136987\n",
            "[151]\ttraining's auc: 0.887814\ttraining's binary_logloss: 0.121351\tvalid_1's auc: 0.837365\tvalid_1's binary_logloss: 0.136942\n",
            "[152]\ttraining's auc: 0.888002\ttraining's binary_logloss: 0.121272\tvalid_1's auc: 0.83739\tvalid_1's binary_logloss: 0.136913\n",
            "[153]\ttraining's auc: 0.888193\ttraining's binary_logloss: 0.121189\tvalid_1's auc: 0.837367\tvalid_1's binary_logloss: 0.136898\n",
            "[154]\ttraining's auc: 0.888379\ttraining's binary_logloss: 0.121101\tvalid_1's auc: 0.837423\tvalid_1's binary_logloss: 0.136879\n",
            "[155]\ttraining's auc: 0.888571\ttraining's binary_logloss: 0.12102\tvalid_1's auc: 0.837413\tvalid_1's binary_logloss: 0.136863\n",
            "[156]\ttraining's auc: 0.888688\ttraining's binary_logloss: 0.120943\tvalid_1's auc: 0.837346\tvalid_1's binary_logloss: 0.136841\n",
            "[157]\ttraining's auc: 0.888947\ttraining's binary_logloss: 0.12087\tvalid_1's auc: 0.837335\tvalid_1's binary_logloss: 0.136823\n",
            "[158]\ttraining's auc: 0.88913\ttraining's binary_logloss: 0.120784\tvalid_1's auc: 0.837337\tvalid_1's binary_logloss: 0.136804\n",
            "[159]\ttraining's auc: 0.889318\ttraining's binary_logloss: 0.120703\tvalid_1's auc: 0.837228\tvalid_1's binary_logloss: 0.136792\n",
            "[160]\ttraining's auc: 0.889463\ttraining's binary_logloss: 0.120631\tvalid_1's auc: 0.837145\tvalid_1's binary_logloss: 0.136781\n",
            "[161]\ttraining's auc: 0.889635\ttraining's binary_logloss: 0.120546\tvalid_1's auc: 0.83717\tvalid_1's binary_logloss: 0.136761\n",
            "[162]\ttraining's auc: 0.88978\ttraining's binary_logloss: 0.120469\tvalid_1's auc: 0.8371\tvalid_1's binary_logloss: 0.136747\n",
            "[163]\ttraining's auc: 0.889954\ttraining's binary_logloss: 0.120392\tvalid_1's auc: 0.837157\tvalid_1's binary_logloss: 0.136724\n",
            "[164]\ttraining's auc: 0.890122\ttraining's binary_logloss: 0.120316\tvalid_1's auc: 0.837132\tvalid_1's binary_logloss: 0.13671\n",
            "[165]\ttraining's auc: 0.890372\ttraining's binary_logloss: 0.120237\tvalid_1's auc: 0.837171\tvalid_1's binary_logloss: 0.136688\n",
            "[166]\ttraining's auc: 0.890517\ttraining's binary_logloss: 0.120165\tvalid_1's auc: 0.837177\tvalid_1's binary_logloss: 0.136667\n",
            "[167]\ttraining's auc: 0.890713\ttraining's binary_logloss: 0.120094\tvalid_1's auc: 0.837092\tvalid_1's binary_logloss: 0.136658\n",
            "[168]\ttraining's auc: 0.890876\ttraining's binary_logloss: 0.120018\tvalid_1's auc: 0.837138\tvalid_1's binary_logloss: 0.136633\n",
            "[169]\ttraining's auc: 0.891062\ttraining's binary_logloss: 0.119948\tvalid_1's auc: 0.837203\tvalid_1's binary_logloss: 0.13661\n",
            "[170]\ttraining's auc: 0.891215\ttraining's binary_logloss: 0.119873\tvalid_1's auc: 0.837362\tvalid_1's binary_logloss: 0.136576\n",
            "[171]\ttraining's auc: 0.891274\ttraining's binary_logloss: 0.119811\tvalid_1's auc: 0.837288\tvalid_1's binary_logloss: 0.136565\n",
            "[172]\ttraining's auc: 0.891566\ttraining's binary_logloss: 0.119727\tvalid_1's auc: 0.837362\tvalid_1's binary_logloss: 0.136545\n",
            "[173]\ttraining's auc: 0.891744\ttraining's binary_logloss: 0.119656\tvalid_1's auc: 0.837406\tvalid_1's binary_logloss: 0.136526\n",
            "[174]\ttraining's auc: 0.891924\ttraining's binary_logloss: 0.119581\tvalid_1's auc: 0.837332\tvalid_1's binary_logloss: 0.136524\n",
            "[175]\ttraining's auc: 0.892064\ttraining's binary_logloss: 0.119515\tvalid_1's auc: 0.837324\tvalid_1's binary_logloss: 0.136507\n",
            "[176]\ttraining's auc: 0.892229\ttraining's binary_logloss: 0.119455\tvalid_1's auc: 0.837373\tvalid_1's binary_logloss: 0.136492\n",
            "[177]\ttraining's auc: 0.892336\ttraining's binary_logloss: 0.119388\tvalid_1's auc: 0.83741\tvalid_1's binary_logloss: 0.136475\n",
            "[178]\ttraining's auc: 0.892585\ttraining's binary_logloss: 0.119304\tvalid_1's auc: 0.837357\tvalid_1's binary_logloss: 0.136467\n",
            "[179]\ttraining's auc: 0.892695\ttraining's binary_logloss: 0.119239\tvalid_1's auc: 0.837357\tvalid_1's binary_logloss: 0.13645\n",
            "[180]\ttraining's auc: 0.892828\ttraining's binary_logloss: 0.119176\tvalid_1's auc: 0.837282\tvalid_1's binary_logloss: 0.136448\n",
            "[181]\ttraining's auc: 0.893006\ttraining's binary_logloss: 0.119102\tvalid_1's auc: 0.837319\tvalid_1's binary_logloss: 0.136427\n",
            "[182]\ttraining's auc: 0.893178\ttraining's binary_logloss: 0.119034\tvalid_1's auc: 0.837334\tvalid_1's binary_logloss: 0.136411\n",
            "[183]\ttraining's auc: 0.8934\ttraining's binary_logloss: 0.118962\tvalid_1's auc: 0.837327\tvalid_1's binary_logloss: 0.136405\n",
            "[184]\ttraining's auc: 0.893577\ttraining's binary_logloss: 0.118887\tvalid_1's auc: 0.837254\tvalid_1's binary_logloss: 0.136397\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 12%|█▏        | 6/50 [04:34<46:51, 63.89s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.151608\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.154833\n",
            "[2]\ttraining's auc: 0.835756\ttraining's binary_logloss: 0.145231\tvalid_1's auc: 0.810724\tvalid_1's binary_logloss: 0.149826\n",
            "[3]\ttraining's auc: 0.844115\ttraining's binary_logloss: 0.140868\tvalid_1's auc: 0.815907\tvalid_1's binary_logloss: 0.146661\n",
            "[4]\ttraining's auc: 0.849616\ttraining's binary_logloss: 0.137451\tvalid_1's auc: 0.816999\tvalid_1's binary_logloss: 0.144479\n",
            "[5]\ttraining's auc: 0.853417\ttraining's binary_logloss: 0.134695\tvalid_1's auc: 0.819967\tvalid_1's binary_logloss: 0.142757\n",
            "[6]\ttraining's auc: 0.856829\ttraining's binary_logloss: 0.132489\tvalid_1's auc: 0.822354\tvalid_1's binary_logloss: 0.141356\n",
            "[7]\ttraining's auc: 0.86132\ttraining's binary_logloss: 0.130517\tvalid_1's auc: 0.823442\tvalid_1's binary_logloss: 0.140308\n",
            "[8]\ttraining's auc: 0.865755\ttraining's binary_logloss: 0.128857\tvalid_1's auc: 0.824954\tvalid_1's binary_logloss: 0.139559\n",
            "[9]\ttraining's auc: 0.868062\ttraining's binary_logloss: 0.127487\tvalid_1's auc: 0.8259\tvalid_1's binary_logloss: 0.138939\n",
            "[10]\ttraining's auc: 0.871417\ttraining's binary_logloss: 0.126223\tvalid_1's auc: 0.82498\tvalid_1's binary_logloss: 0.138541\n",
            "[11]\ttraining's auc: 0.874366\ttraining's binary_logloss: 0.124995\tvalid_1's auc: 0.825918\tvalid_1's binary_logloss: 0.138113\n",
            "[12]\ttraining's auc: 0.877193\ttraining's binary_logloss: 0.123946\tvalid_1's auc: 0.826347\tvalid_1's binary_logloss: 0.137822\n",
            "[13]\ttraining's auc: 0.880393\ttraining's binary_logloss: 0.122912\tvalid_1's auc: 0.826384\tvalid_1's binary_logloss: 0.137512\n",
            "[14]\ttraining's auc: 0.881779\ttraining's binary_logloss: 0.122105\tvalid_1's auc: 0.826634\tvalid_1's binary_logloss: 0.137423\n",
            "[15]\ttraining's auc: 0.884332\ttraining's binary_logloss: 0.121198\tvalid_1's auc: 0.826857\tvalid_1's binary_logloss: 0.137261\n",
            "[16]\ttraining's auc: 0.887131\ttraining's binary_logloss: 0.120386\tvalid_1's auc: 0.827276\tvalid_1's binary_logloss: 0.13715\n",
            "[17]\ttraining's auc: 0.888507\ttraining's binary_logloss: 0.119752\tvalid_1's auc: 0.826889\tvalid_1's binary_logloss: 0.137102\n",
            "[18]\ttraining's auc: 0.890915\ttraining's binary_logloss: 0.118962\tvalid_1's auc: 0.827319\tvalid_1's binary_logloss: 0.136904\n",
            "[19]\ttraining's auc: 0.892893\ttraining's binary_logloss: 0.118299\tvalid_1's auc: 0.827206\tvalid_1's binary_logloss: 0.136811\n",
            "[20]\ttraining's auc: 0.894384\ttraining's binary_logloss: 0.117644\tvalid_1's auc: 0.827205\tvalid_1's binary_logloss: 0.1368\n",
            "[21]\ttraining's auc: 0.898048\ttraining's binary_logloss: 0.116779\tvalid_1's auc: 0.828022\tvalid_1's binary_logloss: 0.136568\n",
            "[22]\ttraining's auc: 0.899735\ttraining's binary_logloss: 0.116191\tvalid_1's auc: 0.828169\tvalid_1's binary_logloss: 0.136524\n",
            "[23]\ttraining's auc: 0.902063\ttraining's binary_logloss: 0.115549\tvalid_1's auc: 0.82813\tvalid_1's binary_logloss: 0.136531\n",
            "[24]\ttraining's auc: 0.903966\ttraining's binary_logloss: 0.114945\tvalid_1's auc: 0.828789\tvalid_1's binary_logloss: 0.136419\n",
            "[25]\ttraining's auc: 0.905151\ttraining's binary_logloss: 0.114386\tvalid_1's auc: 0.828208\tvalid_1's binary_logloss: 0.136543\n",
            "[26]\ttraining's auc: 0.90626\ttraining's binary_logloss: 0.113927\tvalid_1's auc: 0.827906\tvalid_1's binary_logloss: 0.136625\n",
            "[27]\ttraining's auc: 0.907178\ttraining's binary_logloss: 0.11347\tvalid_1's auc: 0.827781\tvalid_1's binary_logloss: 0.136633\n",
            "[28]\ttraining's auc: 0.908411\ttraining's binary_logloss: 0.112926\tvalid_1's auc: 0.827442\tvalid_1's binary_logloss: 0.13673\n",
            "[29]\ttraining's auc: 0.909444\ttraining's binary_logloss: 0.112493\tvalid_1's auc: 0.827388\tvalid_1's binary_logloss: 0.136753\n",
            "[30]\ttraining's auc: 0.910311\ttraining's binary_logloss: 0.111996\tvalid_1's auc: 0.827305\tvalid_1's binary_logloss: 0.136822\n",
            "[31]\ttraining's auc: 0.911106\ttraining's binary_logloss: 0.111583\tvalid_1's auc: 0.827415\tvalid_1's binary_logloss: 0.136869\n",
            "[32]\ttraining's auc: 0.912617\ttraining's binary_logloss: 0.111024\tvalid_1's auc: 0.82741\tvalid_1's binary_logloss: 0.136836\n",
            "[33]\ttraining's auc: 0.913312\ttraining's binary_logloss: 0.11063\tvalid_1's auc: 0.827379\tvalid_1's binary_logloss: 0.136849\n",
            "[34]\ttraining's auc: 0.914462\ttraining's binary_logloss: 0.110153\tvalid_1's auc: 0.827122\tvalid_1's binary_logloss: 0.136922\n",
            "[35]\ttraining's auc: 0.915565\ttraining's binary_logloss: 0.109757\tvalid_1's auc: 0.826924\tvalid_1's binary_logloss: 0.136994\n",
            "[36]\ttraining's auc: 0.916488\ttraining's binary_logloss: 0.109327\tvalid_1's auc: 0.826887\tvalid_1's binary_logloss: 0.137038\n",
            "[37]\ttraining's auc: 0.917036\ttraining's binary_logloss: 0.10897\tvalid_1's auc: 0.826168\tvalid_1's binary_logloss: 0.13723\n",
            "[38]\ttraining's auc: 0.917761\ttraining's binary_logloss: 0.108677\tvalid_1's auc: 0.825899\tvalid_1's binary_logloss: 0.137282\n",
            "[39]\ttraining's auc: 0.919112\ttraining's binary_logloss: 0.108247\tvalid_1's auc: 0.825695\tvalid_1's binary_logloss: 0.137318\n",
            "[40]\ttraining's auc: 0.921203\ttraining's binary_logloss: 0.107803\tvalid_1's auc: 0.825047\tvalid_1's binary_logloss: 0.137452\n",
            "[41]\ttraining's auc: 0.921784\ttraining's binary_logloss: 0.107518\tvalid_1's auc: 0.824467\tvalid_1's binary_logloss: 0.137614\n",
            "[42]\ttraining's auc: 0.922466\ttraining's binary_logloss: 0.107199\tvalid_1's auc: 0.824386\tvalid_1's binary_logloss: 0.137664\n",
            "[43]\ttraining's auc: 0.922925\ttraining's binary_logloss: 0.106924\tvalid_1's auc: 0.824391\tvalid_1's binary_logloss: 0.137671\n",
            "[44]\ttraining's auc: 0.923537\ttraining's binary_logloss: 0.106649\tvalid_1's auc: 0.824276\tvalid_1's binary_logloss: 0.137719\n",
            "[45]\ttraining's auc: 0.923861\ttraining's binary_logloss: 0.106396\tvalid_1's auc: 0.823688\tvalid_1's binary_logloss: 0.137842\n",
            "[46]\ttraining's auc: 0.924423\ttraining's binary_logloss: 0.106045\tvalid_1's auc: 0.823781\tvalid_1's binary_logloss: 0.137828\n",
            "[47]\ttraining's auc: 0.925014\ttraining's binary_logloss: 0.105719\tvalid_1's auc: 0.82338\tvalid_1's binary_logloss: 0.137954\n",
            "[48]\ttraining's auc: 0.925618\ttraining's binary_logloss: 0.105382\tvalid_1's auc: 0.822852\tvalid_1's binary_logloss: 0.138093\n",
            "[49]\ttraining's auc: 0.926065\ttraining's binary_logloss: 0.10508\tvalid_1's auc: 0.82242\tvalid_1's binary_logloss: 0.138194\n",
            "[50]\ttraining's auc: 0.926517\ttraining's binary_logloss: 0.104847\tvalid_1's auc: 0.822217\tvalid_1's binary_logloss: 0.138265\n",
            "[51]\ttraining's auc: 0.92683\ttraining's binary_logloss: 0.10462\tvalid_1's auc: 0.82191\tvalid_1's binary_logloss: 0.138345\n",
            "[52]\ttraining's auc: 0.927041\ttraining's binary_logloss: 0.104427\tvalid_1's auc: 0.821633\tvalid_1's binary_logloss: 0.138445\n",
            "[53]\ttraining's auc: 0.927394\ttraining's binary_logloss: 0.104167\tvalid_1's auc: 0.821768\tvalid_1's binary_logloss: 0.138466\n",
            "[54]\ttraining's auc: 0.927794\ttraining's binary_logloss: 0.103848\tvalid_1's auc: 0.820867\tvalid_1's binary_logloss: 0.138658\n",
            " 12%|█▏        | 6/50 [04:37<46:51, 63.89s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.154058\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.151041\n",
            "[2]\ttraining's auc: 0.83223\ttraining's binary_logloss: 0.14746\tvalid_1's auc: 0.816858\tvalid_1's binary_logloss: 0.146005\n",
            "[3]\ttraining's auc: 0.840791\ttraining's binary_logloss: 0.143025\tvalid_1's auc: 0.820738\tvalid_1's binary_logloss: 0.142704\n",
            "[4]\ttraining's auc: 0.848941\ttraining's binary_logloss: 0.139644\tvalid_1's auc: 0.826987\tvalid_1's binary_logloss: 0.140339\n",
            "[5]\ttraining's auc: 0.852826\ttraining's binary_logloss: 0.136896\tvalid_1's auc: 0.828747\tvalid_1's binary_logloss: 0.138438\n",
            "[6]\ttraining's auc: 0.855461\ttraining's binary_logloss: 0.13466\tvalid_1's auc: 0.828876\tvalid_1's binary_logloss: 0.137241\n",
            "[7]\ttraining's auc: 0.86093\ttraining's binary_logloss: 0.132655\tvalid_1's auc: 0.829449\tvalid_1's binary_logloss: 0.136202\n",
            "[8]\ttraining's auc: 0.866626\ttraining's binary_logloss: 0.130915\tvalid_1's auc: 0.831308\tvalid_1's binary_logloss: 0.135249\n",
            "[9]\ttraining's auc: 0.869804\ttraining's binary_logloss: 0.129397\tvalid_1's auc: 0.831095\tvalid_1's binary_logloss: 0.134618\n",
            "[10]\ttraining's auc: 0.871687\ttraining's binary_logloss: 0.128101\tvalid_1's auc: 0.830741\tvalid_1's binary_logloss: 0.13409\n",
            "[11]\ttraining's auc: 0.873193\ttraining's binary_logloss: 0.126867\tvalid_1's auc: 0.831311\tvalid_1's binary_logloss: 0.133634\n",
            "[12]\ttraining's auc: 0.876901\ttraining's binary_logloss: 0.125671\tvalid_1's auc: 0.831228\tvalid_1's binary_logloss: 0.133342\n",
            "[13]\ttraining's auc: 0.878501\ttraining's binary_logloss: 0.12468\tvalid_1's auc: 0.831083\tvalid_1's binary_logloss: 0.133058\n",
            "[14]\ttraining's auc: 0.880618\ttraining's binary_logloss: 0.123785\tvalid_1's auc: 0.830109\tvalid_1's binary_logloss: 0.132948\n",
            "[15]\ttraining's auc: 0.884289\ttraining's binary_logloss: 0.122863\tvalid_1's auc: 0.82996\tvalid_1's binary_logloss: 0.13278\n",
            "[16]\ttraining's auc: 0.885828\ttraining's binary_logloss: 0.122111\tvalid_1's auc: 0.83097\tvalid_1's binary_logloss: 0.13256\n",
            "[17]\ttraining's auc: 0.887084\ttraining's binary_logloss: 0.121408\tvalid_1's auc: 0.831639\tvalid_1's binary_logloss: 0.132338\n",
            "[18]\ttraining's auc: 0.888753\ttraining's binary_logloss: 0.12071\tvalid_1's auc: 0.832144\tvalid_1's binary_logloss: 0.132203\n",
            "[19]\ttraining's auc: 0.890196\ttraining's binary_logloss: 0.12004\tvalid_1's auc: 0.833202\tvalid_1's binary_logloss: 0.131979\n",
            "[20]\ttraining's auc: 0.892441\ttraining's binary_logloss: 0.119311\tvalid_1's auc: 0.833907\tvalid_1's binary_logloss: 0.131858\n",
            "[21]\ttraining's auc: 0.893842\ttraining's binary_logloss: 0.118731\tvalid_1's auc: 0.834087\tvalid_1's binary_logloss: 0.131772\n",
            "[22]\ttraining's auc: 0.89567\ttraining's binary_logloss: 0.11817\tvalid_1's auc: 0.834922\tvalid_1's binary_logloss: 0.131616\n",
            "[23]\ttraining's auc: 0.897703\ttraining's binary_logloss: 0.117441\tvalid_1's auc: 0.834201\tvalid_1's binary_logloss: 0.131685\n",
            "[24]\ttraining's auc: 0.899105\ttraining's binary_logloss: 0.116928\tvalid_1's auc: 0.833926\tvalid_1's binary_logloss: 0.13172\n",
            "[25]\ttraining's auc: 0.90091\ttraining's binary_logloss: 0.116383\tvalid_1's auc: 0.833542\tvalid_1's binary_logloss: 0.131764\n",
            "[26]\ttraining's auc: 0.903324\ttraining's binary_logloss: 0.115726\tvalid_1's auc: 0.832585\tvalid_1's binary_logloss: 0.131917\n",
            "[27]\ttraining's auc: 0.904839\ttraining's binary_logloss: 0.115084\tvalid_1's auc: 0.832598\tvalid_1's binary_logloss: 0.131942\n",
            "[28]\ttraining's auc: 0.905828\ttraining's binary_logloss: 0.11458\tvalid_1's auc: 0.832878\tvalid_1's binary_logloss: 0.131944\n",
            "[29]\ttraining's auc: 0.907142\ttraining's binary_logloss: 0.114002\tvalid_1's auc: 0.833477\tvalid_1's binary_logloss: 0.131856\n",
            "[30]\ttraining's auc: 0.90835\ttraining's binary_logloss: 0.113539\tvalid_1's auc: 0.833472\tvalid_1's binary_logloss: 0.131834\n",
            "[31]\ttraining's auc: 0.909522\ttraining's binary_logloss: 0.112993\tvalid_1's auc: 0.833384\tvalid_1's binary_logloss: 0.1319\n",
            "[32]\ttraining's auc: 0.910557\ttraining's binary_logloss: 0.112563\tvalid_1's auc: 0.833424\tvalid_1's binary_logloss: 0.131877\n",
            "[33]\ttraining's auc: 0.911184\ttraining's binary_logloss: 0.112175\tvalid_1's auc: 0.833351\tvalid_1's binary_logloss: 0.131906\n",
            "[34]\ttraining's auc: 0.911989\ttraining's binary_logloss: 0.111741\tvalid_1's auc: 0.833511\tvalid_1's binary_logloss: 0.131937\n",
            "[35]\ttraining's auc: 0.912996\ttraining's binary_logloss: 0.111401\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.131987\n",
            "[36]\ttraining's auc: 0.913876\ttraining's binary_logloss: 0.110948\tvalid_1's auc: 0.832984\tvalid_1's binary_logloss: 0.13213\n",
            "[37]\ttraining's auc: 0.914533\ttraining's binary_logloss: 0.110666\tvalid_1's auc: 0.832914\tvalid_1's binary_logloss: 0.132129\n",
            "[38]\ttraining's auc: 0.915065\ttraining's binary_logloss: 0.110354\tvalid_1's auc: 0.83243\tvalid_1's binary_logloss: 0.132214\n",
            "[39]\ttraining's auc: 0.915496\ttraining's binary_logloss: 0.110072\tvalid_1's auc: 0.832349\tvalid_1's binary_logloss: 0.132192\n",
            "[40]\ttraining's auc: 0.916167\ttraining's binary_logloss: 0.109714\tvalid_1's auc: 0.832412\tvalid_1's binary_logloss: 0.132178\n",
            "[41]\ttraining's auc: 0.916961\ttraining's binary_logloss: 0.10934\tvalid_1's auc: 0.832083\tvalid_1's binary_logloss: 0.132211\n",
            "[42]\ttraining's auc: 0.917559\ttraining's binary_logloss: 0.10895\tvalid_1's auc: 0.831689\tvalid_1's binary_logloss: 0.13229\n",
            "[43]\ttraining's auc: 0.918362\ttraining's binary_logloss: 0.108668\tvalid_1's auc: 0.831611\tvalid_1's binary_logloss: 0.132311\n",
            "[44]\ttraining's auc: 0.918853\ttraining's binary_logloss: 0.108367\tvalid_1's auc: 0.831323\tvalid_1's binary_logloss: 0.132439\n",
            "[45]\ttraining's auc: 0.919379\ttraining's binary_logloss: 0.108067\tvalid_1's auc: 0.831477\tvalid_1's binary_logloss: 0.132433\n",
            "[46]\ttraining's auc: 0.919979\ttraining's binary_logloss: 0.10775\tvalid_1's auc: 0.831478\tvalid_1's binary_logloss: 0.132483\n",
            "[47]\ttraining's auc: 0.920441\ttraining's binary_logloss: 0.107429\tvalid_1's auc: 0.831488\tvalid_1's binary_logloss: 0.132524\n",
            "[48]\ttraining's auc: 0.920925\ttraining's binary_logloss: 0.107117\tvalid_1's auc: 0.831398\tvalid_1's binary_logloss: 0.132576\n",
            "[49]\ttraining's auc: 0.92149\ttraining's binary_logloss: 0.106802\tvalid_1's auc: 0.831339\tvalid_1's binary_logloss: 0.132569\n",
            "[50]\ttraining's auc: 0.921734\ttraining's binary_logloss: 0.106588\tvalid_1's auc: 0.831359\tvalid_1's binary_logloss: 0.132589\n",
            "[51]\ttraining's auc: 0.92213\ttraining's binary_logloss: 0.106396\tvalid_1's auc: 0.830916\tvalid_1's binary_logloss: 0.132703\n",
            "[52]\ttraining's auc: 0.922513\ttraining's binary_logloss: 0.106154\tvalid_1's auc: 0.831038\tvalid_1's binary_logloss: 0.132674\n",
            " 12%|█▏        | 6/50 [04:43<46:51, 63.89s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.150954\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.157663\n",
            "[2]\ttraining's auc: 0.835986\ttraining's binary_logloss: 0.144747\tvalid_1's auc: 0.817533\tvalid_1's binary_logloss: 0.152072\n",
            "[3]\ttraining's auc: 0.842581\ttraining's binary_logloss: 0.140452\tvalid_1's auc: 0.821973\tvalid_1's binary_logloss: 0.148546\n",
            "[4]\ttraining's auc: 0.848224\ttraining's binary_logloss: 0.136885\tvalid_1's auc: 0.825037\tvalid_1's binary_logloss: 0.146033\n",
            "[5]\ttraining's auc: 0.852246\ttraining's binary_logloss: 0.134192\tvalid_1's auc: 0.827533\tvalid_1's binary_logloss: 0.144158\n",
            "[6]\ttraining's auc: 0.856269\ttraining's binary_logloss: 0.131984\tvalid_1's auc: 0.82833\tvalid_1's binary_logloss: 0.142601\n",
            "[7]\ttraining's auc: 0.861242\ttraining's binary_logloss: 0.130139\tvalid_1's auc: 0.829258\tvalid_1's binary_logloss: 0.14141\n",
            "[8]\ttraining's auc: 0.865489\ttraining's binary_logloss: 0.128503\tvalid_1's auc: 0.830221\tvalid_1's binary_logloss: 0.140387\n",
            "[9]\ttraining's auc: 0.869953\ttraining's binary_logloss: 0.127043\tvalid_1's auc: 0.832343\tvalid_1's binary_logloss: 0.139759\n",
            "[10]\ttraining's auc: 0.872737\ttraining's binary_logloss: 0.125704\tvalid_1's auc: 0.83284\tvalid_1's binary_logloss: 0.139148\n",
            "[11]\ttraining's auc: 0.875065\ttraining's binary_logloss: 0.124541\tvalid_1's auc: 0.833462\tvalid_1's binary_logloss: 0.138603\n",
            "[12]\ttraining's auc: 0.877124\ttraining's binary_logloss: 0.123502\tvalid_1's auc: 0.834171\tvalid_1's binary_logloss: 0.138127\n",
            "[13]\ttraining's auc: 0.880864\ttraining's binary_logloss: 0.122399\tvalid_1's auc: 0.833668\tvalid_1's binary_logloss: 0.137978\n",
            "[14]\ttraining's auc: 0.884289\ttraining's binary_logloss: 0.121474\tvalid_1's auc: 0.833083\tvalid_1's binary_logloss: 0.137796\n",
            "[15]\ttraining's auc: 0.886156\ttraining's binary_logloss: 0.120697\tvalid_1's auc: 0.834372\tvalid_1's binary_logloss: 0.137465\n",
            "[16]\ttraining's auc: 0.888231\ttraining's binary_logloss: 0.11995\tvalid_1's auc: 0.833983\tvalid_1's binary_logloss: 0.137358\n",
            "[17]\ttraining's auc: 0.890058\ttraining's binary_logloss: 0.119225\tvalid_1's auc: 0.833705\tvalid_1's binary_logloss: 0.137169\n",
            "[18]\ttraining's auc: 0.891742\ttraining's binary_logloss: 0.118491\tvalid_1's auc: 0.834304\tvalid_1's binary_logloss: 0.136966\n",
            "[19]\ttraining's auc: 0.894327\ttraining's binary_logloss: 0.117652\tvalid_1's auc: 0.83411\tvalid_1's binary_logloss: 0.13695\n",
            "[20]\ttraining's auc: 0.896312\ttraining's binary_logloss: 0.116934\tvalid_1's auc: 0.833557\tvalid_1's binary_logloss: 0.136965\n",
            "[21]\ttraining's auc: 0.897951\ttraining's binary_logloss: 0.116259\tvalid_1's auc: 0.833644\tvalid_1's binary_logloss: 0.136836\n",
            "[22]\ttraining's auc: 0.899272\ttraining's binary_logloss: 0.115714\tvalid_1's auc: 0.833448\tvalid_1's binary_logloss: 0.136852\n",
            "[23]\ttraining's auc: 0.900888\ttraining's binary_logloss: 0.115088\tvalid_1's auc: 0.833102\tvalid_1's binary_logloss: 0.13688\n",
            "[24]\ttraining's auc: 0.902585\ttraining's binary_logloss: 0.114476\tvalid_1's auc: 0.833701\tvalid_1's binary_logloss: 0.13684\n",
            "[25]\ttraining's auc: 0.90421\ttraining's binary_logloss: 0.113918\tvalid_1's auc: 0.833679\tvalid_1's binary_logloss: 0.136848\n",
            "[26]\ttraining's auc: 0.905477\ttraining's binary_logloss: 0.113383\tvalid_1's auc: 0.833902\tvalid_1's binary_logloss: 0.136862\n",
            "[27]\ttraining's auc: 0.906645\ttraining's binary_logloss: 0.112871\tvalid_1's auc: 0.834271\tvalid_1's binary_logloss: 0.136798\n",
            "[28]\ttraining's auc: 0.907577\ttraining's binary_logloss: 0.112388\tvalid_1's auc: 0.833962\tvalid_1's binary_logloss: 0.136929\n",
            "[29]\ttraining's auc: 0.908548\ttraining's binary_logloss: 0.111935\tvalid_1's auc: 0.834137\tvalid_1's binary_logloss: 0.136934\n",
            "[30]\ttraining's auc: 0.90956\ttraining's binary_logloss: 0.111471\tvalid_1's auc: 0.834065\tvalid_1's binary_logloss: 0.136963\n",
            "[31]\ttraining's auc: 0.910483\ttraining's binary_logloss: 0.110989\tvalid_1's auc: 0.834031\tvalid_1's binary_logloss: 0.137032\n",
            "[32]\ttraining's auc: 0.911606\ttraining's binary_logloss: 0.110494\tvalid_1's auc: 0.833608\tvalid_1's binary_logloss: 0.137153\n",
            "[33]\ttraining's auc: 0.912563\ttraining's binary_logloss: 0.110013\tvalid_1's auc: 0.833673\tvalid_1's binary_logloss: 0.137179\n",
            "[34]\ttraining's auc: 0.914046\ttraining's binary_logloss: 0.109435\tvalid_1's auc: 0.833351\tvalid_1's binary_logloss: 0.137292\n",
            "[35]\ttraining's auc: 0.914566\ttraining's binary_logloss: 0.109061\tvalid_1's auc: 0.8333\tvalid_1's binary_logloss: 0.137342\n",
            "[36]\ttraining's auc: 0.91544\ttraining's binary_logloss: 0.108645\tvalid_1's auc: 0.83285\tvalid_1's binary_logloss: 0.137451\n",
            "[37]\ttraining's auc: 0.916814\ttraining's binary_logloss: 0.10815\tvalid_1's auc: 0.832689\tvalid_1's binary_logloss: 0.13746\n",
            "[38]\ttraining's auc: 0.917389\ttraining's binary_logloss: 0.107773\tvalid_1's auc: 0.832286\tvalid_1's binary_logloss: 0.137602\n",
            "[39]\ttraining's auc: 0.917785\ttraining's binary_logloss: 0.107491\tvalid_1's auc: 0.832362\tvalid_1's binary_logloss: 0.137576\n",
            "[40]\ttraining's auc: 0.918919\ttraining's binary_logloss: 0.107018\tvalid_1's auc: 0.832036\tvalid_1's binary_logloss: 0.137682\n",
            "[41]\ttraining's auc: 0.91938\ttraining's binary_logloss: 0.106726\tvalid_1's auc: 0.83178\tvalid_1's binary_logloss: 0.137768\n",
            "[42]\ttraining's auc: 0.919847\ttraining's binary_logloss: 0.106404\tvalid_1's auc: 0.831912\tvalid_1's binary_logloss: 0.13777\n",
            "[43]\ttraining's auc: 0.920595\ttraining's binary_logloss: 0.105985\tvalid_1's auc: 0.83217\tvalid_1's binary_logloss: 0.137762\n",
            "[44]\ttraining's auc: 0.922236\ttraining's binary_logloss: 0.105511\tvalid_1's auc: 0.833373\tvalid_1's binary_logloss: 0.137593\n",
            "[45]\ttraining's auc: 0.922545\ttraining's binary_logloss: 0.105288\tvalid_1's auc: 0.833175\tvalid_1's binary_logloss: 0.137741\n",
            " 14%|█▍        | 7/50 [04:48<34:06, 47.60s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.150217\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.153748\n",
            "[2]\ttraining's auc: 0.836205\ttraining's binary_logloss: 0.143743\tvalid_1's auc: 0.808675\tvalid_1's binary_logloss: 0.148651\n",
            "[3]\ttraining's auc: 0.84709\ttraining's binary_logloss: 0.13936\tvalid_1's auc: 0.814811\tvalid_1's binary_logloss: 0.14561\n",
            "[4]\ttraining's auc: 0.852771\ttraining's binary_logloss: 0.135854\tvalid_1's auc: 0.819728\tvalid_1's binary_logloss: 0.143338\n",
            "[5]\ttraining's auc: 0.857582\ttraining's binary_logloss: 0.133026\tvalid_1's auc: 0.821879\tvalid_1's binary_logloss: 0.141598\n",
            "[6]\ttraining's auc: 0.860709\ttraining's binary_logloss: 0.130896\tvalid_1's auc: 0.824151\tvalid_1's binary_logloss: 0.140372\n",
            "[7]\ttraining's auc: 0.865881\ttraining's binary_logloss: 0.128891\tvalid_1's auc: 0.825016\tvalid_1's binary_logloss: 0.139421\n",
            "[8]\ttraining's auc: 0.870166\ttraining's binary_logloss: 0.127342\tvalid_1's auc: 0.825658\tvalid_1's binary_logloss: 0.138748\n",
            "[9]\ttraining's auc: 0.873147\ttraining's binary_logloss: 0.125901\tvalid_1's auc: 0.825936\tvalid_1's binary_logloss: 0.138276\n",
            "[10]\ttraining's auc: 0.87778\ttraining's binary_logloss: 0.124608\tvalid_1's auc: 0.825968\tvalid_1's binary_logloss: 0.137907\n",
            "[11]\ttraining's auc: 0.879624\ttraining's binary_logloss: 0.123531\tvalid_1's auc: 0.827993\tvalid_1's binary_logloss: 0.137366\n",
            "[12]\ttraining's auc: 0.883474\ttraining's binary_logloss: 0.122339\tvalid_1's auc: 0.828863\tvalid_1's binary_logloss: 0.136974\n",
            "[13]\ttraining's auc: 0.884693\ttraining's binary_logloss: 0.12146\tvalid_1's auc: 0.829156\tvalid_1's binary_logloss: 0.136696\n",
            "[14]\ttraining's auc: 0.886446\ttraining's binary_logloss: 0.120617\tvalid_1's auc: 0.828193\tvalid_1's binary_logloss: 0.136682\n",
            "[15]\ttraining's auc: 0.889517\ttraining's binary_logloss: 0.119708\tvalid_1's auc: 0.830199\tvalid_1's binary_logloss: 0.136287\n",
            "[16]\ttraining's auc: 0.891333\ttraining's binary_logloss: 0.118884\tvalid_1's auc: 0.829455\tvalid_1's binary_logloss: 0.136221\n",
            "[17]\ttraining's auc: 0.89433\ttraining's binary_logloss: 0.117956\tvalid_1's auc: 0.82947\tvalid_1's binary_logloss: 0.136188\n",
            "[18]\ttraining's auc: 0.895744\ttraining's binary_logloss: 0.117237\tvalid_1's auc: 0.829544\tvalid_1's binary_logloss: 0.136167\n",
            "[19]\ttraining's auc: 0.898359\ttraining's binary_logloss: 0.116479\tvalid_1's auc: 0.829127\tvalid_1's binary_logloss: 0.136209\n",
            "[20]\ttraining's auc: 0.901312\ttraining's binary_logloss: 0.115856\tvalid_1's auc: 0.829377\tvalid_1's binary_logloss: 0.136211\n",
            "[21]\ttraining's auc: 0.902412\ttraining's binary_logloss: 0.115289\tvalid_1's auc: 0.82886\tvalid_1's binary_logloss: 0.136344\n",
            "[22]\ttraining's auc: 0.90371\ttraining's binary_logloss: 0.114625\tvalid_1's auc: 0.828223\tvalid_1's binary_logloss: 0.136465\n",
            "[23]\ttraining's auc: 0.904786\ttraining's binary_logloss: 0.114046\tvalid_1's auc: 0.82809\tvalid_1's binary_logloss: 0.136502\n",
            "[24]\ttraining's auc: 0.906098\ttraining's binary_logloss: 0.113446\tvalid_1's auc: 0.828507\tvalid_1's binary_logloss: 0.136469\n",
            "[25]\ttraining's auc: 0.906965\ttraining's binary_logloss: 0.112904\tvalid_1's auc: 0.828785\tvalid_1's binary_logloss: 0.136432\n",
            "[26]\ttraining's auc: 0.90885\ttraining's binary_logloss: 0.112224\tvalid_1's auc: 0.828646\tvalid_1's binary_logloss: 0.136493\n",
            "[27]\ttraining's auc: 0.91001\ttraining's binary_logloss: 0.111709\tvalid_1's auc: 0.827964\tvalid_1's binary_logloss: 0.136649\n",
            "[28]\ttraining's auc: 0.911478\ttraining's binary_logloss: 0.111108\tvalid_1's auc: 0.828145\tvalid_1's binary_logloss: 0.136672\n",
            "[29]\ttraining's auc: 0.912369\ttraining's binary_logloss: 0.110659\tvalid_1's auc: 0.82797\tvalid_1's binary_logloss: 0.13675\n",
            "[30]\ttraining's auc: 0.913249\ttraining's binary_logloss: 0.110282\tvalid_1's auc: 0.828218\tvalid_1's binary_logloss: 0.136761\n",
            "[31]\ttraining's auc: 0.914695\ttraining's binary_logloss: 0.109702\tvalid_1's auc: 0.828089\tvalid_1's binary_logloss: 0.136744\n",
            "[32]\ttraining's auc: 0.915798\ttraining's binary_logloss: 0.109195\tvalid_1's auc: 0.828083\tvalid_1's binary_logloss: 0.136779\n",
            "[33]\ttraining's auc: 0.916527\ttraining's binary_logloss: 0.1088\tvalid_1's auc: 0.82772\tvalid_1's binary_logloss: 0.136899\n",
            "[34]\ttraining's auc: 0.917725\ttraining's binary_logloss: 0.108304\tvalid_1's auc: 0.827478\tvalid_1's binary_logloss: 0.136961\n",
            "[35]\ttraining's auc: 0.918656\ttraining's binary_logloss: 0.107891\tvalid_1's auc: 0.827296\tvalid_1's binary_logloss: 0.137023\n",
            "[36]\ttraining's auc: 0.919096\ttraining's binary_logloss: 0.1076\tvalid_1's auc: 0.82619\tvalid_1's binary_logloss: 0.137248\n",
            "[37]\ttraining's auc: 0.919707\ttraining's binary_logloss: 0.107266\tvalid_1's auc: 0.825946\tvalid_1's binary_logloss: 0.137303\n",
            "[38]\ttraining's auc: 0.920192\ttraining's binary_logloss: 0.106969\tvalid_1's auc: 0.825513\tvalid_1's binary_logloss: 0.137427\n",
            "[39]\ttraining's auc: 0.920491\ttraining's binary_logloss: 0.106709\tvalid_1's auc: 0.824731\tvalid_1's binary_logloss: 0.137653\n",
            "[40]\ttraining's auc: 0.9212\ttraining's binary_logloss: 0.106274\tvalid_1's auc: 0.82445\tvalid_1's binary_logloss: 0.137755\n",
            "[41]\ttraining's auc: 0.92289\ttraining's binary_logloss: 0.105754\tvalid_1's auc: 0.823889\tvalid_1's binary_logloss: 0.137895\n",
            "[42]\ttraining's auc: 0.92429\ttraining's binary_logloss: 0.105383\tvalid_1's auc: 0.823938\tvalid_1's binary_logloss: 0.137862\n",
            "[43]\ttraining's auc: 0.925015\ttraining's binary_logloss: 0.10512\tvalid_1's auc: 0.823997\tvalid_1's binary_logloss: 0.137854\n",
            "[44]\ttraining's auc: 0.92582\ttraining's binary_logloss: 0.1048\tvalid_1's auc: 0.823873\tvalid_1's binary_logloss: 0.13795\n",
            "[45]\ttraining's auc: 0.926812\ttraining's binary_logloss: 0.104438\tvalid_1's auc: 0.823751\tvalid_1's binary_logloss: 0.138002\n",
            " 14%|█▍        | 7/50 [04:51<34:06, 47.60s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.152681\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.150069\n",
            "[2]\ttraining's auc: 0.836039\ttraining's binary_logloss: 0.145904\tvalid_1's auc: 0.817959\tvalid_1's binary_logloss: 0.145206\n",
            "[3]\ttraining's auc: 0.845428\ttraining's binary_logloss: 0.141385\tvalid_1's auc: 0.824303\tvalid_1's binary_logloss: 0.141948\n",
            "[4]\ttraining's auc: 0.851443\ttraining's binary_logloss: 0.13805\tvalid_1's auc: 0.82894\tvalid_1's binary_logloss: 0.139741\n",
            "[5]\ttraining's auc: 0.855413\ttraining's binary_logloss: 0.135318\tvalid_1's auc: 0.829769\tvalid_1's binary_logloss: 0.138116\n",
            "[6]\ttraining's auc: 0.860585\ttraining's binary_logloss: 0.133155\tvalid_1's auc: 0.830915\tvalid_1's binary_logloss: 0.136821\n",
            "[7]\ttraining's auc: 0.86597\ttraining's binary_logloss: 0.131151\tvalid_1's auc: 0.83132\tvalid_1's binary_logloss: 0.135862\n",
            "[8]\ttraining's auc: 0.868872\ttraining's binary_logloss: 0.12956\tvalid_1's auc: 0.831391\tvalid_1's binary_logloss: 0.135136\n",
            "[9]\ttraining's auc: 0.871187\ttraining's binary_logloss: 0.12804\tvalid_1's auc: 0.831445\tvalid_1's binary_logloss: 0.134635\n",
            "[10]\ttraining's auc: 0.874061\ttraining's binary_logloss: 0.126653\tvalid_1's auc: 0.831547\tvalid_1's binary_logloss: 0.134168\n",
            "[11]\ttraining's auc: 0.875989\ttraining's binary_logloss: 0.125556\tvalid_1's auc: 0.831689\tvalid_1's binary_logloss: 0.133781\n",
            "[12]\ttraining's auc: 0.878263\ttraining's binary_logloss: 0.124569\tvalid_1's auc: 0.831565\tvalid_1's binary_logloss: 0.133543\n",
            "[13]\ttraining's auc: 0.880675\ttraining's binary_logloss: 0.123515\tvalid_1's auc: 0.831742\tvalid_1's binary_logloss: 0.133371\n",
            "[14]\ttraining's auc: 0.882882\ttraining's binary_logloss: 0.12259\tvalid_1's auc: 0.8316\tvalid_1's binary_logloss: 0.133275\n",
            "[15]\ttraining's auc: 0.885094\ttraining's binary_logloss: 0.121659\tvalid_1's auc: 0.83148\tvalid_1's binary_logloss: 0.133153\n",
            "[16]\ttraining's auc: 0.887744\ttraining's binary_logloss: 0.120808\tvalid_1's auc: 0.831523\tvalid_1's binary_logloss: 0.133077\n",
            "[17]\ttraining's auc: 0.889975\ttraining's binary_logloss: 0.119986\tvalid_1's auc: 0.832794\tvalid_1's binary_logloss: 0.132796\n",
            "[18]\ttraining's auc: 0.891393\ttraining's binary_logloss: 0.119301\tvalid_1's auc: 0.833098\tvalid_1's binary_logloss: 0.132661\n",
            "[19]\ttraining's auc: 0.893647\ttraining's binary_logloss: 0.118608\tvalid_1's auc: 0.832572\tvalid_1's binary_logloss: 0.132692\n",
            "[20]\ttraining's auc: 0.896466\ttraining's binary_logloss: 0.117862\tvalid_1's auc: 0.832859\tvalid_1's binary_logloss: 0.132613\n",
            "[21]\ttraining's auc: 0.898135\ttraining's binary_logloss: 0.117267\tvalid_1's auc: 0.833148\tvalid_1's binary_logloss: 0.132556\n",
            "[22]\ttraining's auc: 0.899873\ttraining's binary_logloss: 0.116728\tvalid_1's auc: 0.832613\tvalid_1's binary_logloss: 0.1326\n",
            "[23]\ttraining's auc: 0.90131\ttraining's binary_logloss: 0.11618\tvalid_1's auc: 0.832791\tvalid_1's binary_logloss: 0.132537\n",
            "[24]\ttraining's auc: 0.902287\ttraining's binary_logloss: 0.115652\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.132483\n",
            "[25]\ttraining's auc: 0.903749\ttraining's binary_logloss: 0.115039\tvalid_1's auc: 0.833103\tvalid_1's binary_logloss: 0.132475\n",
            "[26]\ttraining's auc: 0.905798\ttraining's binary_logloss: 0.114313\tvalid_1's auc: 0.833037\tvalid_1's binary_logloss: 0.132576\n",
            "[27]\ttraining's auc: 0.907671\ttraining's binary_logloss: 0.113734\tvalid_1's auc: 0.832932\tvalid_1's binary_logloss: 0.132585\n",
            "[28]\ttraining's auc: 0.908675\ttraining's binary_logloss: 0.113242\tvalid_1's auc: 0.833668\tvalid_1's binary_logloss: 0.132488\n",
            "[29]\ttraining's auc: 0.910046\ttraining's binary_logloss: 0.11265\tvalid_1's auc: 0.83301\tvalid_1's binary_logloss: 0.132552\n",
            "[30]\ttraining's auc: 0.911728\ttraining's binary_logloss: 0.112033\tvalid_1's auc: 0.832728\tvalid_1's binary_logloss: 0.132627\n",
            "[31]\ttraining's auc: 0.912281\ttraining's binary_logloss: 0.111711\tvalid_1's auc: 0.832788\tvalid_1's binary_logloss: 0.132625\n",
            "[32]\ttraining's auc: 0.91372\ttraining's binary_logloss: 0.111171\tvalid_1's auc: 0.832531\tvalid_1's binary_logloss: 0.132653\n",
            "[33]\ttraining's auc: 0.914339\ttraining's binary_logloss: 0.110759\tvalid_1's auc: 0.832599\tvalid_1's binary_logloss: 0.132669\n",
            "[34]\ttraining's auc: 0.915553\ttraining's binary_logloss: 0.110301\tvalid_1's auc: 0.832587\tvalid_1's binary_logloss: 0.132718\n",
            "[35]\ttraining's auc: 0.916559\ttraining's binary_logloss: 0.109901\tvalid_1's auc: 0.832134\tvalid_1's binary_logloss: 0.132836\n",
            "[36]\ttraining's auc: 0.917233\ttraining's binary_logloss: 0.109541\tvalid_1's auc: 0.831826\tvalid_1's binary_logloss: 0.132871\n",
            "[37]\ttraining's auc: 0.918016\ttraining's binary_logloss: 0.109135\tvalid_1's auc: 0.831821\tvalid_1's binary_logloss: 0.132908\n",
            "[38]\ttraining's auc: 0.918861\ttraining's binary_logloss: 0.10883\tvalid_1's auc: 0.831657\tvalid_1's binary_logloss: 0.132938\n",
            "[39]\ttraining's auc: 0.919314\ttraining's binary_logloss: 0.108514\tvalid_1's auc: 0.831869\tvalid_1's binary_logloss: 0.132921\n",
            "[40]\ttraining's auc: 0.92088\ttraining's binary_logloss: 0.107918\tvalid_1's auc: 0.832499\tvalid_1's binary_logloss: 0.132819\n",
            "[41]\ttraining's auc: 0.921543\ttraining's binary_logloss: 0.107588\tvalid_1's auc: 0.832442\tvalid_1's binary_logloss: 0.132789\n",
            "[42]\ttraining's auc: 0.922301\ttraining's binary_logloss: 0.107188\tvalid_1's auc: 0.832224\tvalid_1's binary_logloss: 0.132812\n",
            "[43]\ttraining's auc: 0.922987\ttraining's binary_logloss: 0.1069\tvalid_1's auc: 0.831836\tvalid_1's binary_logloss: 0.132922\n",
            "[44]\ttraining's auc: 0.923488\ttraining's binary_logloss: 0.106559\tvalid_1's auc: 0.831499\tvalid_1's binary_logloss: 0.133006\n",
            "[45]\ttraining's auc: 0.923859\ttraining's binary_logloss: 0.106274\tvalid_1's auc: 0.831094\tvalid_1's binary_logloss: 0.133051\n",
            "[46]\ttraining's auc: 0.924562\ttraining's binary_logloss: 0.10587\tvalid_1's auc: 0.830759\tvalid_1's binary_logloss: 0.133178\n",
            "[47]\ttraining's auc: 0.92575\ttraining's binary_logloss: 0.10529\tvalid_1's auc: 0.830069\tvalid_1's binary_logloss: 0.133379\n",
            "[48]\ttraining's auc: 0.926844\ttraining's binary_logloss: 0.104818\tvalid_1's auc: 0.829975\tvalid_1's binary_logloss: 0.133404\n",
            "[49]\ttraining's auc: 0.927555\ttraining's binary_logloss: 0.10447\tvalid_1's auc: 0.829686\tvalid_1's binary_logloss: 0.133499\n",
            "[50]\ttraining's auc: 0.927898\ttraining's binary_logloss: 0.104203\tvalid_1's auc: 0.829474\tvalid_1's binary_logloss: 0.133546\n",
            "[51]\ttraining's auc: 0.928789\ttraining's binary_logloss: 0.103926\tvalid_1's auc: 0.829299\tvalid_1's binary_logloss: 0.13366\n",
            "[52]\ttraining's auc: 0.929361\ttraining's binary_logloss: 0.103585\tvalid_1's auc: 0.828954\tvalid_1's binary_logloss: 0.133753\n",
            "[53]\ttraining's auc: 0.92993\ttraining's binary_logloss: 0.103302\tvalid_1's auc: 0.829246\tvalid_1's binary_logloss: 0.133777\n",
            "[54]\ttraining's auc: 0.930325\ttraining's binary_logloss: 0.103029\tvalid_1's auc: 0.82879\tvalid_1's binary_logloss: 0.133873\n",
            "[55]\ttraining's auc: 0.930953\ttraining's binary_logloss: 0.102772\tvalid_1's auc: 0.828815\tvalid_1's binary_logloss: 0.133899\n",
            " 14%|█▍        | 7/50 [04:55<34:06, 47.60s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.149637\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.156518\n",
            "[2]\ttraining's auc: 0.838108\ttraining's binary_logloss: 0.143283\tvalid_1's auc: 0.819162\tvalid_1's binary_logloss: 0.15092\n",
            "[3]\ttraining's auc: 0.846838\ttraining's binary_logloss: 0.138631\tvalid_1's auc: 0.824387\tvalid_1's binary_logloss: 0.14755\n",
            "[4]\ttraining's auc: 0.850592\ttraining's binary_logloss: 0.135353\tvalid_1's auc: 0.826338\tvalid_1's binary_logloss: 0.145113\n",
            "[5]\ttraining's auc: 0.855463\ttraining's binary_logloss: 0.132709\tvalid_1's auc: 0.827268\tvalid_1's binary_logloss: 0.143383\n",
            "[6]\ttraining's auc: 0.859361\ttraining's binary_logloss: 0.130567\tvalid_1's auc: 0.827193\tvalid_1's binary_logloss: 0.142082\n",
            "[7]\ttraining's auc: 0.86265\ttraining's binary_logloss: 0.128762\tvalid_1's auc: 0.827977\tvalid_1's binary_logloss: 0.140999\n",
            "[8]\ttraining's auc: 0.866703\ttraining's binary_logloss: 0.127098\tvalid_1's auc: 0.829722\tvalid_1's binary_logloss: 0.140238\n",
            "[9]\ttraining's auc: 0.871685\ttraining's binary_logloss: 0.125583\tvalid_1's auc: 0.831148\tvalid_1's binary_logloss: 0.139499\n",
            "[10]\ttraining's auc: 0.874478\ttraining's binary_logloss: 0.124407\tvalid_1's auc: 0.831462\tvalid_1's binary_logloss: 0.138976\n",
            "[11]\ttraining's auc: 0.877396\ttraining's binary_logloss: 0.123286\tvalid_1's auc: 0.831986\tvalid_1's binary_logloss: 0.138608\n",
            "[12]\ttraining's auc: 0.88226\ttraining's binary_logloss: 0.122065\tvalid_1's auc: 0.831257\tvalid_1's binary_logloss: 0.138394\n",
            "[13]\ttraining's auc: 0.884735\ttraining's binary_logloss: 0.121079\tvalid_1's auc: 0.832193\tvalid_1's binary_logloss: 0.138017\n",
            "[14]\ttraining's auc: 0.887017\ttraining's binary_logloss: 0.120096\tvalid_1's auc: 0.832517\tvalid_1's binary_logloss: 0.137742\n",
            "[15]\ttraining's auc: 0.888171\ttraining's binary_logloss: 0.119338\tvalid_1's auc: 0.832707\tvalid_1's binary_logloss: 0.137627\n",
            "[16]\ttraining's auc: 0.890069\ttraining's binary_logloss: 0.118568\tvalid_1's auc: 0.832227\tvalid_1's binary_logloss: 0.13759\n",
            "[17]\ttraining's auc: 0.891368\ttraining's binary_logloss: 0.117966\tvalid_1's auc: 0.83242\tvalid_1's binary_logloss: 0.137462\n",
            "[18]\ttraining's auc: 0.893752\ttraining's binary_logloss: 0.11721\tvalid_1's auc: 0.832453\tvalid_1's binary_logloss: 0.137402\n",
            "[19]\ttraining's auc: 0.8951\ttraining's binary_logloss: 0.116554\tvalid_1's auc: 0.832159\tvalid_1's binary_logloss: 0.137442\n",
            "[20]\ttraining's auc: 0.896955\ttraining's binary_logloss: 0.115965\tvalid_1's auc: 0.83126\tvalid_1's binary_logloss: 0.137502\n",
            "[21]\ttraining's auc: 0.899199\ttraining's binary_logloss: 0.115198\tvalid_1's auc: 0.83088\tvalid_1's binary_logloss: 0.13758\n",
            "[22]\ttraining's auc: 0.900709\ttraining's binary_logloss: 0.114571\tvalid_1's auc: 0.831275\tvalid_1's binary_logloss: 0.137505\n",
            "[23]\ttraining's auc: 0.902275\ttraining's binary_logloss: 0.113913\tvalid_1's auc: 0.832021\tvalid_1's binary_logloss: 0.137402\n",
            "[24]\ttraining's auc: 0.904209\ttraining's binary_logloss: 0.113222\tvalid_1's auc: 0.831551\tvalid_1's binary_logloss: 0.137488\n",
            "[25]\ttraining's auc: 0.90509\ttraining's binary_logloss: 0.112754\tvalid_1's auc: 0.831164\tvalid_1's binary_logloss: 0.137578\n",
            "[26]\ttraining's auc: 0.906052\ttraining's binary_logloss: 0.112306\tvalid_1's auc: 0.831541\tvalid_1's binary_logloss: 0.137518\n",
            "[27]\ttraining's auc: 0.906486\ttraining's binary_logloss: 0.112003\tvalid_1's auc: 0.831398\tvalid_1's binary_logloss: 0.137581\n",
            "[28]\ttraining's auc: 0.908421\ttraining's binary_logloss: 0.111357\tvalid_1's auc: 0.830863\tvalid_1's binary_logloss: 0.137706\n",
            "[29]\ttraining's auc: 0.909344\ttraining's binary_logloss: 0.110906\tvalid_1's auc: 0.830398\tvalid_1's binary_logloss: 0.13782\n",
            "[30]\ttraining's auc: 0.910102\ttraining's binary_logloss: 0.110488\tvalid_1's auc: 0.830187\tvalid_1's binary_logloss: 0.13791\n",
            "[31]\ttraining's auc: 0.911746\ttraining's binary_logloss: 0.109891\tvalid_1's auc: 0.830059\tvalid_1's binary_logloss: 0.137966\n",
            "[32]\ttraining's auc: 0.913531\ttraining's binary_logloss: 0.1094\tvalid_1's auc: 0.829846\tvalid_1's binary_logloss: 0.13803\n",
            "[33]\ttraining's auc: 0.914478\ttraining's binary_logloss: 0.108979\tvalid_1's auc: 0.829546\tvalid_1's binary_logloss: 0.138132\n",
            "[34]\ttraining's auc: 0.915575\ttraining's binary_logloss: 0.108603\tvalid_1's auc: 0.829971\tvalid_1's binary_logloss: 0.138091\n",
            "[35]\ttraining's auc: 0.916912\ttraining's binary_logloss: 0.10803\tvalid_1's auc: 0.829941\tvalid_1's binary_logloss: 0.13813\n",
            "[36]\ttraining's auc: 0.917402\ttraining's binary_logloss: 0.107712\tvalid_1's auc: 0.829389\tvalid_1's binary_logloss: 0.1383\n",
            "[37]\ttraining's auc: 0.91892\ttraining's binary_logloss: 0.107097\tvalid_1's auc: 0.829376\tvalid_1's binary_logloss: 0.138289\n",
            "[38]\ttraining's auc: 0.919773\ttraining's binary_logloss: 0.106733\tvalid_1's auc: 0.829476\tvalid_1's binary_logloss: 0.138331\n",
            "[39]\ttraining's auc: 0.920218\ttraining's binary_logloss: 0.106425\tvalid_1's auc: 0.829397\tvalid_1's binary_logloss: 0.138366\n",
            "[40]\ttraining's auc: 0.920508\ttraining's binary_logloss: 0.106181\tvalid_1's auc: 0.829058\tvalid_1's binary_logloss: 0.138488\n",
            "[41]\ttraining's auc: 0.921151\ttraining's binary_logloss: 0.105809\tvalid_1's auc: 0.829121\tvalid_1's binary_logloss: 0.13856\n",
            "[42]\ttraining's auc: 0.922007\ttraining's binary_logloss: 0.10555\tvalid_1's auc: 0.829354\tvalid_1's binary_logloss: 0.138565\n",
            "[43]\ttraining's auc: 0.922386\ttraining's binary_logloss: 0.105238\tvalid_1's auc: 0.829074\tvalid_1's binary_logloss: 0.13865\n",
            "[44]\ttraining's auc: 0.923073\ttraining's binary_logloss: 0.104992\tvalid_1's auc: 0.829753\tvalid_1's binary_logloss: 0.138548\n",
            "[45]\ttraining's auc: 0.923959\ttraining's binary_logloss: 0.104545\tvalid_1's auc: 0.829409\tvalid_1's binary_logloss: 0.138625\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 16%|█▌        | 8/50 [05:02<25:48, 36.86s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.15169\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.154898\n",
            "[2]\ttraining's auc: 0.835698\ttraining's binary_logloss: 0.145333\tvalid_1's auc: 0.81061\tvalid_1's binary_logloss: 0.149909\n",
            "[3]\ttraining's auc: 0.844252\ttraining's binary_logloss: 0.140971\tvalid_1's auc: 0.81569\tvalid_1's binary_logloss: 0.14674\n",
            "[4]\ttraining's auc: 0.849766\ttraining's binary_logloss: 0.137546\tvalid_1's auc: 0.817006\tvalid_1's binary_logloss: 0.144545\n",
            "[5]\ttraining's auc: 0.853611\ttraining's binary_logloss: 0.13479\tvalid_1's auc: 0.819916\tvalid_1's binary_logloss: 0.142835\n",
            "[6]\ttraining's auc: 0.858997\ttraining's binary_logloss: 0.132542\tvalid_1's auc: 0.821357\tvalid_1's binary_logloss: 0.14161\n",
            "[7]\ttraining's auc: 0.863499\ttraining's binary_logloss: 0.13053\tvalid_1's auc: 0.82466\tvalid_1's binary_logloss: 0.14032\n",
            "[8]\ttraining's auc: 0.867235\ttraining's binary_logloss: 0.128919\tvalid_1's auc: 0.824613\tvalid_1's binary_logloss: 0.139585\n",
            "[9]\ttraining's auc: 0.869633\ttraining's binary_logloss: 0.12745\tvalid_1's auc: 0.82521\tvalid_1's binary_logloss: 0.138895\n",
            "[10]\ttraining's auc: 0.872398\ttraining's binary_logloss: 0.126227\tvalid_1's auc: 0.825049\tvalid_1's binary_logloss: 0.138493\n",
            "[11]\ttraining's auc: 0.875974\ttraining's binary_logloss: 0.125013\tvalid_1's auc: 0.824824\tvalid_1's binary_logloss: 0.138096\n",
            "[12]\ttraining's auc: 0.878679\ttraining's binary_logloss: 0.123974\tvalid_1's auc: 0.825268\tvalid_1's binary_logloss: 0.137835\n",
            "[13]\ttraining's auc: 0.882705\ttraining's binary_logloss: 0.122827\tvalid_1's auc: 0.825062\tvalid_1's binary_logloss: 0.13758\n",
            "[14]\ttraining's auc: 0.885372\ttraining's binary_logloss: 0.121874\tvalid_1's auc: 0.82544\tvalid_1's binary_logloss: 0.137335\n",
            "[15]\ttraining's auc: 0.887379\ttraining's binary_logloss: 0.120947\tvalid_1's auc: 0.825088\tvalid_1's binary_logloss: 0.137294\n",
            "[16]\ttraining's auc: 0.889882\ttraining's binary_logloss: 0.120031\tvalid_1's auc: 0.826146\tvalid_1's binary_logloss: 0.13702\n",
            "[17]\ttraining's auc: 0.891707\ttraining's binary_logloss: 0.119354\tvalid_1's auc: 0.82609\tvalid_1's binary_logloss: 0.136988\n",
            "[18]\ttraining's auc: 0.892789\ttraining's binary_logloss: 0.11866\tvalid_1's auc: 0.825589\tvalid_1's binary_logloss: 0.136987\n",
            "[19]\ttraining's auc: 0.896203\ttraining's binary_logloss: 0.1178\tvalid_1's auc: 0.827264\tvalid_1's binary_logloss: 0.136671\n",
            "[20]\ttraining's auc: 0.897382\ttraining's binary_logloss: 0.117191\tvalid_1's auc: 0.827447\tvalid_1's binary_logloss: 0.136667\n",
            "[21]\ttraining's auc: 0.899665\ttraining's binary_logloss: 0.11656\tvalid_1's auc: 0.827071\tvalid_1's binary_logloss: 0.136663\n",
            "[22]\ttraining's auc: 0.901075\ttraining's binary_logloss: 0.115942\tvalid_1's auc: 0.827123\tvalid_1's binary_logloss: 0.136674\n",
            "[23]\ttraining's auc: 0.902531\ttraining's binary_logloss: 0.115431\tvalid_1's auc: 0.827273\tvalid_1's binary_logloss: 0.136646\n",
            "[24]\ttraining's auc: 0.903475\ttraining's binary_logloss: 0.114881\tvalid_1's auc: 0.827344\tvalid_1's binary_logloss: 0.136588\n",
            "[25]\ttraining's auc: 0.904666\ttraining's binary_logloss: 0.114304\tvalid_1's auc: 0.82763\tvalid_1's binary_logloss: 0.136618\n",
            "[26]\ttraining's auc: 0.905367\ttraining's binary_logloss: 0.113891\tvalid_1's auc: 0.827871\tvalid_1's binary_logloss: 0.136573\n",
            "[27]\ttraining's auc: 0.906298\ttraining's binary_logloss: 0.113381\tvalid_1's auc: 0.828133\tvalid_1's binary_logloss: 0.13652\n",
            "[28]\ttraining's auc: 0.908319\ttraining's binary_logloss: 0.112796\tvalid_1's auc: 0.828379\tvalid_1's binary_logloss: 0.136508\n",
            "[29]\ttraining's auc: 0.909733\ttraining's binary_logloss: 0.112263\tvalid_1's auc: 0.828704\tvalid_1's binary_logloss: 0.13643\n",
            "[30]\ttraining's auc: 0.910302\ttraining's binary_logloss: 0.111886\tvalid_1's auc: 0.827808\tvalid_1's binary_logloss: 0.136649\n",
            "[31]\ttraining's auc: 0.91125\ttraining's binary_logloss: 0.111382\tvalid_1's auc: 0.827246\tvalid_1's binary_logloss: 0.136798\n",
            "[32]\ttraining's auc: 0.912203\ttraining's binary_logloss: 0.11095\tvalid_1's auc: 0.826931\tvalid_1's binary_logloss: 0.136844\n",
            "[33]\ttraining's auc: 0.913029\ttraining's binary_logloss: 0.110489\tvalid_1's auc: 0.826854\tvalid_1's binary_logloss: 0.136852\n",
            "[34]\ttraining's auc: 0.914124\ttraining's binary_logloss: 0.110109\tvalid_1's auc: 0.826323\tvalid_1's binary_logloss: 0.13697\n",
            "[35]\ttraining's auc: 0.914529\ttraining's binary_logloss: 0.109816\tvalid_1's auc: 0.825943\tvalid_1's binary_logloss: 0.137048\n",
            "[36]\ttraining's auc: 0.915101\ttraining's binary_logloss: 0.109437\tvalid_1's auc: 0.82542\tvalid_1's binary_logloss: 0.137145\n",
            "[37]\ttraining's auc: 0.915762\ttraining's binary_logloss: 0.109089\tvalid_1's auc: 0.82513\tvalid_1's binary_logloss: 0.137234\n",
            "[38]\ttraining's auc: 0.916324\ttraining's binary_logloss: 0.108758\tvalid_1's auc: 0.825012\tvalid_1's binary_logloss: 0.137279\n",
            "[39]\ttraining's auc: 0.916783\ttraining's binary_logloss: 0.108477\tvalid_1's auc: 0.825184\tvalid_1's binary_logloss: 0.137275\n",
            "[40]\ttraining's auc: 0.91738\ttraining's binary_logloss: 0.108159\tvalid_1's auc: 0.824745\tvalid_1's binary_logloss: 0.137377\n",
            "[41]\ttraining's auc: 0.917905\ttraining's binary_logloss: 0.107871\tvalid_1's auc: 0.824106\tvalid_1's binary_logloss: 0.137507\n",
            "[42]\ttraining's auc: 0.918172\ttraining's binary_logloss: 0.107623\tvalid_1's auc: 0.823939\tvalid_1's binary_logloss: 0.137563\n",
            "[43]\ttraining's auc: 0.918711\ttraining's binary_logloss: 0.107273\tvalid_1's auc: 0.823449\tvalid_1's binary_logloss: 0.137687\n",
            "[44]\ttraining's auc: 0.920442\ttraining's binary_logloss: 0.106798\tvalid_1's auc: 0.823126\tvalid_1's binary_logloss: 0.137794\n",
            "[45]\ttraining's auc: 0.921736\ttraining's binary_logloss: 0.106444\tvalid_1's auc: 0.822955\tvalid_1's binary_logloss: 0.137797\n",
            "[46]\ttraining's auc: 0.922864\ttraining's binary_logloss: 0.106053\tvalid_1's auc: 0.823199\tvalid_1's binary_logloss: 0.137825\n",
            "[47]\ttraining's auc: 0.923048\ttraining's binary_logloss: 0.105858\tvalid_1's auc: 0.822738\tvalid_1's binary_logloss: 0.13793\n",
            "[48]\ttraining's auc: 0.924062\ttraining's binary_logloss: 0.105429\tvalid_1's auc: 0.822687\tvalid_1's binary_logloss: 0.138012\n",
            "[49]\ttraining's auc: 0.924537\ttraining's binary_logloss: 0.105128\tvalid_1's auc: 0.822616\tvalid_1's binary_logloss: 0.138122\n",
            "[50]\ttraining's auc: 0.924955\ttraining's binary_logloss: 0.104835\tvalid_1's auc: 0.822055\tvalid_1's binary_logloss: 0.138262\n",
            "[51]\ttraining's auc: 0.925323\ttraining's binary_logloss: 0.104609\tvalid_1's auc: 0.821667\tvalid_1's binary_logloss: 0.138385\n",
            "[52]\ttraining's auc: 0.925778\ttraining's binary_logloss: 0.104402\tvalid_1's auc: 0.821649\tvalid_1's binary_logloss: 0.138423\n",
            "[53]\ttraining's auc: 0.926333\ttraining's binary_logloss: 0.104133\tvalid_1's auc: 0.821512\tvalid_1's binary_logloss: 0.138498\n",
            "[54]\ttraining's auc: 0.927255\ttraining's binary_logloss: 0.10376\tvalid_1's auc: 0.821643\tvalid_1's binary_logloss: 0.138524\n",
            "[55]\ttraining's auc: 0.927715\ttraining's binary_logloss: 0.103483\tvalid_1's auc: 0.821555\tvalid_1's binary_logloss: 0.138533\n",
            "[56]\ttraining's auc: 0.928481\ttraining's binary_logloss: 0.103143\tvalid_1's auc: 0.821339\tvalid_1's binary_logloss: 0.138573\n",
            "[57]\ttraining's auc: 0.928778\ttraining's binary_logloss: 0.102932\tvalid_1's auc: 0.820845\tvalid_1's binary_logloss: 0.138671\n",
            "[58]\ttraining's auc: 0.929179\ttraining's binary_logloss: 0.102706\tvalid_1's auc: 0.820615\tvalid_1's binary_logloss: 0.138736\n",
            "[59]\ttraining's auc: 0.930467\ttraining's binary_logloss: 0.102269\tvalid_1's auc: 0.820835\tvalid_1's binary_logloss: 0.138748\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 16%|█▌        | 8/50 [05:06<25:48, 36.86s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.15414\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.151099\n",
            "[2]\ttraining's auc: 0.832215\ttraining's binary_logloss: 0.147552\tvalid_1's auc: 0.816865\tvalid_1's binary_logloss: 0.146068\n",
            "[3]\ttraining's auc: 0.840773\ttraining's binary_logloss: 0.143128\tvalid_1's auc: 0.82073\tvalid_1's binary_logloss: 0.142769\n",
            "[4]\ttraining's auc: 0.848956\ttraining's binary_logloss: 0.139765\tvalid_1's auc: 0.826975\tvalid_1's binary_logloss: 0.140396\n",
            "[5]\ttraining's auc: 0.852057\ttraining's binary_logloss: 0.137043\tvalid_1's auc: 0.828653\tvalid_1's binary_logloss: 0.138547\n",
            "[6]\ttraining's auc: 0.855384\ttraining's binary_logloss: 0.134709\tvalid_1's auc: 0.828061\tvalid_1's binary_logloss: 0.137359\n",
            "[7]\ttraining's auc: 0.860806\ttraining's binary_logloss: 0.132693\tvalid_1's auc: 0.829007\tvalid_1's binary_logloss: 0.136293\n",
            "[8]\ttraining's auc: 0.866266\ttraining's binary_logloss: 0.13096\tvalid_1's auc: 0.830883\tvalid_1's binary_logloss: 0.135404\n",
            "[9]\ttraining's auc: 0.869104\ttraining's binary_logloss: 0.129311\tvalid_1's auc: 0.830396\tvalid_1's binary_logloss: 0.134901\n",
            "[10]\ttraining's auc: 0.872475\ttraining's binary_logloss: 0.128039\tvalid_1's auc: 0.830039\tvalid_1's binary_logloss: 0.134341\n",
            "[11]\ttraining's auc: 0.874392\ttraining's binary_logloss: 0.126953\tvalid_1's auc: 0.830045\tvalid_1's binary_logloss: 0.133991\n",
            "[12]\ttraining's auc: 0.877729\ttraining's binary_logloss: 0.1258\tvalid_1's auc: 0.830403\tvalid_1's binary_logloss: 0.133615\n",
            "[13]\ttraining's auc: 0.879549\ttraining's binary_logloss: 0.124774\tvalid_1's auc: 0.83032\tvalid_1's binary_logloss: 0.133301\n",
            "[14]\ttraining's auc: 0.881724\ttraining's binary_logloss: 0.12383\tvalid_1's auc: 0.830127\tvalid_1's binary_logloss: 0.133085\n",
            "[15]\ttraining's auc: 0.883951\ttraining's binary_logloss: 0.123013\tvalid_1's auc: 0.830773\tvalid_1's binary_logloss: 0.132805\n",
            "[16]\ttraining's auc: 0.886179\ttraining's binary_logloss: 0.122195\tvalid_1's auc: 0.830801\tvalid_1's binary_logloss: 0.13271\n",
            "[17]\ttraining's auc: 0.887788\ttraining's binary_logloss: 0.121507\tvalid_1's auc: 0.831706\tvalid_1's binary_logloss: 0.132553\n",
            "[18]\ttraining's auc: 0.889361\ttraining's binary_logloss: 0.120731\tvalid_1's auc: 0.832155\tvalid_1's binary_logloss: 0.132391\n",
            "[19]\ttraining's auc: 0.890981\ttraining's binary_logloss: 0.120094\tvalid_1's auc: 0.831866\tvalid_1's binary_logloss: 0.132386\n",
            "[20]\ttraining's auc: 0.892886\ttraining's binary_logloss: 0.119379\tvalid_1's auc: 0.832871\tvalid_1's binary_logloss: 0.132281\n",
            "[21]\ttraining's auc: 0.894196\ttraining's binary_logloss: 0.118768\tvalid_1's auc: 0.833539\tvalid_1's binary_logloss: 0.132132\n",
            "[22]\ttraining's auc: 0.895684\ttraining's binary_logloss: 0.118142\tvalid_1's auc: 0.833636\tvalid_1's binary_logloss: 0.13206\n",
            "[23]\ttraining's auc: 0.89695\ttraining's binary_logloss: 0.117567\tvalid_1's auc: 0.833425\tvalid_1's binary_logloss: 0.132005\n",
            "[24]\ttraining's auc: 0.898805\ttraining's binary_logloss: 0.117008\tvalid_1's auc: 0.833929\tvalid_1's binary_logloss: 0.131956\n",
            "[25]\ttraining's auc: 0.900405\ttraining's binary_logloss: 0.116382\tvalid_1's auc: 0.833676\tvalid_1's binary_logloss: 0.131979\n",
            "[26]\ttraining's auc: 0.901615\ttraining's binary_logloss: 0.115834\tvalid_1's auc: 0.834021\tvalid_1's binary_logloss: 0.131864\n",
            "[27]\ttraining's auc: 0.90332\ttraining's binary_logloss: 0.115397\tvalid_1's auc: 0.833542\tvalid_1's binary_logloss: 0.131927\n",
            "[28]\ttraining's auc: 0.905529\ttraining's binary_logloss: 0.114814\tvalid_1's auc: 0.83319\tvalid_1's binary_logloss: 0.132002\n",
            "[29]\ttraining's auc: 0.906572\ttraining's binary_logloss: 0.114419\tvalid_1's auc: 0.833666\tvalid_1's binary_logloss: 0.131951\n",
            "[30]\ttraining's auc: 0.907725\ttraining's binary_logloss: 0.11391\tvalid_1's auc: 0.83406\tvalid_1's binary_logloss: 0.131908\n",
            "[31]\ttraining's auc: 0.908728\ttraining's binary_logloss: 0.113451\tvalid_1's auc: 0.834146\tvalid_1's binary_logloss: 0.131848\n",
            "[32]\ttraining's auc: 0.909516\ttraining's binary_logloss: 0.113004\tvalid_1's auc: 0.833983\tvalid_1's binary_logloss: 0.131906\n",
            "[33]\ttraining's auc: 0.910309\ttraining's binary_logloss: 0.112563\tvalid_1's auc: 0.834259\tvalid_1's binary_logloss: 0.131862\n",
            "[34]\ttraining's auc: 0.911252\ttraining's binary_logloss: 0.112198\tvalid_1's auc: 0.834043\tvalid_1's binary_logloss: 0.131891\n",
            "[35]\ttraining's auc: 0.91268\ttraining's binary_logloss: 0.111696\tvalid_1's auc: 0.834558\tvalid_1's binary_logloss: 0.131847\n",
            "[36]\ttraining's auc: 0.913778\ttraining's binary_logloss: 0.111262\tvalid_1's auc: 0.834393\tvalid_1's binary_logloss: 0.131883\n",
            "[37]\ttraining's auc: 0.914521\ttraining's binary_logloss: 0.110887\tvalid_1's auc: 0.834105\tvalid_1's binary_logloss: 0.131966\n",
            "[38]\ttraining's auc: 0.915179\ttraining's binary_logloss: 0.110586\tvalid_1's auc: 0.834259\tvalid_1's binary_logloss: 0.131956\n",
            "[39]\ttraining's auc: 0.915899\ttraining's binary_logloss: 0.110226\tvalid_1's auc: 0.834191\tvalid_1's binary_logloss: 0.131986\n",
            "[40]\ttraining's auc: 0.91665\ttraining's binary_logloss: 0.10985\tvalid_1's auc: 0.834027\tvalid_1's binary_logloss: 0.131981\n",
            "[41]\ttraining's auc: 0.917236\ttraining's binary_logloss: 0.109523\tvalid_1's auc: 0.833983\tvalid_1's binary_logloss: 0.131998\n",
            "[42]\ttraining's auc: 0.918267\ttraining's binary_logloss: 0.109049\tvalid_1's auc: 0.833859\tvalid_1's binary_logloss: 0.132023\n",
            "[43]\ttraining's auc: 0.919174\ttraining's binary_logloss: 0.108585\tvalid_1's auc: 0.833631\tvalid_1's binary_logloss: 0.132099\n",
            "[44]\ttraining's auc: 0.919485\ttraining's binary_logloss: 0.108338\tvalid_1's auc: 0.833794\tvalid_1's binary_logloss: 0.132056\n",
            "[45]\ttraining's auc: 0.920011\ttraining's binary_logloss: 0.108027\tvalid_1's auc: 0.83374\tvalid_1's binary_logloss: 0.132113\n",
            "[46]\ttraining's auc: 0.92155\ttraining's binary_logloss: 0.107522\tvalid_1's auc: 0.833296\tvalid_1's binary_logloss: 0.13223\n",
            "[47]\ttraining's auc: 0.922421\ttraining's binary_logloss: 0.107154\tvalid_1's auc: 0.833102\tvalid_1's binary_logloss: 0.132297\n",
            "[48]\ttraining's auc: 0.923122\ttraining's binary_logloss: 0.10677\tvalid_1's auc: 0.833022\tvalid_1's binary_logloss: 0.13236\n",
            "[49]\ttraining's auc: 0.923681\ttraining's binary_logloss: 0.106497\tvalid_1's auc: 0.832789\tvalid_1's binary_logloss: 0.132442\n",
            "[50]\ttraining's auc: 0.923975\ttraining's binary_logloss: 0.106275\tvalid_1's auc: 0.832782\tvalid_1's binary_logloss: 0.132435\n",
            "[51]\ttraining's auc: 0.92431\ttraining's binary_logloss: 0.106061\tvalid_1's auc: 0.83273\tvalid_1's binary_logloss: 0.132411\n",
            "[52]\ttraining's auc: 0.924878\ttraining's binary_logloss: 0.105816\tvalid_1's auc: 0.832622\tvalid_1's binary_logloss: 0.132485\n",
            "[53]\ttraining's auc: 0.925887\ttraining's binary_logloss: 0.105514\tvalid_1's auc: 0.832252\tvalid_1's binary_logloss: 0.132566\n",
            "[54]\ttraining's auc: 0.926324\ttraining's binary_logloss: 0.105286\tvalid_1's auc: 0.832131\tvalid_1's binary_logloss: 0.132586\n",
            "[55]\ttraining's auc: 0.927853\ttraining's binary_logloss: 0.104831\tvalid_1's auc: 0.831698\tvalid_1's binary_logloss: 0.132695\n",
            "[56]\ttraining's auc: 0.928303\ttraining's binary_logloss: 0.104635\tvalid_1's auc: 0.831675\tvalid_1's binary_logloss: 0.132708\n",
            "[57]\ttraining's auc: 0.928995\ttraining's binary_logloss: 0.104305\tvalid_1's auc: 0.831544\tvalid_1's binary_logloss: 0.132826\n",
            "[58]\ttraining's auc: 0.930883\ttraining's binary_logloss: 0.103733\tvalid_1's auc: 0.831844\tvalid_1's binary_logloss: 0.132821\n",
            "[59]\ttraining's auc: 0.931671\ttraining's binary_logloss: 0.103355\tvalid_1's auc: 0.832062\tvalid_1's binary_logloss: 0.132782\n",
            "[60]\ttraining's auc: 0.932224\ttraining's binary_logloss: 0.103163\tvalid_1's auc: 0.831815\tvalid_1's binary_logloss: 0.132897\n",
            "[61]\ttraining's auc: 0.932744\ttraining's binary_logloss: 0.102924\tvalid_1's auc: 0.83109\tvalid_1's binary_logloss: 0.133051\n",
            "[62]\ttraining's auc: 0.933086\ttraining's binary_logloss: 0.102674\tvalid_1's auc: 0.831097\tvalid_1's binary_logloss: 0.133082\n",
            "[63]\ttraining's auc: 0.933565\ttraining's binary_logloss: 0.102393\tvalid_1's auc: 0.831049\tvalid_1's binary_logloss: 0.133094\n",
            "[64]\ttraining's auc: 0.934477\ttraining's binary_logloss: 0.101929\tvalid_1's auc: 0.831695\tvalid_1's binary_logloss: 0.132971\n",
            "[65]\ttraining's auc: 0.934742\ttraining's binary_logloss: 0.101712\tvalid_1's auc: 0.831569\tvalid_1's binary_logloss: 0.133013\n",
            " 16%|█▌        | 8/50 [05:11<25:48, 36.86s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.151032\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.157731\n",
            "[2]\ttraining's auc: 0.835986\ttraining's binary_logloss: 0.144835\tvalid_1's auc: 0.817532\tvalid_1's binary_logloss: 0.152145\n",
            "[3]\ttraining's auc: 0.842556\ttraining's binary_logloss: 0.140542\tvalid_1's auc: 0.822022\tvalid_1's binary_logloss: 0.148616\n",
            "[4]\ttraining's auc: 0.848203\ttraining's binary_logloss: 0.136977\tvalid_1's auc: 0.825052\tvalid_1's binary_logloss: 0.146099\n",
            "[5]\ttraining's auc: 0.852133\ttraining's binary_logloss: 0.134256\tvalid_1's auc: 0.827164\tvalid_1's binary_logloss: 0.144262\n",
            "[6]\ttraining's auc: 0.855646\ttraining's binary_logloss: 0.132045\tvalid_1's auc: 0.828043\tvalid_1's binary_logloss: 0.142707\n",
            "[7]\ttraining's auc: 0.861146\ttraining's binary_logloss: 0.130111\tvalid_1's auc: 0.829543\tvalid_1's binary_logloss: 0.141437\n",
            "[8]\ttraining's auc: 0.863813\ttraining's binary_logloss: 0.12858\tvalid_1's auc: 0.830293\tvalid_1's binary_logloss: 0.140502\n",
            "[9]\ttraining's auc: 0.867341\ttraining's binary_logloss: 0.127197\tvalid_1's auc: 0.833063\tvalid_1's binary_logloss: 0.13973\n",
            "[10]\ttraining's auc: 0.870814\ttraining's binary_logloss: 0.125952\tvalid_1's auc: 0.832562\tvalid_1's binary_logloss: 0.139194\n",
            "[11]\ttraining's auc: 0.873955\ttraining's binary_logloss: 0.124816\tvalid_1's auc: 0.833183\tvalid_1's binary_logloss: 0.138734\n",
            "[12]\ttraining's auc: 0.876352\ttraining's binary_logloss: 0.123775\tvalid_1's auc: 0.833213\tvalid_1's binary_logloss: 0.138305\n",
            "[13]\ttraining's auc: 0.879497\ttraining's binary_logloss: 0.122797\tvalid_1's auc: 0.833252\tvalid_1's binary_logloss: 0.138076\n",
            "[14]\ttraining's auc: 0.882053\ttraining's binary_logloss: 0.121802\tvalid_1's auc: 0.833029\tvalid_1's binary_logloss: 0.137853\n",
            "[15]\ttraining's auc: 0.883826\ttraining's binary_logloss: 0.121029\tvalid_1's auc: 0.834185\tvalid_1's binary_logloss: 0.137566\n",
            "[16]\ttraining's auc: 0.886125\ttraining's binary_logloss: 0.120233\tvalid_1's auc: 0.834639\tvalid_1's binary_logloss: 0.137396\n",
            "[17]\ttraining's auc: 0.887827\ttraining's binary_logloss: 0.119475\tvalid_1's auc: 0.834376\tvalid_1's binary_logloss: 0.137299\n",
            "[18]\ttraining's auc: 0.889656\ttraining's binary_logloss: 0.118818\tvalid_1's auc: 0.834763\tvalid_1's binary_logloss: 0.137155\n",
            "[19]\ttraining's auc: 0.89238\ttraining's binary_logloss: 0.117962\tvalid_1's auc: 0.833868\tvalid_1's binary_logloss: 0.137195\n",
            "[20]\ttraining's auc: 0.894762\ttraining's binary_logloss: 0.117264\tvalid_1's auc: 0.834111\tvalid_1's binary_logloss: 0.137107\n",
            "[21]\ttraining's auc: 0.896094\ttraining's binary_logloss: 0.116674\tvalid_1's auc: 0.833908\tvalid_1's binary_logloss: 0.137044\n",
            "[22]\ttraining's auc: 0.897434\ttraining's binary_logloss: 0.116121\tvalid_1's auc: 0.834438\tvalid_1's binary_logloss: 0.136935\n",
            "[23]\ttraining's auc: 0.898253\ttraining's binary_logloss: 0.115651\tvalid_1's auc: 0.834276\tvalid_1's binary_logloss: 0.136956\n",
            "[24]\ttraining's auc: 0.900136\ttraining's binary_logloss: 0.115026\tvalid_1's auc: 0.834473\tvalid_1's binary_logloss: 0.136903\n",
            "[25]\ttraining's auc: 0.901508\ttraining's binary_logloss: 0.114509\tvalid_1's auc: 0.834437\tvalid_1's binary_logloss: 0.136925\n",
            "[26]\ttraining's auc: 0.90297\ttraining's binary_logloss: 0.113857\tvalid_1's auc: 0.834741\tvalid_1's binary_logloss: 0.136881\n",
            "[27]\ttraining's auc: 0.904753\ttraining's binary_logloss: 0.113296\tvalid_1's auc: 0.834678\tvalid_1's binary_logloss: 0.136888\n",
            "[28]\ttraining's auc: 0.906532\ttraining's binary_logloss: 0.112803\tvalid_1's auc: 0.834926\tvalid_1's binary_logloss: 0.136859\n",
            "[29]\ttraining's auc: 0.907882\ttraining's binary_logloss: 0.112248\tvalid_1's auc: 0.834965\tvalid_1's binary_logloss: 0.13687\n",
            "[30]\ttraining's auc: 0.909468\ttraining's binary_logloss: 0.111584\tvalid_1's auc: 0.835234\tvalid_1's binary_logloss: 0.136837\n",
            "[31]\ttraining's auc: 0.910923\ttraining's binary_logloss: 0.110967\tvalid_1's auc: 0.835702\tvalid_1's binary_logloss: 0.136711\n",
            "[32]\ttraining's auc: 0.911797\ttraining's binary_logloss: 0.110517\tvalid_1's auc: 0.835631\tvalid_1's binary_logloss: 0.136782\n",
            "[33]\ttraining's auc: 0.913482\ttraining's binary_logloss: 0.10989\tvalid_1's auc: 0.835158\tvalid_1's binary_logloss: 0.136892\n",
            "[34]\ttraining's auc: 0.913883\ttraining's binary_logloss: 0.109581\tvalid_1's auc: 0.834909\tvalid_1's binary_logloss: 0.136992\n",
            "[35]\ttraining's auc: 0.914976\ttraining's binary_logloss: 0.109103\tvalid_1's auc: 0.835187\tvalid_1's binary_logloss: 0.136925\n",
            "[36]\ttraining's auc: 0.915867\ttraining's binary_logloss: 0.108639\tvalid_1's auc: 0.835443\tvalid_1's binary_logloss: 0.136909\n",
            "[37]\ttraining's auc: 0.916665\ttraining's binary_logloss: 0.108326\tvalid_1's auc: 0.835939\tvalid_1's binary_logloss: 0.136814\n",
            "[38]\ttraining's auc: 0.917531\ttraining's binary_logloss: 0.107921\tvalid_1's auc: 0.835689\tvalid_1's binary_logloss: 0.136923\n",
            "[39]\ttraining's auc: 0.918269\ttraining's binary_logloss: 0.107601\tvalid_1's auc: 0.835415\tvalid_1's binary_logloss: 0.137001\n",
            "[40]\ttraining's auc: 0.918895\ttraining's binary_logloss: 0.107285\tvalid_1's auc: 0.835839\tvalid_1's binary_logloss: 0.136945\n",
            "[41]\ttraining's auc: 0.91937\ttraining's binary_logloss: 0.106967\tvalid_1's auc: 0.835687\tvalid_1's binary_logloss: 0.136993\n",
            "[42]\ttraining's auc: 0.920359\ttraining's binary_logloss: 0.106591\tvalid_1's auc: 0.835615\tvalid_1's binary_logloss: 0.137027\n",
            "[43]\ttraining's auc: 0.920738\ttraining's binary_logloss: 0.10632\tvalid_1's auc: 0.835504\tvalid_1's binary_logloss: 0.137067\n",
            "[44]\ttraining's auc: 0.921576\ttraining's binary_logloss: 0.105905\tvalid_1's auc: 0.835519\tvalid_1's binary_logloss: 0.137058\n",
            "[45]\ttraining's auc: 0.922462\ttraining's binary_logloss: 0.105626\tvalid_1's auc: 0.83555\tvalid_1's binary_logloss: 0.137114\n",
            "[46]\ttraining's auc: 0.922776\ttraining's binary_logloss: 0.105391\tvalid_1's auc: 0.835505\tvalid_1's binary_logloss: 0.137173\n",
            "[47]\ttraining's auc: 0.923565\ttraining's binary_logloss: 0.105017\tvalid_1's auc: 0.835519\tvalid_1's binary_logloss: 0.137184\n",
            "[48]\ttraining's auc: 0.924045\ttraining's binary_logloss: 0.104765\tvalid_1's auc: 0.835253\tvalid_1's binary_logloss: 0.137247\n",
            "[49]\ttraining's auc: 0.92465\ttraining's binary_logloss: 0.104408\tvalid_1's auc: 0.835124\tvalid_1's binary_logloss: 0.137267\n",
            "[50]\ttraining's auc: 0.92503\ttraining's binary_logloss: 0.104121\tvalid_1's auc: 0.83494\tvalid_1's binary_logloss: 0.137303\n",
            "[51]\ttraining's auc: 0.925595\ttraining's binary_logloss: 0.103747\tvalid_1's auc: 0.834922\tvalid_1's binary_logloss: 0.137332\n",
            "[52]\ttraining's auc: 0.926867\ttraining's binary_logloss: 0.103238\tvalid_1's auc: 0.835044\tvalid_1's binary_logloss: 0.137286\n",
            "[53]\ttraining's auc: 0.927121\ttraining's binary_logloss: 0.103035\tvalid_1's auc: 0.835051\tvalid_1's binary_logloss: 0.13729\n",
            "[54]\ttraining's auc: 0.928306\ttraining's binary_logloss: 0.102667\tvalid_1's auc: 0.834642\tvalid_1's binary_logloss: 0.13741\n",
            "[55]\ttraining's auc: 0.928742\ttraining's binary_logloss: 0.102367\tvalid_1's auc: 0.834304\tvalid_1's binary_logloss: 0.137513\n",
            "[56]\ttraining's auc: 0.929435\ttraining's binary_logloss: 0.101967\tvalid_1's auc: 0.83451\tvalid_1's binary_logloss: 0.137461\n",
            "[57]\ttraining's auc: 0.929867\ttraining's binary_logloss: 0.101652\tvalid_1's auc: 0.834328\tvalid_1's binary_logloss: 0.1375\n",
            "[58]\ttraining's auc: 0.930335\ttraining's binary_logloss: 0.101333\tvalid_1's auc: 0.834146\tvalid_1's binary_logloss: 0.137526\n",
            "[59]\ttraining's auc: 0.931007\ttraining's binary_logloss: 0.10097\tvalid_1's auc: 0.834378\tvalid_1's binary_logloss: 0.13752\n",
            "[60]\ttraining's auc: 0.931354\ttraining's binary_logloss: 0.100742\tvalid_1's auc: 0.834217\tvalid_1's binary_logloss: 0.137512\n",
            "[61]\ttraining's auc: 0.931872\ttraining's binary_logloss: 0.100452\tvalid_1's auc: 0.834095\tvalid_1's binary_logloss: 0.137556\n",
            " 18%|█▊        | 9/50 [05:17<20:40, 30.27s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.158024\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.160008\n",
            "[2]\ttraining's auc: 0.832842\ttraining's binary_logloss: 0.153442\tvalid_1's auc: 0.806029\tvalid_1's binary_logloss: 0.156409\n",
            "[3]\ttraining's auc: 0.835779\ttraining's binary_logloss: 0.149876\tvalid_1's auc: 0.80871\tvalid_1's binary_logloss: 0.153609\n",
            "[4]\ttraining's auc: 0.843846\ttraining's binary_logloss: 0.146977\tvalid_1's auc: 0.814113\tvalid_1's binary_logloss: 0.15139\n",
            "[5]\ttraining's auc: 0.846996\ttraining's binary_logloss: 0.144499\tvalid_1's auc: 0.817169\tvalid_1's binary_logloss: 0.149473\n",
            "[6]\ttraining's auc: 0.848154\ttraining's binary_logloss: 0.14231\tvalid_1's auc: 0.818521\tvalid_1's binary_logloss: 0.147867\n",
            "[7]\ttraining's auc: 0.851371\ttraining's binary_logloss: 0.140486\tvalid_1's auc: 0.821001\tvalid_1's binary_logloss: 0.146485\n",
            "[8]\ttraining's auc: 0.852982\ttraining's binary_logloss: 0.13881\tvalid_1's auc: 0.821615\tvalid_1's binary_logloss: 0.14535\n",
            "[9]\ttraining's auc: 0.854692\ttraining's binary_logloss: 0.137279\tvalid_1's auc: 0.821641\tvalid_1's binary_logloss: 0.14428\n",
            "[10]\ttraining's auc: 0.857447\ttraining's binary_logloss: 0.135969\tvalid_1's auc: 0.822727\tvalid_1's binary_logloss: 0.143308\n",
            "[11]\ttraining's auc: 0.859879\ttraining's binary_logloss: 0.134677\tvalid_1's auc: 0.822692\tvalid_1's binary_logloss: 0.142479\n",
            "[12]\ttraining's auc: 0.861244\ttraining's binary_logloss: 0.133566\tvalid_1's auc: 0.823443\tvalid_1's binary_logloss: 0.141777\n",
            "[13]\ttraining's auc: 0.86199\ttraining's binary_logloss: 0.13259\tvalid_1's auc: 0.823622\tvalid_1's binary_logloss: 0.141147\n",
            "[14]\ttraining's auc: 0.864658\ttraining's binary_logloss: 0.131652\tvalid_1's auc: 0.825174\tvalid_1's binary_logloss: 0.140487\n",
            "[15]\ttraining's auc: 0.866288\ttraining's binary_logloss: 0.130786\tvalid_1's auc: 0.82556\tvalid_1's binary_logloss: 0.139995\n",
            "[16]\ttraining's auc: 0.867285\ttraining's binary_logloss: 0.129939\tvalid_1's auc: 0.825836\tvalid_1's binary_logloss: 0.139535\n",
            "[17]\ttraining's auc: 0.869475\ttraining's binary_logloss: 0.129144\tvalid_1's auc: 0.826306\tvalid_1's binary_logloss: 0.139196\n",
            "[18]\ttraining's auc: 0.871115\ttraining's binary_logloss: 0.128418\tvalid_1's auc: 0.826473\tvalid_1's binary_logloss: 0.138806\n",
            "[19]\ttraining's auc: 0.872682\ttraining's binary_logloss: 0.127691\tvalid_1's auc: 0.826317\tvalid_1's binary_logloss: 0.138535\n",
            "[20]\ttraining's auc: 0.873907\ttraining's binary_logloss: 0.127044\tvalid_1's auc: 0.826505\tvalid_1's binary_logloss: 0.138294\n",
            "[21]\ttraining's auc: 0.874936\ttraining's binary_logloss: 0.126457\tvalid_1's auc: 0.826791\tvalid_1's binary_logloss: 0.138052\n",
            "[22]\ttraining's auc: 0.876223\ttraining's binary_logloss: 0.125873\tvalid_1's auc: 0.826897\tvalid_1's binary_logloss: 0.13786\n",
            "[23]\ttraining's auc: 0.878317\ttraining's binary_logloss: 0.125276\tvalid_1's auc: 0.827099\tvalid_1's binary_logloss: 0.137653\n",
            "[24]\ttraining's auc: 0.879112\ttraining's binary_logloss: 0.124769\tvalid_1's auc: 0.827092\tvalid_1's binary_logloss: 0.137487\n",
            "[25]\ttraining's auc: 0.880322\ttraining's binary_logloss: 0.124221\tvalid_1's auc: 0.827082\tvalid_1's binary_logloss: 0.137337\n",
            "[26]\ttraining's auc: 0.881393\ttraining's binary_logloss: 0.123722\tvalid_1's auc: 0.827927\tvalid_1's binary_logloss: 0.137153\n",
            "[27]\ttraining's auc: 0.882199\ttraining's binary_logloss: 0.123268\tvalid_1's auc: 0.828133\tvalid_1's binary_logloss: 0.137026\n",
            "[28]\ttraining's auc: 0.883829\ttraining's binary_logloss: 0.122744\tvalid_1's auc: 0.828058\tvalid_1's binary_logloss: 0.136947\n",
            "[29]\ttraining's auc: 0.885378\ttraining's binary_logloss: 0.122206\tvalid_1's auc: 0.82806\tvalid_1's binary_logloss: 0.136873\n",
            "[30]\ttraining's auc: 0.88672\ttraining's binary_logloss: 0.121738\tvalid_1's auc: 0.828657\tvalid_1's binary_logloss: 0.136734\n",
            "[31]\ttraining's auc: 0.887643\ttraining's binary_logloss: 0.121343\tvalid_1's auc: 0.828805\tvalid_1's binary_logloss: 0.13667\n",
            "[32]\ttraining's auc: 0.888521\ttraining's binary_logloss: 0.120957\tvalid_1's auc: 0.829236\tvalid_1's binary_logloss: 0.136561\n",
            "[33]\ttraining's auc: 0.889105\ttraining's binary_logloss: 0.120594\tvalid_1's auc: 0.829529\tvalid_1's binary_logloss: 0.136451\n",
            "[34]\ttraining's auc: 0.88965\ttraining's binary_logloss: 0.120239\tvalid_1's auc: 0.830003\tvalid_1's binary_logloss: 0.136295\n",
            "[35]\ttraining's auc: 0.890686\ttraining's binary_logloss: 0.11987\tvalid_1's auc: 0.830672\tvalid_1's binary_logloss: 0.136145\n",
            "[36]\ttraining's auc: 0.891365\ttraining's binary_logloss: 0.119561\tvalid_1's auc: 0.830894\tvalid_1's binary_logloss: 0.136084\n",
            "[37]\ttraining's auc: 0.891675\ttraining's binary_logloss: 0.119273\tvalid_1's auc: 0.830963\tvalid_1's binary_logloss: 0.136016\n",
            "[38]\ttraining's auc: 0.892473\ttraining's binary_logloss: 0.118962\tvalid_1's auc: 0.830678\tvalid_1's binary_logloss: 0.13602\n",
            "[39]\ttraining's auc: 0.893703\ttraining's binary_logloss: 0.118594\tvalid_1's auc: 0.831143\tvalid_1's binary_logloss: 0.135906\n",
            "[40]\ttraining's auc: 0.894683\ttraining's binary_logloss: 0.11827\tvalid_1's auc: 0.831134\tvalid_1's binary_logloss: 0.13588\n",
            "[41]\ttraining's auc: 0.895782\ttraining's binary_logloss: 0.11795\tvalid_1's auc: 0.831192\tvalid_1's binary_logloss: 0.135864\n",
            "[42]\ttraining's auc: 0.897361\ttraining's binary_logloss: 0.117557\tvalid_1's auc: 0.831632\tvalid_1's binary_logloss: 0.135742\n",
            "[43]\ttraining's auc: 0.89788\ttraining's binary_logloss: 0.117278\tvalid_1's auc: 0.831562\tvalid_1's binary_logloss: 0.135743\n",
            "[44]\ttraining's auc: 0.898559\ttraining's binary_logloss: 0.11699\tvalid_1's auc: 0.831241\tvalid_1's binary_logloss: 0.135785\n",
            "[45]\ttraining's auc: 0.899568\ttraining's binary_logloss: 0.116718\tvalid_1's auc: 0.831154\tvalid_1's binary_logloss: 0.135789\n",
            "[46]\ttraining's auc: 0.900596\ttraining's binary_logloss: 0.116411\tvalid_1's auc: 0.831765\tvalid_1's binary_logloss: 0.135671\n",
            "[47]\ttraining's auc: 0.901442\ttraining's binary_logloss: 0.116106\tvalid_1's auc: 0.831717\tvalid_1's binary_logloss: 0.135673\n",
            "[48]\ttraining's auc: 0.90208\ttraining's binary_logloss: 0.115847\tvalid_1's auc: 0.831663\tvalid_1's binary_logloss: 0.135669\n",
            "[49]\ttraining's auc: 0.903148\ttraining's binary_logloss: 0.115513\tvalid_1's auc: 0.831762\tvalid_1's binary_logloss: 0.135615\n",
            "[50]\ttraining's auc: 0.903628\ttraining's binary_logloss: 0.115257\tvalid_1's auc: 0.831924\tvalid_1's binary_logloss: 0.135583\n",
            "[51]\ttraining's auc: 0.904292\ttraining's binary_logloss: 0.114983\tvalid_1's auc: 0.831864\tvalid_1's binary_logloss: 0.1356\n",
            "[52]\ttraining's auc: 0.90557\ttraining's binary_logloss: 0.114601\tvalid_1's auc: 0.831499\tvalid_1's binary_logloss: 0.135669\n",
            "[53]\ttraining's auc: 0.906112\ttraining's binary_logloss: 0.114319\tvalid_1's auc: 0.831547\tvalid_1's binary_logloss: 0.13567\n",
            "[54]\ttraining's auc: 0.906389\ttraining's binary_logloss: 0.114117\tvalid_1's auc: 0.831499\tvalid_1's binary_logloss: 0.135685\n",
            "[55]\ttraining's auc: 0.90719\ttraining's binary_logloss: 0.113915\tvalid_1's auc: 0.831338\tvalid_1's binary_logloss: 0.135713\n",
            "[56]\ttraining's auc: 0.907856\ttraining's binary_logloss: 0.113673\tvalid_1's auc: 0.83135\tvalid_1's binary_logloss: 0.135723\n",
            "[57]\ttraining's auc: 0.908319\ttraining's binary_logloss: 0.113436\tvalid_1's auc: 0.831146\tvalid_1's binary_logloss: 0.135758\n",
            "[58]\ttraining's auc: 0.908899\ttraining's binary_logloss: 0.113209\tvalid_1's auc: 0.83097\tvalid_1's binary_logloss: 0.13581\n",
            "[59]\ttraining's auc: 0.909415\ttraining's binary_logloss: 0.112993\tvalid_1's auc: 0.830963\tvalid_1's binary_logloss: 0.135806\n",
            "[60]\ttraining's auc: 0.909878\ttraining's binary_logloss: 0.112782\tvalid_1's auc: 0.830825\tvalid_1's binary_logloss: 0.135841\n",
            "[61]\ttraining's auc: 0.910251\ttraining's binary_logloss: 0.112572\tvalid_1's auc: 0.830544\tvalid_1's binary_logloss: 0.1359\n",
            "[62]\ttraining's auc: 0.911087\ttraining's binary_logloss: 0.112326\tvalid_1's auc: 0.830399\tvalid_1's binary_logloss: 0.135922\n",
            "[63]\ttraining's auc: 0.911845\ttraining's binary_logloss: 0.112071\tvalid_1's auc: 0.83045\tvalid_1's binary_logloss: 0.135922\n",
            "[64]\ttraining's auc: 0.912139\ttraining's binary_logloss: 0.111892\tvalid_1's auc: 0.830269\tvalid_1's binary_logloss: 0.135962\n",
            "[65]\ttraining's auc: 0.912589\ttraining's binary_logloss: 0.111693\tvalid_1's auc: 0.829962\tvalid_1's binary_logloss: 0.136006\n",
            "[66]\ttraining's auc: 0.91328\ttraining's binary_logloss: 0.111408\tvalid_1's auc: 0.829743\tvalid_1's binary_logloss: 0.136078\n",
            "[67]\ttraining's auc: 0.913691\ttraining's binary_logloss: 0.111181\tvalid_1's auc: 0.829495\tvalid_1's binary_logloss: 0.136108\n",
            "[68]\ttraining's auc: 0.914014\ttraining's binary_logloss: 0.111\tvalid_1's auc: 0.829547\tvalid_1's binary_logloss: 0.136117\n",
            "[69]\ttraining's auc: 0.914255\ttraining's binary_logloss: 0.110859\tvalid_1's auc: 0.829218\tvalid_1's binary_logloss: 0.136188\n",
            "[70]\ttraining's auc: 0.914735\ttraining's binary_logloss: 0.110612\tvalid_1's auc: 0.829246\tvalid_1's binary_logloss: 0.13618\n",
            "[71]\ttraining's auc: 0.915216\ttraining's binary_logloss: 0.110408\tvalid_1's auc: 0.829018\tvalid_1's binary_logloss: 0.136233\n",
            "[72]\ttraining's auc: 0.915472\ttraining's binary_logloss: 0.110264\tvalid_1's auc: 0.82895\tvalid_1's binary_logloss: 0.136249\n",
            "[73]\ttraining's auc: 0.915979\ttraining's binary_logloss: 0.110112\tvalid_1's auc: 0.829107\tvalid_1's binary_logloss: 0.136246\n",
            "[74]\ttraining's auc: 0.916248\ttraining's binary_logloss: 0.109958\tvalid_1's auc: 0.829046\tvalid_1's binary_logloss: 0.136283\n",
            "[75]\ttraining's auc: 0.916426\ttraining's binary_logloss: 0.109827\tvalid_1's auc: 0.828876\tvalid_1's binary_logloss: 0.136314\n",
            "[76]\ttraining's auc: 0.916646\ttraining's binary_logloss: 0.109675\tvalid_1's auc: 0.828958\tvalid_1's binary_logloss: 0.13631\n",
            "[77]\ttraining's auc: 0.917152\ttraining's binary_logloss: 0.109461\tvalid_1's auc: 0.829104\tvalid_1's binary_logloss: 0.136306\n",
            "[78]\ttraining's auc: 0.917453\ttraining's binary_logloss: 0.109295\tvalid_1's auc: 0.828916\tvalid_1's binary_logloss: 0.136376\n",
            "[79]\ttraining's auc: 0.917804\ttraining's binary_logloss: 0.109097\tvalid_1's auc: 0.828915\tvalid_1's binary_logloss: 0.13636\n",
            "[80]\ttraining's auc: 0.917965\ttraining's binary_logloss: 0.108962\tvalid_1's auc: 0.828662\tvalid_1's binary_logloss: 0.136431\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 18%|█▊        | 9/50 [05:23<20:40, 30.27s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.160428\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.15574\n",
            "[2]\ttraining's auc: 0.826684\ttraining's binary_logloss: 0.155778\tvalid_1's auc: 0.81556\tvalid_1's binary_logloss: 0.152188\n",
            "[3]\ttraining's auc: 0.832624\ttraining's binary_logloss: 0.15208\tvalid_1's auc: 0.817753\tvalid_1's binary_logloss: 0.149358\n",
            "[4]\ttraining's auc: 0.83615\ttraining's binary_logloss: 0.149113\tvalid_1's auc: 0.820524\tvalid_1's binary_logloss: 0.147029\n",
            "[5]\ttraining's auc: 0.840684\ttraining's binary_logloss: 0.146614\tvalid_1's auc: 0.823607\tvalid_1's binary_logloss: 0.145123\n",
            "[6]\ttraining's auc: 0.848081\ttraining's binary_logloss: 0.144404\tvalid_1's auc: 0.828186\tvalid_1's binary_logloss: 0.143558\n",
            "[7]\ttraining's auc: 0.850146\ttraining's binary_logloss: 0.142479\tvalid_1's auc: 0.829166\tvalid_1's binary_logloss: 0.142125\n",
            "[8]\ttraining's auc: 0.852356\ttraining's binary_logloss: 0.140787\tvalid_1's auc: 0.829488\tvalid_1's binary_logloss: 0.140907\n",
            "[9]\ttraining's auc: 0.855214\ttraining's binary_logloss: 0.139314\tvalid_1's auc: 0.830296\tvalid_1's binary_logloss: 0.139855\n",
            "[10]\ttraining's auc: 0.857699\ttraining's binary_logloss: 0.137963\tvalid_1's auc: 0.832204\tvalid_1's binary_logloss: 0.138851\n",
            "[11]\ttraining's auc: 0.858374\ttraining's binary_logloss: 0.13671\tvalid_1's auc: 0.831964\tvalid_1's binary_logloss: 0.138091\n",
            "[12]\ttraining's auc: 0.861785\ttraining's binary_logloss: 0.135497\tvalid_1's auc: 0.833021\tvalid_1's binary_logloss: 0.137357\n",
            "[13]\ttraining's auc: 0.862559\ttraining's binary_logloss: 0.134498\tvalid_1's auc: 0.832902\tvalid_1's binary_logloss: 0.136711\n",
            "[14]\ttraining's auc: 0.864262\ttraining's binary_logloss: 0.133541\tvalid_1's auc: 0.832784\tvalid_1's binary_logloss: 0.136177\n",
            "[15]\ttraining's auc: 0.867702\ttraining's binary_logloss: 0.132585\tvalid_1's auc: 0.833096\tvalid_1's binary_logloss: 0.135657\n",
            "[16]\ttraining's auc: 0.869672\ttraining's binary_logloss: 0.131722\tvalid_1's auc: 0.833409\tvalid_1's binary_logloss: 0.13527\n",
            "[17]\ttraining's auc: 0.871038\ttraining's binary_logloss: 0.130936\tvalid_1's auc: 0.833363\tvalid_1's binary_logloss: 0.134894\n",
            "[18]\ttraining's auc: 0.872222\ttraining's binary_logloss: 0.130196\tvalid_1's auc: 0.833433\tvalid_1's binary_logloss: 0.13452\n",
            "[19]\ttraining's auc: 0.87295\ttraining's binary_logloss: 0.12951\tvalid_1's auc: 0.833197\tvalid_1's binary_logloss: 0.134177\n",
            "[20]\ttraining's auc: 0.87379\ttraining's binary_logloss: 0.128866\tvalid_1's auc: 0.832726\tvalid_1's binary_logloss: 0.133962\n",
            "[21]\ttraining's auc: 0.87444\ttraining's binary_logloss: 0.128264\tvalid_1's auc: 0.832861\tvalid_1's binary_logloss: 0.133711\n",
            "[22]\ttraining's auc: 0.875467\ttraining's binary_logloss: 0.127691\tvalid_1's auc: 0.833129\tvalid_1's binary_logloss: 0.13346\n",
            "[23]\ttraining's auc: 0.87615\ttraining's binary_logloss: 0.127125\tvalid_1's auc: 0.832816\tvalid_1's binary_logloss: 0.133298\n",
            "[24]\ttraining's auc: 0.877317\ttraining's binary_logloss: 0.126588\tvalid_1's auc: 0.832946\tvalid_1's binary_logloss: 0.133102\n",
            "[25]\ttraining's auc: 0.878472\ttraining's binary_logloss: 0.126046\tvalid_1's auc: 0.833316\tvalid_1's binary_logloss: 0.132899\n",
            "[26]\ttraining's auc: 0.879056\ttraining's binary_logloss: 0.125561\tvalid_1's auc: 0.833298\tvalid_1's binary_logloss: 0.132782\n",
            "[27]\ttraining's auc: 0.879983\ttraining's binary_logloss: 0.125118\tvalid_1's auc: 0.832854\tvalid_1's binary_logloss: 0.132655\n",
            "[28]\ttraining's auc: 0.880792\ttraining's binary_logloss: 0.124642\tvalid_1's auc: 0.832712\tvalid_1's binary_logloss: 0.132569\n",
            "[29]\ttraining's auc: 0.882013\ttraining's binary_logloss: 0.124185\tvalid_1's auc: 0.832703\tvalid_1's binary_logloss: 0.132447\n",
            "[30]\ttraining's auc: 0.883514\ttraining's binary_logloss: 0.123753\tvalid_1's auc: 0.832545\tvalid_1's binary_logloss: 0.132359\n",
            "[31]\ttraining's auc: 0.884721\ttraining's binary_logloss: 0.123295\tvalid_1's auc: 0.832622\tvalid_1's binary_logloss: 0.132253\n",
            "[32]\ttraining's auc: 0.88597\ttraining's binary_logloss: 0.122828\tvalid_1's auc: 0.833037\tvalid_1's binary_logloss: 0.132152\n",
            "[33]\ttraining's auc: 0.886949\ttraining's binary_logloss: 0.12241\tvalid_1's auc: 0.832904\tvalid_1's binary_logloss: 0.13208\n",
            "[34]\ttraining's auc: 0.88811\ttraining's binary_logloss: 0.122\tvalid_1's auc: 0.832721\tvalid_1's binary_logloss: 0.132053\n",
            "[35]\ttraining's auc: 0.890122\ttraining's binary_logloss: 0.121564\tvalid_1's auc: 0.832881\tvalid_1's binary_logloss: 0.132021\n",
            "[36]\ttraining's auc: 0.890653\ttraining's binary_logloss: 0.121223\tvalid_1's auc: 0.83314\tvalid_1's binary_logloss: 0.131898\n",
            "[37]\ttraining's auc: 0.891617\ttraining's binary_logloss: 0.120892\tvalid_1's auc: 0.833377\tvalid_1's binary_logloss: 0.13183\n",
            "[38]\ttraining's auc: 0.892432\ttraining's binary_logloss: 0.120541\tvalid_1's auc: 0.833235\tvalid_1's binary_logloss: 0.131799\n",
            "[39]\ttraining's auc: 0.893059\ttraining's binary_logloss: 0.1202\tvalid_1's auc: 0.833372\tvalid_1's binary_logloss: 0.131697\n",
            "[40]\ttraining's auc: 0.894182\ttraining's binary_logloss: 0.11986\tvalid_1's auc: 0.833493\tvalid_1's binary_logloss: 0.131679\n",
            "[41]\ttraining's auc: 0.894811\ttraining's binary_logloss: 0.119571\tvalid_1's auc: 0.833708\tvalid_1's binary_logloss: 0.131618\n",
            "[42]\ttraining's auc: 0.895712\ttraining's binary_logloss: 0.119279\tvalid_1's auc: 0.833673\tvalid_1's binary_logloss: 0.131566\n",
            "[43]\ttraining's auc: 0.896257\ttraining's binary_logloss: 0.119044\tvalid_1's auc: 0.833742\tvalid_1's binary_logloss: 0.131522\n",
            "[44]\ttraining's auc: 0.896863\ttraining's binary_logloss: 0.118765\tvalid_1's auc: 0.834056\tvalid_1's binary_logloss: 0.131455\n",
            "[45]\ttraining's auc: 0.897722\ttraining's binary_logloss: 0.118496\tvalid_1's auc: 0.833954\tvalid_1's binary_logloss: 0.131453\n",
            "[46]\ttraining's auc: 0.899164\ttraining's binary_logloss: 0.118171\tvalid_1's auc: 0.833882\tvalid_1's binary_logloss: 0.131438\n",
            "[47]\ttraining's auc: 0.900012\ttraining's binary_logloss: 0.117926\tvalid_1's auc: 0.834096\tvalid_1's binary_logloss: 0.131408\n",
            "[48]\ttraining's auc: 0.900657\ttraining's binary_logloss: 0.117667\tvalid_1's auc: 0.834169\tvalid_1's binary_logloss: 0.131385\n",
            "[49]\ttraining's auc: 0.901392\ttraining's binary_logloss: 0.117372\tvalid_1's auc: 0.834289\tvalid_1's binary_logloss: 0.131365\n",
            "[50]\ttraining's auc: 0.902201\ttraining's binary_logloss: 0.117097\tvalid_1's auc: 0.834476\tvalid_1's binary_logloss: 0.131333\n",
            "[51]\ttraining's auc: 0.903119\ttraining's binary_logloss: 0.116854\tvalid_1's auc: 0.834614\tvalid_1's binary_logloss: 0.131311\n",
            "[52]\ttraining's auc: 0.903749\ttraining's binary_logloss: 0.116633\tvalid_1's auc: 0.834712\tvalid_1's binary_logloss: 0.131284\n",
            "[53]\ttraining's auc: 0.904449\ttraining's binary_logloss: 0.116388\tvalid_1's auc: 0.834638\tvalid_1's binary_logloss: 0.131274\n",
            "[54]\ttraining's auc: 0.90493\ttraining's binary_logloss: 0.11611\tvalid_1's auc: 0.834762\tvalid_1's binary_logloss: 0.131262\n",
            "[55]\ttraining's auc: 0.905534\ttraining's binary_logloss: 0.115818\tvalid_1's auc: 0.834931\tvalid_1's binary_logloss: 0.131257\n",
            "[56]\ttraining's auc: 0.906203\ttraining's binary_logloss: 0.115574\tvalid_1's auc: 0.834825\tvalid_1's binary_logloss: 0.13126\n",
            "[57]\ttraining's auc: 0.906777\ttraining's binary_logloss: 0.115309\tvalid_1's auc: 0.834869\tvalid_1's binary_logloss: 0.131267\n",
            "[58]\ttraining's auc: 0.907349\ttraining's binary_logloss: 0.115045\tvalid_1's auc: 0.8349\tvalid_1's binary_logloss: 0.131257\n",
            "[59]\ttraining's auc: 0.90777\ttraining's binary_logloss: 0.114872\tvalid_1's auc: 0.834941\tvalid_1's binary_logloss: 0.13125\n",
            "[60]\ttraining's auc: 0.908251\ttraining's binary_logloss: 0.11461\tvalid_1's auc: 0.835035\tvalid_1's binary_logloss: 0.13123\n",
            "[61]\ttraining's auc: 0.909009\ttraining's binary_logloss: 0.114344\tvalid_1's auc: 0.834907\tvalid_1's binary_logloss: 0.131237\n",
            "[62]\ttraining's auc: 0.909515\ttraining's binary_logloss: 0.11418\tvalid_1's auc: 0.834977\tvalid_1's binary_logloss: 0.131249\n",
            "[63]\ttraining's auc: 0.909806\ttraining's binary_logloss: 0.113981\tvalid_1's auc: 0.83494\tvalid_1's binary_logloss: 0.13127\n",
            "[64]\ttraining's auc: 0.91032\ttraining's binary_logloss: 0.113765\tvalid_1's auc: 0.834885\tvalid_1's binary_logloss: 0.131293\n",
            "[65]\ttraining's auc: 0.910908\ttraining's binary_logloss: 0.113506\tvalid_1's auc: 0.834679\tvalid_1's binary_logloss: 0.131314\n",
            "[66]\ttraining's auc: 0.911327\ttraining's binary_logloss: 0.113277\tvalid_1's auc: 0.834904\tvalid_1's binary_logloss: 0.131249\n",
            "[67]\ttraining's auc: 0.911918\ttraining's binary_logloss: 0.113022\tvalid_1's auc: 0.835002\tvalid_1's binary_logloss: 0.13124\n",
            "[68]\ttraining's auc: 0.912305\ttraining's binary_logloss: 0.112824\tvalid_1's auc: 0.835005\tvalid_1's binary_logloss: 0.131237\n",
            "[69]\ttraining's auc: 0.912723\ttraining's binary_logloss: 0.112633\tvalid_1's auc: 0.834898\tvalid_1's binary_logloss: 0.131245\n",
            "[70]\ttraining's auc: 0.91318\ttraining's binary_logloss: 0.112449\tvalid_1's auc: 0.834758\tvalid_1's binary_logloss: 0.131263\n",
            "[71]\ttraining's auc: 0.913536\ttraining's binary_logloss: 0.112252\tvalid_1's auc: 0.834749\tvalid_1's binary_logloss: 0.13125\n",
            "[72]\ttraining's auc: 0.913769\ttraining's binary_logloss: 0.112065\tvalid_1's auc: 0.83468\tvalid_1's binary_logloss: 0.131249\n",
            "[73]\ttraining's auc: 0.914213\ttraining's binary_logloss: 0.111853\tvalid_1's auc: 0.834587\tvalid_1's binary_logloss: 0.131268\n",
            "[74]\ttraining's auc: 0.914691\ttraining's binary_logloss: 0.111646\tvalid_1's auc: 0.834387\tvalid_1's binary_logloss: 0.131309\n",
            "[75]\ttraining's auc: 0.914953\ttraining's binary_logloss: 0.111515\tvalid_1's auc: 0.83422\tvalid_1's binary_logloss: 0.131338\n",
            "[76]\ttraining's auc: 0.915312\ttraining's binary_logloss: 0.111343\tvalid_1's auc: 0.834145\tvalid_1's binary_logloss: 0.131347\n",
            "[77]\ttraining's auc: 0.915698\ttraining's binary_logloss: 0.111138\tvalid_1's auc: 0.833973\tvalid_1's binary_logloss: 0.131357\n",
            "[78]\ttraining's auc: 0.916011\ttraining's binary_logloss: 0.110968\tvalid_1's auc: 0.834171\tvalid_1's binary_logloss: 0.131329\n",
            "[79]\ttraining's auc: 0.916533\ttraining's binary_logloss: 0.110736\tvalid_1's auc: 0.833811\tvalid_1's binary_logloss: 0.131395\n",
            "[80]\ttraining's auc: 0.917096\ttraining's binary_logloss: 0.110492\tvalid_1's auc: 0.833717\tvalid_1's binary_logloss: 0.131395\n",
            "[81]\ttraining's auc: 0.917395\ttraining's binary_logloss: 0.110296\tvalid_1's auc: 0.833716\tvalid_1's binary_logloss: 0.131409\n",
            "[82]\ttraining's auc: 0.917733\ttraining's binary_logloss: 0.110118\tvalid_1's auc: 0.833819\tvalid_1's binary_logloss: 0.131361\n",
            "[83]\ttraining's auc: 0.917902\ttraining's binary_logloss: 0.109975\tvalid_1's auc: 0.833698\tvalid_1's binary_logloss: 0.131372\n",
            "[84]\ttraining's auc: 0.918229\ttraining's binary_logloss: 0.109829\tvalid_1's auc: 0.833377\tvalid_1's binary_logloss: 0.131403\n",
            "[85]\ttraining's auc: 0.918805\ttraining's binary_logloss: 0.109603\tvalid_1's auc: 0.833468\tvalid_1's binary_logloss: 0.131374\n",
            "[86]\ttraining's auc: 0.919132\ttraining's binary_logloss: 0.109443\tvalid_1's auc: 0.83329\tvalid_1's binary_logloss: 0.131393\n",
            "[87]\ttraining's auc: 0.919267\ttraining's binary_logloss: 0.109326\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.131402\n",
            "[88]\ttraining's auc: 0.919818\ttraining's binary_logloss: 0.109085\tvalid_1's auc: 0.833137\tvalid_1's binary_logloss: 0.131416\n",
            "[89]\ttraining's auc: 0.920081\ttraining's binary_logloss: 0.108933\tvalid_1's auc: 0.833096\tvalid_1's binary_logloss: 0.131437\n",
            "[90]\ttraining's auc: 0.920368\ttraining's binary_logloss: 0.108758\tvalid_1's auc: 0.832957\tvalid_1's binary_logloss: 0.131469\n",
            " 18%|█▊        | 9/50 [05:32<20:40, 30.27s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.156968\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.162981\n",
            "[2]\ttraining's auc: 0.83279\ttraining's binary_logloss: 0.152448\tvalid_1's auc: 0.815362\tvalid_1's binary_logloss: 0.158898\n",
            "[3]\ttraining's auc: 0.83679\ttraining's binary_logloss: 0.148957\tvalid_1's auc: 0.817818\tvalid_1's binary_logloss: 0.15587\n",
            "[4]\ttraining's auc: 0.839656\ttraining's binary_logloss: 0.146118\tvalid_1's auc: 0.818636\tvalid_1's binary_logloss: 0.153485\n",
            "[5]\ttraining's auc: 0.845283\ttraining's binary_logloss: 0.143523\tvalid_1's auc: 0.823299\tvalid_1's binary_logloss: 0.151378\n",
            "[6]\ttraining's auc: 0.849535\ttraining's binary_logloss: 0.141356\tvalid_1's auc: 0.82608\tvalid_1's binary_logloss: 0.149646\n",
            "[7]\ttraining's auc: 0.850975\ttraining's binary_logloss: 0.139476\tvalid_1's auc: 0.826939\tvalid_1's binary_logloss: 0.148116\n",
            "[8]\ttraining's auc: 0.853346\ttraining's binary_logloss: 0.137807\tvalid_1's auc: 0.82796\tvalid_1's binary_logloss: 0.146855\n",
            "[9]\ttraining's auc: 0.855301\ttraining's binary_logloss: 0.136346\tvalid_1's auc: 0.828501\tvalid_1's binary_logloss: 0.145756\n",
            "[10]\ttraining's auc: 0.856746\ttraining's binary_logloss: 0.135002\tvalid_1's auc: 0.828869\tvalid_1's binary_logloss: 0.144775\n",
            "[11]\ttraining's auc: 0.857919\ttraining's binary_logloss: 0.133853\tvalid_1's auc: 0.829459\tvalid_1's binary_logloss: 0.143872\n",
            "[12]\ttraining's auc: 0.85955\ttraining's binary_logloss: 0.132775\tvalid_1's auc: 0.829727\tvalid_1's binary_logloss: 0.143039\n",
            "[13]\ttraining's auc: 0.861232\ttraining's binary_logloss: 0.131761\tvalid_1's auc: 0.829552\tvalid_1's binary_logloss: 0.142353\n",
            "[14]\ttraining's auc: 0.86251\ttraining's binary_logloss: 0.130842\tvalid_1's auc: 0.830411\tvalid_1's binary_logloss: 0.141698\n",
            "[15]\ttraining's auc: 0.864496\ttraining's binary_logloss: 0.129951\tvalid_1's auc: 0.830931\tvalid_1's binary_logloss: 0.141117\n",
            "[16]\ttraining's auc: 0.866963\ttraining's binary_logloss: 0.129103\tvalid_1's auc: 0.831305\tvalid_1's binary_logloss: 0.140631\n",
            "[17]\ttraining's auc: 0.868403\ttraining's binary_logloss: 0.128336\tvalid_1's auc: 0.831437\tvalid_1's binary_logloss: 0.14023\n",
            "[18]\ttraining's auc: 0.870144\ttraining's binary_logloss: 0.127626\tvalid_1's auc: 0.832922\tvalid_1's binary_logloss: 0.139895\n",
            "[19]\ttraining's auc: 0.871962\ttraining's binary_logloss: 0.126936\tvalid_1's auc: 0.833165\tvalid_1's binary_logloss: 0.139556\n",
            "[20]\ttraining's auc: 0.873428\ttraining's binary_logloss: 0.126315\tvalid_1's auc: 0.833511\tvalid_1's binary_logloss: 0.139277\n",
            "[21]\ttraining's auc: 0.875044\ttraining's binary_logloss: 0.125664\tvalid_1's auc: 0.833619\tvalid_1's binary_logloss: 0.139011\n",
            "[22]\ttraining's auc: 0.87702\ttraining's binary_logloss: 0.125063\tvalid_1's auc: 0.834374\tvalid_1's binary_logloss: 0.138718\n",
            "[23]\ttraining's auc: 0.878886\ttraining's binary_logloss: 0.124492\tvalid_1's auc: 0.834514\tvalid_1's binary_logloss: 0.138506\n",
            "[24]\ttraining's auc: 0.879815\ttraining's binary_logloss: 0.123996\tvalid_1's auc: 0.835033\tvalid_1's binary_logloss: 0.138288\n",
            "[25]\ttraining's auc: 0.880683\ttraining's binary_logloss: 0.123486\tvalid_1's auc: 0.835648\tvalid_1's binary_logloss: 0.138088\n",
            "[26]\ttraining's auc: 0.88181\ttraining's binary_logloss: 0.123017\tvalid_1's auc: 0.835296\tvalid_1's binary_logloss: 0.13791\n",
            "[27]\ttraining's auc: 0.882911\ttraining's binary_logloss: 0.122521\tvalid_1's auc: 0.835014\tvalid_1's binary_logloss: 0.137752\n",
            "[28]\ttraining's auc: 0.884176\ttraining's binary_logloss: 0.122003\tvalid_1's auc: 0.834786\tvalid_1's binary_logloss: 0.137701\n",
            "[29]\ttraining's auc: 0.885819\ttraining's binary_logloss: 0.121549\tvalid_1's auc: 0.834545\tvalid_1's binary_logloss: 0.137577\n",
            "[30]\ttraining's auc: 0.886957\ttraining's binary_logloss: 0.121103\tvalid_1's auc: 0.835275\tvalid_1's binary_logloss: 0.137438\n",
            "[31]\ttraining's auc: 0.88826\ttraining's binary_logloss: 0.120647\tvalid_1's auc: 0.835192\tvalid_1's binary_logloss: 0.137341\n",
            "[32]\ttraining's auc: 0.889136\ttraining's binary_logloss: 0.120269\tvalid_1's auc: 0.835166\tvalid_1's binary_logloss: 0.137212\n",
            "[33]\ttraining's auc: 0.890135\ttraining's binary_logloss: 0.119891\tvalid_1's auc: 0.835001\tvalid_1's binary_logloss: 0.137151\n",
            "[34]\ttraining's auc: 0.890907\ttraining's binary_logloss: 0.119528\tvalid_1's auc: 0.835404\tvalid_1's binary_logloss: 0.137012\n",
            "[35]\ttraining's auc: 0.891662\ttraining's binary_logloss: 0.119181\tvalid_1's auc: 0.835393\tvalid_1's binary_logloss: 0.136964\n",
            "[36]\ttraining's auc: 0.892271\ttraining's binary_logloss: 0.11885\tvalid_1's auc: 0.835486\tvalid_1's binary_logloss: 0.136896\n",
            "[37]\ttraining's auc: 0.892995\ttraining's binary_logloss: 0.118528\tvalid_1's auc: 0.835589\tvalid_1's binary_logloss: 0.136816\n",
            "[38]\ttraining's auc: 0.893992\ttraining's binary_logloss: 0.118175\tvalid_1's auc: 0.835439\tvalid_1's binary_logloss: 0.136805\n",
            "[39]\ttraining's auc: 0.895166\ttraining's binary_logloss: 0.117837\tvalid_1's auc: 0.835103\tvalid_1's binary_logloss: 0.136788\n",
            "[40]\ttraining's auc: 0.896124\ttraining's binary_logloss: 0.117499\tvalid_1's auc: 0.834962\tvalid_1's binary_logloss: 0.136756\n",
            "[41]\ttraining's auc: 0.896758\ttraining's binary_logloss: 0.117203\tvalid_1's auc: 0.834843\tvalid_1's binary_logloss: 0.136739\n",
            "[42]\ttraining's auc: 0.897241\ttraining's binary_logloss: 0.116956\tvalid_1's auc: 0.834492\tvalid_1's binary_logloss: 0.13672\n",
            "[43]\ttraining's auc: 0.898298\ttraining's binary_logloss: 0.116682\tvalid_1's auc: 0.834875\tvalid_1's binary_logloss: 0.136649\n",
            "[44]\ttraining's auc: 0.899193\ttraining's binary_logloss: 0.116366\tvalid_1's auc: 0.834814\tvalid_1's binary_logloss: 0.136621\n",
            "[45]\ttraining's auc: 0.900009\ttraining's binary_logloss: 0.116073\tvalid_1's auc: 0.834735\tvalid_1's binary_logloss: 0.136626\n",
            "[46]\ttraining's auc: 0.900624\ttraining's binary_logloss: 0.115806\tvalid_1's auc: 0.834652\tvalid_1's binary_logloss: 0.136603\n",
            "[47]\ttraining's auc: 0.90131\ttraining's binary_logloss: 0.115526\tvalid_1's auc: 0.834506\tvalid_1's binary_logloss: 0.136615\n",
            "[48]\ttraining's auc: 0.902127\ttraining's binary_logloss: 0.115252\tvalid_1's auc: 0.83473\tvalid_1's binary_logloss: 0.136578\n",
            "[49]\ttraining's auc: 0.902729\ttraining's binary_logloss: 0.114998\tvalid_1's auc: 0.834815\tvalid_1's binary_logloss: 0.136572\n",
            "[50]\ttraining's auc: 0.903255\ttraining's binary_logloss: 0.114755\tvalid_1's auc: 0.834734\tvalid_1's binary_logloss: 0.136572\n",
            "[51]\ttraining's auc: 0.9038\ttraining's binary_logloss: 0.114465\tvalid_1's auc: 0.834691\tvalid_1's binary_logloss: 0.136578\n",
            "[52]\ttraining's auc: 0.904603\ttraining's binary_logloss: 0.114184\tvalid_1's auc: 0.834664\tvalid_1's binary_logloss: 0.136618\n",
            "[53]\ttraining's auc: 0.905108\ttraining's binary_logloss: 0.113996\tvalid_1's auc: 0.834623\tvalid_1's binary_logloss: 0.136616\n",
            "[54]\ttraining's auc: 0.905829\ttraining's binary_logloss: 0.113676\tvalid_1's auc: 0.834753\tvalid_1's binary_logloss: 0.136634\n",
            "[55]\ttraining's auc: 0.906625\ttraining's binary_logloss: 0.113356\tvalid_1's auc: 0.83498\tvalid_1's binary_logloss: 0.136609\n",
            " 20%|██        | 10/50 [05:37<17:55, 26.88s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.147445\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.151655\n",
            "[2]\ttraining's auc: 0.840889\ttraining's binary_logloss: 0.140948\tvalid_1's auc: 0.809531\tvalid_1's binary_logloss: 0.146937\n",
            "[3]\ttraining's auc: 0.848092\ttraining's binary_logloss: 0.136507\tvalid_1's auc: 0.816919\tvalid_1's binary_logloss: 0.143871\n",
            "[4]\ttraining's auc: 0.852963\ttraining's binary_logloss: 0.133163\tvalid_1's auc: 0.818939\tvalid_1's binary_logloss: 0.141841\n",
            "[5]\ttraining's auc: 0.860016\ttraining's binary_logloss: 0.130475\tvalid_1's auc: 0.819239\tvalid_1's binary_logloss: 0.140743\n",
            "[6]\ttraining's auc: 0.86567\ttraining's binary_logloss: 0.128372\tvalid_1's auc: 0.820661\tvalid_1's binary_logloss: 0.139881\n",
            "[7]\ttraining's auc: 0.870112\ttraining's binary_logloss: 0.126441\tvalid_1's auc: 0.82063\tvalid_1's binary_logloss: 0.1394\n",
            "[8]\ttraining's auc: 0.872762\ttraining's binary_logloss: 0.124953\tvalid_1's auc: 0.821049\tvalid_1's binary_logloss: 0.138797\n",
            "[9]\ttraining's auc: 0.876329\ttraining's binary_logloss: 0.12354\tvalid_1's auc: 0.821907\tvalid_1's binary_logloss: 0.138416\n",
            "[10]\ttraining's auc: 0.879894\ttraining's binary_logloss: 0.122229\tvalid_1's auc: 0.82302\tvalid_1's binary_logloss: 0.138228\n",
            "[11]\ttraining's auc: 0.883705\ttraining's binary_logloss: 0.120967\tvalid_1's auc: 0.822144\tvalid_1's binary_logloss: 0.138304\n",
            "[12]\ttraining's auc: 0.885989\ttraining's binary_logloss: 0.119834\tvalid_1's auc: 0.821516\tvalid_1's binary_logloss: 0.138206\n",
            "[13]\ttraining's auc: 0.890715\ttraining's binary_logloss: 0.118698\tvalid_1's auc: 0.823307\tvalid_1's binary_logloss: 0.137835\n",
            "[14]\ttraining's auc: 0.893638\ttraining's binary_logloss: 0.117819\tvalid_1's auc: 0.821754\tvalid_1's binary_logloss: 0.138098\n",
            "[15]\ttraining's auc: 0.896372\ttraining's binary_logloss: 0.116908\tvalid_1's auc: 0.821464\tvalid_1's binary_logloss: 0.138104\n",
            "[16]\ttraining's auc: 0.899721\ttraining's binary_logloss: 0.115992\tvalid_1's auc: 0.822409\tvalid_1's binary_logloss: 0.137959\n",
            "[17]\ttraining's auc: 0.90197\ttraining's binary_logloss: 0.115213\tvalid_1's auc: 0.823158\tvalid_1's binary_logloss: 0.137796\n",
            "[18]\ttraining's auc: 0.903877\ttraining's binary_logloss: 0.114436\tvalid_1's auc: 0.823087\tvalid_1's binary_logloss: 0.137873\n",
            "[19]\ttraining's auc: 0.905476\ttraining's binary_logloss: 0.113723\tvalid_1's auc: 0.82308\tvalid_1's binary_logloss: 0.137865\n",
            "[20]\ttraining's auc: 0.907205\ttraining's binary_logloss: 0.113028\tvalid_1's auc: 0.823237\tvalid_1's binary_logloss: 0.137985\n",
            "[21]\ttraining's auc: 0.909523\ttraining's binary_logloss: 0.112238\tvalid_1's auc: 0.822902\tvalid_1's binary_logloss: 0.138084\n",
            "[22]\ttraining's auc: 0.912011\ttraining's binary_logloss: 0.111659\tvalid_1's auc: 0.822479\tvalid_1's binary_logloss: 0.138179\n",
            "[23]\ttraining's auc: 0.913907\ttraining's binary_logloss: 0.110952\tvalid_1's auc: 0.822052\tvalid_1's binary_logloss: 0.138302\n",
            "[24]\ttraining's auc: 0.915318\ttraining's binary_logloss: 0.110248\tvalid_1's auc: 0.821124\tvalid_1's binary_logloss: 0.138497\n",
            "[25]\ttraining's auc: 0.916308\ttraining's binary_logloss: 0.109769\tvalid_1's auc: 0.820937\tvalid_1's binary_logloss: 0.138562\n",
            "[26]\ttraining's auc: 0.917415\ttraining's binary_logloss: 0.109164\tvalid_1's auc: 0.820894\tvalid_1's binary_logloss: 0.138639\n",
            "[27]\ttraining's auc: 0.918387\ttraining's binary_logloss: 0.108703\tvalid_1's auc: 0.820965\tvalid_1's binary_logloss: 0.13872\n",
            "[28]\ttraining's auc: 0.919805\ttraining's binary_logloss: 0.108223\tvalid_1's auc: 0.820995\tvalid_1's binary_logloss: 0.138775\n",
            "[29]\ttraining's auc: 0.920375\ttraining's binary_logloss: 0.107854\tvalid_1's auc: 0.820166\tvalid_1's binary_logloss: 0.139027\n",
            "[30]\ttraining's auc: 0.921315\ttraining's binary_logloss: 0.107349\tvalid_1's auc: 0.819521\tvalid_1's binary_logloss: 0.139214\n",
            "[31]\ttraining's auc: 0.922156\ttraining's binary_logloss: 0.106864\tvalid_1's auc: 0.819416\tvalid_1's binary_logloss: 0.139325\n",
            "[32]\ttraining's auc: 0.922925\ttraining's binary_logloss: 0.106433\tvalid_1's auc: 0.819186\tvalid_1's binary_logloss: 0.139473\n",
            "[33]\ttraining's auc: 0.923809\ttraining's binary_logloss: 0.105985\tvalid_1's auc: 0.819162\tvalid_1's binary_logloss: 0.139522\n",
            "[34]\ttraining's auc: 0.92454\ttraining's binary_logloss: 0.105614\tvalid_1's auc: 0.818612\tvalid_1's binary_logloss: 0.139661\n",
            "[35]\ttraining's auc: 0.925103\ttraining's binary_logloss: 0.105179\tvalid_1's auc: 0.818209\tvalid_1's binary_logloss: 0.139786\n",
            "[36]\ttraining's auc: 0.926099\ttraining's binary_logloss: 0.104544\tvalid_1's auc: 0.818352\tvalid_1's binary_logloss: 0.139835\n",
            "[37]\ttraining's auc: 0.927409\ttraining's binary_logloss: 0.103947\tvalid_1's auc: 0.817818\tvalid_1's binary_logloss: 0.139985\n",
            "[38]\ttraining's auc: 0.928387\ttraining's binary_logloss: 0.103412\tvalid_1's auc: 0.817568\tvalid_1's binary_logloss: 0.140116\n",
            "[39]\ttraining's auc: 0.928694\ttraining's binary_logloss: 0.103126\tvalid_1's auc: 0.816903\tvalid_1's binary_logloss: 0.140296\n",
            "[40]\ttraining's auc: 0.929126\ttraining's binary_logloss: 0.102832\tvalid_1's auc: 0.815973\tvalid_1's binary_logloss: 0.140558\n",
            "[41]\ttraining's auc: 0.929437\ttraining's binary_logloss: 0.102568\tvalid_1's auc: 0.815792\tvalid_1's binary_logloss: 0.140676\n",
            "[42]\ttraining's auc: 0.930912\ttraining's binary_logloss: 0.101932\tvalid_1's auc: 0.815687\tvalid_1's binary_logloss: 0.140722\n",
            "[43]\ttraining's auc: 0.932743\ttraining's binary_logloss: 0.101309\tvalid_1's auc: 0.815004\tvalid_1's binary_logloss: 0.140905\n",
            " 20%|██        | 10/50 [05:43<17:55, 26.88s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.149946\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.148223\n",
            "[2]\ttraining's auc: 0.836841\ttraining's binary_logloss: 0.143089\tvalid_1's auc: 0.819484\tvalid_1's binary_logloss: 0.143478\n",
            "[3]\ttraining's auc: 0.847285\ttraining's binary_logloss: 0.138573\tvalid_1's auc: 0.824592\tvalid_1's binary_logloss: 0.140639\n",
            "[4]\ttraining's auc: 0.85312\ttraining's binary_logloss: 0.135169\tvalid_1's auc: 0.827469\tvalid_1's binary_logloss: 0.138625\n",
            "[5]\ttraining's auc: 0.85902\ttraining's binary_logloss: 0.132575\tvalid_1's auc: 0.827328\tvalid_1's binary_logloss: 0.137179\n",
            "[6]\ttraining's auc: 0.864138\ttraining's binary_logloss: 0.130371\tvalid_1's auc: 0.829092\tvalid_1's binary_logloss: 0.136076\n",
            "[7]\ttraining's auc: 0.868716\ttraining's binary_logloss: 0.128575\tvalid_1's auc: 0.83018\tvalid_1's binary_logloss: 0.135309\n",
            "[8]\ttraining's auc: 0.872701\ttraining's binary_logloss: 0.126899\tvalid_1's auc: 0.831293\tvalid_1's binary_logloss: 0.134664\n",
            "[9]\ttraining's auc: 0.876029\ttraining's binary_logloss: 0.125482\tvalid_1's auc: 0.831204\tvalid_1's binary_logloss: 0.134323\n",
            "[10]\ttraining's auc: 0.87818\ttraining's binary_logloss: 0.124199\tvalid_1's auc: 0.830832\tvalid_1's binary_logloss: 0.134166\n",
            "[11]\ttraining's auc: 0.880885\ttraining's binary_logloss: 0.12304\tvalid_1's auc: 0.830731\tvalid_1's binary_logloss: 0.13385\n",
            "[12]\ttraining's auc: 0.884066\ttraining's binary_logloss: 0.121952\tvalid_1's auc: 0.830331\tvalid_1's binary_logloss: 0.133801\n",
            "[13]\ttraining's auc: 0.886703\ttraining's binary_logloss: 0.120861\tvalid_1's auc: 0.831375\tvalid_1's binary_logloss: 0.133429\n",
            "[14]\ttraining's auc: 0.890487\ttraining's binary_logloss: 0.119848\tvalid_1's auc: 0.830421\tvalid_1's binary_logloss: 0.13342\n",
            "[15]\ttraining's auc: 0.893219\ttraining's binary_logloss: 0.119051\tvalid_1's auc: 0.831748\tvalid_1's binary_logloss: 0.133272\n",
            "[16]\ttraining's auc: 0.895358\ttraining's binary_logloss: 0.118301\tvalid_1's auc: 0.831428\tvalid_1's binary_logloss: 0.133223\n",
            "[17]\ttraining's auc: 0.897637\ttraining's binary_logloss: 0.117486\tvalid_1's auc: 0.830584\tvalid_1's binary_logloss: 0.13337\n",
            "[18]\ttraining's auc: 0.899783\ttraining's binary_logloss: 0.116665\tvalid_1's auc: 0.830125\tvalid_1's binary_logloss: 0.133502\n",
            "[19]\ttraining's auc: 0.902137\ttraining's binary_logloss: 0.115835\tvalid_1's auc: 0.829864\tvalid_1's binary_logloss: 0.133646\n",
            "[20]\ttraining's auc: 0.903342\ttraining's binary_logloss: 0.115192\tvalid_1's auc: 0.829601\tvalid_1's binary_logloss: 0.133771\n",
            "[21]\ttraining's auc: 0.905452\ttraining's binary_logloss: 0.114404\tvalid_1's auc: 0.829209\tvalid_1's binary_logloss: 0.133824\n",
            "[22]\ttraining's auc: 0.90739\ttraining's binary_logloss: 0.113737\tvalid_1's auc: 0.828902\tvalid_1's binary_logloss: 0.133897\n",
            "[23]\ttraining's auc: 0.908478\ttraining's binary_logloss: 0.113203\tvalid_1's auc: 0.828781\tvalid_1's binary_logloss: 0.133949\n",
            "[24]\ttraining's auc: 0.910033\ttraining's binary_logloss: 0.11251\tvalid_1's auc: 0.828704\tvalid_1's binary_logloss: 0.133945\n",
            "[25]\ttraining's auc: 0.911433\ttraining's binary_logloss: 0.111807\tvalid_1's auc: 0.828814\tvalid_1's binary_logloss: 0.133934\n",
            "[26]\ttraining's auc: 0.913771\ttraining's binary_logloss: 0.110998\tvalid_1's auc: 0.829374\tvalid_1's binary_logloss: 0.133846\n",
            "[27]\ttraining's auc: 0.915134\ttraining's binary_logloss: 0.110306\tvalid_1's auc: 0.829422\tvalid_1's binary_logloss: 0.133786\n",
            "[28]\ttraining's auc: 0.916157\ttraining's binary_logloss: 0.1098\tvalid_1's auc: 0.828919\tvalid_1's binary_logloss: 0.133902\n",
            "[29]\ttraining's auc: 0.916969\ttraining's binary_logloss: 0.109289\tvalid_1's auc: 0.828902\tvalid_1's binary_logloss: 0.133881\n",
            "[30]\ttraining's auc: 0.917974\ttraining's binary_logloss: 0.10881\tvalid_1's auc: 0.828219\tvalid_1's binary_logloss: 0.134007\n",
            "[31]\ttraining's auc: 0.919783\ttraining's binary_logloss: 0.108293\tvalid_1's auc: 0.828307\tvalid_1's binary_logloss: 0.134094\n",
            "[32]\ttraining's auc: 0.921219\ttraining's binary_logloss: 0.107707\tvalid_1's auc: 0.828587\tvalid_1's binary_logloss: 0.134085\n",
            "[33]\ttraining's auc: 0.922082\ttraining's binary_logloss: 0.107225\tvalid_1's auc: 0.82866\tvalid_1's binary_logloss: 0.134103\n",
            "[34]\ttraining's auc: 0.922738\ttraining's binary_logloss: 0.106811\tvalid_1's auc: 0.8284\tvalid_1's binary_logloss: 0.134192\n",
            "[35]\ttraining's auc: 0.923509\ttraining's binary_logloss: 0.106318\tvalid_1's auc: 0.828589\tvalid_1's binary_logloss: 0.134199\n",
            "[36]\ttraining's auc: 0.924262\ttraining's binary_logloss: 0.105856\tvalid_1's auc: 0.828754\tvalid_1's binary_logloss: 0.134225\n",
            "[37]\ttraining's auc: 0.925132\ttraining's binary_logloss: 0.105387\tvalid_1's auc: 0.828588\tvalid_1's binary_logloss: 0.134281\n",
            "[38]\ttraining's auc: 0.926001\ttraining's binary_logloss: 0.10491\tvalid_1's auc: 0.828156\tvalid_1's binary_logloss: 0.134406\n",
            "[39]\ttraining's auc: 0.927701\ttraining's binary_logloss: 0.104276\tvalid_1's auc: 0.827666\tvalid_1's binary_logloss: 0.134569\n",
            "[40]\ttraining's auc: 0.928768\ttraining's binary_logloss: 0.103762\tvalid_1's auc: 0.827548\tvalid_1's binary_logloss: 0.134601\n",
            "[41]\ttraining's auc: 0.929641\ttraining's binary_logloss: 0.103276\tvalid_1's auc: 0.827292\tvalid_1's binary_logloss: 0.13467\n",
            "[42]\ttraining's auc: 0.931621\ttraining's binary_logloss: 0.102679\tvalid_1's auc: 0.826607\tvalid_1's binary_logloss: 0.134813\n",
            "[43]\ttraining's auc: 0.931993\ttraining's binary_logloss: 0.102409\tvalid_1's auc: 0.826964\tvalid_1's binary_logloss: 0.134773\n",
            "[44]\ttraining's auc: 0.932539\ttraining's binary_logloss: 0.102009\tvalid_1's auc: 0.827111\tvalid_1's binary_logloss: 0.134777\n",
            "[45]\ttraining's auc: 0.933169\ttraining's binary_logloss: 0.101579\tvalid_1's auc: 0.826634\tvalid_1's binary_logloss: 0.134933\n",
            " 20%|██        | 10/50 [05:47<17:55, 26.88s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.146983\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.154248\n",
            "[2]\ttraining's auc: 0.839313\ttraining's binary_logloss: 0.14029\tvalid_1's auc: 0.820756\tvalid_1's binary_logloss: 0.149065\n",
            "[3]\ttraining's auc: 0.84739\ttraining's binary_logloss: 0.135657\tvalid_1's auc: 0.824382\tvalid_1's binary_logloss: 0.145875\n",
            "[4]\ttraining's auc: 0.852345\ttraining's binary_logloss: 0.132489\tvalid_1's auc: 0.827272\tvalid_1's binary_logloss: 0.143526\n",
            "[5]\ttraining's auc: 0.859781\ttraining's binary_logloss: 0.129867\tvalid_1's auc: 0.828145\tvalid_1's binary_logloss: 0.142075\n",
            "[6]\ttraining's auc: 0.866822\ttraining's binary_logloss: 0.12765\tvalid_1's auc: 0.830754\tvalid_1's binary_logloss: 0.140855\n",
            "[7]\ttraining's auc: 0.869934\ttraining's binary_logloss: 0.125894\tvalid_1's auc: 0.831479\tvalid_1's binary_logloss: 0.140118\n",
            "[8]\ttraining's auc: 0.873307\ttraining's binary_logloss: 0.124454\tvalid_1's auc: 0.831122\tvalid_1's binary_logloss: 0.139597\n",
            "[9]\ttraining's auc: 0.875647\ttraining's binary_logloss: 0.1232\tvalid_1's auc: 0.831486\tvalid_1's binary_logloss: 0.139171\n",
            "[10]\ttraining's auc: 0.879191\ttraining's binary_logloss: 0.121858\tvalid_1's auc: 0.832245\tvalid_1's binary_logloss: 0.138709\n",
            "[11]\ttraining's auc: 0.883293\ttraining's binary_logloss: 0.120648\tvalid_1's auc: 0.832454\tvalid_1's binary_logloss: 0.138493\n",
            "[12]\ttraining's auc: 0.886616\ttraining's binary_logloss: 0.119555\tvalid_1's auc: 0.832247\tvalid_1's binary_logloss: 0.13835\n",
            "[13]\ttraining's auc: 0.888326\ttraining's binary_logloss: 0.118596\tvalid_1's auc: 0.833103\tvalid_1's binary_logloss: 0.13803\n",
            "[14]\ttraining's auc: 0.890706\ttraining's binary_logloss: 0.117751\tvalid_1's auc: 0.833671\tvalid_1's binary_logloss: 0.137865\n",
            "[15]\ttraining's auc: 0.89424\ttraining's binary_logloss: 0.116798\tvalid_1's auc: 0.832907\tvalid_1's binary_logloss: 0.138027\n",
            "[16]\ttraining's auc: 0.897121\ttraining's binary_logloss: 0.115881\tvalid_1's auc: 0.832551\tvalid_1's binary_logloss: 0.138103\n",
            "[17]\ttraining's auc: 0.898736\ttraining's binary_logloss: 0.115138\tvalid_1's auc: 0.832108\tvalid_1's binary_logloss: 0.138189\n",
            "[18]\ttraining's auc: 0.900169\ttraining's binary_logloss: 0.114425\tvalid_1's auc: 0.831984\tvalid_1's binary_logloss: 0.138208\n",
            "[19]\ttraining's auc: 0.902073\ttraining's binary_logloss: 0.113862\tvalid_1's auc: 0.832035\tvalid_1's binary_logloss: 0.13814\n",
            "[20]\ttraining's auc: 0.904183\ttraining's binary_logloss: 0.113104\tvalid_1's auc: 0.831479\tvalid_1's binary_logloss: 0.138292\n",
            "[21]\ttraining's auc: 0.906926\ttraining's binary_logloss: 0.112161\tvalid_1's auc: 0.831035\tvalid_1's binary_logloss: 0.138392\n",
            "[22]\ttraining's auc: 0.908612\ttraining's binary_logloss: 0.111437\tvalid_1's auc: 0.831094\tvalid_1's binary_logloss: 0.138419\n",
            "[23]\ttraining's auc: 0.909652\ttraining's binary_logloss: 0.110888\tvalid_1's auc: 0.830883\tvalid_1's binary_logloss: 0.138552\n",
            "[24]\ttraining's auc: 0.911413\ttraining's binary_logloss: 0.110142\tvalid_1's auc: 0.830806\tvalid_1's binary_logloss: 0.138587\n",
            "[25]\ttraining's auc: 0.913112\ttraining's binary_logloss: 0.109412\tvalid_1's auc: 0.830225\tvalid_1's binary_logloss: 0.138775\n",
            "[26]\ttraining's auc: 0.913939\ttraining's binary_logloss: 0.108918\tvalid_1's auc: 0.830202\tvalid_1's binary_logloss: 0.138844\n",
            "[27]\ttraining's auc: 0.914712\ttraining's binary_logloss: 0.10843\tvalid_1's auc: 0.829635\tvalid_1's binary_logloss: 0.139019\n",
            "[28]\ttraining's auc: 0.916712\ttraining's binary_logloss: 0.107678\tvalid_1's auc: 0.829517\tvalid_1's binary_logloss: 0.139043\n",
            "[29]\ttraining's auc: 0.918471\ttraining's binary_logloss: 0.106986\tvalid_1's auc: 0.828828\tvalid_1's binary_logloss: 0.139116\n",
            "[30]\ttraining's auc: 0.919488\ttraining's binary_logloss: 0.106455\tvalid_1's auc: 0.828486\tvalid_1's binary_logloss: 0.13927\n",
            "[31]\ttraining's auc: 0.921624\ttraining's binary_logloss: 0.105864\tvalid_1's auc: 0.828758\tvalid_1's binary_logloss: 0.139338\n",
            "[32]\ttraining's auc: 0.922171\ttraining's binary_logloss: 0.105422\tvalid_1's auc: 0.82873\tvalid_1's binary_logloss: 0.139397\n",
            "[33]\ttraining's auc: 0.923495\ttraining's binary_logloss: 0.104892\tvalid_1's auc: 0.82865\tvalid_1's binary_logloss: 0.139387\n",
            "[34]\ttraining's auc: 0.925175\ttraining's binary_logloss: 0.104285\tvalid_1's auc: 0.828226\tvalid_1's binary_logloss: 0.139534\n",
            "[35]\ttraining's auc: 0.926077\ttraining's binary_logloss: 0.103815\tvalid_1's auc: 0.827913\tvalid_1's binary_logloss: 0.139656\n",
            "[36]\ttraining's auc: 0.926734\ttraining's binary_logloss: 0.10334\tvalid_1's auc: 0.827475\tvalid_1's binary_logloss: 0.139757\n",
            "[37]\ttraining's auc: 0.928095\ttraining's binary_logloss: 0.102783\tvalid_1's auc: 0.827336\tvalid_1's binary_logloss: 0.139844\n",
            "[38]\ttraining's auc: 0.928585\ttraining's binary_logloss: 0.102448\tvalid_1's auc: 0.827212\tvalid_1's binary_logloss: 0.139843\n",
            "[39]\ttraining's auc: 0.929438\ttraining's binary_logloss: 0.101841\tvalid_1's auc: 0.827461\tvalid_1's binary_logloss: 0.139889\n",
            "[40]\ttraining's auc: 0.931238\ttraining's binary_logloss: 0.101198\tvalid_1's auc: 0.82755\tvalid_1's binary_logloss: 0.139891\n",
            "[41]\ttraining's auc: 0.931619\ttraining's binary_logloss: 0.100901\tvalid_1's auc: 0.827052\tvalid_1's binary_logloss: 0.140013\n",
            "[42]\ttraining's auc: 0.931852\ttraining's binary_logloss: 0.100653\tvalid_1's auc: 0.826698\tvalid_1's binary_logloss: 0.140173\n",
            "[43]\ttraining's auc: 0.932603\ttraining's binary_logloss: 0.10025\tvalid_1's auc: 0.826718\tvalid_1's binary_logloss: 0.140249\n",
            "[44]\ttraining's auc: 0.933826\ttraining's binary_logloss: 0.0997553\tvalid_1's auc: 0.826006\tvalid_1's binary_logloss: 0.140418\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 22%|██▏       | 11/50 [05:51<14:57, 23.01s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.158843\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.160682\n",
            "[2]\ttraining's auc: 0.832666\ttraining's binary_logloss: 0.154641\tvalid_1's auc: 0.805913\tvalid_1's binary_logloss: 0.157429\n",
            "[3]\ttraining's auc: 0.833996\ttraining's binary_logloss: 0.151309\tvalid_1's auc: 0.806733\tvalid_1's binary_logloss: 0.154897\n",
            "[4]\ttraining's auc: 0.840847\ttraining's binary_logloss: 0.148487\tvalid_1's auc: 0.810833\tvalid_1's binary_logloss: 0.15268\n",
            "[5]\ttraining's auc: 0.845647\ttraining's binary_logloss: 0.146117\tvalid_1's auc: 0.814828\tvalid_1's binary_logloss: 0.150838\n",
            "[6]\ttraining's auc: 0.848086\ttraining's binary_logloss: 0.144079\tvalid_1's auc: 0.815921\tvalid_1's binary_logloss: 0.149343\n",
            "[7]\ttraining's auc: 0.849611\ttraining's binary_logloss: 0.142189\tvalid_1's auc: 0.817206\tvalid_1's binary_logloss: 0.14803\n",
            "[8]\ttraining's auc: 0.850885\ttraining's binary_logloss: 0.140571\tvalid_1's auc: 0.819131\tvalid_1's binary_logloss: 0.146775\n",
            "[9]\ttraining's auc: 0.851774\ttraining's binary_logloss: 0.139108\tvalid_1's auc: 0.818914\tvalid_1's binary_logloss: 0.145809\n",
            "[10]\ttraining's auc: 0.8555\ttraining's binary_logloss: 0.137724\tvalid_1's auc: 0.820837\tvalid_1's binary_logloss: 0.144875\n",
            "[11]\ttraining's auc: 0.856381\ttraining's binary_logloss: 0.136499\tvalid_1's auc: 0.821239\tvalid_1's binary_logloss: 0.144034\n",
            "[12]\ttraining's auc: 0.857282\ttraining's binary_logloss: 0.135405\tvalid_1's auc: 0.821034\tvalid_1's binary_logloss: 0.143273\n",
            "[13]\ttraining's auc: 0.859342\ttraining's binary_logloss: 0.134375\tvalid_1's auc: 0.821797\tvalid_1's binary_logloss: 0.142623\n",
            "[14]\ttraining's auc: 0.860136\ttraining's binary_logloss: 0.133443\tvalid_1's auc: 0.822277\tvalid_1's binary_logloss: 0.14205\n",
            "[15]\ttraining's auc: 0.862999\ttraining's binary_logloss: 0.132495\tvalid_1's auc: 0.82294\tvalid_1's binary_logloss: 0.141503\n",
            "[16]\ttraining's auc: 0.864875\ttraining's binary_logloss: 0.131665\tvalid_1's auc: 0.823645\tvalid_1's binary_logloss: 0.140985\n",
            "[17]\ttraining's auc: 0.866332\ttraining's binary_logloss: 0.130912\tvalid_1's auc: 0.824858\tvalid_1's binary_logloss: 0.14054\n",
            "[18]\ttraining's auc: 0.8676\ttraining's binary_logloss: 0.130173\tvalid_1's auc: 0.825477\tvalid_1's binary_logloss: 0.14012\n",
            "[19]\ttraining's auc: 0.869176\ttraining's binary_logloss: 0.129471\tvalid_1's auc: 0.826301\tvalid_1's binary_logloss: 0.139691\n",
            "[20]\ttraining's auc: 0.870015\ttraining's binary_logloss: 0.12887\tvalid_1's auc: 0.826368\tvalid_1's binary_logloss: 0.139375\n",
            "[21]\ttraining's auc: 0.870502\ttraining's binary_logloss: 0.12831\tvalid_1's auc: 0.826435\tvalid_1's binary_logloss: 0.139051\n",
            "[22]\ttraining's auc: 0.871733\ttraining's binary_logloss: 0.127699\tvalid_1's auc: 0.826594\tvalid_1's binary_logloss: 0.138779\n",
            "[23]\ttraining's auc: 0.872904\ttraining's binary_logloss: 0.127129\tvalid_1's auc: 0.827066\tvalid_1's binary_logloss: 0.138556\n",
            "[24]\ttraining's auc: 0.874501\ttraining's binary_logloss: 0.126567\tvalid_1's auc: 0.826848\tvalid_1's binary_logloss: 0.138317\n",
            "[25]\ttraining's auc: 0.875419\ttraining's binary_logloss: 0.126041\tvalid_1's auc: 0.826996\tvalid_1's binary_logloss: 0.138074\n",
            "[26]\ttraining's auc: 0.876623\ttraining's binary_logloss: 0.125553\tvalid_1's auc: 0.82689\tvalid_1's binary_logloss: 0.1379\n",
            "[27]\ttraining's auc: 0.87827\ttraining's binary_logloss: 0.125065\tvalid_1's auc: 0.826823\tvalid_1's binary_logloss: 0.137741\n",
            "[28]\ttraining's auc: 0.879284\ttraining's binary_logloss: 0.124582\tvalid_1's auc: 0.82682\tvalid_1's binary_logloss: 0.137617\n",
            "[29]\ttraining's auc: 0.880321\ttraining's binary_logloss: 0.124134\tvalid_1's auc: 0.827541\tvalid_1's binary_logloss: 0.137421\n",
            "[30]\ttraining's auc: 0.881253\ttraining's binary_logloss: 0.123729\tvalid_1's auc: 0.82794\tvalid_1's binary_logloss: 0.137216\n",
            "[31]\ttraining's auc: 0.882339\ttraining's binary_logloss: 0.123298\tvalid_1's auc: 0.827876\tvalid_1's binary_logloss: 0.137094\n",
            "[32]\ttraining's auc: 0.883516\ttraining's binary_logloss: 0.122902\tvalid_1's auc: 0.827785\tvalid_1's binary_logloss: 0.137037\n",
            "[33]\ttraining's auc: 0.883962\ttraining's binary_logloss: 0.122532\tvalid_1's auc: 0.827415\tvalid_1's binary_logloss: 0.136995\n",
            "[34]\ttraining's auc: 0.884985\ttraining's binary_logloss: 0.122134\tvalid_1's auc: 0.827311\tvalid_1's binary_logloss: 0.136928\n",
            "[35]\ttraining's auc: 0.886343\ttraining's binary_logloss: 0.121684\tvalid_1's auc: 0.82735\tvalid_1's binary_logloss: 0.136868\n",
            "[36]\ttraining's auc: 0.887345\ttraining's binary_logloss: 0.121294\tvalid_1's auc: 0.828117\tvalid_1's binary_logloss: 0.136743\n",
            "[37]\ttraining's auc: 0.887931\ttraining's binary_logloss: 0.12096\tvalid_1's auc: 0.828527\tvalid_1's binary_logloss: 0.136662\n",
            "[38]\ttraining's auc: 0.888648\ttraining's binary_logloss: 0.120627\tvalid_1's auc: 0.828802\tvalid_1's binary_logloss: 0.136586\n",
            "[39]\ttraining's auc: 0.88915\ttraining's binary_logloss: 0.120321\tvalid_1's auc: 0.829331\tvalid_1's binary_logloss: 0.136447\n",
            "[40]\ttraining's auc: 0.890542\ttraining's binary_logloss: 0.119942\tvalid_1's auc: 0.8292\tvalid_1's binary_logloss: 0.136387\n",
            "[41]\ttraining's auc: 0.89112\ttraining's binary_logloss: 0.119655\tvalid_1's auc: 0.829587\tvalid_1's binary_logloss: 0.136311\n",
            "[42]\ttraining's auc: 0.891845\ttraining's binary_logloss: 0.11935\tvalid_1's auc: 0.829455\tvalid_1's binary_logloss: 0.136279\n",
            "[43]\ttraining's auc: 0.892307\ttraining's binary_logloss: 0.119067\tvalid_1's auc: 0.829433\tvalid_1's binary_logloss: 0.136224\n",
            "[44]\ttraining's auc: 0.893326\ttraining's binary_logloss: 0.118741\tvalid_1's auc: 0.830167\tvalid_1's binary_logloss: 0.136083\n",
            "[45]\ttraining's auc: 0.893861\ttraining's binary_logloss: 0.118474\tvalid_1's auc: 0.830035\tvalid_1's binary_logloss: 0.136096\n",
            "[46]\ttraining's auc: 0.894885\ttraining's binary_logloss: 0.118208\tvalid_1's auc: 0.830262\tvalid_1's binary_logloss: 0.136025\n",
            "[47]\ttraining's auc: 0.89577\ttraining's binary_logloss: 0.117893\tvalid_1's auc: 0.830607\tvalid_1's binary_logloss: 0.135956\n",
            "[48]\ttraining's auc: 0.896433\ttraining's binary_logloss: 0.117621\tvalid_1's auc: 0.830265\tvalid_1's binary_logloss: 0.135992\n",
            "[49]\ttraining's auc: 0.89703\ttraining's binary_logloss: 0.117339\tvalid_1's auc: 0.830109\tvalid_1's binary_logloss: 0.135969\n",
            "[50]\ttraining's auc: 0.897519\ttraining's binary_logloss: 0.117083\tvalid_1's auc: 0.830008\tvalid_1's binary_logloss: 0.135981\n",
            "[51]\ttraining's auc: 0.899228\ttraining's binary_logloss: 0.116738\tvalid_1's auc: 0.830434\tvalid_1's binary_logloss: 0.135881\n",
            "[52]\ttraining's auc: 0.899856\ttraining's binary_logloss: 0.116483\tvalid_1's auc: 0.830513\tvalid_1's binary_logloss: 0.135871\n",
            "[53]\ttraining's auc: 0.900622\ttraining's binary_logloss: 0.116221\tvalid_1's auc: 0.83036\tvalid_1's binary_logloss: 0.135895\n",
            "[54]\ttraining's auc: 0.901221\ttraining's binary_logloss: 0.11601\tvalid_1's auc: 0.83036\tvalid_1's binary_logloss: 0.13587\n",
            "[55]\ttraining's auc: 0.902028\ttraining's binary_logloss: 0.115775\tvalid_1's auc: 0.830451\tvalid_1's binary_logloss: 0.135843\n",
            "[56]\ttraining's auc: 0.902603\ttraining's binary_logloss: 0.115523\tvalid_1's auc: 0.830719\tvalid_1's binary_logloss: 0.135819\n",
            "[57]\ttraining's auc: 0.90303\ttraining's binary_logloss: 0.115309\tvalid_1's auc: 0.830783\tvalid_1's binary_logloss: 0.135816\n",
            "[58]\ttraining's auc: 0.903442\ttraining's binary_logloss: 0.115075\tvalid_1's auc: 0.83073\tvalid_1's binary_logloss: 0.135847\n",
            "[59]\ttraining's auc: 0.904172\ttraining's binary_logloss: 0.114832\tvalid_1's auc: 0.83098\tvalid_1's binary_logloss: 0.135777\n",
            "[60]\ttraining's auc: 0.904948\ttraining's binary_logloss: 0.114639\tvalid_1's auc: 0.831076\tvalid_1's binary_logloss: 0.135756\n",
            "[61]\ttraining's auc: 0.905521\ttraining's binary_logloss: 0.114409\tvalid_1's auc: 0.831148\tvalid_1's binary_logloss: 0.135773\n",
            "[62]\ttraining's auc: 0.905801\ttraining's binary_logloss: 0.114223\tvalid_1's auc: 0.831064\tvalid_1's binary_logloss: 0.135792\n",
            "[63]\ttraining's auc: 0.906203\ttraining's binary_logloss: 0.114029\tvalid_1's auc: 0.831123\tvalid_1's binary_logloss: 0.135798\n",
            "[64]\ttraining's auc: 0.906773\ttraining's binary_logloss: 0.113829\tvalid_1's auc: 0.830997\tvalid_1's binary_logloss: 0.135828\n",
            "[65]\ttraining's auc: 0.907223\ttraining's binary_logloss: 0.113627\tvalid_1's auc: 0.83121\tvalid_1's binary_logloss: 0.135792\n",
            "[66]\ttraining's auc: 0.907929\ttraining's binary_logloss: 0.113408\tvalid_1's auc: 0.831153\tvalid_1's binary_logloss: 0.135792\n",
            "[67]\ttraining's auc: 0.908644\ttraining's binary_logloss: 0.113236\tvalid_1's auc: 0.830965\tvalid_1's binary_logloss: 0.135802\n",
            "[68]\ttraining's auc: 0.909199\ttraining's binary_logloss: 0.113005\tvalid_1's auc: 0.830745\tvalid_1's binary_logloss: 0.135855\n",
            "[69]\ttraining's auc: 0.909784\ttraining's binary_logloss: 0.112762\tvalid_1's auc: 0.830684\tvalid_1's binary_logloss: 0.135854\n",
            "[70]\ttraining's auc: 0.910437\ttraining's binary_logloss: 0.112539\tvalid_1's auc: 0.830515\tvalid_1's binary_logloss: 0.135905\n",
            "[71]\ttraining's auc: 0.910938\ttraining's binary_logloss: 0.112374\tvalid_1's auc: 0.830541\tvalid_1's binary_logloss: 0.135918\n",
            "[72]\ttraining's auc: 0.911181\ttraining's binary_logloss: 0.112234\tvalid_1's auc: 0.830227\tvalid_1's binary_logloss: 0.135969\n",
            "[73]\ttraining's auc: 0.911927\ttraining's binary_logloss: 0.112029\tvalid_1's auc: 0.830017\tvalid_1's binary_logloss: 0.13601\n",
            "[74]\ttraining's auc: 0.91233\ttraining's binary_logloss: 0.11187\tvalid_1's auc: 0.830068\tvalid_1's binary_logloss: 0.136008\n",
            "[75]\ttraining's auc: 0.912775\ttraining's binary_logloss: 0.111673\tvalid_1's auc: 0.830085\tvalid_1's binary_logloss: 0.136005\n",
            "[76]\ttraining's auc: 0.91316\ttraining's binary_logloss: 0.111506\tvalid_1's auc: 0.830119\tvalid_1's binary_logloss: 0.135997\n",
            "[77]\ttraining's auc: 0.913863\ttraining's binary_logloss: 0.111226\tvalid_1's auc: 0.829947\tvalid_1's binary_logloss: 0.136046\n",
            "[78]\ttraining's auc: 0.91424\ttraining's binary_logloss: 0.111042\tvalid_1's auc: 0.829754\tvalid_1's binary_logloss: 0.136078\n",
            "[79]\ttraining's auc: 0.9146\ttraining's binary_logloss: 0.110866\tvalid_1's auc: 0.829556\tvalid_1's binary_logloss: 0.136116\n",
            "[80]\ttraining's auc: 0.914754\ttraining's binary_logloss: 0.110753\tvalid_1's auc: 0.829437\tvalid_1's binary_logloss: 0.136145\n",
            "[81]\ttraining's auc: 0.91535\ttraining's binary_logloss: 0.110519\tvalid_1's auc: 0.82937\tvalid_1's binary_logloss: 0.13616\n",
            "[82]\ttraining's auc: 0.916109\ttraining's binary_logloss: 0.110347\tvalid_1's auc: 0.829184\tvalid_1's binary_logloss: 0.136189\n",
            "[83]\ttraining's auc: 0.916813\ttraining's binary_logloss: 0.110112\tvalid_1's auc: 0.828924\tvalid_1's binary_logloss: 0.136256\n",
            "[84]\ttraining's auc: 0.917039\ttraining's binary_logloss: 0.109995\tvalid_1's auc: 0.82884\tvalid_1's binary_logloss: 0.136274\n",
            "[85]\ttraining's auc: 0.91756\ttraining's binary_logloss: 0.109847\tvalid_1's auc: 0.828778\tvalid_1's binary_logloss: 0.136296\n",
            "[86]\ttraining's auc: 0.918035\ttraining's binary_logloss: 0.109652\tvalid_1's auc: 0.828843\tvalid_1's binary_logloss: 0.136287\n",
            "[87]\ttraining's auc: 0.918395\ttraining's binary_logloss: 0.109502\tvalid_1's auc: 0.828963\tvalid_1's binary_logloss: 0.136287\n",
            "[88]\ttraining's auc: 0.918516\ttraining's binary_logloss: 0.109385\tvalid_1's auc: 0.82901\tvalid_1's binary_logloss: 0.136297\n",
            "[89]\ttraining's auc: 0.918766\ttraining's binary_logloss: 0.109241\tvalid_1's auc: 0.828731\tvalid_1's binary_logloss: 0.136347\n",
            "[90]\ttraining's auc: 0.919063\ttraining's binary_logloss: 0.109067\tvalid_1's auc: 0.828713\tvalid_1's binary_logloss: 0.136369\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 22%|██▏       | 11/50 [06:00<14:57, 23.01s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.161242\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156356\n",
            "[2]\ttraining's auc: 0.826913\ttraining's binary_logloss: 0.157044\tvalid_1's auc: 0.817441\tvalid_1's binary_logloss: 0.152899\n",
            "[3]\ttraining's auc: 0.833077\ttraining's binary_logloss: 0.153624\tvalid_1's auc: 0.819082\tvalid_1's binary_logloss: 0.15027\n",
            "[4]\ttraining's auc: 0.834522\ttraining's binary_logloss: 0.150878\tvalid_1's auc: 0.819605\tvalid_1's binary_logloss: 0.148041\n",
            "[5]\ttraining's auc: 0.839248\ttraining's binary_logloss: 0.148503\tvalid_1's auc: 0.82292\tvalid_1's binary_logloss: 0.146281\n",
            "[6]\ttraining's auc: 0.844484\ttraining's binary_logloss: 0.1464\tvalid_1's auc: 0.825099\tvalid_1's binary_logloss: 0.144702\n",
            "[7]\ttraining's auc: 0.848575\ttraining's binary_logloss: 0.144474\tvalid_1's auc: 0.827653\tvalid_1's binary_logloss: 0.143319\n",
            "[8]\ttraining's auc: 0.84999\ttraining's binary_logloss: 0.142799\tvalid_1's auc: 0.828202\tvalid_1's binary_logloss: 0.142061\n",
            "[9]\ttraining's auc: 0.852467\ttraining's binary_logloss: 0.141319\tvalid_1's auc: 0.828887\tvalid_1's binary_logloss: 0.141024\n",
            "[10]\ttraining's auc: 0.854395\ttraining's binary_logloss: 0.139967\tvalid_1's auc: 0.830315\tvalid_1's binary_logloss: 0.140023\n",
            "[11]\ttraining's auc: 0.856234\ttraining's binary_logloss: 0.138748\tvalid_1's auc: 0.832643\tvalid_1's binary_logloss: 0.139088\n",
            "[12]\ttraining's auc: 0.857557\ttraining's binary_logloss: 0.137608\tvalid_1's auc: 0.832779\tvalid_1's binary_logloss: 0.138294\n",
            "[13]\ttraining's auc: 0.858588\ttraining's binary_logloss: 0.136524\tvalid_1's auc: 0.831924\tvalid_1's binary_logloss: 0.137648\n",
            "[14]\ttraining's auc: 0.859694\ttraining's binary_logloss: 0.135541\tvalid_1's auc: 0.831788\tvalid_1's binary_logloss: 0.137062\n",
            "[15]\ttraining's auc: 0.861927\ttraining's binary_logloss: 0.134656\tvalid_1's auc: 0.832962\tvalid_1's binary_logloss: 0.136479\n",
            "[16]\ttraining's auc: 0.864959\ttraining's binary_logloss: 0.13378\tvalid_1's auc: 0.833564\tvalid_1's binary_logloss: 0.135967\n",
            "[17]\ttraining's auc: 0.866996\ttraining's binary_logloss: 0.132961\tvalid_1's auc: 0.833738\tvalid_1's binary_logloss: 0.135523\n",
            "[18]\ttraining's auc: 0.868572\ttraining's binary_logloss: 0.132194\tvalid_1's auc: 0.833957\tvalid_1's binary_logloss: 0.135119\n",
            "[19]\ttraining's auc: 0.870278\ttraining's binary_logloss: 0.13148\tvalid_1's auc: 0.833568\tvalid_1's binary_logloss: 0.134784\n",
            "[20]\ttraining's auc: 0.871275\ttraining's binary_logloss: 0.13083\tvalid_1's auc: 0.833856\tvalid_1's binary_logloss: 0.13445\n",
            "[21]\ttraining's auc: 0.872088\ttraining's binary_logloss: 0.130192\tvalid_1's auc: 0.833584\tvalid_1's binary_logloss: 0.134184\n",
            "[22]\ttraining's auc: 0.872929\ttraining's binary_logloss: 0.129617\tvalid_1's auc: 0.833974\tvalid_1's binary_logloss: 0.133876\n",
            "[23]\ttraining's auc: 0.873731\ttraining's binary_logloss: 0.12905\tvalid_1's auc: 0.834065\tvalid_1's binary_logloss: 0.133608\n",
            "[24]\ttraining's auc: 0.874277\ttraining's binary_logloss: 0.128504\tvalid_1's auc: 0.83361\tvalid_1's binary_logloss: 0.133411\n",
            "[25]\ttraining's auc: 0.875095\ttraining's binary_logloss: 0.12799\tvalid_1's auc: 0.833643\tvalid_1's binary_logloss: 0.133227\n",
            "[26]\ttraining's auc: 0.875683\ttraining's binary_logloss: 0.12751\tvalid_1's auc: 0.833622\tvalid_1's binary_logloss: 0.133011\n",
            "[27]\ttraining's auc: 0.876655\ttraining's binary_logloss: 0.12699\tvalid_1's auc: 0.833918\tvalid_1's binary_logloss: 0.132831\n",
            "[28]\ttraining's auc: 0.877502\ttraining's binary_logloss: 0.126518\tvalid_1's auc: 0.834377\tvalid_1's binary_logloss: 0.132644\n",
            "[29]\ttraining's auc: 0.878471\ttraining's binary_logloss: 0.12607\tvalid_1's auc: 0.834172\tvalid_1's binary_logloss: 0.132507\n",
            "[30]\ttraining's auc: 0.879016\ttraining's binary_logloss: 0.125645\tvalid_1's auc: 0.834099\tvalid_1's binary_logloss: 0.132355\n",
            "[31]\ttraining's auc: 0.880152\ttraining's binary_logloss: 0.1252\tvalid_1's auc: 0.834137\tvalid_1's binary_logloss: 0.132206\n",
            "[32]\ttraining's auc: 0.880909\ttraining's binary_logloss: 0.124815\tvalid_1's auc: 0.834445\tvalid_1's binary_logloss: 0.13207\n",
            "[33]\ttraining's auc: 0.882166\ttraining's binary_logloss: 0.124391\tvalid_1's auc: 0.83482\tvalid_1's binary_logloss: 0.131935\n",
            "[34]\ttraining's auc: 0.883071\ttraining's binary_logloss: 0.124004\tvalid_1's auc: 0.834804\tvalid_1's binary_logloss: 0.131824\n",
            "[35]\ttraining's auc: 0.883835\ttraining's binary_logloss: 0.123619\tvalid_1's auc: 0.83523\tvalid_1's binary_logloss: 0.131706\n",
            "[36]\ttraining's auc: 0.884866\ttraining's binary_logloss: 0.12326\tvalid_1's auc: 0.835291\tvalid_1's binary_logloss: 0.131604\n",
            "[37]\ttraining's auc: 0.885752\ttraining's binary_logloss: 0.122883\tvalid_1's auc: 0.835432\tvalid_1's binary_logloss: 0.131555\n",
            "[38]\ttraining's auc: 0.886164\ttraining's binary_logloss: 0.122563\tvalid_1's auc: 0.83514\tvalid_1's binary_logloss: 0.131518\n",
            "[39]\ttraining's auc: 0.887481\ttraining's binary_logloss: 0.122207\tvalid_1's auc: 0.835907\tvalid_1's binary_logloss: 0.131444\n",
            "[40]\ttraining's auc: 0.888505\ttraining's binary_logloss: 0.121844\tvalid_1's auc: 0.835845\tvalid_1's binary_logloss: 0.131388\n",
            "[41]\ttraining's auc: 0.889741\ttraining's binary_logloss: 0.121492\tvalid_1's auc: 0.835689\tvalid_1's binary_logloss: 0.131342\n",
            "[42]\ttraining's auc: 0.890631\ttraining's binary_logloss: 0.121177\tvalid_1's auc: 0.835518\tvalid_1's binary_logloss: 0.131288\n",
            "[43]\ttraining's auc: 0.891165\ttraining's binary_logloss: 0.120879\tvalid_1's auc: 0.835493\tvalid_1's binary_logloss: 0.131256\n",
            "[44]\ttraining's auc: 0.891558\ttraining's binary_logloss: 0.120622\tvalid_1's auc: 0.835321\tvalid_1's binary_logloss: 0.13123\n",
            "[45]\ttraining's auc: 0.892779\ttraining's binary_logloss: 0.120309\tvalid_1's auc: 0.835064\tvalid_1's binary_logloss: 0.131202\n",
            "[46]\ttraining's auc: 0.893246\ttraining's binary_logloss: 0.120042\tvalid_1's auc: 0.835145\tvalid_1's binary_logloss: 0.131137\n",
            "[47]\ttraining's auc: 0.89366\ttraining's binary_logloss: 0.11979\tvalid_1's auc: 0.835178\tvalid_1's binary_logloss: 0.131116\n",
            "[48]\ttraining's auc: 0.894648\ttraining's binary_logloss: 0.11952\tvalid_1's auc: 0.835075\tvalid_1's binary_logloss: 0.131083\n",
            "[49]\ttraining's auc: 0.895534\ttraining's binary_logloss: 0.119268\tvalid_1's auc: 0.834951\tvalid_1's binary_logloss: 0.131069\n",
            "[50]\ttraining's auc: 0.896253\ttraining's binary_logloss: 0.119017\tvalid_1's auc: 0.835046\tvalid_1's binary_logloss: 0.131035\n",
            "[51]\ttraining's auc: 0.896983\ttraining's binary_logloss: 0.118782\tvalid_1's auc: 0.8351\tvalid_1's binary_logloss: 0.130992\n",
            "[52]\ttraining's auc: 0.897686\ttraining's binary_logloss: 0.118549\tvalid_1's auc: 0.83506\tvalid_1's binary_logloss: 0.130974\n",
            "[53]\ttraining's auc: 0.898367\ttraining's binary_logloss: 0.118297\tvalid_1's auc: 0.834962\tvalid_1's binary_logloss: 0.130983\n",
            "[54]\ttraining's auc: 0.899417\ttraining's binary_logloss: 0.118037\tvalid_1's auc: 0.834978\tvalid_1's binary_logloss: 0.130969\n",
            "[55]\ttraining's auc: 0.899899\ttraining's binary_logloss: 0.117802\tvalid_1's auc: 0.835038\tvalid_1's binary_logloss: 0.130947\n",
            "[56]\ttraining's auc: 0.901015\ttraining's binary_logloss: 0.11754\tvalid_1's auc: 0.835015\tvalid_1's binary_logloss: 0.130939\n",
            "[57]\ttraining's auc: 0.901494\ttraining's binary_logloss: 0.11732\tvalid_1's auc: 0.835094\tvalid_1's binary_logloss: 0.130919\n",
            "[58]\ttraining's auc: 0.902526\ttraining's binary_logloss: 0.117044\tvalid_1's auc: 0.835118\tvalid_1's binary_logloss: 0.130903\n",
            "[59]\ttraining's auc: 0.903533\ttraining's binary_logloss: 0.116802\tvalid_1's auc: 0.835486\tvalid_1's binary_logloss: 0.130857\n",
            "[60]\ttraining's auc: 0.904405\ttraining's binary_logloss: 0.116577\tvalid_1's auc: 0.835572\tvalid_1's binary_logloss: 0.130841\n",
            "[61]\ttraining's auc: 0.904782\ttraining's binary_logloss: 0.11636\tvalid_1's auc: 0.835505\tvalid_1's binary_logloss: 0.130857\n",
            "[62]\ttraining's auc: 0.905281\ttraining's binary_logloss: 0.116142\tvalid_1's auc: 0.835544\tvalid_1's binary_logloss: 0.130867\n",
            "[63]\ttraining's auc: 0.90594\ttraining's binary_logloss: 0.115928\tvalid_1's auc: 0.83555\tvalid_1's binary_logloss: 0.130854\n",
            "[64]\ttraining's auc: 0.906297\ttraining's binary_logloss: 0.115781\tvalid_1's auc: 0.835716\tvalid_1's binary_logloss: 0.130827\n",
            "[65]\ttraining's auc: 0.906707\ttraining's binary_logloss: 0.115553\tvalid_1's auc: 0.835572\tvalid_1's binary_logloss: 0.130866\n",
            "[66]\ttraining's auc: 0.907273\ttraining's binary_logloss: 0.115308\tvalid_1's auc: 0.835608\tvalid_1's binary_logloss: 0.130869\n",
            "[67]\ttraining's auc: 0.907703\ttraining's binary_logloss: 0.115112\tvalid_1's auc: 0.835513\tvalid_1's binary_logloss: 0.13088\n",
            "[68]\ttraining's auc: 0.908041\ttraining's binary_logloss: 0.114952\tvalid_1's auc: 0.835579\tvalid_1's binary_logloss: 0.130875\n",
            "[69]\ttraining's auc: 0.90856\ttraining's binary_logloss: 0.114745\tvalid_1's auc: 0.835364\tvalid_1's binary_logloss: 0.130911\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 22%|██▏       | 11/50 [06:06<14:57, 23.01s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.157732\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.163664\n",
            "[2]\ttraining's auc: 0.831442\ttraining's binary_logloss: 0.153674\tvalid_1's auc: 0.814431\tvalid_1's binary_logloss: 0.160021\n",
            "[3]\ttraining's auc: 0.834634\ttraining's binary_logloss: 0.150479\tvalid_1's auc: 0.815976\tvalid_1's binary_logloss: 0.157148\n",
            "[4]\ttraining's auc: 0.838744\ttraining's binary_logloss: 0.147801\tvalid_1's auc: 0.819113\tvalid_1's binary_logloss: 0.154791\n",
            "[5]\ttraining's auc: 0.84255\ttraining's binary_logloss: 0.145473\tvalid_1's auc: 0.820854\tvalid_1's binary_logloss: 0.152715\n",
            "[6]\ttraining's auc: 0.84856\ttraining's binary_logloss: 0.143334\tvalid_1's auc: 0.825569\tvalid_1's binary_logloss: 0.15102\n",
            "[7]\ttraining's auc: 0.851065\ttraining's binary_logloss: 0.141534\tvalid_1's auc: 0.826483\tvalid_1's binary_logloss: 0.149537\n",
            "[8]\ttraining's auc: 0.852955\ttraining's binary_logloss: 0.139809\tvalid_1's auc: 0.827721\tvalid_1's binary_logloss: 0.148223\n",
            "[9]\ttraining's auc: 0.853551\ttraining's binary_logloss: 0.13833\tvalid_1's auc: 0.827687\tvalid_1's binary_logloss: 0.147079\n",
            "[10]\ttraining's auc: 0.854118\ttraining's binary_logloss: 0.137012\tvalid_1's auc: 0.82917\tvalid_1's binary_logloss: 0.146038\n",
            "[11]\ttraining's auc: 0.856266\ttraining's binary_logloss: 0.135789\tvalid_1's auc: 0.829811\tvalid_1's binary_logloss: 0.145128\n",
            "[12]\ttraining's auc: 0.856858\ttraining's binary_logloss: 0.134684\tvalid_1's auc: 0.829955\tvalid_1's binary_logloss: 0.144323\n",
            "[13]\ttraining's auc: 0.858309\ttraining's binary_logloss: 0.133658\tvalid_1's auc: 0.830129\tvalid_1's binary_logloss: 0.143616\n",
            "[14]\ttraining's auc: 0.860782\ttraining's binary_logloss: 0.132687\tvalid_1's auc: 0.830873\tvalid_1's binary_logloss: 0.142946\n",
            "[15]\ttraining's auc: 0.862322\ttraining's binary_logloss: 0.131833\tvalid_1's auc: 0.831299\tvalid_1's binary_logloss: 0.142272\n",
            "[16]\ttraining's auc: 0.863708\ttraining's binary_logloss: 0.131031\tvalid_1's auc: 0.831041\tvalid_1's binary_logloss: 0.141785\n",
            "[17]\ttraining's auc: 0.865741\ttraining's binary_logloss: 0.130252\tvalid_1's auc: 0.831665\tvalid_1's binary_logloss: 0.14128\n",
            "[18]\ttraining's auc: 0.86741\ttraining's binary_logloss: 0.129531\tvalid_1's auc: 0.831896\tvalid_1's binary_logloss: 0.140838\n",
            "[19]\ttraining's auc: 0.868412\ttraining's binary_logloss: 0.128845\tvalid_1's auc: 0.831853\tvalid_1's binary_logloss: 0.140493\n",
            "[20]\ttraining's auc: 0.87019\ttraining's binary_logloss: 0.128192\tvalid_1's auc: 0.834132\tvalid_1's binary_logloss: 0.140086\n",
            "[21]\ttraining's auc: 0.871939\ttraining's binary_logloss: 0.127545\tvalid_1's auc: 0.834214\tvalid_1's binary_logloss: 0.139773\n",
            "[22]\ttraining's auc: 0.872817\ttraining's binary_logloss: 0.126952\tvalid_1's auc: 0.834241\tvalid_1's binary_logloss: 0.139495\n",
            "[23]\ttraining's auc: 0.874601\ttraining's binary_logloss: 0.126384\tvalid_1's auc: 0.834863\tvalid_1's binary_logloss: 0.139191\n",
            "[24]\ttraining's auc: 0.875769\ttraining's binary_logloss: 0.12586\tvalid_1's auc: 0.835164\tvalid_1's binary_logloss: 0.138931\n",
            "[25]\ttraining's auc: 0.876349\ttraining's binary_logloss: 0.125381\tvalid_1's auc: 0.835217\tvalid_1's binary_logloss: 0.138721\n",
            "[26]\ttraining's auc: 0.877574\ttraining's binary_logloss: 0.124861\tvalid_1's auc: 0.835182\tvalid_1's binary_logloss: 0.138482\n",
            "[27]\ttraining's auc: 0.878541\ttraining's binary_logloss: 0.124388\tvalid_1's auc: 0.835589\tvalid_1's binary_logloss: 0.138265\n",
            "[28]\ttraining's auc: 0.879774\ttraining's binary_logloss: 0.123918\tvalid_1's auc: 0.836032\tvalid_1's binary_logloss: 0.138077\n",
            "[29]\ttraining's auc: 0.881158\ttraining's binary_logloss: 0.12344\tvalid_1's auc: 0.836391\tvalid_1's binary_logloss: 0.137883\n",
            "[30]\ttraining's auc: 0.882372\ttraining's binary_logloss: 0.123017\tvalid_1's auc: 0.836157\tvalid_1's binary_logloss: 0.137769\n",
            "[31]\ttraining's auc: 0.883927\ttraining's binary_logloss: 0.122577\tvalid_1's auc: 0.835834\tvalid_1's binary_logloss: 0.137648\n",
            "[32]\ttraining's auc: 0.885023\ttraining's binary_logloss: 0.122164\tvalid_1's auc: 0.836374\tvalid_1's binary_logloss: 0.137456\n",
            "[33]\ttraining's auc: 0.886\ttraining's binary_logloss: 0.12177\tvalid_1's auc: 0.836608\tvalid_1's binary_logloss: 0.13728\n",
            "[34]\ttraining's auc: 0.886798\ttraining's binary_logloss: 0.121392\tvalid_1's auc: 0.836785\tvalid_1's binary_logloss: 0.137195\n",
            "[35]\ttraining's auc: 0.887421\ttraining's binary_logloss: 0.121047\tvalid_1's auc: 0.836898\tvalid_1's binary_logloss: 0.137062\n",
            "[36]\ttraining's auc: 0.888165\ttraining's binary_logloss: 0.120741\tvalid_1's auc: 0.83667\tvalid_1's binary_logloss: 0.136993\n",
            "[37]\ttraining's auc: 0.889279\ttraining's binary_logloss: 0.120353\tvalid_1's auc: 0.836439\tvalid_1's binary_logloss: 0.136952\n",
            "[38]\ttraining's auc: 0.890175\ttraining's binary_logloss: 0.119998\tvalid_1's auc: 0.836028\tvalid_1's binary_logloss: 0.136918\n",
            "[39]\ttraining's auc: 0.890876\ttraining's binary_logloss: 0.119688\tvalid_1's auc: 0.836087\tvalid_1's binary_logloss: 0.136877\n",
            "[40]\ttraining's auc: 0.891657\ttraining's binary_logloss: 0.119331\tvalid_1's auc: 0.836265\tvalid_1's binary_logloss: 0.136801\n",
            "[41]\ttraining's auc: 0.89223\ttraining's binary_logloss: 0.119037\tvalid_1's auc: 0.836292\tvalid_1's binary_logloss: 0.136752\n",
            "[42]\ttraining's auc: 0.892889\ttraining's binary_logloss: 0.118737\tvalid_1's auc: 0.836445\tvalid_1's binary_logloss: 0.136697\n",
            "[43]\ttraining's auc: 0.894007\ttraining's binary_logloss: 0.118384\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.136662\n",
            "[44]\ttraining's auc: 0.894407\ttraining's binary_logloss: 0.118139\tvalid_1's auc: 0.836388\tvalid_1's binary_logloss: 0.136657\n",
            "[45]\ttraining's auc: 0.89484\ttraining's binary_logloss: 0.11789\tvalid_1's auc: 0.836354\tvalid_1's binary_logloss: 0.136607\n",
            "[46]\ttraining's auc: 0.895544\ttraining's binary_logloss: 0.117627\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.136562\n",
            "[47]\ttraining's auc: 0.896398\ttraining's binary_logloss: 0.117331\tvalid_1's auc: 0.83628\tvalid_1's binary_logloss: 0.136559\n",
            "[48]\ttraining's auc: 0.897339\ttraining's binary_logloss: 0.117037\tvalid_1's auc: 0.836072\tvalid_1's binary_logloss: 0.13656\n",
            "[49]\ttraining's auc: 0.898257\ttraining's binary_logloss: 0.116768\tvalid_1's auc: 0.83589\tvalid_1's binary_logloss: 0.136563\n",
            "[50]\ttraining's auc: 0.898947\ttraining's binary_logloss: 0.116533\tvalid_1's auc: 0.835934\tvalid_1's binary_logloss: 0.136528\n",
            "[51]\ttraining's auc: 0.899638\ttraining's binary_logloss: 0.11627\tvalid_1's auc: 0.835854\tvalid_1's binary_logloss: 0.136511\n",
            "[52]\ttraining's auc: 0.90019\ttraining's binary_logloss: 0.116\tvalid_1's auc: 0.835838\tvalid_1's binary_logloss: 0.136483\n",
            "[53]\ttraining's auc: 0.900625\ttraining's binary_logloss: 0.115759\tvalid_1's auc: 0.835433\tvalid_1's binary_logloss: 0.136499\n",
            "[54]\ttraining's auc: 0.900924\ttraining's binary_logloss: 0.115559\tvalid_1's auc: 0.835535\tvalid_1's binary_logloss: 0.136486\n",
            "[55]\ttraining's auc: 0.901539\ttraining's binary_logloss: 0.115295\tvalid_1's auc: 0.835602\tvalid_1's binary_logloss: 0.136479\n",
            "[56]\ttraining's auc: 0.902012\ttraining's binary_logloss: 0.11509\tvalid_1's auc: 0.83558\tvalid_1's binary_logloss: 0.136477\n",
            "[57]\ttraining's auc: 0.902477\ttraining's binary_logloss: 0.114849\tvalid_1's auc: 0.835805\tvalid_1's binary_logloss: 0.136424\n",
            "[58]\ttraining's auc: 0.902945\ttraining's binary_logloss: 0.114618\tvalid_1's auc: 0.835665\tvalid_1's binary_logloss: 0.136441\n",
            "[59]\ttraining's auc: 0.90361\ttraining's binary_logloss: 0.114328\tvalid_1's auc: 0.835822\tvalid_1's binary_logloss: 0.136445\n",
            "[60]\ttraining's auc: 0.904435\ttraining's binary_logloss: 0.114029\tvalid_1's auc: 0.835696\tvalid_1's binary_logloss: 0.136431\n",
            "[61]\ttraining's auc: 0.904936\ttraining's binary_logloss: 0.113839\tvalid_1's auc: 0.835839\tvalid_1's binary_logloss: 0.136418\n",
            "[62]\ttraining's auc: 0.905662\ttraining's binary_logloss: 0.113543\tvalid_1's auc: 0.835589\tvalid_1's binary_logloss: 0.136499\n",
            "[63]\ttraining's auc: 0.906281\ttraining's binary_logloss: 0.113308\tvalid_1's auc: 0.835309\tvalid_1's binary_logloss: 0.136571\n",
            "[64]\ttraining's auc: 0.906861\ttraining's binary_logloss: 0.113067\tvalid_1's auc: 0.83537\tvalid_1's binary_logloss: 0.136549\n",
            "[65]\ttraining's auc: 0.907456\ttraining's binary_logloss: 0.112796\tvalid_1's auc: 0.835582\tvalid_1's binary_logloss: 0.136525\n",
            " 24%|██▍       | 12/50 [06:12<14:17, 22.56s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.147747\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.151877\n",
            "[2]\ttraining's auc: 0.840486\ttraining's binary_logloss: 0.141234\tvalid_1's auc: 0.809639\tvalid_1's binary_logloss: 0.147053\n",
            "[3]\ttraining's auc: 0.847891\ttraining's binary_logloss: 0.136771\tvalid_1's auc: 0.816322\tvalid_1's binary_logloss: 0.144117\n",
            "[4]\ttraining's auc: 0.852977\ttraining's binary_logloss: 0.133298\tvalid_1's auc: 0.819388\tvalid_1's binary_logloss: 0.14188\n",
            "[5]\ttraining's auc: 0.858883\ttraining's binary_logloss: 0.130778\tvalid_1's auc: 0.822051\tvalid_1's binary_logloss: 0.140483\n",
            "[6]\ttraining's auc: 0.86521\ttraining's binary_logloss: 0.128685\tvalid_1's auc: 0.822645\tvalid_1's binary_logloss: 0.139668\n",
            "[7]\ttraining's auc: 0.868895\ttraining's binary_logloss: 0.127005\tvalid_1's auc: 0.824224\tvalid_1's binary_logloss: 0.138912\n",
            "[8]\ttraining's auc: 0.871901\ttraining's binary_logloss: 0.125411\tvalid_1's auc: 0.824257\tvalid_1's binary_logloss: 0.138273\n",
            "[9]\ttraining's auc: 0.875974\ttraining's binary_logloss: 0.12398\tvalid_1's auc: 0.824157\tvalid_1's binary_logloss: 0.137886\n",
            "[10]\ttraining's auc: 0.879057\ttraining's binary_logloss: 0.12267\tvalid_1's auc: 0.824291\tvalid_1's binary_logloss: 0.137659\n",
            "[11]\ttraining's auc: 0.884234\ttraining's binary_logloss: 0.121297\tvalid_1's auc: 0.823924\tvalid_1's binary_logloss: 0.137567\n",
            "[12]\ttraining's auc: 0.886522\ttraining's binary_logloss: 0.120279\tvalid_1's auc: 0.826156\tvalid_1's binary_logloss: 0.137116\n",
            "[13]\ttraining's auc: 0.888526\ttraining's binary_logloss: 0.11927\tvalid_1's auc: 0.825939\tvalid_1's binary_logloss: 0.137106\n",
            "[14]\ttraining's auc: 0.892474\ttraining's binary_logloss: 0.118165\tvalid_1's auc: 0.825117\tvalid_1's binary_logloss: 0.137165\n",
            "[15]\ttraining's auc: 0.896613\ttraining's binary_logloss: 0.117051\tvalid_1's auc: 0.827301\tvalid_1's binary_logloss: 0.136735\n",
            "[16]\ttraining's auc: 0.898714\ttraining's binary_logloss: 0.116251\tvalid_1's auc: 0.826603\tvalid_1's binary_logloss: 0.13684\n",
            "[17]\ttraining's auc: 0.900394\ttraining's binary_logloss: 0.115484\tvalid_1's auc: 0.826085\tvalid_1's binary_logloss: 0.136988\n",
            "[18]\ttraining's auc: 0.902279\ttraining's binary_logloss: 0.114766\tvalid_1's auc: 0.82543\tvalid_1's binary_logloss: 0.137089\n",
            "[19]\ttraining's auc: 0.904189\ttraining's binary_logloss: 0.114045\tvalid_1's auc: 0.825803\tvalid_1's binary_logloss: 0.137162\n",
            "[20]\ttraining's auc: 0.904949\ttraining's binary_logloss: 0.113422\tvalid_1's auc: 0.825992\tvalid_1's binary_logloss: 0.137206\n",
            "[21]\ttraining's auc: 0.906762\ttraining's binary_logloss: 0.112733\tvalid_1's auc: 0.825568\tvalid_1's binary_logloss: 0.137306\n",
            "[22]\ttraining's auc: 0.907954\ttraining's binary_logloss: 0.112176\tvalid_1's auc: 0.825449\tvalid_1's binary_logloss: 0.137412\n",
            "[23]\ttraining's auc: 0.909569\ttraining's binary_logloss: 0.111541\tvalid_1's auc: 0.825673\tvalid_1's binary_logloss: 0.137333\n",
            "[24]\ttraining's auc: 0.910492\ttraining's binary_logloss: 0.11112\tvalid_1's auc: 0.82507\tvalid_1's binary_logloss: 0.137455\n",
            "[25]\ttraining's auc: 0.911833\ttraining's binary_logloss: 0.110514\tvalid_1's auc: 0.824849\tvalid_1's binary_logloss: 0.137563\n",
            "[26]\ttraining's auc: 0.912704\ttraining's binary_logloss: 0.110035\tvalid_1's auc: 0.824679\tvalid_1's binary_logloss: 0.137664\n",
            "[27]\ttraining's auc: 0.913301\ttraining's binary_logloss: 0.109628\tvalid_1's auc: 0.82441\tvalid_1's binary_logloss: 0.137789\n",
            "[28]\ttraining's auc: 0.914664\ttraining's binary_logloss: 0.109019\tvalid_1's auc: 0.823667\tvalid_1's binary_logloss: 0.138024\n",
            "[29]\ttraining's auc: 0.915565\ttraining's binary_logloss: 0.10851\tvalid_1's auc: 0.823462\tvalid_1's binary_logloss: 0.138165\n",
            "[30]\ttraining's auc: 0.917126\ttraining's binary_logloss: 0.107907\tvalid_1's auc: 0.823278\tvalid_1's binary_logloss: 0.138256\n",
            "[31]\ttraining's auc: 0.918369\ttraining's binary_logloss: 0.107356\tvalid_1's auc: 0.822655\tvalid_1's binary_logloss: 0.138416\n",
            "[32]\ttraining's auc: 0.919748\ttraining's binary_logloss: 0.106919\tvalid_1's auc: 0.822832\tvalid_1's binary_logloss: 0.138409\n",
            "[33]\ttraining's auc: 0.921976\ttraining's binary_logloss: 0.106427\tvalid_1's auc: 0.822324\tvalid_1's binary_logloss: 0.138558\n",
            "[34]\ttraining's auc: 0.922984\ttraining's binary_logloss: 0.106054\tvalid_1's auc: 0.821957\tvalid_1's binary_logloss: 0.138688\n",
            "[35]\ttraining's auc: 0.923926\ttraining's binary_logloss: 0.105586\tvalid_1's auc: 0.821668\tvalid_1's binary_logloss: 0.138817\n",
            "[36]\ttraining's auc: 0.924324\ttraining's binary_logloss: 0.105286\tvalid_1's auc: 0.82123\tvalid_1's binary_logloss: 0.138958\n",
            "[37]\ttraining's auc: 0.925221\ttraining's binary_logloss: 0.104768\tvalid_1's auc: 0.821302\tvalid_1's binary_logloss: 0.139008\n",
            "[38]\ttraining's auc: 0.925726\ttraining's binary_logloss: 0.104417\tvalid_1's auc: 0.821003\tvalid_1's binary_logloss: 0.139192\n",
            "[39]\ttraining's auc: 0.926664\ttraining's binary_logloss: 0.103952\tvalid_1's auc: 0.820381\tvalid_1's binary_logloss: 0.139359\n",
            "[40]\ttraining's auc: 0.927505\ttraining's binary_logloss: 0.103485\tvalid_1's auc: 0.82016\tvalid_1's binary_logloss: 0.139448\n",
            "[41]\ttraining's auc: 0.928119\ttraining's binary_logloss: 0.103103\tvalid_1's auc: 0.820262\tvalid_1's binary_logloss: 0.139486\n",
            "[42]\ttraining's auc: 0.92927\ttraining's binary_logloss: 0.102693\tvalid_1's auc: 0.819956\tvalid_1's binary_logloss: 0.139562\n",
            "[43]\ttraining's auc: 0.930247\ttraining's binary_logloss: 0.102294\tvalid_1's auc: 0.819954\tvalid_1's binary_logloss: 0.139627\n",
            "[44]\ttraining's auc: 0.930593\ttraining's binary_logloss: 0.102\tvalid_1's auc: 0.819418\tvalid_1's binary_logloss: 0.139817\n",
            "[45]\ttraining's auc: 0.930887\ttraining's binary_logloss: 0.101731\tvalid_1's auc: 0.81891\tvalid_1's binary_logloss: 0.139983\n",
            " 24%|██▍       | 12/50 [06:18<14:17, 22.56s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.150242\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.148416\n",
            "[2]\ttraining's auc: 0.834976\ttraining's binary_logloss: 0.143381\tvalid_1's auc: 0.818136\tvalid_1's binary_logloss: 0.143654\n",
            "[3]\ttraining's auc: 0.846148\ttraining's binary_logloss: 0.138922\tvalid_1's auc: 0.826441\tvalid_1's binary_logloss: 0.140505\n",
            "[4]\ttraining's auc: 0.852254\ttraining's binary_logloss: 0.135453\tvalid_1's auc: 0.827647\tvalid_1's binary_logloss: 0.138527\n",
            "[5]\ttraining's auc: 0.858993\ttraining's binary_logloss: 0.13274\tvalid_1's auc: 0.828663\tvalid_1's binary_logloss: 0.136986\n",
            "[6]\ttraining's auc: 0.863877\ttraining's binary_logloss: 0.130693\tvalid_1's auc: 0.829582\tvalid_1's binary_logloss: 0.136066\n",
            "[7]\ttraining's auc: 0.868552\ttraining's binary_logloss: 0.12886\tvalid_1's auc: 0.829415\tvalid_1's binary_logloss: 0.135211\n",
            "[8]\ttraining's auc: 0.870803\ttraining's binary_logloss: 0.127179\tvalid_1's auc: 0.830179\tvalid_1's binary_logloss: 0.134827\n",
            "[9]\ttraining's auc: 0.874673\ttraining's binary_logloss: 0.12567\tvalid_1's auc: 0.830413\tvalid_1's binary_logloss: 0.13438\n",
            "[10]\ttraining's auc: 0.877636\ttraining's binary_logloss: 0.124336\tvalid_1's auc: 0.830368\tvalid_1's binary_logloss: 0.134073\n",
            "[11]\ttraining's auc: 0.881338\ttraining's binary_logloss: 0.122989\tvalid_1's auc: 0.829713\tvalid_1's binary_logloss: 0.134099\n",
            "[12]\ttraining's auc: 0.885241\ttraining's binary_logloss: 0.121958\tvalid_1's auc: 0.831301\tvalid_1's binary_logloss: 0.133855\n",
            "[13]\ttraining's auc: 0.887138\ttraining's binary_logloss: 0.12113\tvalid_1's auc: 0.832033\tvalid_1's binary_logloss: 0.133631\n",
            "[14]\ttraining's auc: 0.889631\ttraining's binary_logloss: 0.120185\tvalid_1's auc: 0.831446\tvalid_1's binary_logloss: 0.133634\n",
            "[15]\ttraining's auc: 0.892364\ttraining's binary_logloss: 0.1193\tvalid_1's auc: 0.831728\tvalid_1's binary_logloss: 0.1335\n",
            "[16]\ttraining's auc: 0.894258\ttraining's binary_logloss: 0.118471\tvalid_1's auc: 0.832186\tvalid_1's binary_logloss: 0.133393\n",
            "[17]\ttraining's auc: 0.897594\ttraining's binary_logloss: 0.117609\tvalid_1's auc: 0.831115\tvalid_1's binary_logloss: 0.13352\n",
            "[18]\ttraining's auc: 0.899193\ttraining's binary_logloss: 0.116833\tvalid_1's auc: 0.831223\tvalid_1's binary_logloss: 0.133472\n",
            "[19]\ttraining's auc: 0.900323\ttraining's binary_logloss: 0.116123\tvalid_1's auc: 0.831591\tvalid_1's binary_logloss: 0.133425\n",
            "[20]\ttraining's auc: 0.902735\ttraining's binary_logloss: 0.11529\tvalid_1's auc: 0.830619\tvalid_1's binary_logloss: 0.133535\n",
            "[21]\ttraining's auc: 0.904051\ttraining's binary_logloss: 0.11471\tvalid_1's auc: 0.831397\tvalid_1's binary_logloss: 0.133378\n",
            "[22]\ttraining's auc: 0.905777\ttraining's binary_logloss: 0.114059\tvalid_1's auc: 0.83093\tvalid_1's binary_logloss: 0.133448\n",
            "[23]\ttraining's auc: 0.907768\ttraining's binary_logloss: 0.113245\tvalid_1's auc: 0.830837\tvalid_1's binary_logloss: 0.133486\n",
            "[24]\ttraining's auc: 0.908786\ttraining's binary_logloss: 0.112684\tvalid_1's auc: 0.831165\tvalid_1's binary_logloss: 0.133479\n",
            "[25]\ttraining's auc: 0.910194\ttraining's binary_logloss: 0.112024\tvalid_1's auc: 0.830578\tvalid_1's binary_logloss: 0.133563\n",
            "[26]\ttraining's auc: 0.911358\ttraining's binary_logloss: 0.111576\tvalid_1's auc: 0.830379\tvalid_1's binary_logloss: 0.133565\n",
            "[27]\ttraining's auc: 0.912727\ttraining's binary_logloss: 0.110957\tvalid_1's auc: 0.82988\tvalid_1's binary_logloss: 0.133614\n",
            "[28]\ttraining's auc: 0.913984\ttraining's binary_logloss: 0.110379\tvalid_1's auc: 0.829551\tvalid_1's binary_logloss: 0.133637\n",
            "[29]\ttraining's auc: 0.91505\ttraining's binary_logloss: 0.109807\tvalid_1's auc: 0.828978\tvalid_1's binary_logloss: 0.133802\n",
            "[30]\ttraining's auc: 0.916619\ttraining's binary_logloss: 0.109302\tvalid_1's auc: 0.82872\tvalid_1's binary_logloss: 0.133858\n",
            "[31]\ttraining's auc: 0.919433\ttraining's binary_logloss: 0.108473\tvalid_1's auc: 0.828439\tvalid_1's binary_logloss: 0.133993\n",
            "[32]\ttraining's auc: 0.920433\ttraining's binary_logloss: 0.107937\tvalid_1's auc: 0.828704\tvalid_1's binary_logloss: 0.133924\n",
            "[33]\ttraining's auc: 0.921634\ttraining's binary_logloss: 0.107415\tvalid_1's auc: 0.828396\tvalid_1's binary_logloss: 0.134019\n",
            "[34]\ttraining's auc: 0.923767\ttraining's binary_logloss: 0.106697\tvalid_1's auc: 0.827877\tvalid_1's binary_logloss: 0.134258\n",
            "[35]\ttraining's auc: 0.925952\ttraining's binary_logloss: 0.10619\tvalid_1's auc: 0.828112\tvalid_1's binary_logloss: 0.134366\n",
            "[36]\ttraining's auc: 0.927225\ttraining's binary_logloss: 0.105719\tvalid_1's auc: 0.827898\tvalid_1's binary_logloss: 0.134438\n",
            "[37]\ttraining's auc: 0.92787\ttraining's binary_logloss: 0.105339\tvalid_1's auc: 0.827775\tvalid_1's binary_logloss: 0.134501\n",
            "[38]\ttraining's auc: 0.928828\ttraining's binary_logloss: 0.104911\tvalid_1's auc: 0.82772\tvalid_1's binary_logloss: 0.134582\n",
            "[39]\ttraining's auc: 0.929562\ttraining's binary_logloss: 0.104403\tvalid_1's auc: 0.827328\tvalid_1's binary_logloss: 0.13471\n",
            "[40]\ttraining's auc: 0.930116\ttraining's binary_logloss: 0.104011\tvalid_1's auc: 0.827514\tvalid_1's binary_logloss: 0.134697\n",
            "[41]\ttraining's auc: 0.930828\ttraining's binary_logloss: 0.103585\tvalid_1's auc: 0.827208\tvalid_1's binary_logloss: 0.134796\n",
            "[42]\ttraining's auc: 0.932097\ttraining's binary_logloss: 0.102955\tvalid_1's auc: 0.827207\tvalid_1's binary_logloss: 0.134905\n",
            "[43]\ttraining's auc: 0.932519\ttraining's binary_logloss: 0.102629\tvalid_1's auc: 0.827629\tvalid_1's binary_logloss: 0.134853\n",
            "[44]\ttraining's auc: 0.933089\ttraining's binary_logloss: 0.102278\tvalid_1's auc: 0.827644\tvalid_1's binary_logloss: 0.134907\n",
            "[45]\ttraining's auc: 0.933678\ttraining's binary_logloss: 0.101869\tvalid_1's auc: 0.826997\tvalid_1's binary_logloss: 0.135024\n",
            "[46]\ttraining's auc: 0.93409\ttraining's binary_logloss: 0.1015\tvalid_1's auc: 0.82731\tvalid_1's binary_logloss: 0.135056\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 24%|██▍       | 12/50 [06:23<14:17, 22.56s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.147274\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.154494\n",
            "[2]\ttraining's auc: 0.839298\ttraining's binary_logloss: 0.140576\tvalid_1's auc: 0.820764\tvalid_1's binary_logloss: 0.149278\n",
            "[3]\ttraining's auc: 0.846697\ttraining's binary_logloss: 0.136083\tvalid_1's auc: 0.824847\tvalid_1's binary_logloss: 0.145893\n",
            "[4]\ttraining's auc: 0.852188\ttraining's binary_logloss: 0.13287\tvalid_1's auc: 0.827515\tvalid_1's binary_logloss: 0.143486\n",
            "[5]\ttraining's auc: 0.858056\ttraining's binary_logloss: 0.130252\tvalid_1's auc: 0.827205\tvalid_1's binary_logloss: 0.141959\n",
            "[6]\ttraining's auc: 0.861639\ttraining's binary_logloss: 0.12812\tvalid_1's auc: 0.827521\tvalid_1's binary_logloss: 0.14077\n",
            "[7]\ttraining's auc: 0.866833\ttraining's binary_logloss: 0.126273\tvalid_1's auc: 0.831739\tvalid_1's binary_logloss: 0.139874\n",
            "[8]\ttraining's auc: 0.871195\ttraining's binary_logloss: 0.124707\tvalid_1's auc: 0.83274\tvalid_1's binary_logloss: 0.139188\n",
            "[9]\ttraining's auc: 0.874278\ttraining's binary_logloss: 0.123414\tvalid_1's auc: 0.833736\tvalid_1's binary_logloss: 0.138546\n",
            "[10]\ttraining's auc: 0.879157\ttraining's binary_logloss: 0.121922\tvalid_1's auc: 0.834159\tvalid_1's binary_logloss: 0.138212\n",
            "[11]\ttraining's auc: 0.882293\ttraining's binary_logloss: 0.120736\tvalid_1's auc: 0.835\tvalid_1's binary_logloss: 0.137854\n",
            "[12]\ttraining's auc: 0.885554\ttraining's binary_logloss: 0.119526\tvalid_1's auc: 0.835239\tvalid_1's binary_logloss: 0.137735\n",
            "[13]\ttraining's auc: 0.889693\ttraining's binary_logloss: 0.11837\tvalid_1's auc: 0.834379\tvalid_1's binary_logloss: 0.137699\n",
            "[14]\ttraining's auc: 0.892216\ttraining's binary_logloss: 0.117455\tvalid_1's auc: 0.833723\tvalid_1's binary_logloss: 0.1377\n",
            "[15]\ttraining's auc: 0.89564\ttraining's binary_logloss: 0.11635\tvalid_1's auc: 0.833445\tvalid_1's binary_logloss: 0.137799\n",
            "[16]\ttraining's auc: 0.898006\ttraining's binary_logloss: 0.115414\tvalid_1's auc: 0.832838\tvalid_1's binary_logloss: 0.137921\n",
            "[17]\ttraining's auc: 0.900052\ttraining's binary_logloss: 0.114776\tvalid_1's auc: 0.832422\tvalid_1's binary_logloss: 0.137937\n",
            "[18]\ttraining's auc: 0.902194\ttraining's binary_logloss: 0.113797\tvalid_1's auc: 0.831752\tvalid_1's binary_logloss: 0.138108\n",
            "[19]\ttraining's auc: 0.90415\ttraining's binary_logloss: 0.113156\tvalid_1's auc: 0.832661\tvalid_1's binary_logloss: 0.137952\n",
            "[20]\ttraining's auc: 0.906324\ttraining's binary_logloss: 0.11225\tvalid_1's auc: 0.831956\tvalid_1's binary_logloss: 0.138123\n",
            "[21]\ttraining's auc: 0.908221\ttraining's binary_logloss: 0.111521\tvalid_1's auc: 0.831576\tvalid_1's binary_logloss: 0.138225\n",
            "[22]\ttraining's auc: 0.910215\ttraining's binary_logloss: 0.11064\tvalid_1's auc: 0.831586\tvalid_1's binary_logloss: 0.138343\n",
            "[23]\ttraining's auc: 0.911425\ttraining's binary_logloss: 0.110054\tvalid_1's auc: 0.831307\tvalid_1's binary_logloss: 0.138429\n",
            "[24]\ttraining's auc: 0.912339\ttraining's binary_logloss: 0.109524\tvalid_1's auc: 0.831117\tvalid_1's binary_logloss: 0.138523\n",
            "[25]\ttraining's auc: 0.913957\ttraining's binary_logloss: 0.108892\tvalid_1's auc: 0.830595\tvalid_1's binary_logloss: 0.138618\n",
            "[26]\ttraining's auc: 0.914815\ttraining's binary_logloss: 0.108381\tvalid_1's auc: 0.830531\tvalid_1's binary_logloss: 0.138666\n",
            "[27]\ttraining's auc: 0.916464\ttraining's binary_logloss: 0.107727\tvalid_1's auc: 0.830064\tvalid_1's binary_logloss: 0.13881\n",
            "[28]\ttraining's auc: 0.917281\ttraining's binary_logloss: 0.107266\tvalid_1's auc: 0.830113\tvalid_1's binary_logloss: 0.138858\n",
            "[29]\ttraining's auc: 0.918384\ttraining's binary_logloss: 0.106772\tvalid_1's auc: 0.829803\tvalid_1's binary_logloss: 0.138937\n",
            "[30]\ttraining's auc: 0.919098\ttraining's binary_logloss: 0.10638\tvalid_1's auc: 0.829753\tvalid_1's binary_logloss: 0.138971\n",
            "[31]\ttraining's auc: 0.921112\ttraining's binary_logloss: 0.105681\tvalid_1's auc: 0.829944\tvalid_1's binary_logloss: 0.139047\n",
            "[32]\ttraining's auc: 0.922166\ttraining's binary_logloss: 0.105189\tvalid_1's auc: 0.829649\tvalid_1's binary_logloss: 0.139108\n",
            "[33]\ttraining's auc: 0.923478\ttraining's binary_logloss: 0.104608\tvalid_1's auc: 0.829613\tvalid_1's binary_logloss: 0.139124\n",
            "[34]\ttraining's auc: 0.924866\ttraining's binary_logloss: 0.103902\tvalid_1's auc: 0.829152\tvalid_1's binary_logloss: 0.139294\n",
            "[35]\ttraining's auc: 0.926636\ttraining's binary_logloss: 0.103248\tvalid_1's auc: 0.828714\tvalid_1's binary_logloss: 0.139412\n",
            "[36]\ttraining's auc: 0.927149\ttraining's binary_logloss: 0.102859\tvalid_1's auc: 0.828492\tvalid_1's binary_logloss: 0.13949\n",
            "[37]\ttraining's auc: 0.928372\ttraining's binary_logloss: 0.102294\tvalid_1's auc: 0.828173\tvalid_1's binary_logloss: 0.139591\n",
            "[38]\ttraining's auc: 0.929604\ttraining's binary_logloss: 0.10174\tvalid_1's auc: 0.828002\tvalid_1's binary_logloss: 0.139613\n",
            "[39]\ttraining's auc: 0.930204\ttraining's binary_logloss: 0.101343\tvalid_1's auc: 0.827542\tvalid_1's binary_logloss: 0.139736\n",
            "[40]\ttraining's auc: 0.932664\ttraining's binary_logloss: 0.100755\tvalid_1's auc: 0.827528\tvalid_1's binary_logloss: 0.139797\n",
            "[41]\ttraining's auc: 0.933773\ttraining's binary_logloss: 0.100321\tvalid_1's auc: 0.827815\tvalid_1's binary_logloss: 0.139789\n",
            "[42]\ttraining's auc: 0.934727\ttraining's binary_logloss: 0.0998975\tvalid_1's auc: 0.827754\tvalid_1's binary_logloss: 0.139879\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 26%|██▌       | 13/50 [06:26<12:14, 19.85s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.160027\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.16166\n",
            "[2]\ttraining's auc: 0.832691\ttraining's binary_logloss: 0.156445\tvalid_1's auc: 0.805527\tvalid_1's binary_logloss: 0.158927\n",
            "[3]\ttraining's auc: 0.834192\ttraining's binary_logloss: 0.153502\tvalid_1's auc: 0.807333\tvalid_1's binary_logloss: 0.156592\n",
            "[4]\ttraining's auc: 0.836468\ttraining's binary_logloss: 0.151022\tvalid_1's auc: 0.808269\tvalid_1's binary_logloss: 0.154608\n",
            "[5]\ttraining's auc: 0.842172\ttraining's binary_logloss: 0.148815\tvalid_1's auc: 0.811651\tvalid_1's binary_logloss: 0.152948\n",
            "[6]\ttraining's auc: 0.845473\ttraining's binary_logloss: 0.146872\tvalid_1's auc: 0.815483\tvalid_1's binary_logloss: 0.151468\n",
            "[7]\ttraining's auc: 0.847144\ttraining's binary_logloss: 0.145155\tvalid_1's auc: 0.817219\tvalid_1's binary_logloss: 0.150148\n",
            "[8]\ttraining's auc: 0.848701\ttraining's binary_logloss: 0.143545\tvalid_1's auc: 0.818308\tvalid_1's binary_logloss: 0.148922\n",
            "[9]\ttraining's auc: 0.850473\ttraining's binary_logloss: 0.142117\tvalid_1's auc: 0.820393\tvalid_1's binary_logloss: 0.147875\n",
            "[10]\ttraining's auc: 0.85252\ttraining's binary_logloss: 0.140797\tvalid_1's auc: 0.821328\tvalid_1's binary_logloss: 0.146873\n",
            "[11]\ttraining's auc: 0.853459\ttraining's binary_logloss: 0.139583\tvalid_1's auc: 0.822515\tvalid_1's binary_logloss: 0.145991\n",
            "[12]\ttraining's auc: 0.854381\ttraining's binary_logloss: 0.138489\tvalid_1's auc: 0.822976\tvalid_1's binary_logloss: 0.145208\n",
            "[13]\ttraining's auc: 0.856416\ttraining's binary_logloss: 0.137482\tvalid_1's auc: 0.823941\tvalid_1's binary_logloss: 0.14454\n",
            "[14]\ttraining's auc: 0.857578\ttraining's binary_logloss: 0.136516\tvalid_1's auc: 0.824394\tvalid_1's binary_logloss: 0.143891\n",
            "[15]\ttraining's auc: 0.858658\ttraining's binary_logloss: 0.135602\tvalid_1's auc: 0.82432\tvalid_1's binary_logloss: 0.143258\n",
            "[16]\ttraining's auc: 0.859556\ttraining's binary_logloss: 0.134807\tvalid_1's auc: 0.82514\tvalid_1's binary_logloss: 0.142676\n",
            "[17]\ttraining's auc: 0.861631\ttraining's binary_logloss: 0.133988\tvalid_1's auc: 0.825415\tvalid_1's binary_logloss: 0.142166\n",
            "[18]\ttraining's auc: 0.861832\ttraining's binary_logloss: 0.133258\tvalid_1's auc: 0.825386\tvalid_1's binary_logloss: 0.141741\n",
            "[19]\ttraining's auc: 0.863443\ttraining's binary_logloss: 0.132554\tvalid_1's auc: 0.825849\tvalid_1's binary_logloss: 0.14131\n",
            "[20]\ttraining's auc: 0.864917\ttraining's binary_logloss: 0.131893\tvalid_1's auc: 0.82708\tvalid_1's binary_logloss: 0.140888\n",
            "[21]\ttraining's auc: 0.865931\ttraining's binary_logloss: 0.131272\tvalid_1's auc: 0.827003\tvalid_1's binary_logloss: 0.140532\n",
            "[22]\ttraining's auc: 0.867041\ttraining's binary_logloss: 0.130668\tvalid_1's auc: 0.827233\tvalid_1's binary_logloss: 0.140156\n",
            "[23]\ttraining's auc: 0.868252\ttraining's binary_logloss: 0.130111\tvalid_1's auc: 0.828097\tvalid_1's binary_logloss: 0.139833\n",
            "[24]\ttraining's auc: 0.869343\ttraining's binary_logloss: 0.129528\tvalid_1's auc: 0.828068\tvalid_1's binary_logloss: 0.139545\n",
            "[25]\ttraining's auc: 0.870082\ttraining's binary_logloss: 0.129017\tvalid_1's auc: 0.82818\tvalid_1's binary_logloss: 0.13931\n",
            "[26]\ttraining's auc: 0.870903\ttraining's binary_logloss: 0.128521\tvalid_1's auc: 0.828322\tvalid_1's binary_logloss: 0.139007\n",
            "[27]\ttraining's auc: 0.87181\ttraining's binary_logloss: 0.127996\tvalid_1's auc: 0.828566\tvalid_1's binary_logloss: 0.13877\n",
            "[28]\ttraining's auc: 0.873002\ttraining's binary_logloss: 0.127532\tvalid_1's auc: 0.828553\tvalid_1's binary_logloss: 0.138596\n",
            "[29]\ttraining's auc: 0.873896\ttraining's binary_logloss: 0.12708\tvalid_1's auc: 0.828726\tvalid_1's binary_logloss: 0.138419\n",
            "[30]\ttraining's auc: 0.874839\ttraining's binary_logloss: 0.126613\tvalid_1's auc: 0.828504\tvalid_1's binary_logloss: 0.138246\n",
            "[31]\ttraining's auc: 0.875284\ttraining's binary_logloss: 0.126233\tvalid_1's auc: 0.828572\tvalid_1's binary_logloss: 0.138074\n",
            "[32]\ttraining's auc: 0.876086\ttraining's binary_logloss: 0.125814\tvalid_1's auc: 0.828576\tvalid_1's binary_logloss: 0.137908\n",
            "[33]\ttraining's auc: 0.876692\ttraining's binary_logloss: 0.125411\tvalid_1's auc: 0.828706\tvalid_1's binary_logloss: 0.137766\n",
            "[34]\ttraining's auc: 0.877371\ttraining's binary_logloss: 0.125061\tvalid_1's auc: 0.828692\tvalid_1's binary_logloss: 0.137631\n",
            "[35]\ttraining's auc: 0.879316\ttraining's binary_logloss: 0.124655\tvalid_1's auc: 0.828739\tvalid_1's binary_logloss: 0.13751\n",
            "[36]\ttraining's auc: 0.879859\ttraining's binary_logloss: 0.124317\tvalid_1's auc: 0.828392\tvalid_1's binary_logloss: 0.137426\n",
            "[37]\ttraining's auc: 0.880573\ttraining's binary_logloss: 0.123979\tvalid_1's auc: 0.828693\tvalid_1's binary_logloss: 0.137297\n",
            "[38]\ttraining's auc: 0.881326\ttraining's binary_logloss: 0.123647\tvalid_1's auc: 0.828727\tvalid_1's binary_logloss: 0.137218\n",
            "[39]\ttraining's auc: 0.882867\ttraining's binary_logloss: 0.123271\tvalid_1's auc: 0.828876\tvalid_1's binary_logloss: 0.137108\n",
            "[40]\ttraining's auc: 0.88376\ttraining's binary_logloss: 0.122941\tvalid_1's auc: 0.828824\tvalid_1's binary_logloss: 0.137017\n",
            "[41]\ttraining's auc: 0.884759\ttraining's binary_logloss: 0.12261\tvalid_1's auc: 0.828958\tvalid_1's binary_logloss: 0.136934\n",
            "[42]\ttraining's auc: 0.885289\ttraining's binary_logloss: 0.122306\tvalid_1's auc: 0.828999\tvalid_1's binary_logloss: 0.136861\n",
            "[43]\ttraining's auc: 0.886192\ttraining's binary_logloss: 0.121959\tvalid_1's auc: 0.82921\tvalid_1's binary_logloss: 0.136803\n",
            "[44]\ttraining's auc: 0.886925\ttraining's binary_logloss: 0.121649\tvalid_1's auc: 0.829174\tvalid_1's binary_logloss: 0.13673\n",
            "[45]\ttraining's auc: 0.887961\ttraining's binary_logloss: 0.121323\tvalid_1's auc: 0.829695\tvalid_1's binary_logloss: 0.13661\n",
            "[46]\ttraining's auc: 0.888527\ttraining's binary_logloss: 0.121055\tvalid_1's auc: 0.82952\tvalid_1's binary_logloss: 0.136565\n",
            "[47]\ttraining's auc: 0.888996\ttraining's binary_logloss: 0.120782\tvalid_1's auc: 0.82974\tvalid_1's binary_logloss: 0.136501\n",
            "[48]\ttraining's auc: 0.889642\ttraining's binary_logloss: 0.120509\tvalid_1's auc: 0.830014\tvalid_1's binary_logloss: 0.136424\n",
            "[49]\ttraining's auc: 0.890003\ttraining's binary_logloss: 0.120281\tvalid_1's auc: 0.830169\tvalid_1's binary_logloss: 0.136359\n",
            "[50]\ttraining's auc: 0.890502\ttraining's binary_logloss: 0.12001\tvalid_1's auc: 0.830225\tvalid_1's binary_logloss: 0.136347\n",
            "[51]\ttraining's auc: 0.890843\ttraining's binary_logloss: 0.11978\tvalid_1's auc: 0.83019\tvalid_1's binary_logloss: 0.136311\n",
            "[52]\ttraining's auc: 0.891598\ttraining's binary_logloss: 0.119572\tvalid_1's auc: 0.83025\tvalid_1's binary_logloss: 0.136281\n",
            "[53]\ttraining's auc: 0.893139\ttraining's binary_logloss: 0.119242\tvalid_1's auc: 0.830617\tvalid_1's binary_logloss: 0.136159\n",
            "[54]\ttraining's auc: 0.893738\ttraining's binary_logloss: 0.118998\tvalid_1's auc: 0.830438\tvalid_1's binary_logloss: 0.136148\n",
            "[55]\ttraining's auc: 0.894136\ttraining's binary_logloss: 0.118764\tvalid_1's auc: 0.830429\tvalid_1's binary_logloss: 0.136118\n",
            "[56]\ttraining's auc: 0.8948\ttraining's binary_logloss: 0.118515\tvalid_1's auc: 0.830857\tvalid_1's binary_logloss: 0.136054\n",
            "[57]\ttraining's auc: 0.895491\ttraining's binary_logloss: 0.118287\tvalid_1's auc: 0.830895\tvalid_1's binary_logloss: 0.136022\n",
            "[58]\ttraining's auc: 0.895867\ttraining's binary_logloss: 0.118088\tvalid_1's auc: 0.831026\tvalid_1's binary_logloss: 0.135999\n",
            "[59]\ttraining's auc: 0.896997\ttraining's binary_logloss: 0.11783\tvalid_1's auc: 0.831429\tvalid_1's binary_logloss: 0.135906\n",
            "[60]\ttraining's auc: 0.897451\ttraining's binary_logloss: 0.117604\tvalid_1's auc: 0.831498\tvalid_1's binary_logloss: 0.135894\n",
            "[61]\ttraining's auc: 0.898215\ttraining's binary_logloss: 0.117381\tvalid_1's auc: 0.831651\tvalid_1's binary_logloss: 0.135839\n",
            "[62]\ttraining's auc: 0.898689\ttraining's binary_logloss: 0.117156\tvalid_1's auc: 0.831496\tvalid_1's binary_logloss: 0.135839\n",
            "[63]\ttraining's auc: 0.899113\ttraining's binary_logloss: 0.116969\tvalid_1's auc: 0.831474\tvalid_1's binary_logloss: 0.135839\n",
            "[64]\ttraining's auc: 0.89959\ttraining's binary_logloss: 0.116768\tvalid_1's auc: 0.8314\tvalid_1's binary_logloss: 0.135841\n",
            "[65]\ttraining's auc: 0.900284\ttraining's binary_logloss: 0.116549\tvalid_1's auc: 0.831306\tvalid_1's binary_logloss: 0.135841\n",
            "[66]\ttraining's auc: 0.900934\ttraining's binary_logloss: 0.11636\tvalid_1's auc: 0.831418\tvalid_1's binary_logloss: 0.135807\n",
            "[67]\ttraining's auc: 0.901528\ttraining's binary_logloss: 0.116165\tvalid_1's auc: 0.831336\tvalid_1's binary_logloss: 0.135821\n",
            "[68]\ttraining's auc: 0.90192\ttraining's binary_logloss: 0.115987\tvalid_1's auc: 0.831218\tvalid_1's binary_logloss: 0.135832\n",
            "[69]\ttraining's auc: 0.902517\ttraining's binary_logloss: 0.115798\tvalid_1's auc: 0.831109\tvalid_1's binary_logloss: 0.135825\n",
            "[70]\ttraining's auc: 0.902845\ttraining's binary_logloss: 0.115625\tvalid_1's auc: 0.831037\tvalid_1's binary_logloss: 0.135836\n",
            "[71]\ttraining's auc: 0.903191\ttraining's binary_logloss: 0.115456\tvalid_1's auc: 0.830914\tvalid_1's binary_logloss: 0.135843\n",
            "[72]\ttraining's auc: 0.903545\ttraining's binary_logloss: 0.115266\tvalid_1's auc: 0.830988\tvalid_1's binary_logloss: 0.135834\n",
            "[73]\ttraining's auc: 0.903986\ttraining's binary_logloss: 0.115102\tvalid_1's auc: 0.831159\tvalid_1's binary_logloss: 0.1358\n",
            "[74]\ttraining's auc: 0.904326\ttraining's binary_logloss: 0.11492\tvalid_1's auc: 0.830952\tvalid_1's binary_logloss: 0.135837\n",
            "[75]\ttraining's auc: 0.904698\ttraining's binary_logloss: 0.114716\tvalid_1's auc: 0.831052\tvalid_1's binary_logloss: 0.13584\n",
            "[76]\ttraining's auc: 0.905266\ttraining's binary_logloss: 0.11457\tvalid_1's auc: 0.831192\tvalid_1's binary_logloss: 0.135825\n",
            "[77]\ttraining's auc: 0.905633\ttraining's binary_logloss: 0.114402\tvalid_1's auc: 0.83105\tvalid_1's binary_logloss: 0.135853\n",
            "[78]\ttraining's auc: 0.906015\ttraining's binary_logloss: 0.114226\tvalid_1's auc: 0.831004\tvalid_1's binary_logloss: 0.135856\n",
            "[79]\ttraining's auc: 0.906253\ttraining's binary_logloss: 0.114081\tvalid_1's auc: 0.830932\tvalid_1's binary_logloss: 0.135884\n",
            "[80]\ttraining's auc: 0.906543\ttraining's binary_logloss: 0.113925\tvalid_1's auc: 0.830988\tvalid_1's binary_logloss: 0.135875\n",
            "[81]\ttraining's auc: 0.906806\ttraining's binary_logloss: 0.113783\tvalid_1's auc: 0.830805\tvalid_1's binary_logloss: 0.135916\n",
            "[82]\ttraining's auc: 0.907295\ttraining's binary_logloss: 0.113595\tvalid_1's auc: 0.830932\tvalid_1's binary_logloss: 0.135928\n",
            "[83]\ttraining's auc: 0.908149\ttraining's binary_logloss: 0.113398\tvalid_1's auc: 0.830865\tvalid_1's binary_logloss: 0.135936\n",
            "[84]\ttraining's auc: 0.908743\ttraining's binary_logloss: 0.113188\tvalid_1's auc: 0.830711\tvalid_1's binary_logloss: 0.135953\n",
            "[85]\ttraining's auc: 0.909482\ttraining's binary_logloss: 0.11296\tvalid_1's auc: 0.830554\tvalid_1's binary_logloss: 0.135979\n",
            "[86]\ttraining's auc: 0.909878\ttraining's binary_logloss: 0.112773\tvalid_1's auc: 0.830647\tvalid_1's binary_logloss: 0.135974\n",
            "[87]\ttraining's auc: 0.910508\ttraining's binary_logloss: 0.112552\tvalid_1's auc: 0.83047\tvalid_1's binary_logloss: 0.135994\n",
            "[88]\ttraining's auc: 0.911283\ttraining's binary_logloss: 0.112395\tvalid_1's auc: 0.830334\tvalid_1's binary_logloss: 0.136005\n",
            "[89]\ttraining's auc: 0.911799\ttraining's binary_logloss: 0.112224\tvalid_1's auc: 0.830413\tvalid_1's binary_logloss: 0.13598\n",
            "[90]\ttraining's auc: 0.912024\ttraining's binary_logloss: 0.112108\tvalid_1's auc: 0.830351\tvalid_1's binary_logloss: 0.135982\n",
            "[91]\ttraining's auc: 0.912541\ttraining's binary_logloss: 0.111941\tvalid_1's auc: 0.830269\tvalid_1's binary_logloss: 0.13601\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 26%|██▌       | 13/50 [06:36<12:14, 19.85s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.162419\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.157252\n",
            "[2]\ttraining's auc: 0.823422\ttraining's binary_logloss: 0.158909\tvalid_1's auc: 0.804254\tvalid_1's binary_logloss: 0.154441\n",
            "[3]\ttraining's auc: 0.831134\ttraining's binary_logloss: 0.155895\tvalid_1's auc: 0.81583\tvalid_1's binary_logloss: 0.152059\n",
            "[4]\ttraining's auc: 0.834824\ttraining's binary_logloss: 0.153346\tvalid_1's auc: 0.818368\tvalid_1's binary_logloss: 0.150051\n",
            "[5]\ttraining's auc: 0.835327\ttraining's binary_logloss: 0.15118\tvalid_1's auc: 0.819302\tvalid_1's binary_logloss: 0.148314\n",
            "[6]\ttraining's auc: 0.839763\ttraining's binary_logloss: 0.149234\tvalid_1's auc: 0.822513\tvalid_1's binary_logloss: 0.146918\n",
            "[7]\ttraining's auc: 0.840814\ttraining's binary_logloss: 0.147509\tvalid_1's auc: 0.822371\tvalid_1's binary_logloss: 0.145657\n",
            "[8]\ttraining's auc: 0.844954\ttraining's binary_logloss: 0.145919\tvalid_1's auc: 0.82475\tvalid_1's binary_logloss: 0.144496\n",
            "[9]\ttraining's auc: 0.849608\ttraining's binary_logloss: 0.144463\tvalid_1's auc: 0.827469\tvalid_1's binary_logloss: 0.143418\n",
            "[10]\ttraining's auc: 0.850625\ttraining's binary_logloss: 0.143133\tvalid_1's auc: 0.82846\tvalid_1's binary_logloss: 0.14242\n",
            "[11]\ttraining's auc: 0.852057\ttraining's binary_logloss: 0.141934\tvalid_1's auc: 0.829165\tvalid_1's binary_logloss: 0.141549\n",
            "[12]\ttraining's auc: 0.853075\ttraining's binary_logloss: 0.140828\tvalid_1's auc: 0.829256\tvalid_1's binary_logloss: 0.14073\n",
            "[13]\ttraining's auc: 0.854776\ttraining's binary_logloss: 0.139804\tvalid_1's auc: 0.829484\tvalid_1's binary_logloss: 0.140025\n",
            "[14]\ttraining's auc: 0.85703\ttraining's binary_logloss: 0.138848\tvalid_1's auc: 0.831924\tvalid_1's binary_logloss: 0.139337\n",
            "[15]\ttraining's auc: 0.857611\ttraining's binary_logloss: 0.137926\tvalid_1's auc: 0.831826\tvalid_1's binary_logloss: 0.138778\n",
            "[16]\ttraining's auc: 0.858323\ttraining's binary_logloss: 0.137067\tvalid_1's auc: 0.831456\tvalid_1's binary_logloss: 0.138237\n",
            "[17]\ttraining's auc: 0.860755\ttraining's binary_logloss: 0.136266\tvalid_1's auc: 0.832836\tvalid_1's binary_logloss: 0.137682\n",
            "[18]\ttraining's auc: 0.861642\ttraining's binary_logloss: 0.135482\tvalid_1's auc: 0.83245\tvalid_1's binary_logloss: 0.137234\n",
            "[19]\ttraining's auc: 0.862699\ttraining's binary_logloss: 0.134711\tvalid_1's auc: 0.832351\tvalid_1's binary_logloss: 0.136802\n",
            "[20]\ttraining's auc: 0.863661\ttraining's binary_logloss: 0.134027\tvalid_1's auc: 0.832323\tvalid_1's binary_logloss: 0.136436\n",
            "[21]\ttraining's auc: 0.866013\ttraining's binary_logloss: 0.133325\tvalid_1's auc: 0.83278\tvalid_1's binary_logloss: 0.136075\n",
            "[22]\ttraining's auc: 0.867794\ttraining's binary_logloss: 0.132696\tvalid_1's auc: 0.833389\tvalid_1's binary_logloss: 0.135745\n",
            "[23]\ttraining's auc: 0.869631\ttraining's binary_logloss: 0.132075\tvalid_1's auc: 0.834026\tvalid_1's binary_logloss: 0.135353\n",
            "[24]\ttraining's auc: 0.870856\ttraining's binary_logloss: 0.131521\tvalid_1's auc: 0.833561\tvalid_1's binary_logloss: 0.135078\n",
            "[25]\ttraining's auc: 0.871354\ttraining's binary_logloss: 0.131005\tvalid_1's auc: 0.833707\tvalid_1's binary_logloss: 0.134792\n",
            "[26]\ttraining's auc: 0.872352\ttraining's binary_logloss: 0.130507\tvalid_1's auc: 0.834036\tvalid_1's binary_logloss: 0.134534\n",
            "[27]\ttraining's auc: 0.873095\ttraining's binary_logloss: 0.130022\tvalid_1's auc: 0.83399\tvalid_1's binary_logloss: 0.134307\n",
            "[28]\ttraining's auc: 0.873715\ttraining's binary_logloss: 0.129534\tvalid_1's auc: 0.833843\tvalid_1's binary_logloss: 0.134106\n",
            "[29]\ttraining's auc: 0.874063\ttraining's binary_logloss: 0.129075\tvalid_1's auc: 0.833303\tvalid_1's binary_logloss: 0.133948\n",
            "[30]\ttraining's auc: 0.874552\ttraining's binary_logloss: 0.128646\tvalid_1's auc: 0.833157\tvalid_1's binary_logloss: 0.133775\n",
            "[31]\ttraining's auc: 0.875293\ttraining's binary_logloss: 0.128192\tvalid_1's auc: 0.833374\tvalid_1's binary_logloss: 0.133551\n",
            "[32]\ttraining's auc: 0.876537\ttraining's binary_logloss: 0.127744\tvalid_1's auc: 0.833282\tvalid_1's binary_logloss: 0.133389\n",
            "[33]\ttraining's auc: 0.877048\ttraining's binary_logloss: 0.12736\tvalid_1's auc: 0.833769\tvalid_1's binary_logloss: 0.133225\n",
            "[34]\ttraining's auc: 0.877807\ttraining's binary_logloss: 0.126972\tvalid_1's auc: 0.833998\tvalid_1's binary_logloss: 0.133082\n",
            "[35]\ttraining's auc: 0.878521\ttraining's binary_logloss: 0.126592\tvalid_1's auc: 0.833918\tvalid_1's binary_logloss: 0.132957\n",
            "[36]\ttraining's auc: 0.879494\ttraining's binary_logloss: 0.126194\tvalid_1's auc: 0.834302\tvalid_1's binary_logloss: 0.132769\n",
            "[37]\ttraining's auc: 0.880015\ttraining's binary_logloss: 0.125867\tvalid_1's auc: 0.834219\tvalid_1's binary_logloss: 0.132662\n",
            "[38]\ttraining's auc: 0.88076\ttraining's binary_logloss: 0.125483\tvalid_1's auc: 0.834265\tvalid_1's binary_logloss: 0.13256\n",
            "[39]\ttraining's auc: 0.881345\ttraining's binary_logloss: 0.125149\tvalid_1's auc: 0.834094\tvalid_1's binary_logloss: 0.132473\n",
            "[40]\ttraining's auc: 0.882317\ttraining's binary_logloss: 0.124803\tvalid_1's auc: 0.834455\tvalid_1's binary_logloss: 0.132341\n",
            "[41]\ttraining's auc: 0.882774\ttraining's binary_logloss: 0.124483\tvalid_1's auc: 0.834232\tvalid_1's binary_logloss: 0.132271\n",
            "[42]\ttraining's auc: 0.883355\ttraining's binary_logloss: 0.124192\tvalid_1's auc: 0.83438\tvalid_1's binary_logloss: 0.132158\n",
            "[43]\ttraining's auc: 0.88431\ttraining's binary_logloss: 0.123889\tvalid_1's auc: 0.834068\tvalid_1's binary_logloss: 0.132086\n",
            "[44]\ttraining's auc: 0.88508\ttraining's binary_logloss: 0.123604\tvalid_1's auc: 0.834171\tvalid_1's binary_logloss: 0.132018\n",
            "[45]\ttraining's auc: 0.886063\ttraining's binary_logloss: 0.123294\tvalid_1's auc: 0.834367\tvalid_1's binary_logloss: 0.131937\n",
            "[46]\ttraining's auc: 0.886436\ttraining's binary_logloss: 0.123029\tvalid_1's auc: 0.83422\tvalid_1's binary_logloss: 0.131893\n",
            "[47]\ttraining's auc: 0.887515\ttraining's binary_logloss: 0.122708\tvalid_1's auc: 0.834373\tvalid_1's binary_logloss: 0.131812\n",
            "[48]\ttraining's auc: 0.888186\ttraining's binary_logloss: 0.122419\tvalid_1's auc: 0.83467\tvalid_1's binary_logloss: 0.131736\n",
            "[49]\ttraining's auc: 0.889126\ttraining's binary_logloss: 0.122141\tvalid_1's auc: 0.83463\tvalid_1's binary_logloss: 0.131687\n",
            "[50]\ttraining's auc: 0.889768\ttraining's binary_logloss: 0.121892\tvalid_1's auc: 0.834648\tvalid_1's binary_logloss: 0.131626\n",
            "[51]\ttraining's auc: 0.890232\ttraining's binary_logloss: 0.121611\tvalid_1's auc: 0.83474\tvalid_1's binary_logloss: 0.131584\n",
            "[52]\ttraining's auc: 0.890778\ttraining's binary_logloss: 0.121365\tvalid_1's auc: 0.834818\tvalid_1's binary_logloss: 0.131533\n",
            "[53]\ttraining's auc: 0.891068\ttraining's binary_logloss: 0.121141\tvalid_1's auc: 0.834917\tvalid_1's binary_logloss: 0.131482\n",
            "[54]\ttraining's auc: 0.891316\ttraining's binary_logloss: 0.120934\tvalid_1's auc: 0.834752\tvalid_1's binary_logloss: 0.13148\n",
            "[55]\ttraining's auc: 0.892045\ttraining's binary_logloss: 0.120706\tvalid_1's auc: 0.835203\tvalid_1's binary_logloss: 0.131422\n",
            "[56]\ttraining's auc: 0.892388\ttraining's binary_logloss: 0.120488\tvalid_1's auc: 0.835243\tvalid_1's binary_logloss: 0.13137\n",
            "[57]\ttraining's auc: 0.892668\ttraining's binary_logloss: 0.120275\tvalid_1's auc: 0.835356\tvalid_1's binary_logloss: 0.131323\n",
            "[58]\ttraining's auc: 0.893016\ttraining's binary_logloss: 0.120078\tvalid_1's auc: 0.835349\tvalid_1's binary_logloss: 0.131291\n",
            "[59]\ttraining's auc: 0.894479\ttraining's binary_logloss: 0.1198\tvalid_1's auc: 0.835147\tvalid_1's binary_logloss: 0.131264\n",
            "[60]\ttraining's auc: 0.895416\ttraining's binary_logloss: 0.119563\tvalid_1's auc: 0.834979\tvalid_1's binary_logloss: 0.131251\n",
            "[61]\ttraining's auc: 0.895824\ttraining's binary_logloss: 0.119366\tvalid_1's auc: 0.835285\tvalid_1's binary_logloss: 0.131191\n",
            "[62]\ttraining's auc: 0.896386\ttraining's binary_logloss: 0.119181\tvalid_1's auc: 0.835547\tvalid_1's binary_logloss: 0.131135\n",
            "[63]\ttraining's auc: 0.896843\ttraining's binary_logloss: 0.118994\tvalid_1's auc: 0.835593\tvalid_1's binary_logloss: 0.13111\n",
            "[64]\ttraining's auc: 0.897552\ttraining's binary_logloss: 0.118772\tvalid_1's auc: 0.835573\tvalid_1's binary_logloss: 0.131094\n",
            "[65]\ttraining's auc: 0.898069\ttraining's binary_logloss: 0.118595\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.131046\n",
            "[66]\ttraining's auc: 0.898973\ttraining's binary_logloss: 0.118337\tvalid_1's auc: 0.835821\tvalid_1's binary_logloss: 0.131008\n",
            "[67]\ttraining's auc: 0.899835\ttraining's binary_logloss: 0.118111\tvalid_1's auc: 0.835769\tvalid_1's binary_logloss: 0.130997\n",
            "[68]\ttraining's auc: 0.900107\ttraining's binary_logloss: 0.11792\tvalid_1's auc: 0.835782\tvalid_1's binary_logloss: 0.130976\n",
            "[69]\ttraining's auc: 0.900869\ttraining's binary_logloss: 0.117692\tvalid_1's auc: 0.835814\tvalid_1's binary_logloss: 0.130968\n",
            "[70]\ttraining's auc: 0.901521\ttraining's binary_logloss: 0.117514\tvalid_1's auc: 0.835709\tvalid_1's binary_logloss: 0.130979\n",
            "[71]\ttraining's auc: 0.902169\ttraining's binary_logloss: 0.117311\tvalid_1's auc: 0.835666\tvalid_1's binary_logloss: 0.130964\n",
            "[72]\ttraining's auc: 0.902516\ttraining's binary_logloss: 0.117138\tvalid_1's auc: 0.835602\tvalid_1's binary_logloss: 0.130936\n",
            "[73]\ttraining's auc: 0.903195\ttraining's binary_logloss: 0.116942\tvalid_1's auc: 0.835716\tvalid_1's binary_logloss: 0.130923\n",
            "[74]\ttraining's auc: 0.903739\ttraining's binary_logloss: 0.116732\tvalid_1's auc: 0.835864\tvalid_1's binary_logloss: 0.130892\n",
            "[75]\ttraining's auc: 0.904239\ttraining's binary_logloss: 0.116533\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.130863\n",
            "[76]\ttraining's auc: 0.904628\ttraining's binary_logloss: 0.116345\tvalid_1's auc: 0.836121\tvalid_1's binary_logloss: 0.130856\n",
            "[77]\ttraining's auc: 0.905111\ttraining's binary_logloss: 0.11617\tvalid_1's auc: 0.836146\tvalid_1's binary_logloss: 0.130844\n",
            "[78]\ttraining's auc: 0.905609\ttraining's binary_logloss: 0.116002\tvalid_1's auc: 0.836088\tvalid_1's binary_logloss: 0.130849\n",
            "[79]\ttraining's auc: 0.905907\ttraining's binary_logloss: 0.115875\tvalid_1's auc: 0.836107\tvalid_1's binary_logloss: 0.130854\n",
            "[80]\ttraining's auc: 0.9062\ttraining's binary_logloss: 0.115692\tvalid_1's auc: 0.836205\tvalid_1's binary_logloss: 0.130842\n",
            "[81]\ttraining's auc: 0.906578\ttraining's binary_logloss: 0.115526\tvalid_1's auc: 0.836185\tvalid_1's binary_logloss: 0.130846\n",
            "[82]\ttraining's auc: 0.906924\ttraining's binary_logloss: 0.115371\tvalid_1's auc: 0.836161\tvalid_1's binary_logloss: 0.130855\n",
            "[83]\ttraining's auc: 0.907262\ttraining's binary_logloss: 0.115198\tvalid_1's auc: 0.836212\tvalid_1's binary_logloss: 0.130839\n",
            "[84]\ttraining's auc: 0.907674\ttraining's binary_logloss: 0.115006\tvalid_1's auc: 0.836242\tvalid_1's binary_logloss: 0.130817\n",
            "[85]\ttraining's auc: 0.907967\ttraining's binary_logloss: 0.114895\tvalid_1's auc: 0.836313\tvalid_1's binary_logloss: 0.130801\n",
            "[86]\ttraining's auc: 0.908402\ttraining's binary_logloss: 0.114733\tvalid_1's auc: 0.836267\tvalid_1's binary_logloss: 0.130799\n",
            "[87]\ttraining's auc: 0.908788\ttraining's binary_logloss: 0.114568\tvalid_1's auc: 0.836032\tvalid_1's binary_logloss: 0.130835\n",
            "[88]\ttraining's auc: 0.909226\ttraining's binary_logloss: 0.114383\tvalid_1's auc: 0.836053\tvalid_1's binary_logloss: 0.13083\n",
            "[89]\ttraining's auc: 0.909659\ttraining's binary_logloss: 0.114198\tvalid_1's auc: 0.8362\tvalid_1's binary_logloss: 0.130799\n",
            "[90]\ttraining's auc: 0.909936\ttraining's binary_logloss: 0.114038\tvalid_1's auc: 0.836256\tvalid_1's binary_logloss: 0.13079\n",
            "[91]\ttraining's auc: 0.9102\ttraining's binary_logloss: 0.113909\tvalid_1's auc: 0.836201\tvalid_1's binary_logloss: 0.130792\n",
            "[92]\ttraining's auc: 0.910579\ttraining's binary_logloss: 0.113797\tvalid_1's auc: 0.836214\tvalid_1's binary_logloss: 0.130799\n",
            "[93]\ttraining's auc: 0.910949\ttraining's binary_logloss: 0.113637\tvalid_1's auc: 0.836335\tvalid_1's binary_logloss: 0.130779\n",
            "[94]\ttraining's auc: 0.911145\ttraining's binary_logloss: 0.113507\tvalid_1's auc: 0.836271\tvalid_1's binary_logloss: 0.13077\n",
            "[95]\ttraining's auc: 0.911679\ttraining's binary_logloss: 0.113323\tvalid_1's auc: 0.83624\tvalid_1's binary_logloss: 0.130776\n",
            "[96]\ttraining's auc: 0.91194\ttraining's binary_logloss: 0.113177\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.130778\n",
            "[97]\ttraining's auc: 0.912415\ttraining's binary_logloss: 0.113028\tvalid_1's auc: 0.836221\tvalid_1's binary_logloss: 0.130778\n",
            "[98]\ttraining's auc: 0.912751\ttraining's binary_logloss: 0.112878\tvalid_1's auc: 0.836319\tvalid_1's binary_logloss: 0.130765\n",
            "[99]\ttraining's auc: 0.913068\ttraining's binary_logloss: 0.112753\tvalid_1's auc: 0.836282\tvalid_1's binary_logloss: 0.130782\n",
            "[100]\ttraining's auc: 0.913321\ttraining's binary_logloss: 0.112629\tvalid_1's auc: 0.836285\tvalid_1's binary_logloss: 0.130777\n",
            "[101]\ttraining's auc: 0.913687\ttraining's binary_logloss: 0.112498\tvalid_1's auc: 0.836223\tvalid_1's binary_logloss: 0.130783\n",
            "[102]\ttraining's auc: 0.914022\ttraining's binary_logloss: 0.112335\tvalid_1's auc: 0.836135\tvalid_1's binary_logloss: 0.130788\n",
            "[103]\ttraining's auc: 0.914623\ttraining's binary_logloss: 0.112177\tvalid_1's auc: 0.836138\tvalid_1's binary_logloss: 0.130797\n",
            "[104]\ttraining's auc: 0.914962\ttraining's binary_logloss: 0.112035\tvalid_1's auc: 0.836211\tvalid_1's binary_logloss: 0.130785\n",
            "[105]\ttraining's auc: 0.915211\ttraining's binary_logloss: 0.11191\tvalid_1's auc: 0.836007\tvalid_1's binary_logloss: 0.130805\n",
            "[106]\ttraining's auc: 0.915445\ttraining's binary_logloss: 0.11178\tvalid_1's auc: 0.836097\tvalid_1's binary_logloss: 0.130785\n",
            "[107]\ttraining's auc: 0.915627\ttraining's binary_logloss: 0.111688\tvalid_1's auc: 0.836111\tvalid_1's binary_logloss: 0.130789\n",
            "[108]\ttraining's auc: 0.915978\ttraining's binary_logloss: 0.111513\tvalid_1's auc: 0.835927\tvalid_1's binary_logloss: 0.130823\n",
            "[109]\ttraining's auc: 0.916247\ttraining's binary_logloss: 0.11139\tvalid_1's auc: 0.835906\tvalid_1's binary_logloss: 0.130834\n",
            "[110]\ttraining's auc: 0.91643\ttraining's binary_logloss: 0.111288\tvalid_1's auc: 0.835799\tvalid_1's binary_logloss: 0.130856\n",
            "[111]\ttraining's auc: 0.916532\ttraining's binary_logloss: 0.111186\tvalid_1's auc: 0.835743\tvalid_1's binary_logloss: 0.130856\n",
            "[112]\ttraining's auc: 0.916782\ttraining's binary_logloss: 0.111037\tvalid_1's auc: 0.835855\tvalid_1's binary_logloss: 0.130826\n",
            "[113]\ttraining's auc: 0.917059\ttraining's binary_logloss: 0.110908\tvalid_1's auc: 0.835768\tvalid_1's binary_logloss: 0.130827\n",
            "[114]\ttraining's auc: 0.917258\ttraining's binary_logloss: 0.110815\tvalid_1's auc: 0.83567\tvalid_1's binary_logloss: 0.130835\n",
            "[115]\ttraining's auc: 0.917577\ttraining's binary_logloss: 0.110669\tvalid_1's auc: 0.835553\tvalid_1's binary_logloss: 0.130865\n",
            "[116]\ttraining's auc: 0.917763\ttraining's binary_logloss: 0.110547\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.130855\n",
            "[117]\ttraining's auc: 0.917856\ttraining's binary_logloss: 0.11046\tvalid_1's auc: 0.835569\tvalid_1's binary_logloss: 0.130851\n",
            "[118]\ttraining's auc: 0.918088\ttraining's binary_logloss: 0.11033\tvalid_1's auc: 0.835626\tvalid_1's binary_logloss: 0.130844\n",
            "[119]\ttraining's auc: 0.918365\ttraining's binary_logloss: 0.110184\tvalid_1's auc: 0.835714\tvalid_1's binary_logloss: 0.130816\n",
            "[120]\ttraining's auc: 0.918715\ttraining's binary_logloss: 0.110083\tvalid_1's auc: 0.835723\tvalid_1's binary_logloss: 0.130823\n",
            "[121]\ttraining's auc: 0.918973\ttraining's binary_logloss: 0.109954\tvalid_1's auc: 0.835467\tvalid_1's binary_logloss: 0.130878\n",
            "[122]\ttraining's auc: 0.919099\ttraining's binary_logloss: 0.109872\tvalid_1's auc: 0.835334\tvalid_1's binary_logloss: 0.130898\n",
            "[123]\ttraining's auc: 0.919304\ttraining's binary_logloss: 0.109764\tvalid_1's auc: 0.835426\tvalid_1's binary_logloss: 0.130879\n",
            " 26%|██▌       | 13/50 [06:44<12:14, 19.85s/trial, best loss: -0.8348113380735939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.158835\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.164653\n",
            "[2]\ttraining's auc: 0.830738\ttraining's binary_logloss: 0.155441\tvalid_1's auc: 0.81491\tvalid_1's binary_logloss: 0.161575\n",
            "[3]\ttraining's auc: 0.833449\ttraining's binary_logloss: 0.152625\tvalid_1's auc: 0.81509\tvalid_1's binary_logloss: 0.159116\n",
            "[4]\ttraining's auc: 0.836945\ttraining's binary_logloss: 0.150174\tvalid_1's auc: 0.817831\tvalid_1's binary_logloss: 0.156881\n",
            "[5]\ttraining's auc: 0.837763\ttraining's binary_logloss: 0.148096\tvalid_1's auc: 0.818017\tvalid_1's binary_logloss: 0.155051\n",
            "[6]\ttraining's auc: 0.840376\ttraining's binary_logloss: 0.146171\tvalid_1's auc: 0.818831\tvalid_1's binary_logloss: 0.153508\n",
            "[7]\ttraining's auc: 0.847562\ttraining's binary_logloss: 0.144389\tvalid_1's auc: 0.82401\tvalid_1's binary_logloss: 0.152005\n",
            "[8]\ttraining's auc: 0.849687\ttraining's binary_logloss: 0.142851\tvalid_1's auc: 0.825724\tvalid_1's binary_logloss: 0.150745\n",
            "[9]\ttraining's auc: 0.849484\ttraining's binary_logloss: 0.141447\tvalid_1's auc: 0.825873\tvalid_1's binary_logloss: 0.14957\n",
            "[10]\ttraining's auc: 0.851326\ttraining's binary_logloss: 0.14007\tvalid_1's auc: 0.827208\tvalid_1's binary_logloss: 0.148502\n",
            "[11]\ttraining's auc: 0.852048\ttraining's binary_logloss: 0.13887\tvalid_1's auc: 0.827883\tvalid_1's binary_logloss: 0.147538\n",
            "[12]\ttraining's auc: 0.85241\ttraining's binary_logloss: 0.137763\tvalid_1's auc: 0.828117\tvalid_1's binary_logloss: 0.146684\n",
            "[13]\ttraining's auc: 0.854049\ttraining's binary_logloss: 0.136722\tvalid_1's auc: 0.828954\tvalid_1's binary_logloss: 0.145913\n",
            "[14]\ttraining's auc: 0.855239\ttraining's binary_logloss: 0.135786\tvalid_1's auc: 0.829178\tvalid_1's binary_logloss: 0.145217\n",
            "[15]\ttraining's auc: 0.856515\ttraining's binary_logloss: 0.13493\tvalid_1's auc: 0.829856\tvalid_1's binary_logloss: 0.144518\n",
            "[16]\ttraining's auc: 0.857179\ttraining's binary_logloss: 0.134111\tvalid_1's auc: 0.830845\tvalid_1's binary_logloss: 0.143879\n",
            "[17]\ttraining's auc: 0.858689\ttraining's binary_logloss: 0.133339\tvalid_1's auc: 0.831519\tvalid_1's binary_logloss: 0.143278\n",
            "[18]\ttraining's auc: 0.859417\ttraining's binary_logloss: 0.132605\tvalid_1's auc: 0.831919\tvalid_1's binary_logloss: 0.142745\n",
            "[19]\ttraining's auc: 0.861739\ttraining's binary_logloss: 0.131884\tvalid_1's auc: 0.832298\tvalid_1's binary_logloss: 0.142269\n",
            "[20]\ttraining's auc: 0.862679\ttraining's binary_logloss: 0.131226\tvalid_1's auc: 0.832407\tvalid_1's binary_logloss: 0.141805\n",
            "[21]\ttraining's auc: 0.863646\ttraining's binary_logloss: 0.130615\tvalid_1's auc: 0.832292\tvalid_1's binary_logloss: 0.141438\n",
            "[22]\ttraining's auc: 0.864758\ttraining's binary_logloss: 0.130035\tvalid_1's auc: 0.832208\tvalid_1's binary_logloss: 0.141101\n",
            "[23]\ttraining's auc: 0.867073\ttraining's binary_logloss: 0.129444\tvalid_1's auc: 0.832647\tvalid_1's binary_logloss: 0.14073\n",
            "[24]\ttraining's auc: 0.868875\ttraining's binary_logloss: 0.128866\tvalid_1's auc: 0.832753\tvalid_1's binary_logloss: 0.140404\n",
            "[25]\ttraining's auc: 0.869881\ttraining's binary_logloss: 0.128359\tvalid_1's auc: 0.832827\tvalid_1's binary_logloss: 0.140138\n",
            "[26]\ttraining's auc: 0.871107\ttraining's binary_logloss: 0.127888\tvalid_1's auc: 0.83444\tvalid_1's binary_logloss: 0.139872\n",
            "[27]\ttraining's auc: 0.872006\ttraining's binary_logloss: 0.127387\tvalid_1's auc: 0.834494\tvalid_1's binary_logloss: 0.139662\n",
            "[28]\ttraining's auc: 0.873233\ttraining's binary_logloss: 0.126942\tvalid_1's auc: 0.835136\tvalid_1's binary_logloss: 0.139403\n",
            "[29]\ttraining's auc: 0.874011\ttraining's binary_logloss: 0.126476\tvalid_1's auc: 0.835216\tvalid_1's binary_logloss: 0.139204\n",
            "[30]\ttraining's auc: 0.87512\ttraining's binary_logloss: 0.126019\tvalid_1's auc: 0.835478\tvalid_1's binary_logloss: 0.138966\n",
            "[31]\ttraining's auc: 0.875749\ttraining's binary_logloss: 0.125595\tvalid_1's auc: 0.835616\tvalid_1's binary_logloss: 0.138771\n",
            "[32]\ttraining's auc: 0.876295\ttraining's binary_logloss: 0.125199\tvalid_1's auc: 0.835848\tvalid_1's binary_logloss: 0.138578\n",
            "[33]\ttraining's auc: 0.877624\ttraining's binary_logloss: 0.1248\tvalid_1's auc: 0.835804\tvalid_1's binary_logloss: 0.138426\n",
            "[34]\ttraining's auc: 0.879316\ttraining's binary_logloss: 0.124393\tvalid_1's auc: 0.835974\tvalid_1's binary_logloss: 0.138253\n",
            "[35]\ttraining's auc: 0.879978\ttraining's binary_logloss: 0.124059\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.138079\n",
            "[36]\ttraining's auc: 0.88113\ttraining's binary_logloss: 0.123672\tvalid_1's auc: 0.836224\tvalid_1's binary_logloss: 0.137988\n",
            "[37]\ttraining's auc: 0.882034\ttraining's binary_logloss: 0.123345\tvalid_1's auc: 0.836323\tvalid_1's binary_logloss: 0.137877\n",
            "[38]\ttraining's auc: 0.883254\ttraining's binary_logloss: 0.122998\tvalid_1's auc: 0.836284\tvalid_1's binary_logloss: 0.137764\n",
            "[39]\ttraining's auc: 0.883766\ttraining's binary_logloss: 0.122674\tvalid_1's auc: 0.836473\tvalid_1's binary_logloss: 0.137634\n",
            "[40]\ttraining's auc: 0.884301\ttraining's binary_logloss: 0.122354\tvalid_1's auc: 0.83657\tvalid_1's binary_logloss: 0.137514\n",
            "[41]\ttraining's auc: 0.884968\ttraining's binary_logloss: 0.122042\tvalid_1's auc: 0.83659\tvalid_1's binary_logloss: 0.137437\n",
            "[42]\ttraining's auc: 0.886116\ttraining's binary_logloss: 0.121719\tvalid_1's auc: 0.836443\tvalid_1's binary_logloss: 0.137359\n",
            "[43]\ttraining's auc: 0.886952\ttraining's binary_logloss: 0.121399\tvalid_1's auc: 0.836492\tvalid_1's binary_logloss: 0.137275\n",
            "[44]\ttraining's auc: 0.88763\ttraining's binary_logloss: 0.12109\tvalid_1's auc: 0.836887\tvalid_1's binary_logloss: 0.137145\n",
            "[45]\ttraining's auc: 0.888324\ttraining's binary_logloss: 0.120793\tvalid_1's auc: 0.836954\tvalid_1's binary_logloss: 0.137054\n",
            "[46]\ttraining's auc: 0.888959\ttraining's binary_logloss: 0.120509\tvalid_1's auc: 0.836903\tvalid_1's binary_logloss: 0.136991\n",
            "[47]\ttraining's auc: 0.889743\ttraining's binary_logloss: 0.120215\tvalid_1's auc: 0.83664\tvalid_1's binary_logloss: 0.136959\n",
            "[48]\ttraining's auc: 0.890095\ttraining's binary_logloss: 0.119973\tvalid_1's auc: 0.836413\tvalid_1's binary_logloss: 0.136922\n",
            "[49]\ttraining's auc: 0.890844\ttraining's binary_logloss: 0.1197\tvalid_1's auc: 0.836803\tvalid_1's binary_logloss: 0.136823\n",
            "[50]\ttraining's auc: 0.891318\ttraining's binary_logloss: 0.119454\tvalid_1's auc: 0.836971\tvalid_1's binary_logloss: 0.136758\n",
            "[51]\ttraining's auc: 0.89182\ttraining's binary_logloss: 0.119214\tvalid_1's auc: 0.837195\tvalid_1's binary_logloss: 0.136691\n",
            "[52]\ttraining's auc: 0.892343\ttraining's binary_logloss: 0.118961\tvalid_1's auc: 0.837173\tvalid_1's binary_logloss: 0.136638\n",
            "[53]\ttraining's auc: 0.892923\ttraining's binary_logloss: 0.118711\tvalid_1's auc: 0.837234\tvalid_1's binary_logloss: 0.136588\n",
            "[54]\ttraining's auc: 0.893618\ttraining's binary_logloss: 0.118466\tvalid_1's auc: 0.837185\tvalid_1's binary_logloss: 0.136559\n",
            "[55]\ttraining's auc: 0.894925\ttraining's binary_logloss: 0.118207\tvalid_1's auc: 0.837033\tvalid_1's binary_logloss: 0.136554\n",
            "[56]\ttraining's auc: 0.895842\ttraining's binary_logloss: 0.117952\tvalid_1's auc: 0.837092\tvalid_1's binary_logloss: 0.136507\n",
            "[57]\ttraining's auc: 0.896469\ttraining's binary_logloss: 0.117701\tvalid_1's auc: 0.836906\tvalid_1's binary_logloss: 0.136498\n",
            "[58]\ttraining's auc: 0.897015\ttraining's binary_logloss: 0.117483\tvalid_1's auc: 0.837038\tvalid_1's binary_logloss: 0.136439\n",
            "[59]\ttraining's auc: 0.897502\ttraining's binary_logloss: 0.117273\tvalid_1's auc: 0.836872\tvalid_1's binary_logloss: 0.136426\n",
            "[60]\ttraining's auc: 0.897977\ttraining's binary_logloss: 0.117093\tvalid_1's auc: 0.836923\tvalid_1's binary_logloss: 0.136394\n",
            "[61]\ttraining's auc: 0.898238\ttraining's binary_logloss: 0.116894\tvalid_1's auc: 0.836829\tvalid_1's binary_logloss: 0.13639\n",
            "[62]\ttraining's auc: 0.898687\ttraining's binary_logloss: 0.116688\tvalid_1's auc: 0.836741\tvalid_1's binary_logloss: 0.136382\n",
            "[63]\ttraining's auc: 0.899163\ttraining's binary_logloss: 0.116486\tvalid_1's auc: 0.836782\tvalid_1's binary_logloss: 0.136377\n",
            "[64]\ttraining's auc: 0.89954\ttraining's binary_logloss: 0.116321\tvalid_1's auc: 0.836753\tvalid_1's binary_logloss: 0.136371\n",
            "[65]\ttraining's auc: 0.899851\ttraining's binary_logloss: 0.116151\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.136353\n",
            "[66]\ttraining's auc: 0.900482\ttraining's binary_logloss: 0.115933\tvalid_1's auc: 0.836398\tvalid_1's binary_logloss: 0.136368\n",
            "[67]\ttraining's auc: 0.900815\ttraining's binary_logloss: 0.115765\tvalid_1's auc: 0.836196\tvalid_1's binary_logloss: 0.136365\n",
            "[68]\ttraining's auc: 0.901326\ttraining's binary_logloss: 0.115591\tvalid_1's auc: 0.836292\tvalid_1's binary_logloss: 0.136336\n",
            "[69]\ttraining's auc: 0.901682\ttraining's binary_logloss: 0.115439\tvalid_1's auc: 0.836439\tvalid_1's binary_logloss: 0.136316\n",
            "[70]\ttraining's auc: 0.901993\ttraining's binary_logloss: 0.115303\tvalid_1's auc: 0.836318\tvalid_1's binary_logloss: 0.136325\n",
            "[71]\ttraining's auc: 0.902389\ttraining's binary_logloss: 0.115138\tvalid_1's auc: 0.836426\tvalid_1's binary_logloss: 0.136291\n",
            "[72]\ttraining's auc: 0.902852\ttraining's binary_logloss: 0.114937\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.136268\n",
            "[73]\ttraining's auc: 0.903535\ttraining's binary_logloss: 0.114681\tvalid_1's auc: 0.836549\tvalid_1's binary_logloss: 0.136243\n",
            "[74]\ttraining's auc: 0.904056\ttraining's binary_logloss: 0.114461\tvalid_1's auc: 0.836538\tvalid_1's binary_logloss: 0.136235\n",
            "[75]\ttraining's auc: 0.904439\ttraining's binary_logloss: 0.1143\tvalid_1's auc: 0.836518\tvalid_1's binary_logloss: 0.136223\n",
            "[76]\ttraining's auc: 0.904778\ttraining's binary_logloss: 0.114149\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.136216\n",
            "[77]\ttraining's auc: 0.905402\ttraining's binary_logloss: 0.113916\tvalid_1's auc: 0.83639\tvalid_1's binary_logloss: 0.136248\n",
            "[78]\ttraining's auc: 0.905888\ttraining's binary_logloss: 0.113705\tvalid_1's auc: 0.836349\tvalid_1's binary_logloss: 0.136272\n",
            "[79]\ttraining's auc: 0.906595\ttraining's binary_logloss: 0.113482\tvalid_1's auc: 0.836343\tvalid_1's binary_logloss: 0.136283\n",
            "[80]\ttraining's auc: 0.906847\ttraining's binary_logloss: 0.113319\tvalid_1's auc: 0.836387\tvalid_1's binary_logloss: 0.136282\n",
            "[81]\ttraining's auc: 0.907284\ttraining's binary_logloss: 0.113135\tvalid_1's auc: 0.836224\tvalid_1's binary_logloss: 0.136319\n",
            "[82]\ttraining's auc: 0.907876\ttraining's binary_logloss: 0.112913\tvalid_1's auc: 0.836273\tvalid_1's binary_logloss: 0.13631\n",
            "[83]\ttraining's auc: 0.908302\ttraining's binary_logloss: 0.112727\tvalid_1's auc: 0.836296\tvalid_1's binary_logloss: 0.13633\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 28%|██▊       | 14/50 [06:53<13:09, 21.94s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.153476\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.156317\n",
            "[2]\ttraining's auc: 0.835546\ttraining's binary_logloss: 0.147391\tvalid_1's auc: 0.810478\tvalid_1's binary_logloss: 0.151555\n",
            "[3]\ttraining's auc: 0.842823\ttraining's binary_logloss: 0.143171\tvalid_1's auc: 0.815104\tvalid_1's binary_logloss: 0.148277\n",
            "[4]\ttraining's auc: 0.848912\ttraining's binary_logloss: 0.139721\tvalid_1's auc: 0.817652\tvalid_1's binary_logloss: 0.145992\n",
            "[5]\ttraining's auc: 0.851455\ttraining's binary_logloss: 0.136922\tvalid_1's auc: 0.818207\tvalid_1's binary_logloss: 0.144175\n",
            "[6]\ttraining's auc: 0.854196\ttraining's binary_logloss: 0.134691\tvalid_1's auc: 0.820411\tvalid_1's binary_logloss: 0.142631\n",
            "[7]\ttraining's auc: 0.856975\ttraining's binary_logloss: 0.132694\tvalid_1's auc: 0.821885\tvalid_1's binary_logloss: 0.141348\n",
            "[8]\ttraining's auc: 0.862264\ttraining's binary_logloss: 0.130995\tvalid_1's auc: 0.821887\tvalid_1's binary_logloss: 0.140595\n",
            "[9]\ttraining's auc: 0.863983\ttraining's binary_logloss: 0.129585\tvalid_1's auc: 0.822562\tvalid_1's binary_logloss: 0.139951\n",
            "[10]\ttraining's auc: 0.86801\ttraining's binary_logloss: 0.128263\tvalid_1's auc: 0.822699\tvalid_1's binary_logloss: 0.139263\n",
            "[11]\ttraining's auc: 0.870449\ttraining's binary_logloss: 0.127047\tvalid_1's auc: 0.824534\tvalid_1's binary_logloss: 0.138632\n",
            "[12]\ttraining's auc: 0.872376\ttraining's binary_logloss: 0.126037\tvalid_1's auc: 0.824318\tvalid_1's binary_logloss: 0.138278\n",
            "[13]\ttraining's auc: 0.873614\ttraining's binary_logloss: 0.125171\tvalid_1's auc: 0.823961\tvalid_1's binary_logloss: 0.137973\n",
            "[14]\ttraining's auc: 0.876249\ttraining's binary_logloss: 0.124339\tvalid_1's auc: 0.824487\tvalid_1's binary_logloss: 0.13769\n",
            "[15]\ttraining's auc: 0.878908\ttraining's binary_logloss: 0.123523\tvalid_1's auc: 0.824749\tvalid_1's binary_logloss: 0.137514\n",
            "[16]\ttraining's auc: 0.88279\ttraining's binary_logloss: 0.122574\tvalid_1's auc: 0.825627\tvalid_1's binary_logloss: 0.137237\n",
            "[17]\ttraining's auc: 0.883901\ttraining's binary_logloss: 0.121926\tvalid_1's auc: 0.825846\tvalid_1's binary_logloss: 0.137118\n",
            "[18]\ttraining's auc: 0.884772\ttraining's binary_logloss: 0.121309\tvalid_1's auc: 0.825746\tvalid_1's binary_logloss: 0.137033\n",
            "[19]\ttraining's auc: 0.887528\ttraining's binary_logloss: 0.120433\tvalid_1's auc: 0.825647\tvalid_1's binary_logloss: 0.137021\n",
            "[20]\ttraining's auc: 0.888622\ttraining's binary_logloss: 0.119831\tvalid_1's auc: 0.825684\tvalid_1's binary_logloss: 0.136911\n",
            "[21]\ttraining's auc: 0.891655\ttraining's binary_logloss: 0.119059\tvalid_1's auc: 0.826395\tvalid_1's binary_logloss: 0.136741\n",
            "[22]\ttraining's auc: 0.892991\ttraining's binary_logloss: 0.118465\tvalid_1's auc: 0.826057\tvalid_1's binary_logloss: 0.13676\n",
            "[23]\ttraining's auc: 0.895143\ttraining's binary_logloss: 0.11782\tvalid_1's auc: 0.826733\tvalid_1's binary_logloss: 0.136597\n",
            "[24]\ttraining's auc: 0.897281\ttraining's binary_logloss: 0.117281\tvalid_1's auc: 0.826465\tvalid_1's binary_logloss: 0.136596\n",
            "[25]\ttraining's auc: 0.897914\ttraining's binary_logloss: 0.116862\tvalid_1's auc: 0.826276\tvalid_1's binary_logloss: 0.136637\n",
            "[26]\ttraining's auc: 0.899349\ttraining's binary_logloss: 0.116273\tvalid_1's auc: 0.826471\tvalid_1's binary_logloss: 0.13663\n",
            "[27]\ttraining's auc: 0.900865\ttraining's binary_logloss: 0.115795\tvalid_1's auc: 0.826334\tvalid_1's binary_logloss: 0.136665\n",
            "[28]\ttraining's auc: 0.901828\ttraining's binary_logloss: 0.115317\tvalid_1's auc: 0.825951\tvalid_1's binary_logloss: 0.136754\n",
            "[29]\ttraining's auc: 0.903751\ttraining's binary_logloss: 0.1148\tvalid_1's auc: 0.826189\tvalid_1's binary_logloss: 0.136771\n",
            "[30]\ttraining's auc: 0.90547\ttraining's binary_logloss: 0.114412\tvalid_1's auc: 0.826777\tvalid_1's binary_logloss: 0.13668\n",
            "[31]\ttraining's auc: 0.906574\ttraining's binary_logloss: 0.11398\tvalid_1's auc: 0.826557\tvalid_1's binary_logloss: 0.136772\n",
            "[32]\ttraining's auc: 0.907493\ttraining's binary_logloss: 0.113591\tvalid_1's auc: 0.827001\tvalid_1's binary_logloss: 0.136744\n",
            "[33]\ttraining's auc: 0.908307\ttraining's binary_logloss: 0.113165\tvalid_1's auc: 0.826524\tvalid_1's binary_logloss: 0.136823\n",
            "[34]\ttraining's auc: 0.909157\ttraining's binary_logloss: 0.112782\tvalid_1's auc: 0.826468\tvalid_1's binary_logloss: 0.136894\n",
            "[35]\ttraining's auc: 0.91007\ttraining's binary_logloss: 0.112398\tvalid_1's auc: 0.82657\tvalid_1's binary_logloss: 0.136922\n",
            "[36]\ttraining's auc: 0.910718\ttraining's binary_logloss: 0.11204\tvalid_1's auc: 0.82639\tvalid_1's binary_logloss: 0.137\n",
            "[37]\ttraining's auc: 0.911666\ttraining's binary_logloss: 0.111663\tvalid_1's auc: 0.826036\tvalid_1's binary_logloss: 0.137075\n",
            "[38]\ttraining's auc: 0.912932\ttraining's binary_logloss: 0.111187\tvalid_1's auc: 0.825916\tvalid_1's binary_logloss: 0.137053\n",
            "[39]\ttraining's auc: 0.913761\ttraining's binary_logloss: 0.110822\tvalid_1's auc: 0.825473\tvalid_1's binary_logloss: 0.137129\n",
            "[40]\ttraining's auc: 0.914486\ttraining's binary_logloss: 0.110503\tvalid_1's auc: 0.825422\tvalid_1's binary_logloss: 0.137151\n",
            "[41]\ttraining's auc: 0.915456\ttraining's binary_logloss: 0.110127\tvalid_1's auc: 0.825105\tvalid_1's binary_logloss: 0.137249\n",
            "[42]\ttraining's auc: 0.916086\ttraining's binary_logloss: 0.109823\tvalid_1's auc: 0.824979\tvalid_1's binary_logloss: 0.137322\n",
            "[43]\ttraining's auc: 0.916963\ttraining's binary_logloss: 0.109418\tvalid_1's auc: 0.825219\tvalid_1's binary_logloss: 0.137284\n",
            "[44]\ttraining's auc: 0.918276\ttraining's binary_logloss: 0.109026\tvalid_1's auc: 0.824809\tvalid_1's binary_logloss: 0.137443\n",
            "[45]\ttraining's auc: 0.919696\ttraining's binary_logloss: 0.108677\tvalid_1's auc: 0.824653\tvalid_1's binary_logloss: 0.137458\n",
            "[46]\ttraining's auc: 0.920562\ttraining's binary_logloss: 0.108381\tvalid_1's auc: 0.824681\tvalid_1's binary_logloss: 0.137486\n",
            "[47]\ttraining's auc: 0.920965\ttraining's binary_logloss: 0.108066\tvalid_1's auc: 0.824253\tvalid_1's binary_logloss: 0.137628\n",
            "[48]\ttraining's auc: 0.921269\ttraining's binary_logloss: 0.107869\tvalid_1's auc: 0.823806\tvalid_1's binary_logloss: 0.137754\n",
            "[49]\ttraining's auc: 0.92238\ttraining's binary_logloss: 0.107435\tvalid_1's auc: 0.823314\tvalid_1's binary_logloss: 0.137865\n",
            "[50]\ttraining's auc: 0.922752\ttraining's binary_logloss: 0.10715\tvalid_1's auc: 0.823151\tvalid_1's binary_logloss: 0.137954\n",
            "[51]\ttraining's auc: 0.923262\ttraining's binary_logloss: 0.106849\tvalid_1's auc: 0.82298\tvalid_1's binary_logloss: 0.138009\n",
            "[52]\ttraining's auc: 0.923782\ttraining's binary_logloss: 0.10655\tvalid_1's auc: 0.822951\tvalid_1's binary_logloss: 0.138038\n",
            "[53]\ttraining's auc: 0.924398\ttraining's binary_logloss: 0.106229\tvalid_1's auc: 0.822697\tvalid_1's binary_logloss: 0.138137\n",
            "[54]\ttraining's auc: 0.924632\ttraining's binary_logloss: 0.106045\tvalid_1's auc: 0.822626\tvalid_1's binary_logloss: 0.138193\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 28%|██▊       | 14/50 [06:57<13:09, 21.94s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.155912\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.15238\n",
            "[2]\ttraining's auc: 0.83171\ttraining's binary_logloss: 0.149712\tvalid_1's auc: 0.81676\tvalid_1's binary_logloss: 0.147581\n",
            "[3]\ttraining's auc: 0.839282\ttraining's binary_logloss: 0.145238\tvalid_1's auc: 0.820621\tvalid_1's binary_logloss: 0.144261\n",
            "[4]\ttraining's auc: 0.847261\ttraining's binary_logloss: 0.141834\tvalid_1's auc: 0.826211\tvalid_1's binary_logloss: 0.141853\n",
            "[5]\ttraining's auc: 0.852588\ttraining's binary_logloss: 0.13915\tvalid_1's auc: 0.828734\tvalid_1's binary_logloss: 0.140063\n",
            "[6]\ttraining's auc: 0.856757\ttraining's binary_logloss: 0.136796\tvalid_1's auc: 0.830643\tvalid_1's binary_logloss: 0.13856\n",
            "[7]\ttraining's auc: 0.858448\ttraining's binary_logloss: 0.134926\tvalid_1's auc: 0.830798\tvalid_1's binary_logloss: 0.1373\n",
            "[8]\ttraining's auc: 0.861428\ttraining's binary_logloss: 0.13327\tvalid_1's auc: 0.831818\tvalid_1's binary_logloss: 0.136275\n",
            "[9]\ttraining's auc: 0.866605\ttraining's binary_logloss: 0.131716\tvalid_1's auc: 0.832413\tvalid_1's binary_logloss: 0.135503\n",
            "[10]\ttraining's auc: 0.86941\ttraining's binary_logloss: 0.130314\tvalid_1's auc: 0.833124\tvalid_1's binary_logloss: 0.134745\n",
            "[11]\ttraining's auc: 0.871058\ttraining's binary_logloss: 0.129105\tvalid_1's auc: 0.83297\tvalid_1's binary_logloss: 0.134238\n",
            "[12]\ttraining's auc: 0.872357\ttraining's binary_logloss: 0.12809\tvalid_1's auc: 0.832213\tvalid_1's binary_logloss: 0.133919\n",
            "[13]\ttraining's auc: 0.874611\ttraining's binary_logloss: 0.127084\tvalid_1's auc: 0.833507\tvalid_1's binary_logloss: 0.133463\n",
            "[14]\ttraining's auc: 0.876866\ttraining's binary_logloss: 0.126091\tvalid_1's auc: 0.833538\tvalid_1's binary_logloss: 0.133219\n",
            "[15]\ttraining's auc: 0.878771\ttraining's binary_logloss: 0.125097\tvalid_1's auc: 0.832872\tvalid_1's binary_logloss: 0.133045\n",
            "[16]\ttraining's auc: 0.880621\ttraining's binary_logloss: 0.124247\tvalid_1's auc: 0.832688\tvalid_1's binary_logloss: 0.13283\n",
            "[17]\ttraining's auc: 0.881618\ttraining's binary_logloss: 0.123532\tvalid_1's auc: 0.832847\tvalid_1's binary_logloss: 0.132699\n",
            "[18]\ttraining's auc: 0.884348\ttraining's binary_logloss: 0.122698\tvalid_1's auc: 0.833443\tvalid_1's binary_logloss: 0.132495\n",
            "[19]\ttraining's auc: 0.886851\ttraining's binary_logloss: 0.121879\tvalid_1's auc: 0.83443\tvalid_1's binary_logloss: 0.132292\n",
            "[20]\ttraining's auc: 0.890007\ttraining's binary_logloss: 0.121153\tvalid_1's auc: 0.83426\tvalid_1's binary_logloss: 0.132231\n",
            "[21]\ttraining's auc: 0.892039\ttraining's binary_logloss: 0.120519\tvalid_1's auc: 0.83468\tvalid_1's binary_logloss: 0.132086\n",
            "[22]\ttraining's auc: 0.893274\ttraining's binary_logloss: 0.119925\tvalid_1's auc: 0.834829\tvalid_1's binary_logloss: 0.131904\n",
            "[23]\ttraining's auc: 0.894984\ttraining's binary_logloss: 0.119328\tvalid_1's auc: 0.834842\tvalid_1's binary_logloss: 0.131833\n",
            "[24]\ttraining's auc: 0.895835\ttraining's binary_logloss: 0.118803\tvalid_1's auc: 0.834858\tvalid_1's binary_logloss: 0.131766\n",
            "[25]\ttraining's auc: 0.896815\ttraining's binary_logloss: 0.118318\tvalid_1's auc: 0.834952\tvalid_1's binary_logloss: 0.131684\n",
            "[26]\ttraining's auc: 0.898076\ttraining's binary_logloss: 0.117869\tvalid_1's auc: 0.834776\tvalid_1's binary_logloss: 0.131637\n",
            "[27]\ttraining's auc: 0.899096\ttraining's binary_logloss: 0.117416\tvalid_1's auc: 0.834795\tvalid_1's binary_logloss: 0.131612\n",
            "[28]\ttraining's auc: 0.900467\ttraining's binary_logloss: 0.116985\tvalid_1's auc: 0.834581\tvalid_1's binary_logloss: 0.13162\n",
            "[29]\ttraining's auc: 0.902078\ttraining's binary_logloss: 0.116478\tvalid_1's auc: 0.834373\tvalid_1's binary_logloss: 0.131673\n",
            "[30]\ttraining's auc: 0.903236\ttraining's binary_logloss: 0.116112\tvalid_1's auc: 0.834566\tvalid_1's binary_logloss: 0.131642\n",
            "[31]\ttraining's auc: 0.904335\ttraining's binary_logloss: 0.115602\tvalid_1's auc: 0.83415\tvalid_1's binary_logloss: 0.131743\n",
            "[32]\ttraining's auc: 0.905562\ttraining's binary_logloss: 0.115129\tvalid_1's auc: 0.833842\tvalid_1's binary_logloss: 0.131787\n",
            "[33]\ttraining's auc: 0.906271\ttraining's binary_logloss: 0.114694\tvalid_1's auc: 0.833872\tvalid_1's binary_logloss: 0.131779\n",
            "[34]\ttraining's auc: 0.907325\ttraining's binary_logloss: 0.114218\tvalid_1's auc: 0.833495\tvalid_1's binary_logloss: 0.131887\n",
            "[35]\ttraining's auc: 0.908168\ttraining's binary_logloss: 0.113859\tvalid_1's auc: 0.833801\tvalid_1's binary_logloss: 0.131824\n",
            "[36]\ttraining's auc: 0.909449\ttraining's binary_logloss: 0.113361\tvalid_1's auc: 0.833618\tvalid_1's binary_logloss: 0.131838\n",
            "[37]\ttraining's auc: 0.910078\ttraining's binary_logloss: 0.113062\tvalid_1's auc: 0.833327\tvalid_1's binary_logloss: 0.131857\n",
            "[38]\ttraining's auc: 0.911798\ttraining's binary_logloss: 0.11261\tvalid_1's auc: 0.833373\tvalid_1's binary_logloss: 0.131878\n",
            "[39]\ttraining's auc: 0.912968\ttraining's binary_logloss: 0.11215\tvalid_1's auc: 0.833393\tvalid_1's binary_logloss: 0.131914\n",
            "[40]\ttraining's auc: 0.913778\ttraining's binary_logloss: 0.111778\tvalid_1's auc: 0.833341\tvalid_1's binary_logloss: 0.131932\n",
            "[41]\ttraining's auc: 0.914369\ttraining's binary_logloss: 0.111502\tvalid_1's auc: 0.833538\tvalid_1's binary_logloss: 0.131892\n",
            "[42]\ttraining's auc: 0.914862\ttraining's binary_logloss: 0.111185\tvalid_1's auc: 0.834052\tvalid_1's binary_logloss: 0.131805\n",
            "[43]\ttraining's auc: 0.915527\ttraining's binary_logloss: 0.110837\tvalid_1's auc: 0.833652\tvalid_1's binary_logloss: 0.131869\n",
            "[44]\ttraining's auc: 0.916194\ttraining's binary_logloss: 0.110512\tvalid_1's auc: 0.833485\tvalid_1's binary_logloss: 0.131908\n",
            "[45]\ttraining's auc: 0.916877\ttraining's binary_logloss: 0.110164\tvalid_1's auc: 0.833599\tvalid_1's binary_logloss: 0.131887\n",
            "[46]\ttraining's auc: 0.917729\ttraining's binary_logloss: 0.109771\tvalid_1's auc: 0.833416\tvalid_1's binary_logloss: 0.131909\n",
            "[47]\ttraining's auc: 0.918167\ttraining's binary_logloss: 0.109518\tvalid_1's auc: 0.833565\tvalid_1's binary_logloss: 0.131875\n",
            "[48]\ttraining's auc: 0.919225\ttraining's binary_logloss: 0.109249\tvalid_1's auc: 0.833634\tvalid_1's binary_logloss: 0.131885\n",
            "[49]\ttraining's auc: 0.919771\ttraining's binary_logloss: 0.109019\tvalid_1's auc: 0.833677\tvalid_1's binary_logloss: 0.131935\n",
            "[50]\ttraining's auc: 0.920803\ttraining's binary_logloss: 0.108653\tvalid_1's auc: 0.833442\tvalid_1's binary_logloss: 0.131937\n",
            "[51]\ttraining's auc: 0.92117\ttraining's binary_logloss: 0.108438\tvalid_1's auc: 0.833345\tvalid_1's binary_logloss: 0.13195\n",
            "[52]\ttraining's auc: 0.921462\ttraining's binary_logloss: 0.108236\tvalid_1's auc: 0.833148\tvalid_1's binary_logloss: 0.131985\n",
            "[53]\ttraining's auc: 0.921868\ttraining's binary_logloss: 0.107997\tvalid_1's auc: 0.832696\tvalid_1's binary_logloss: 0.132068\n",
            "[54]\ttraining's auc: 0.922055\ttraining's binary_logloss: 0.107825\tvalid_1's auc: 0.832423\tvalid_1's binary_logloss: 0.132094\n",
            "[55]\ttraining's auc: 0.923098\ttraining's binary_logloss: 0.107504\tvalid_1's auc: 0.832357\tvalid_1's binary_logloss: 0.132124\n",
            " 28%|██▊       | 14/50 [07:05<13:09, 21.94s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.152714\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.159206\n",
            "[2]\ttraining's auc: 0.834332\ttraining's binary_logloss: 0.146848\tvalid_1's auc: 0.816885\tvalid_1's binary_logloss: 0.153912\n",
            "[3]\ttraining's auc: 0.845843\ttraining's binary_logloss: 0.142449\tvalid_1's auc: 0.824245\tvalid_1's binary_logloss: 0.150232\n",
            "[4]\ttraining's auc: 0.848861\ttraining's binary_logloss: 0.139036\tvalid_1's auc: 0.826548\tvalid_1's binary_logloss: 0.147507\n",
            "[5]\ttraining's auc: 0.851519\ttraining's binary_logloss: 0.136351\tvalid_1's auc: 0.827138\tvalid_1's binary_logloss: 0.145455\n",
            "[6]\ttraining's auc: 0.856282\ttraining's binary_logloss: 0.134152\tvalid_1's auc: 0.829187\tvalid_1's binary_logloss: 0.14381\n",
            "[7]\ttraining's auc: 0.858275\ttraining's binary_logloss: 0.132323\tvalid_1's auc: 0.829811\tvalid_1's binary_logloss: 0.142559\n",
            "[8]\ttraining's auc: 0.862493\ttraining's binary_logloss: 0.130716\tvalid_1's auc: 0.829851\tvalid_1's binary_logloss: 0.141561\n",
            "[9]\ttraining's auc: 0.866422\ttraining's binary_logloss: 0.129216\tvalid_1's auc: 0.831191\tvalid_1's binary_logloss: 0.140622\n",
            "[10]\ttraining's auc: 0.869721\ttraining's binary_logloss: 0.127862\tvalid_1's auc: 0.832593\tvalid_1's binary_logloss: 0.13996\n",
            "[11]\ttraining's auc: 0.871721\ttraining's binary_logloss: 0.126709\tvalid_1's auc: 0.83398\tvalid_1's binary_logloss: 0.1392\n",
            "[12]\ttraining's auc: 0.875178\ttraining's binary_logloss: 0.125611\tvalid_1's auc: 0.834869\tvalid_1's binary_logloss: 0.138724\n",
            "[13]\ttraining's auc: 0.877614\ttraining's binary_logloss: 0.124628\tvalid_1's auc: 0.834217\tvalid_1's binary_logloss: 0.138313\n",
            "[14]\ttraining's auc: 0.879193\ttraining's binary_logloss: 0.123771\tvalid_1's auc: 0.833699\tvalid_1's binary_logloss: 0.138075\n",
            "[15]\ttraining's auc: 0.880466\ttraining's binary_logloss: 0.122949\tvalid_1's auc: 0.833904\tvalid_1's binary_logloss: 0.137853\n",
            "[16]\ttraining's auc: 0.883153\ttraining's binary_logloss: 0.122048\tvalid_1's auc: 0.833699\tvalid_1's binary_logloss: 0.137725\n",
            "[17]\ttraining's auc: 0.88611\ttraining's binary_logloss: 0.121172\tvalid_1's auc: 0.83395\tvalid_1's binary_logloss: 0.137529\n",
            "[18]\ttraining's auc: 0.887506\ttraining's binary_logloss: 0.120465\tvalid_1's auc: 0.834318\tvalid_1's binary_logloss: 0.137317\n",
            "[19]\ttraining's auc: 0.889867\ttraining's binary_logloss: 0.119721\tvalid_1's auc: 0.833997\tvalid_1's binary_logloss: 0.137235\n",
            "[20]\ttraining's auc: 0.891369\ttraining's binary_logloss: 0.119151\tvalid_1's auc: 0.834944\tvalid_1's binary_logloss: 0.137067\n",
            "[21]\ttraining's auc: 0.8929\ttraining's binary_logloss: 0.118532\tvalid_1's auc: 0.834914\tvalid_1's binary_logloss: 0.136975\n",
            "[22]\ttraining's auc: 0.8943\ttraining's binary_logloss: 0.1179\tvalid_1's auc: 0.835284\tvalid_1's binary_logloss: 0.136849\n",
            "[23]\ttraining's auc: 0.896501\ttraining's binary_logloss: 0.117363\tvalid_1's auc: 0.834916\tvalid_1's binary_logloss: 0.136858\n",
            "[24]\ttraining's auc: 0.898336\ttraining's binary_logloss: 0.116762\tvalid_1's auc: 0.834417\tvalid_1's binary_logloss: 0.136857\n",
            "[25]\ttraining's auc: 0.899654\ttraining's binary_logloss: 0.116254\tvalid_1's auc: 0.833825\tvalid_1's binary_logloss: 0.136933\n",
            "[26]\ttraining's auc: 0.900765\ttraining's binary_logloss: 0.115777\tvalid_1's auc: 0.833403\tvalid_1's binary_logloss: 0.136905\n",
            "[27]\ttraining's auc: 0.901751\ttraining's binary_logloss: 0.115246\tvalid_1's auc: 0.834021\tvalid_1's binary_logloss: 0.136743\n",
            "[28]\ttraining's auc: 0.902916\ttraining's binary_logloss: 0.11472\tvalid_1's auc: 0.833642\tvalid_1's binary_logloss: 0.136843\n",
            "[29]\ttraining's auc: 0.904045\ttraining's binary_logloss: 0.114284\tvalid_1's auc: 0.833437\tvalid_1's binary_logloss: 0.136857\n",
            "[30]\ttraining's auc: 0.905271\ttraining's binary_logloss: 0.113708\tvalid_1's auc: 0.833494\tvalid_1's binary_logloss: 0.136818\n",
            "[31]\ttraining's auc: 0.906263\ttraining's binary_logloss: 0.113286\tvalid_1's auc: 0.833357\tvalid_1's binary_logloss: 0.136817\n",
            "[32]\ttraining's auc: 0.908107\ttraining's binary_logloss: 0.112706\tvalid_1's auc: 0.833121\tvalid_1's binary_logloss: 0.136835\n",
            "[33]\ttraining's auc: 0.909396\ttraining's binary_logloss: 0.112176\tvalid_1's auc: 0.833114\tvalid_1's binary_logloss: 0.136932\n",
            "[34]\ttraining's auc: 0.910263\ttraining's binary_logloss: 0.111847\tvalid_1's auc: 0.83371\tvalid_1's binary_logloss: 0.136857\n",
            "[35]\ttraining's auc: 0.910958\ttraining's binary_logloss: 0.111443\tvalid_1's auc: 0.833813\tvalid_1's binary_logloss: 0.13682\n",
            "[36]\ttraining's auc: 0.91164\ttraining's binary_logloss: 0.111097\tvalid_1's auc: 0.833714\tvalid_1's binary_logloss: 0.136848\n",
            "[37]\ttraining's auc: 0.912431\ttraining's binary_logloss: 0.110716\tvalid_1's auc: 0.833587\tvalid_1's binary_logloss: 0.136889\n",
            "[38]\ttraining's auc: 0.913224\ttraining's binary_logloss: 0.110347\tvalid_1's auc: 0.833507\tvalid_1's binary_logloss: 0.136945\n",
            "[39]\ttraining's auc: 0.91387\ttraining's binary_logloss: 0.109976\tvalid_1's auc: 0.833421\tvalid_1's binary_logloss: 0.136949\n",
            "[40]\ttraining's auc: 0.914466\ttraining's binary_logloss: 0.109648\tvalid_1's auc: 0.833195\tvalid_1's binary_logloss: 0.13698\n",
            "[41]\ttraining's auc: 0.915073\ttraining's binary_logloss: 0.10939\tvalid_1's auc: 0.833261\tvalid_1's binary_logloss: 0.13699\n",
            "[42]\ttraining's auc: 0.916094\ttraining's binary_logloss: 0.108935\tvalid_1's auc: 0.833417\tvalid_1's binary_logloss: 0.137005\n",
            "[43]\ttraining's auc: 0.916957\ttraining's binary_logloss: 0.108567\tvalid_1's auc: 0.833442\tvalid_1's binary_logloss: 0.137086\n",
            "[44]\ttraining's auc: 0.9174\ttraining's binary_logloss: 0.108234\tvalid_1's auc: 0.833211\tvalid_1's binary_logloss: 0.137098\n",
            "[45]\ttraining's auc: 0.918565\ttraining's binary_logloss: 0.107757\tvalid_1's auc: 0.833145\tvalid_1's binary_logloss: 0.137134\n",
            "[46]\ttraining's auc: 0.919414\ttraining's binary_logloss: 0.107401\tvalid_1's auc: 0.832836\tvalid_1's binary_logloss: 0.137217\n",
            "[47]\ttraining's auc: 0.919713\ttraining's binary_logloss: 0.107195\tvalid_1's auc: 0.832838\tvalid_1's binary_logloss: 0.13724\n",
            "[48]\ttraining's auc: 0.920973\ttraining's binary_logloss: 0.106746\tvalid_1's auc: 0.832415\tvalid_1's binary_logloss: 0.137336\n",
            "[49]\ttraining's auc: 0.921634\ttraining's binary_logloss: 0.106381\tvalid_1's auc: 0.83234\tvalid_1's binary_logloss: 0.137348\n",
            "[50]\ttraining's auc: 0.921837\ttraining's binary_logloss: 0.106199\tvalid_1's auc: 0.83226\tvalid_1's binary_logloss: 0.137394\n",
            "[51]\ttraining's auc: 0.922329\ttraining's binary_logloss: 0.105913\tvalid_1's auc: 0.832212\tvalid_1's binary_logloss: 0.137434\n",
            "[52]\ttraining's auc: 0.923613\ttraining's binary_logloss: 0.105477\tvalid_1's auc: 0.832034\tvalid_1's binary_logloss: 0.137488\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 30%|███       | 15/50 [07:09<11:48, 20.25s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.159311\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.161068\n",
            "[2]\ttraining's auc: 0.832577\ttraining's binary_logloss: 0.155351\tvalid_1's auc: 0.805536\tvalid_1's binary_logloss: 0.158047\n",
            "[3]\ttraining's auc: 0.833816\ttraining's binary_logloss: 0.152177\tvalid_1's auc: 0.8068\tvalid_1's binary_logloss: 0.155561\n",
            "[4]\ttraining's auc: 0.839631\ttraining's binary_logloss: 0.149516\tvalid_1's auc: 0.813082\tvalid_1's binary_logloss: 0.153337\n",
            "[5]\ttraining's auc: 0.844463\ttraining's binary_logloss: 0.147221\tvalid_1's auc: 0.813937\tvalid_1's binary_logloss: 0.151596\n",
            "[6]\ttraining's auc: 0.847206\ttraining's binary_logloss: 0.145177\tvalid_1's auc: 0.816337\tvalid_1's binary_logloss: 0.150103\n",
            "[7]\ttraining's auc: 0.849649\ttraining's binary_logloss: 0.143338\tvalid_1's auc: 0.818187\tvalid_1's binary_logloss: 0.148712\n",
            "[8]\ttraining's auc: 0.851089\ttraining's binary_logloss: 0.141682\tvalid_1's auc: 0.819413\tvalid_1's binary_logloss: 0.147553\n",
            "[9]\ttraining's auc: 0.85214\ttraining's binary_logloss: 0.14022\tvalid_1's auc: 0.821015\tvalid_1's binary_logloss: 0.146439\n",
            "[10]\ttraining's auc: 0.853747\ttraining's binary_logloss: 0.13887\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.145578\n",
            "[11]\ttraining's auc: 0.854962\ttraining's binary_logloss: 0.137606\tvalid_1's auc: 0.82173\tvalid_1's binary_logloss: 0.144688\n",
            "[12]\ttraining's auc: 0.857267\ttraining's binary_logloss: 0.136487\tvalid_1's auc: 0.823098\tvalid_1's binary_logloss: 0.14388\n",
            "[13]\ttraining's auc: 0.857999\ttraining's binary_logloss: 0.135434\tvalid_1's auc: 0.822858\tvalid_1's binary_logloss: 0.143265\n",
            "[14]\ttraining's auc: 0.860326\ttraining's binary_logloss: 0.134508\tvalid_1's auc: 0.823319\tvalid_1's binary_logloss: 0.142666\n",
            "[15]\ttraining's auc: 0.861516\ttraining's binary_logloss: 0.133557\tvalid_1's auc: 0.823606\tvalid_1's binary_logloss: 0.142053\n",
            "[16]\ttraining's auc: 0.863812\ttraining's binary_logloss: 0.132679\tvalid_1's auc: 0.824417\tvalid_1's binary_logloss: 0.141513\n",
            "[17]\ttraining's auc: 0.865698\ttraining's binary_logloss: 0.1319\tvalid_1's auc: 0.824974\tvalid_1's binary_logloss: 0.141037\n",
            "[18]\ttraining's auc: 0.866733\ttraining's binary_logloss: 0.131181\tvalid_1's auc: 0.825423\tvalid_1's binary_logloss: 0.14063\n",
            "[19]\ttraining's auc: 0.867782\ttraining's binary_logloss: 0.130516\tvalid_1's auc: 0.825346\tvalid_1's binary_logloss: 0.140275\n",
            "[20]\ttraining's auc: 0.868427\ttraining's binary_logloss: 0.129833\tvalid_1's auc: 0.826416\tvalid_1's binary_logloss: 0.139861\n",
            "[21]\ttraining's auc: 0.870041\ttraining's binary_logloss: 0.129213\tvalid_1's auc: 0.826722\tvalid_1's binary_logloss: 0.139528\n",
            "[22]\ttraining's auc: 0.870819\ttraining's binary_logloss: 0.128676\tvalid_1's auc: 0.82679\tvalid_1's binary_logloss: 0.139234\n",
            "[23]\ttraining's auc: 0.872137\ttraining's binary_logloss: 0.128065\tvalid_1's auc: 0.827172\tvalid_1's binary_logloss: 0.138936\n",
            "[24]\ttraining's auc: 0.873227\ttraining's binary_logloss: 0.127487\tvalid_1's auc: 0.82744\tvalid_1's binary_logloss: 0.138701\n",
            "[25]\ttraining's auc: 0.874218\ttraining's binary_logloss: 0.12699\tvalid_1's auc: 0.827215\tvalid_1's binary_logloss: 0.138525\n",
            "[26]\ttraining's auc: 0.874973\ttraining's binary_logloss: 0.126503\tvalid_1's auc: 0.827358\tvalid_1's binary_logloss: 0.138301\n",
            "[27]\ttraining's auc: 0.876028\ttraining's binary_logloss: 0.126027\tvalid_1's auc: 0.827729\tvalid_1's binary_logloss: 0.138104\n",
            "[28]\ttraining's auc: 0.876758\ttraining's binary_logloss: 0.125571\tvalid_1's auc: 0.827567\tvalid_1's binary_logloss: 0.137933\n",
            "[29]\ttraining's auc: 0.877272\ttraining's binary_logloss: 0.125167\tvalid_1's auc: 0.828029\tvalid_1's binary_logloss: 0.137778\n",
            "[30]\ttraining's auc: 0.879813\ttraining's binary_logloss: 0.124651\tvalid_1's auc: 0.82832\tvalid_1's binary_logloss: 0.13761\n",
            "[31]\ttraining's auc: 0.880636\ttraining's binary_logloss: 0.124247\tvalid_1's auc: 0.82818\tvalid_1's binary_logloss: 0.137477\n",
            "[32]\ttraining's auc: 0.881459\ttraining's binary_logloss: 0.123849\tvalid_1's auc: 0.828679\tvalid_1's binary_logloss: 0.137353\n",
            "[33]\ttraining's auc: 0.882212\ttraining's binary_logloss: 0.123455\tvalid_1's auc: 0.82885\tvalid_1's binary_logloss: 0.137232\n",
            "[34]\ttraining's auc: 0.88351\ttraining's binary_logloss: 0.123061\tvalid_1's auc: 0.828949\tvalid_1's binary_logloss: 0.13711\n",
            "[35]\ttraining's auc: 0.884709\ttraining's binary_logloss: 0.122678\tvalid_1's auc: 0.829354\tvalid_1's binary_logloss: 0.136969\n",
            "[36]\ttraining's auc: 0.885275\ttraining's binary_logloss: 0.122336\tvalid_1's auc: 0.829411\tvalid_1's binary_logloss: 0.136926\n",
            "[37]\ttraining's auc: 0.885698\ttraining's binary_logloss: 0.121993\tvalid_1's auc: 0.829646\tvalid_1's binary_logloss: 0.136827\n",
            "[38]\ttraining's auc: 0.886407\ttraining's binary_logloss: 0.121659\tvalid_1's auc: 0.829742\tvalid_1's binary_logloss: 0.136739\n",
            "[39]\ttraining's auc: 0.887398\ttraining's binary_logloss: 0.121271\tvalid_1's auc: 0.830265\tvalid_1's binary_logloss: 0.136634\n",
            "[40]\ttraining's auc: 0.888381\ttraining's binary_logloss: 0.12091\tvalid_1's auc: 0.830283\tvalid_1's binary_logloss: 0.136583\n",
            "[41]\ttraining's auc: 0.889089\ttraining's binary_logloss: 0.120598\tvalid_1's auc: 0.830233\tvalid_1's binary_logloss: 0.136548\n",
            "[42]\ttraining's auc: 0.889823\ttraining's binary_logloss: 0.120298\tvalid_1's auc: 0.830233\tvalid_1's binary_logloss: 0.136512\n",
            "[43]\ttraining's auc: 0.890501\ttraining's binary_logloss: 0.12\tvalid_1's auc: 0.830054\tvalid_1's binary_logloss: 0.136493\n",
            "[44]\ttraining's auc: 0.891636\ttraining's binary_logloss: 0.11966\tvalid_1's auc: 0.830259\tvalid_1's binary_logloss: 0.136407\n",
            "[45]\ttraining's auc: 0.892119\ttraining's binary_logloss: 0.119359\tvalid_1's auc: 0.830439\tvalid_1's binary_logloss: 0.136337\n",
            "[46]\ttraining's auc: 0.892499\ttraining's binary_logloss: 0.119094\tvalid_1's auc: 0.830489\tvalid_1's binary_logloss: 0.136308\n",
            "[47]\ttraining's auc: 0.893711\ttraining's binary_logloss: 0.118752\tvalid_1's auc: 0.831128\tvalid_1's binary_logloss: 0.136214\n",
            "[48]\ttraining's auc: 0.894231\ttraining's binary_logloss: 0.118513\tvalid_1's auc: 0.831191\tvalid_1's binary_logloss: 0.136174\n",
            "[49]\ttraining's auc: 0.894797\ttraining's binary_logloss: 0.118248\tvalid_1's auc: 0.831053\tvalid_1's binary_logloss: 0.136182\n",
            "[50]\ttraining's auc: 0.89568\ttraining's binary_logloss: 0.117965\tvalid_1's auc: 0.830935\tvalid_1's binary_logloss: 0.136188\n",
            "[51]\ttraining's auc: 0.896764\ttraining's binary_logloss: 0.117666\tvalid_1's auc: 0.83142\tvalid_1's binary_logloss: 0.136102\n",
            "[52]\ttraining's auc: 0.897242\ttraining's binary_logloss: 0.117436\tvalid_1's auc: 0.831247\tvalid_1's binary_logloss: 0.136105\n",
            "[53]\ttraining's auc: 0.897651\ttraining's binary_logloss: 0.117227\tvalid_1's auc: 0.831048\tvalid_1's binary_logloss: 0.136115\n",
            "[54]\ttraining's auc: 0.898029\ttraining's binary_logloss: 0.117011\tvalid_1's auc: 0.830787\tvalid_1's binary_logloss: 0.13614\n",
            "[55]\ttraining's auc: 0.898739\ttraining's binary_logloss: 0.116766\tvalid_1's auc: 0.830995\tvalid_1's binary_logloss: 0.136074\n",
            "[56]\ttraining's auc: 0.899151\ttraining's binary_logloss: 0.11655\tvalid_1's auc: 0.831002\tvalid_1's binary_logloss: 0.136062\n",
            "[57]\ttraining's auc: 0.899632\ttraining's binary_logloss: 0.116327\tvalid_1's auc: 0.830978\tvalid_1's binary_logloss: 0.136054\n",
            "[58]\ttraining's auc: 0.900009\ttraining's binary_logloss: 0.116121\tvalid_1's auc: 0.831146\tvalid_1's binary_logloss: 0.136002\n",
            "[59]\ttraining's auc: 0.90063\ttraining's binary_logloss: 0.115891\tvalid_1's auc: 0.831148\tvalid_1's binary_logloss: 0.135997\n",
            "[60]\ttraining's auc: 0.901212\ttraining's binary_logloss: 0.115701\tvalid_1's auc: 0.831075\tvalid_1's binary_logloss: 0.136005\n",
            "[61]\ttraining's auc: 0.902228\ttraining's binary_logloss: 0.115454\tvalid_1's auc: 0.83148\tvalid_1's binary_logloss: 0.135944\n",
            "[62]\ttraining's auc: 0.902866\ttraining's binary_logloss: 0.115264\tvalid_1's auc: 0.831515\tvalid_1's binary_logloss: 0.135916\n",
            "[63]\ttraining's auc: 0.903524\ttraining's binary_logloss: 0.115035\tvalid_1's auc: 0.831667\tvalid_1's binary_logloss: 0.135893\n",
            "[64]\ttraining's auc: 0.904156\ttraining's binary_logloss: 0.114856\tvalid_1's auc: 0.831507\tvalid_1's binary_logloss: 0.135928\n",
            "[65]\ttraining's auc: 0.904912\ttraining's binary_logloss: 0.114615\tvalid_1's auc: 0.831237\tvalid_1's binary_logloss: 0.135952\n",
            "[66]\ttraining's auc: 0.905371\ttraining's binary_logloss: 0.114395\tvalid_1's auc: 0.831285\tvalid_1's binary_logloss: 0.135947\n",
            "[67]\ttraining's auc: 0.905856\ttraining's binary_logloss: 0.114201\tvalid_1's auc: 0.831487\tvalid_1's binary_logloss: 0.135918\n",
            "[68]\ttraining's auc: 0.906274\ttraining's binary_logloss: 0.113983\tvalid_1's auc: 0.831319\tvalid_1's binary_logloss: 0.135954\n",
            "[69]\ttraining's auc: 0.906909\ttraining's binary_logloss: 0.11378\tvalid_1's auc: 0.831184\tvalid_1's binary_logloss: 0.135989\n",
            "[70]\ttraining's auc: 0.907726\ttraining's binary_logloss: 0.11357\tvalid_1's auc: 0.831099\tvalid_1's binary_logloss: 0.135995\n",
            "[71]\ttraining's auc: 0.908195\ttraining's binary_logloss: 0.113345\tvalid_1's auc: 0.831198\tvalid_1's binary_logloss: 0.135988\n",
            "[72]\ttraining's auc: 0.908685\ttraining's binary_logloss: 0.113126\tvalid_1's auc: 0.830878\tvalid_1's binary_logloss: 0.136034\n",
            "[73]\ttraining's auc: 0.909288\ttraining's binary_logloss: 0.112931\tvalid_1's auc: 0.830594\tvalid_1's binary_logloss: 0.13608\n",
            "[74]\ttraining's auc: 0.909548\ttraining's binary_logloss: 0.112759\tvalid_1's auc: 0.830659\tvalid_1's binary_logloss: 0.136078\n",
            "[75]\ttraining's auc: 0.909955\ttraining's binary_logloss: 0.112553\tvalid_1's auc: 0.830634\tvalid_1's binary_logloss: 0.136063\n",
            "[76]\ttraining's auc: 0.910266\ttraining's binary_logloss: 0.112394\tvalid_1's auc: 0.830395\tvalid_1's binary_logloss: 0.136102\n",
            "[77]\ttraining's auc: 0.910784\ttraining's binary_logloss: 0.112242\tvalid_1's auc: 0.830358\tvalid_1's binary_logloss: 0.136114\n",
            "[78]\ttraining's auc: 0.911141\ttraining's binary_logloss: 0.112073\tvalid_1's auc: 0.830312\tvalid_1's binary_logloss: 0.136119\n",
            "[79]\ttraining's auc: 0.911447\ttraining's binary_logloss: 0.111909\tvalid_1's auc: 0.830376\tvalid_1's binary_logloss: 0.136123\n",
            "[80]\ttraining's auc: 0.911832\ttraining's binary_logloss: 0.111722\tvalid_1's auc: 0.830272\tvalid_1's binary_logloss: 0.136139\n",
            "[81]\ttraining's auc: 0.911999\ttraining's binary_logloss: 0.111583\tvalid_1's auc: 0.830055\tvalid_1's binary_logloss: 0.136191\n",
            "[82]\ttraining's auc: 0.912338\ttraining's binary_logloss: 0.111423\tvalid_1's auc: 0.830004\tvalid_1's binary_logloss: 0.136205\n",
            "[83]\ttraining's auc: 0.912921\ttraining's binary_logloss: 0.111245\tvalid_1's auc: 0.830049\tvalid_1's binary_logloss: 0.136211\n",
            "[84]\ttraining's auc: 0.913393\ttraining's binary_logloss: 0.111068\tvalid_1's auc: 0.830038\tvalid_1's binary_logloss: 0.136235\n",
            "[85]\ttraining's auc: 0.913633\ttraining's binary_logloss: 0.110938\tvalid_1's auc: 0.830111\tvalid_1's binary_logloss: 0.13623\n",
            "[86]\ttraining's auc: 0.913798\ttraining's binary_logloss: 0.11082\tvalid_1's auc: 0.829861\tvalid_1's binary_logloss: 0.136278\n",
            "[87]\ttraining's auc: 0.914532\ttraining's binary_logloss: 0.110656\tvalid_1's auc: 0.829986\tvalid_1's binary_logloss: 0.13627\n",
            "[88]\ttraining's auc: 0.914912\ttraining's binary_logloss: 0.110487\tvalid_1's auc: 0.829848\tvalid_1's binary_logloss: 0.136298\n",
            "[89]\ttraining's auc: 0.915147\ttraining's binary_logloss: 0.110349\tvalid_1's auc: 0.829947\tvalid_1's binary_logloss: 0.136295\n",
            "[90]\ttraining's auc: 0.915471\ttraining's binary_logloss: 0.110192\tvalid_1's auc: 0.829871\tvalid_1's binary_logloss: 0.13633\n",
            "[91]\ttraining's auc: 0.91649\ttraining's binary_logloss: 0.109913\tvalid_1's auc: 0.829791\tvalid_1's binary_logloss: 0.136359\n",
            "[92]\ttraining's auc: 0.917057\ttraining's binary_logloss: 0.109714\tvalid_1's auc: 0.829748\tvalid_1's binary_logloss: 0.136379\n",
            "[93]\ttraining's auc: 0.917699\ttraining's binary_logloss: 0.109578\tvalid_1's auc: 0.829692\tvalid_1's binary_logloss: 0.136383\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 30%|███       | 15/50 [07:19<11:48, 20.25s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.161707\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156709\n",
            "[2]\ttraining's auc: 0.823429\ttraining's binary_logloss: 0.157796\tvalid_1's auc: 0.804273\tvalid_1's binary_logloss: 0.153585\n",
            "[3]\ttraining's auc: 0.831535\ttraining's binary_logloss: 0.154519\tvalid_1's auc: 0.815664\tvalid_1's binary_logloss: 0.150994\n",
            "[4]\ttraining's auc: 0.835094\ttraining's binary_logloss: 0.151756\tvalid_1's auc: 0.81746\tvalid_1's binary_logloss: 0.148977\n",
            "[5]\ttraining's auc: 0.837851\ttraining's binary_logloss: 0.149429\tvalid_1's auc: 0.818904\tvalid_1's binary_logloss: 0.147218\n",
            "[6]\ttraining's auc: 0.841694\ttraining's binary_logloss: 0.147434\tvalid_1's auc: 0.822338\tvalid_1's binary_logloss: 0.145711\n",
            "[7]\ttraining's auc: 0.844836\ttraining's binary_logloss: 0.145618\tvalid_1's auc: 0.823932\tvalid_1's binary_logloss: 0.144376\n",
            "[8]\ttraining's auc: 0.848701\ttraining's binary_logloss: 0.143982\tvalid_1's auc: 0.827278\tvalid_1's binary_logloss: 0.143182\n",
            "[9]\ttraining's auc: 0.851526\ttraining's binary_logloss: 0.142457\tvalid_1's auc: 0.827797\tvalid_1's binary_logloss: 0.142077\n",
            "[10]\ttraining's auc: 0.852935\ttraining's binary_logloss: 0.141111\tvalid_1's auc: 0.828831\tvalid_1's binary_logloss: 0.141061\n",
            "[11]\ttraining's auc: 0.854568\ttraining's binary_logloss: 0.139872\tvalid_1's auc: 0.828982\tvalid_1's binary_logloss: 0.14019\n",
            "[12]\ttraining's auc: 0.856217\ttraining's binary_logloss: 0.138759\tvalid_1's auc: 0.83143\tvalid_1's binary_logloss: 0.139339\n",
            "[13]\ttraining's auc: 0.857741\ttraining's binary_logloss: 0.137734\tvalid_1's auc: 0.831478\tvalid_1's binary_logloss: 0.138642\n",
            "[14]\ttraining's auc: 0.858931\ttraining's binary_logloss: 0.136735\tvalid_1's auc: 0.831288\tvalid_1's binary_logloss: 0.138067\n",
            "[15]\ttraining's auc: 0.85995\ttraining's binary_logloss: 0.135817\tvalid_1's auc: 0.831144\tvalid_1's binary_logloss: 0.13748\n",
            "[16]\ttraining's auc: 0.862149\ttraining's binary_logloss: 0.13498\tvalid_1's auc: 0.831885\tvalid_1's binary_logloss: 0.136927\n",
            "[17]\ttraining's auc: 0.86468\ttraining's binary_logloss: 0.134132\tvalid_1's auc: 0.832065\tvalid_1's binary_logloss: 0.136451\n",
            "[18]\ttraining's auc: 0.866246\ttraining's binary_logloss: 0.133351\tvalid_1's auc: 0.83194\tvalid_1's binary_logloss: 0.136019\n",
            "[19]\ttraining's auc: 0.86782\ttraining's binary_logloss: 0.132597\tvalid_1's auc: 0.831939\tvalid_1's binary_logloss: 0.135673\n",
            "[20]\ttraining's auc: 0.869835\ttraining's binary_logloss: 0.131879\tvalid_1's auc: 0.832466\tvalid_1's binary_logloss: 0.135332\n",
            "[21]\ttraining's auc: 0.870874\ttraining's binary_logloss: 0.13124\tvalid_1's auc: 0.832368\tvalid_1's binary_logloss: 0.135024\n",
            "[22]\ttraining's auc: 0.871917\ttraining's binary_logloss: 0.130598\tvalid_1's auc: 0.832688\tvalid_1's binary_logloss: 0.134718\n",
            "[23]\ttraining's auc: 0.872757\ttraining's binary_logloss: 0.130054\tvalid_1's auc: 0.832611\tvalid_1's binary_logloss: 0.13446\n",
            "[24]\ttraining's auc: 0.873482\ttraining's binary_logloss: 0.129514\tvalid_1's auc: 0.832233\tvalid_1's binary_logloss: 0.134237\n",
            "[25]\ttraining's auc: 0.874389\ttraining's binary_logloss: 0.129005\tvalid_1's auc: 0.832578\tvalid_1's binary_logloss: 0.133984\n",
            "[26]\ttraining's auc: 0.875158\ttraining's binary_logloss: 0.128488\tvalid_1's auc: 0.832446\tvalid_1's binary_logloss: 0.133779\n",
            "[27]\ttraining's auc: 0.875785\ttraining's binary_logloss: 0.128001\tvalid_1's auc: 0.832749\tvalid_1's binary_logloss: 0.133577\n",
            "[28]\ttraining's auc: 0.877513\ttraining's binary_logloss: 0.127448\tvalid_1's auc: 0.833507\tvalid_1's binary_logloss: 0.133352\n",
            "[29]\ttraining's auc: 0.878505\ttraining's binary_logloss: 0.126996\tvalid_1's auc: 0.833682\tvalid_1's binary_logloss: 0.133139\n",
            "[30]\ttraining's auc: 0.879057\ttraining's binary_logloss: 0.126547\tvalid_1's auc: 0.833688\tvalid_1's binary_logloss: 0.132971\n",
            "[31]\ttraining's auc: 0.879962\ttraining's binary_logloss: 0.126098\tvalid_1's auc: 0.833567\tvalid_1's binary_logloss: 0.132836\n",
            "[32]\ttraining's auc: 0.880484\ttraining's binary_logloss: 0.125686\tvalid_1's auc: 0.83356\tvalid_1's binary_logloss: 0.132712\n",
            "[33]\ttraining's auc: 0.881488\ttraining's binary_logloss: 0.125254\tvalid_1's auc: 0.833359\tvalid_1's binary_logloss: 0.1326\n",
            "[34]\ttraining's auc: 0.882007\ttraining's binary_logloss: 0.124883\tvalid_1's auc: 0.833542\tvalid_1's binary_logloss: 0.132486\n",
            "[35]\ttraining's auc: 0.88285\ttraining's binary_logloss: 0.12451\tvalid_1's auc: 0.833598\tvalid_1's binary_logloss: 0.132347\n",
            "[36]\ttraining's auc: 0.884068\ttraining's binary_logloss: 0.124131\tvalid_1's auc: 0.833579\tvalid_1's binary_logloss: 0.132233\n",
            "[37]\ttraining's auc: 0.884515\ttraining's binary_logloss: 0.123772\tvalid_1's auc: 0.833691\tvalid_1's binary_logloss: 0.132171\n",
            "[38]\ttraining's auc: 0.884742\ttraining's binary_logloss: 0.123457\tvalid_1's auc: 0.833711\tvalid_1's binary_logloss: 0.132078\n",
            "[39]\ttraining's auc: 0.885569\ttraining's binary_logloss: 0.123093\tvalid_1's auc: 0.833795\tvalid_1's binary_logloss: 0.13197\n",
            "[40]\ttraining's auc: 0.886708\ttraining's binary_logloss: 0.122747\tvalid_1's auc: 0.833735\tvalid_1's binary_logloss: 0.131911\n",
            "[41]\ttraining's auc: 0.887957\ttraining's binary_logloss: 0.122401\tvalid_1's auc: 0.833729\tvalid_1's binary_logloss: 0.13185\n",
            "[42]\ttraining's auc: 0.888308\ttraining's binary_logloss: 0.122133\tvalid_1's auc: 0.833554\tvalid_1's binary_logloss: 0.131825\n",
            "[43]\ttraining's auc: 0.889327\ttraining's binary_logloss: 0.121814\tvalid_1's auc: 0.833768\tvalid_1's binary_logloss: 0.131771\n",
            "[44]\ttraining's auc: 0.890159\ttraining's binary_logloss: 0.121484\tvalid_1's auc: 0.833784\tvalid_1's binary_logloss: 0.131705\n",
            "[45]\ttraining's auc: 0.891185\ttraining's binary_logloss: 0.121182\tvalid_1's auc: 0.834162\tvalid_1's binary_logloss: 0.131656\n",
            "[46]\ttraining's auc: 0.891652\ttraining's binary_logloss: 0.120911\tvalid_1's auc: 0.834547\tvalid_1's binary_logloss: 0.131566\n",
            "[47]\ttraining's auc: 0.89212\ttraining's binary_logloss: 0.120619\tvalid_1's auc: 0.834401\tvalid_1's binary_logloss: 0.13154\n",
            "[48]\ttraining's auc: 0.893177\ttraining's binary_logloss: 0.120322\tvalid_1's auc: 0.834514\tvalid_1's binary_logloss: 0.131489\n",
            "[49]\ttraining's auc: 0.893919\ttraining's binary_logloss: 0.120062\tvalid_1's auc: 0.834558\tvalid_1's binary_logloss: 0.131441\n",
            "[50]\ttraining's auc: 0.894929\ttraining's binary_logloss: 0.119794\tvalid_1's auc: 0.834635\tvalid_1's binary_logloss: 0.131406\n",
            "[51]\ttraining's auc: 0.895308\ttraining's binary_logloss: 0.11957\tvalid_1's auc: 0.834741\tvalid_1's binary_logloss: 0.13135\n",
            "[52]\ttraining's auc: 0.895647\ttraining's binary_logloss: 0.119348\tvalid_1's auc: 0.83448\tvalid_1's binary_logloss: 0.131337\n",
            "[53]\ttraining's auc: 0.896048\ttraining's binary_logloss: 0.119097\tvalid_1's auc: 0.834788\tvalid_1's binary_logloss: 0.131272\n",
            "[54]\ttraining's auc: 0.896768\ttraining's binary_logloss: 0.118852\tvalid_1's auc: 0.835377\tvalid_1's binary_logloss: 0.131171\n",
            "[55]\ttraining's auc: 0.897424\ttraining's binary_logloss: 0.118629\tvalid_1's auc: 0.83537\tvalid_1's binary_logloss: 0.131139\n",
            "[56]\ttraining's auc: 0.897963\ttraining's binary_logloss: 0.118417\tvalid_1's auc: 0.835485\tvalid_1's binary_logloss: 0.131106\n",
            "[57]\ttraining's auc: 0.898614\ttraining's binary_logloss: 0.118197\tvalid_1's auc: 0.835505\tvalid_1's binary_logloss: 0.131088\n",
            "[58]\ttraining's auc: 0.89955\ttraining's binary_logloss: 0.117921\tvalid_1's auc: 0.835445\tvalid_1's binary_logloss: 0.131076\n",
            "[59]\ttraining's auc: 0.900343\ttraining's binary_logloss: 0.117701\tvalid_1's auc: 0.835601\tvalid_1's binary_logloss: 0.131035\n",
            "[60]\ttraining's auc: 0.900821\ttraining's binary_logloss: 0.117481\tvalid_1's auc: 0.835566\tvalid_1's binary_logloss: 0.131028\n",
            "[61]\ttraining's auc: 0.902015\ttraining's binary_logloss: 0.117189\tvalid_1's auc: 0.835312\tvalid_1's binary_logloss: 0.131042\n",
            "[62]\ttraining's auc: 0.903268\ttraining's binary_logloss: 0.116939\tvalid_1's auc: 0.835156\tvalid_1's binary_logloss: 0.13105\n",
            "[63]\ttraining's auc: 0.903778\ttraining's binary_logloss: 0.116743\tvalid_1's auc: 0.835194\tvalid_1's binary_logloss: 0.13103\n",
            "[64]\ttraining's auc: 0.904184\ttraining's binary_logloss: 0.116553\tvalid_1's auc: 0.835068\tvalid_1's binary_logloss: 0.131025\n",
            "[65]\ttraining's auc: 0.904428\ttraining's binary_logloss: 0.11639\tvalid_1's auc: 0.834826\tvalid_1's binary_logloss: 0.131054\n",
            "[66]\ttraining's auc: 0.904823\ttraining's binary_logloss: 0.116198\tvalid_1's auc: 0.834831\tvalid_1's binary_logloss: 0.131053\n",
            "[67]\ttraining's auc: 0.905121\ttraining's binary_logloss: 0.115991\tvalid_1's auc: 0.834922\tvalid_1's binary_logloss: 0.13104\n",
            "[68]\ttraining's auc: 0.905477\ttraining's binary_logloss: 0.115811\tvalid_1's auc: 0.834999\tvalid_1's binary_logloss: 0.131017\n",
            "[69]\ttraining's auc: 0.906034\ttraining's binary_logloss: 0.115586\tvalid_1's auc: 0.834987\tvalid_1's binary_logloss: 0.131015\n",
            "[70]\ttraining's auc: 0.906287\ttraining's binary_logloss: 0.115438\tvalid_1's auc: 0.835136\tvalid_1's binary_logloss: 0.130995\n",
            "[71]\ttraining's auc: 0.906921\ttraining's binary_logloss: 0.115223\tvalid_1's auc: 0.835047\tvalid_1's binary_logloss: 0.130999\n",
            "[72]\ttraining's auc: 0.907348\ttraining's binary_logloss: 0.115022\tvalid_1's auc: 0.83485\tvalid_1's binary_logloss: 0.131018\n",
            "[73]\ttraining's auc: 0.907712\ttraining's binary_logloss: 0.114823\tvalid_1's auc: 0.834827\tvalid_1's binary_logloss: 0.131015\n",
            "[74]\ttraining's auc: 0.908154\ttraining's binary_logloss: 0.114601\tvalid_1's auc: 0.834843\tvalid_1's binary_logloss: 0.131026\n",
            "[75]\ttraining's auc: 0.908578\ttraining's binary_logloss: 0.114417\tvalid_1's auc: 0.834958\tvalid_1's binary_logloss: 0.131017\n",
            "[76]\ttraining's auc: 0.90883\ttraining's binary_logloss: 0.114257\tvalid_1's auc: 0.834959\tvalid_1's binary_logloss: 0.131014\n",
            "[77]\ttraining's auc: 0.9091\ttraining's binary_logloss: 0.114093\tvalid_1's auc: 0.834855\tvalid_1's binary_logloss: 0.131008\n",
            "[78]\ttraining's auc: 0.909597\ttraining's binary_logloss: 0.113894\tvalid_1's auc: 0.834882\tvalid_1's binary_logloss: 0.131008\n",
            "[79]\ttraining's auc: 0.91006\ttraining's binary_logloss: 0.113684\tvalid_1's auc: 0.834841\tvalid_1's binary_logloss: 0.131019\n",
            "[80]\ttraining's auc: 0.910382\ttraining's binary_logloss: 0.11352\tvalid_1's auc: 0.834737\tvalid_1's binary_logloss: 0.131048\n",
            "[81]\ttraining's auc: 0.91181\ttraining's binary_logloss: 0.113224\tvalid_1's auc: 0.835175\tvalid_1's binary_logloss: 0.130973\n",
            "[82]\ttraining's auc: 0.912188\ttraining's binary_logloss: 0.113058\tvalid_1's auc: 0.835212\tvalid_1's binary_logloss: 0.130974\n",
            "[83]\ttraining's auc: 0.912503\ttraining's binary_logloss: 0.112931\tvalid_1's auc: 0.835353\tvalid_1's binary_logloss: 0.130953\n",
            "[84]\ttraining's auc: 0.912659\ttraining's binary_logloss: 0.112801\tvalid_1's auc: 0.835342\tvalid_1's binary_logloss: 0.130954\n",
            "[85]\ttraining's auc: 0.91287\ttraining's binary_logloss: 0.112677\tvalid_1's auc: 0.835388\tvalid_1's binary_logloss: 0.130953\n",
            "[86]\ttraining's auc: 0.913272\ttraining's binary_logloss: 0.112507\tvalid_1's auc: 0.835389\tvalid_1's binary_logloss: 0.130965\n",
            "[87]\ttraining's auc: 0.913782\ttraining's binary_logloss: 0.112271\tvalid_1's auc: 0.835136\tvalid_1's binary_logloss: 0.131016\n",
            "[88]\ttraining's auc: 0.914131\ttraining's binary_logloss: 0.112116\tvalid_1's auc: 0.835073\tvalid_1's binary_logloss: 0.131024\n",
            "[89]\ttraining's auc: 0.914482\ttraining's binary_logloss: 0.111952\tvalid_1's auc: 0.834844\tvalid_1's binary_logloss: 0.13105\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 30%|███       | 15/50 [07:27<11:48, 20.25s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.158168\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.164055\n",
            "[2]\ttraining's auc: 0.831482\ttraining's binary_logloss: 0.15434\tvalid_1's auc: 0.814485\tvalid_1's binary_logloss: 0.160615\n",
            "[3]\ttraining's auc: 0.834122\ttraining's binary_logloss: 0.151301\tvalid_1's auc: 0.816294\tvalid_1's binary_logloss: 0.157913\n",
            "[4]\ttraining's auc: 0.838285\ttraining's binary_logloss: 0.148654\tvalid_1's auc: 0.818454\tvalid_1's binary_logloss: 0.15563\n",
            "[5]\ttraining's auc: 0.84207\ttraining's binary_logloss: 0.1464\tvalid_1's auc: 0.821364\tvalid_1's binary_logloss: 0.153649\n",
            "[6]\ttraining's auc: 0.846348\ttraining's binary_logloss: 0.144331\tvalid_1's auc: 0.824766\tvalid_1's binary_logloss: 0.151962\n",
            "[7]\ttraining's auc: 0.848731\ttraining's binary_logloss: 0.142592\tvalid_1's auc: 0.826247\tvalid_1's binary_logloss: 0.150452\n",
            "[8]\ttraining's auc: 0.849263\ttraining's binary_logloss: 0.141026\tvalid_1's auc: 0.827054\tvalid_1's binary_logloss: 0.149144\n",
            "[9]\ttraining's auc: 0.851115\ttraining's binary_logloss: 0.13955\tvalid_1's auc: 0.828202\tvalid_1's binary_logloss: 0.147928\n",
            "[10]\ttraining's auc: 0.851917\ttraining's binary_logloss: 0.138242\tvalid_1's auc: 0.82855\tvalid_1's binary_logloss: 0.146899\n",
            "[11]\ttraining's auc: 0.854728\ttraining's binary_logloss: 0.137008\tvalid_1's auc: 0.829412\tvalid_1's binary_logloss: 0.145961\n",
            "[12]\ttraining's auc: 0.85553\ttraining's binary_logloss: 0.135925\tvalid_1's auc: 0.829654\tvalid_1's binary_logloss: 0.145124\n",
            "[13]\ttraining's auc: 0.856019\ttraining's binary_logloss: 0.134916\tvalid_1's auc: 0.830226\tvalid_1's binary_logloss: 0.14438\n",
            "[14]\ttraining's auc: 0.857731\ttraining's binary_logloss: 0.133963\tvalid_1's auc: 0.830912\tvalid_1's binary_logloss: 0.143657\n",
            "[15]\ttraining's auc: 0.859372\ttraining's binary_logloss: 0.133091\tvalid_1's auc: 0.831208\tvalid_1's binary_logloss: 0.143034\n",
            "[16]\ttraining's auc: 0.861166\ttraining's binary_logloss: 0.132298\tvalid_1's auc: 0.831702\tvalid_1's binary_logloss: 0.142444\n",
            "[17]\ttraining's auc: 0.862423\ttraining's binary_logloss: 0.131532\tvalid_1's auc: 0.831952\tvalid_1's binary_logloss: 0.14194\n",
            "[18]\ttraining's auc: 0.863407\ttraining's binary_logloss: 0.130816\tvalid_1's auc: 0.832095\tvalid_1's binary_logloss: 0.141469\n",
            "[19]\ttraining's auc: 0.864241\ttraining's binary_logloss: 0.130147\tvalid_1's auc: 0.832158\tvalid_1's binary_logloss: 0.141056\n",
            "[20]\ttraining's auc: 0.866379\ttraining's binary_logloss: 0.129458\tvalid_1's auc: 0.83257\tvalid_1's binary_logloss: 0.140643\n",
            "[21]\ttraining's auc: 0.868432\ttraining's binary_logloss: 0.128834\tvalid_1's auc: 0.833083\tvalid_1's binary_logloss: 0.140331\n",
            "[22]\ttraining's auc: 0.869427\ttraining's binary_logloss: 0.12826\tvalid_1's auc: 0.832952\tvalid_1's binary_logloss: 0.140029\n",
            "[23]\ttraining's auc: 0.871066\ttraining's binary_logloss: 0.127692\tvalid_1's auc: 0.834273\tvalid_1's binary_logloss: 0.139732\n",
            "[24]\ttraining's auc: 0.872383\ttraining's binary_logloss: 0.127128\tvalid_1's auc: 0.834698\tvalid_1's binary_logloss: 0.13945\n",
            "[25]\ttraining's auc: 0.873056\ttraining's binary_logloss: 0.126615\tvalid_1's auc: 0.835036\tvalid_1's binary_logloss: 0.139172\n",
            "[26]\ttraining's auc: 0.874415\ttraining's binary_logloss: 0.126108\tvalid_1's auc: 0.835923\tvalid_1's binary_logloss: 0.138876\n",
            "[27]\ttraining's auc: 0.875196\ttraining's binary_logloss: 0.125625\tvalid_1's auc: 0.836345\tvalid_1's binary_logloss: 0.138654\n",
            "[28]\ttraining's auc: 0.877134\ttraining's binary_logloss: 0.12512\tvalid_1's auc: 0.835786\tvalid_1's binary_logloss: 0.1385\n",
            "[29]\ttraining's auc: 0.878292\ttraining's binary_logloss: 0.124665\tvalid_1's auc: 0.835912\tvalid_1's binary_logloss: 0.138312\n",
            "[30]\ttraining's auc: 0.879523\ttraining's binary_logloss: 0.124215\tvalid_1's auc: 0.836015\tvalid_1's binary_logloss: 0.138115\n",
            "[31]\ttraining's auc: 0.880546\ttraining's binary_logloss: 0.123799\tvalid_1's auc: 0.835859\tvalid_1's binary_logloss: 0.137951\n",
            "[32]\ttraining's auc: 0.881134\ttraining's binary_logloss: 0.1234\tvalid_1's auc: 0.835956\tvalid_1's binary_logloss: 0.137847\n",
            "[33]\ttraining's auc: 0.882174\ttraining's binary_logloss: 0.123014\tvalid_1's auc: 0.835875\tvalid_1's binary_logloss: 0.137735\n",
            "[34]\ttraining's auc: 0.882787\ttraining's binary_logloss: 0.122665\tvalid_1's auc: 0.836045\tvalid_1's binary_logloss: 0.137545\n",
            "[35]\ttraining's auc: 0.883794\ttraining's binary_logloss: 0.122293\tvalid_1's auc: 0.835962\tvalid_1's binary_logloss: 0.137458\n",
            "[36]\ttraining's auc: 0.88457\ttraining's binary_logloss: 0.121934\tvalid_1's auc: 0.836045\tvalid_1's binary_logloss: 0.13733\n",
            "[37]\ttraining's auc: 0.88581\ttraining's binary_logloss: 0.121592\tvalid_1's auc: 0.836699\tvalid_1's binary_logloss: 0.137193\n",
            "[38]\ttraining's auc: 0.88657\ttraining's binary_logloss: 0.121211\tvalid_1's auc: 0.836659\tvalid_1's binary_logloss: 0.137117\n",
            "[39]\ttraining's auc: 0.887797\ttraining's binary_logloss: 0.120847\tvalid_1's auc: 0.836703\tvalid_1's binary_logloss: 0.137035\n",
            "[40]\ttraining's auc: 0.888397\ttraining's binary_logloss: 0.12057\tvalid_1's auc: 0.836746\tvalid_1's binary_logloss: 0.136949\n",
            "[41]\ttraining's auc: 0.889308\ttraining's binary_logloss: 0.12022\tvalid_1's auc: 0.836711\tvalid_1's binary_logloss: 0.136905\n",
            "[42]\ttraining's auc: 0.890203\ttraining's binary_logloss: 0.11991\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.136868\n",
            "[43]\ttraining's auc: 0.890948\ttraining's binary_logloss: 0.119617\tvalid_1's auc: 0.836357\tvalid_1's binary_logloss: 0.136856\n",
            "[44]\ttraining's auc: 0.891757\ttraining's binary_logloss: 0.119293\tvalid_1's auc: 0.836509\tvalid_1's binary_logloss: 0.136793\n",
            "[45]\ttraining's auc: 0.892544\ttraining's binary_logloss: 0.118948\tvalid_1's auc: 0.836662\tvalid_1's binary_logloss: 0.136702\n",
            "[46]\ttraining's auc: 0.892772\ttraining's binary_logloss: 0.118714\tvalid_1's auc: 0.836589\tvalid_1's binary_logloss: 0.136678\n",
            "[47]\ttraining's auc: 0.893474\ttraining's binary_logloss: 0.11847\tvalid_1's auc: 0.836635\tvalid_1's binary_logloss: 0.136635\n",
            "[48]\ttraining's auc: 0.894088\ttraining's binary_logloss: 0.118215\tvalid_1's auc: 0.836454\tvalid_1's binary_logloss: 0.136637\n",
            "[49]\ttraining's auc: 0.894927\ttraining's binary_logloss: 0.117948\tvalid_1's auc: 0.836398\tvalid_1's binary_logloss: 0.136612\n",
            "[50]\ttraining's auc: 0.89582\ttraining's binary_logloss: 0.117658\tvalid_1's auc: 0.836299\tvalid_1's binary_logloss: 0.136601\n",
            "[51]\ttraining's auc: 0.896576\ttraining's binary_logloss: 0.117386\tvalid_1's auc: 0.836434\tvalid_1's binary_logloss: 0.136544\n",
            "[52]\ttraining's auc: 0.897379\ttraining's binary_logloss: 0.117109\tvalid_1's auc: 0.836394\tvalid_1's binary_logloss: 0.136501\n",
            "[53]\ttraining's auc: 0.897795\ttraining's binary_logloss: 0.116885\tvalid_1's auc: 0.836269\tvalid_1's binary_logloss: 0.136499\n",
            "[54]\ttraining's auc: 0.898442\ttraining's binary_logloss: 0.11662\tvalid_1's auc: 0.836251\tvalid_1's binary_logloss: 0.136474\n",
            "[55]\ttraining's auc: 0.898883\ttraining's binary_logloss: 0.116405\tvalid_1's auc: 0.836322\tvalid_1's binary_logloss: 0.136423\n",
            "[56]\ttraining's auc: 0.899679\ttraining's binary_logloss: 0.116152\tvalid_1's auc: 0.836409\tvalid_1's binary_logloss: 0.136394\n",
            "[57]\ttraining's auc: 0.900317\ttraining's binary_logloss: 0.115935\tvalid_1's auc: 0.836416\tvalid_1's binary_logloss: 0.136354\n",
            "[58]\ttraining's auc: 0.90091\ttraining's binary_logloss: 0.115732\tvalid_1's auc: 0.836424\tvalid_1's binary_logloss: 0.13635\n",
            "[59]\ttraining's auc: 0.901523\ttraining's binary_logloss: 0.115514\tvalid_1's auc: 0.835962\tvalid_1's binary_logloss: 0.136379\n",
            "[60]\ttraining's auc: 0.902011\ttraining's binary_logloss: 0.115303\tvalid_1's auc: 0.835909\tvalid_1's binary_logloss: 0.136378\n",
            "[61]\ttraining's auc: 0.902759\ttraining's binary_logloss: 0.114993\tvalid_1's auc: 0.835965\tvalid_1's binary_logloss: 0.136392\n",
            "[62]\ttraining's auc: 0.903215\ttraining's binary_logloss: 0.114814\tvalid_1's auc: 0.835848\tvalid_1's binary_logloss: 0.136381\n",
            "[63]\ttraining's auc: 0.903941\ttraining's binary_logloss: 0.114593\tvalid_1's auc: 0.835829\tvalid_1's binary_logloss: 0.13638\n",
            "[64]\ttraining's auc: 0.904483\ttraining's binary_logloss: 0.114321\tvalid_1's auc: 0.835445\tvalid_1's binary_logloss: 0.136441\n",
            "[65]\ttraining's auc: 0.905172\ttraining's binary_logloss: 0.114086\tvalid_1's auc: 0.835383\tvalid_1's binary_logloss: 0.136442\n",
            "[66]\ttraining's auc: 0.905659\ttraining's binary_logloss: 0.113896\tvalid_1's auc: 0.835579\tvalid_1's binary_logloss: 0.136403\n",
            "[67]\ttraining's auc: 0.906113\ttraining's binary_logloss: 0.113699\tvalid_1's auc: 0.835477\tvalid_1's binary_logloss: 0.136434\n",
            "[68]\ttraining's auc: 0.906915\ttraining's binary_logloss: 0.113439\tvalid_1's auc: 0.835502\tvalid_1's binary_logloss: 0.136423\n",
            "[69]\ttraining's auc: 0.907348\ttraining's binary_logloss: 0.113252\tvalid_1's auc: 0.83561\tvalid_1's binary_logloss: 0.136427\n",
            "[70]\ttraining's auc: 0.907929\ttraining's binary_logloss: 0.113028\tvalid_1's auc: 0.835376\tvalid_1's binary_logloss: 0.136462\n",
            " 32%|███▏      | 16/50 [07:34<12:15, 21.62s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.162182\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.163448\n",
            "[2]\ttraining's auc: 0.827172\ttraining's binary_logloss: 0.160061\tvalid_1's auc: 0.80445\tvalid_1's binary_logloss: 0.161724\n",
            "[3]\ttraining's auc: 0.833323\ttraining's binary_logloss: 0.158181\tvalid_1's auc: 0.80783\tvalid_1's binary_logloss: 0.16022\n",
            "[4]\ttraining's auc: 0.834123\ttraining's binary_logloss: 0.156499\tvalid_1's auc: 0.807905\tvalid_1's binary_logloss: 0.158909\n",
            "[5]\ttraining's auc: 0.835937\ttraining's binary_logloss: 0.15495\tvalid_1's auc: 0.809267\tvalid_1's binary_logloss: 0.157688\n",
            "[6]\ttraining's auc: 0.836228\ttraining's binary_logloss: 0.153546\tvalid_1's auc: 0.808726\tvalid_1's binary_logloss: 0.156584\n",
            "[7]\ttraining's auc: 0.83744\ttraining's binary_logloss: 0.152207\tvalid_1's auc: 0.809873\tvalid_1's binary_logloss: 0.155521\n",
            "[8]\ttraining's auc: 0.839039\ttraining's binary_logloss: 0.150993\tvalid_1's auc: 0.811253\tvalid_1's binary_logloss: 0.154563\n",
            "[9]\ttraining's auc: 0.843596\ttraining's binary_logloss: 0.149838\tvalid_1's auc: 0.816086\tvalid_1's binary_logloss: 0.153651\n",
            "[10]\ttraining's auc: 0.843944\ttraining's binary_logloss: 0.14878\tvalid_1's auc: 0.815806\tvalid_1's binary_logloss: 0.152814\n",
            "[11]\ttraining's auc: 0.846232\ttraining's binary_logloss: 0.147792\tvalid_1's auc: 0.816739\tvalid_1's binary_logloss: 0.152057\n",
            "[12]\ttraining's auc: 0.846715\ttraining's binary_logloss: 0.146845\tvalid_1's auc: 0.816909\tvalid_1's binary_logloss: 0.151354\n",
            "[13]\ttraining's auc: 0.84777\ttraining's binary_logloss: 0.145964\tvalid_1's auc: 0.818416\tvalid_1's binary_logloss: 0.150659\n",
            "[14]\ttraining's auc: 0.848672\ttraining's binary_logloss: 0.145103\tvalid_1's auc: 0.818609\tvalid_1's binary_logloss: 0.150008\n",
            "[15]\ttraining's auc: 0.849482\ttraining's binary_logloss: 0.144268\tvalid_1's auc: 0.819077\tvalid_1's binary_logloss: 0.149382\n",
            "[16]\ttraining's auc: 0.849936\ttraining's binary_logloss: 0.143458\tvalid_1's auc: 0.81992\tvalid_1's binary_logloss: 0.148769\n",
            "[17]\ttraining's auc: 0.850749\ttraining's binary_logloss: 0.142718\tvalid_1's auc: 0.820444\tvalid_1's binary_logloss: 0.148232\n",
            "[18]\ttraining's auc: 0.852442\ttraining's binary_logloss: 0.142016\tvalid_1's auc: 0.821526\tvalid_1's binary_logloss: 0.147692\n",
            "[19]\ttraining's auc: 0.853172\ttraining's binary_logloss: 0.14134\tvalid_1's auc: 0.82191\tvalid_1's binary_logloss: 0.147191\n",
            "[20]\ttraining's auc: 0.853233\ttraining's binary_logloss: 0.140695\tvalid_1's auc: 0.822148\tvalid_1's binary_logloss: 0.146705\n",
            "[21]\ttraining's auc: 0.853769\ttraining's binary_logloss: 0.140091\tvalid_1's auc: 0.822571\tvalid_1's binary_logloss: 0.146262\n",
            "[22]\ttraining's auc: 0.853982\ttraining's binary_logloss: 0.139516\tvalid_1's auc: 0.822684\tvalid_1's binary_logloss: 0.145849\n",
            "[23]\ttraining's auc: 0.85443\ttraining's binary_logloss: 0.138952\tvalid_1's auc: 0.822858\tvalid_1's binary_logloss: 0.145436\n",
            "[24]\ttraining's auc: 0.854716\ttraining's binary_logloss: 0.138419\tvalid_1's auc: 0.822795\tvalid_1's binary_logloss: 0.145067\n",
            "[25]\ttraining's auc: 0.855229\ttraining's binary_logloss: 0.137874\tvalid_1's auc: 0.82295\tvalid_1's binary_logloss: 0.144697\n",
            "[26]\ttraining's auc: 0.857312\ttraining's binary_logloss: 0.13737\tvalid_1's auc: 0.824049\tvalid_1's binary_logloss: 0.144331\n",
            "[27]\ttraining's auc: 0.858013\ttraining's binary_logloss: 0.136873\tvalid_1's auc: 0.824177\tvalid_1's binary_logloss: 0.143978\n",
            "[28]\ttraining's auc: 0.858625\ttraining's binary_logloss: 0.136377\tvalid_1's auc: 0.824457\tvalid_1's binary_logloss: 0.143673\n",
            "[29]\ttraining's auc: 0.858829\ttraining's binary_logloss: 0.135924\tvalid_1's auc: 0.824444\tvalid_1's binary_logloss: 0.143374\n",
            "[30]\ttraining's auc: 0.859309\ttraining's binary_logloss: 0.135504\tvalid_1's auc: 0.824816\tvalid_1's binary_logloss: 0.143063\n",
            "[31]\ttraining's auc: 0.859603\ttraining's binary_logloss: 0.135083\tvalid_1's auc: 0.824932\tvalid_1's binary_logloss: 0.142793\n",
            "[32]\ttraining's auc: 0.860923\ttraining's binary_logloss: 0.134658\tvalid_1's auc: 0.825312\tvalid_1's binary_logloss: 0.142517\n",
            "[33]\ttraining's auc: 0.861742\ttraining's binary_logloss: 0.134246\tvalid_1's auc: 0.825604\tvalid_1's binary_logloss: 0.142239\n",
            "[34]\ttraining's auc: 0.861842\ttraining's binary_logloss: 0.133864\tvalid_1's auc: 0.825743\tvalid_1's binary_logloss: 0.141986\n",
            "[35]\ttraining's auc: 0.862492\ttraining's binary_logloss: 0.133493\tvalid_1's auc: 0.826043\tvalid_1's binary_logloss: 0.14174\n",
            "[36]\ttraining's auc: 0.862922\ttraining's binary_logloss: 0.133123\tvalid_1's auc: 0.826331\tvalid_1's binary_logloss: 0.14151\n",
            "[37]\ttraining's auc: 0.863971\ttraining's binary_logloss: 0.132758\tvalid_1's auc: 0.82663\tvalid_1's binary_logloss: 0.141284\n",
            "[38]\ttraining's auc: 0.864298\ttraining's binary_logloss: 0.1324\tvalid_1's auc: 0.827007\tvalid_1's binary_logloss: 0.141097\n",
            "[39]\ttraining's auc: 0.864998\ttraining's binary_logloss: 0.132063\tvalid_1's auc: 0.827146\tvalid_1's binary_logloss: 0.140866\n",
            "[40]\ttraining's auc: 0.865662\ttraining's binary_logloss: 0.131736\tvalid_1's auc: 0.827133\tvalid_1's binary_logloss: 0.140677\n",
            "[41]\ttraining's auc: 0.866009\ttraining's binary_logloss: 0.131401\tvalid_1's auc: 0.827525\tvalid_1's binary_logloss: 0.140483\n",
            "[42]\ttraining's auc: 0.866607\ttraining's binary_logloss: 0.131082\tvalid_1's auc: 0.827796\tvalid_1's binary_logloss: 0.1403\n",
            "[43]\ttraining's auc: 0.867213\ttraining's binary_logloss: 0.130777\tvalid_1's auc: 0.827773\tvalid_1's binary_logloss: 0.14012\n",
            "[44]\ttraining's auc: 0.86771\ttraining's binary_logloss: 0.130489\tvalid_1's auc: 0.828073\tvalid_1's binary_logloss: 0.139953\n",
            "[45]\ttraining's auc: 0.868359\ttraining's binary_logloss: 0.13018\tvalid_1's auc: 0.828325\tvalid_1's binary_logloss: 0.139798\n",
            "[46]\ttraining's auc: 0.869064\ttraining's binary_logloss: 0.129886\tvalid_1's auc: 0.828512\tvalid_1's binary_logloss: 0.139669\n",
            "[47]\ttraining's auc: 0.869384\ttraining's binary_logloss: 0.129602\tvalid_1's auc: 0.828493\tvalid_1's binary_logloss: 0.139503\n",
            "[48]\ttraining's auc: 0.869878\ttraining's binary_logloss: 0.129331\tvalid_1's auc: 0.828425\tvalid_1's binary_logloss: 0.139394\n",
            "[49]\ttraining's auc: 0.870267\ttraining's binary_logloss: 0.129086\tvalid_1's auc: 0.828522\tvalid_1's binary_logloss: 0.139244\n",
            "[50]\ttraining's auc: 0.870602\ttraining's binary_logloss: 0.128829\tvalid_1's auc: 0.828523\tvalid_1's binary_logloss: 0.139108\n",
            "[51]\ttraining's auc: 0.870943\ttraining's binary_logloss: 0.128587\tvalid_1's auc: 0.828583\tvalid_1's binary_logloss: 0.138985\n",
            "[52]\ttraining's auc: 0.871459\ttraining's binary_logloss: 0.128317\tvalid_1's auc: 0.828823\tvalid_1's binary_logloss: 0.138848\n",
            "[53]\ttraining's auc: 0.871916\ttraining's binary_logloss: 0.128073\tvalid_1's auc: 0.828952\tvalid_1's binary_logloss: 0.138722\n",
            "[54]\ttraining's auc: 0.872331\ttraining's binary_logloss: 0.127843\tvalid_1's auc: 0.828971\tvalid_1's binary_logloss: 0.138629\n",
            "[55]\ttraining's auc: 0.872805\ttraining's binary_logloss: 0.127611\tvalid_1's auc: 0.829044\tvalid_1's binary_logloss: 0.13852\n",
            "[56]\ttraining's auc: 0.873415\ttraining's binary_logloss: 0.127362\tvalid_1's auc: 0.829049\tvalid_1's binary_logloss: 0.138405\n",
            "[57]\ttraining's auc: 0.873958\ttraining's binary_logloss: 0.12712\tvalid_1's auc: 0.82923\tvalid_1's binary_logloss: 0.138295\n",
            "[58]\ttraining's auc: 0.874302\ttraining's binary_logloss: 0.126891\tvalid_1's auc: 0.829105\tvalid_1's binary_logloss: 0.138205\n",
            "[59]\ttraining's auc: 0.874719\ttraining's binary_logloss: 0.126664\tvalid_1's auc: 0.828963\tvalid_1's binary_logloss: 0.138123\n",
            "[60]\ttraining's auc: 0.875179\ttraining's binary_logloss: 0.126442\tvalid_1's auc: 0.829058\tvalid_1's binary_logloss: 0.138021\n",
            "[61]\ttraining's auc: 0.875459\ttraining's binary_logloss: 0.126229\tvalid_1's auc: 0.829093\tvalid_1's binary_logloss: 0.137935\n",
            "[62]\ttraining's auc: 0.875803\ttraining's binary_logloss: 0.126017\tvalid_1's auc: 0.829153\tvalid_1's binary_logloss: 0.137858\n",
            "[63]\ttraining's auc: 0.876853\ttraining's binary_logloss: 0.125787\tvalid_1's auc: 0.829247\tvalid_1's binary_logloss: 0.137768\n",
            "[64]\ttraining's auc: 0.877182\ttraining's binary_logloss: 0.125595\tvalid_1's auc: 0.829226\tvalid_1's binary_logloss: 0.1377\n",
            "[65]\ttraining's auc: 0.87777\ttraining's binary_logloss: 0.1254\tvalid_1's auc: 0.829101\tvalid_1's binary_logloss: 0.137635\n",
            "[66]\ttraining's auc: 0.877909\ttraining's binary_logloss: 0.125225\tvalid_1's auc: 0.829009\tvalid_1's binary_logloss: 0.13757\n",
            "[67]\ttraining's auc: 0.878089\ttraining's binary_logloss: 0.125043\tvalid_1's auc: 0.828974\tvalid_1's binary_logloss: 0.137502\n",
            "[68]\ttraining's auc: 0.878784\ttraining's binary_logloss: 0.124832\tvalid_1's auc: 0.829132\tvalid_1's binary_logloss: 0.137429\n",
            "[69]\ttraining's auc: 0.879031\ttraining's binary_logloss: 0.12466\tvalid_1's auc: 0.829298\tvalid_1's binary_logloss: 0.13736\n",
            "[70]\ttraining's auc: 0.879394\ttraining's binary_logloss: 0.124464\tvalid_1's auc: 0.829518\tvalid_1's binary_logloss: 0.137294\n",
            "[71]\ttraining's auc: 0.879666\ttraining's binary_logloss: 0.124288\tvalid_1's auc: 0.829665\tvalid_1's binary_logloss: 0.137217\n",
            "[72]\ttraining's auc: 0.879943\ttraining's binary_logloss: 0.124119\tvalid_1's auc: 0.829595\tvalid_1's binary_logloss: 0.137158\n",
            "[73]\ttraining's auc: 0.880315\ttraining's binary_logloss: 0.123949\tvalid_1's auc: 0.830039\tvalid_1's binary_logloss: 0.137077\n",
            "[74]\ttraining's auc: 0.88086\ttraining's binary_logloss: 0.123766\tvalid_1's auc: 0.829856\tvalid_1's binary_logloss: 0.137032\n",
            "[75]\ttraining's auc: 0.881671\ttraining's binary_logloss: 0.123568\tvalid_1's auc: 0.82972\tvalid_1's binary_logloss: 0.136992\n",
            "[76]\ttraining's auc: 0.882143\ttraining's binary_logloss: 0.123395\tvalid_1's auc: 0.829801\tvalid_1's binary_logloss: 0.136951\n",
            "[77]\ttraining's auc: 0.882774\ttraining's binary_logloss: 0.123211\tvalid_1's auc: 0.829739\tvalid_1's binary_logloss: 0.136919\n",
            "[78]\ttraining's auc: 0.883177\ttraining's binary_logloss: 0.12304\tvalid_1's auc: 0.829813\tvalid_1's binary_logloss: 0.136907\n",
            "[79]\ttraining's auc: 0.883498\ttraining's binary_logloss: 0.122886\tvalid_1's auc: 0.82986\tvalid_1's binary_logloss: 0.136869\n",
            "[80]\ttraining's auc: 0.883987\ttraining's binary_logloss: 0.122733\tvalid_1's auc: 0.82972\tvalid_1's binary_logloss: 0.136842\n",
            "[81]\ttraining's auc: 0.884459\ttraining's binary_logloss: 0.122569\tvalid_1's auc: 0.829649\tvalid_1's binary_logloss: 0.136802\n",
            "[82]\ttraining's auc: 0.884813\ttraining's binary_logloss: 0.122412\tvalid_1's auc: 0.829983\tvalid_1's binary_logloss: 0.136721\n",
            "[83]\ttraining's auc: 0.885133\ttraining's binary_logloss: 0.122269\tvalid_1's auc: 0.82992\tvalid_1's binary_logloss: 0.136702\n",
            "[84]\ttraining's auc: 0.885673\ttraining's binary_logloss: 0.122106\tvalid_1's auc: 0.830066\tvalid_1's binary_logloss: 0.136653\n",
            "[85]\ttraining's auc: 0.886084\ttraining's binary_logloss: 0.121954\tvalid_1's auc: 0.830058\tvalid_1's binary_logloss: 0.136628\n",
            "[86]\ttraining's auc: 0.886381\ttraining's binary_logloss: 0.121818\tvalid_1's auc: 0.830087\tvalid_1's binary_logloss: 0.136602\n",
            "[87]\ttraining's auc: 0.886718\ttraining's binary_logloss: 0.121679\tvalid_1's auc: 0.830007\tvalid_1's binary_logloss: 0.136579\n",
            "[88]\ttraining's auc: 0.887128\ttraining's binary_logloss: 0.121519\tvalid_1's auc: 0.829969\tvalid_1's binary_logloss: 0.136549\n",
            "[89]\ttraining's auc: 0.887585\ttraining's binary_logloss: 0.121368\tvalid_1's auc: 0.830027\tvalid_1's binary_logloss: 0.136502\n",
            "[90]\ttraining's auc: 0.887856\ttraining's binary_logloss: 0.121229\tvalid_1's auc: 0.830569\tvalid_1's binary_logloss: 0.136454\n",
            "[91]\ttraining's auc: 0.888391\ttraining's binary_logloss: 0.121056\tvalid_1's auc: 0.830409\tvalid_1's binary_logloss: 0.136433\n",
            "[92]\ttraining's auc: 0.888748\ttraining's binary_logloss: 0.120912\tvalid_1's auc: 0.830471\tvalid_1's binary_logloss: 0.136393\n",
            "[93]\ttraining's auc: 0.889179\ttraining's binary_logloss: 0.120748\tvalid_1's auc: 0.830645\tvalid_1's binary_logloss: 0.136362\n",
            "[94]\ttraining's auc: 0.889491\ttraining's binary_logloss: 0.120597\tvalid_1's auc: 0.830636\tvalid_1's binary_logloss: 0.136352\n",
            "[95]\ttraining's auc: 0.889686\ttraining's binary_logloss: 0.120474\tvalid_1's auc: 0.830504\tvalid_1's binary_logloss: 0.136355\n",
            "[96]\ttraining's auc: 0.890456\ttraining's binary_logloss: 0.120296\tvalid_1's auc: 0.830733\tvalid_1's binary_logloss: 0.136284\n",
            "[97]\ttraining's auc: 0.890698\ttraining's binary_logloss: 0.120166\tvalid_1's auc: 0.830721\tvalid_1's binary_logloss: 0.136265\n",
            "[98]\ttraining's auc: 0.890948\ttraining's binary_logloss: 0.120038\tvalid_1's auc: 0.830773\tvalid_1's binary_logloss: 0.136234\n",
            "[99]\ttraining's auc: 0.891566\ttraining's binary_logloss: 0.119883\tvalid_1's auc: 0.830921\tvalid_1's binary_logloss: 0.136186\n",
            "[100]\ttraining's auc: 0.891868\ttraining's binary_logloss: 0.119755\tvalid_1's auc: 0.830977\tvalid_1's binary_logloss: 0.13616\n",
            "[101]\ttraining's auc: 0.892103\ttraining's binary_logloss: 0.119636\tvalid_1's auc: 0.830922\tvalid_1's binary_logloss: 0.136145\n",
            "[102]\ttraining's auc: 0.892365\ttraining's binary_logloss: 0.11951\tvalid_1's auc: 0.831211\tvalid_1's binary_logloss: 0.136113\n",
            "[103]\ttraining's auc: 0.892561\ttraining's binary_logloss: 0.119399\tvalid_1's auc: 0.831188\tvalid_1's binary_logloss: 0.136096\n",
            "[104]\ttraining's auc: 0.893148\ttraining's binary_logloss: 0.119258\tvalid_1's auc: 0.831415\tvalid_1's binary_logloss: 0.136045\n",
            "[105]\ttraining's auc: 0.893393\ttraining's binary_logloss: 0.119139\tvalid_1's auc: 0.831364\tvalid_1's binary_logloss: 0.136038\n",
            "[106]\ttraining's auc: 0.893647\ttraining's binary_logloss: 0.119027\tvalid_1's auc: 0.831307\tvalid_1's binary_logloss: 0.136024\n",
            "[107]\ttraining's auc: 0.893887\ttraining's binary_logloss: 0.118906\tvalid_1's auc: 0.831429\tvalid_1's binary_logloss: 0.135992\n",
            "[108]\ttraining's auc: 0.894264\ttraining's binary_logloss: 0.118776\tvalid_1's auc: 0.831623\tvalid_1's binary_logloss: 0.13595\n",
            "[109]\ttraining's auc: 0.894668\ttraining's binary_logloss: 0.11865\tvalid_1's auc: 0.831597\tvalid_1's binary_logloss: 0.13593\n",
            "[110]\ttraining's auc: 0.894934\ttraining's binary_logloss: 0.118544\tvalid_1's auc: 0.831656\tvalid_1's binary_logloss: 0.135902\n",
            "[111]\ttraining's auc: 0.895229\ttraining's binary_logloss: 0.11842\tvalid_1's auc: 0.831637\tvalid_1's binary_logloss: 0.135879\n",
            "[112]\ttraining's auc: 0.895457\ttraining's binary_logloss: 0.11831\tvalid_1's auc: 0.831655\tvalid_1's binary_logloss: 0.135875\n",
            "[113]\ttraining's auc: 0.895699\ttraining's binary_logloss: 0.118197\tvalid_1's auc: 0.831558\tvalid_1's binary_logloss: 0.135867\n",
            "[114]\ttraining's auc: 0.895894\ttraining's binary_logloss: 0.118088\tvalid_1's auc: 0.831519\tvalid_1's binary_logloss: 0.135862\n",
            "[115]\ttraining's auc: 0.89623\ttraining's binary_logloss: 0.117969\tvalid_1's auc: 0.83162\tvalid_1's binary_logloss: 0.135849\n",
            "[116]\ttraining's auc: 0.896475\ttraining's binary_logloss: 0.117851\tvalid_1's auc: 0.831483\tvalid_1's binary_logloss: 0.135862\n",
            "[117]\ttraining's auc: 0.896808\ttraining's binary_logloss: 0.117739\tvalid_1's auc: 0.831536\tvalid_1's binary_logloss: 0.135841\n",
            "[118]\ttraining's auc: 0.897431\ttraining's binary_logloss: 0.11761\tvalid_1's auc: 0.831798\tvalid_1's binary_logloss: 0.135797\n",
            "[119]\ttraining's auc: 0.897858\ttraining's binary_logloss: 0.117497\tvalid_1's auc: 0.831861\tvalid_1's binary_logloss: 0.135781\n",
            "[120]\ttraining's auc: 0.898151\ttraining's binary_logloss: 0.117395\tvalid_1's auc: 0.831826\tvalid_1's binary_logloss: 0.135773\n",
            "[121]\ttraining's auc: 0.898371\ttraining's binary_logloss: 0.117279\tvalid_1's auc: 0.831838\tvalid_1's binary_logloss: 0.135769\n",
            "[122]\ttraining's auc: 0.898682\ttraining's binary_logloss: 0.117166\tvalid_1's auc: 0.831827\tvalid_1's binary_logloss: 0.135754\n",
            "[123]\ttraining's auc: 0.898974\ttraining's binary_logloss: 0.117056\tvalid_1's auc: 0.831767\tvalid_1's binary_logloss: 0.135759\n",
            "[124]\ttraining's auc: 0.8992\ttraining's binary_logloss: 0.116957\tvalid_1's auc: 0.831675\tvalid_1's binary_logloss: 0.135773\n",
            "[125]\ttraining's auc: 0.899437\ttraining's binary_logloss: 0.116853\tvalid_1's auc: 0.831703\tvalid_1's binary_logloss: 0.135762\n",
            "[126]\ttraining's auc: 0.899697\ttraining's binary_logloss: 0.116744\tvalid_1's auc: 0.831589\tvalid_1's binary_logloss: 0.13576\n",
            "[127]\ttraining's auc: 0.899983\ttraining's binary_logloss: 0.116645\tvalid_1's auc: 0.831683\tvalid_1's binary_logloss: 0.13575\n",
            "[128]\ttraining's auc: 0.900524\ttraining's binary_logloss: 0.116533\tvalid_1's auc: 0.831916\tvalid_1's binary_logloss: 0.135716\n",
            "[129]\ttraining's auc: 0.900854\ttraining's binary_logloss: 0.116442\tvalid_1's auc: 0.83182\tvalid_1's binary_logloss: 0.135725\n",
            "[130]\ttraining's auc: 0.901411\ttraining's binary_logloss: 0.116333\tvalid_1's auc: 0.831802\tvalid_1's binary_logloss: 0.13571\n",
            "[131]\ttraining's auc: 0.901596\ttraining's binary_logloss: 0.116238\tvalid_1's auc: 0.831875\tvalid_1's binary_logloss: 0.13569\n",
            "[132]\ttraining's auc: 0.901857\ttraining's binary_logloss: 0.116144\tvalid_1's auc: 0.831895\tvalid_1's binary_logloss: 0.135689\n",
            "[133]\ttraining's auc: 0.902056\ttraining's binary_logloss: 0.116037\tvalid_1's auc: 0.83172\tvalid_1's binary_logloss: 0.135703\n",
            "[134]\ttraining's auc: 0.902529\ttraining's binary_logloss: 0.115943\tvalid_1's auc: 0.831781\tvalid_1's binary_logloss: 0.135691\n",
            "[135]\ttraining's auc: 0.902871\ttraining's binary_logloss: 0.115842\tvalid_1's auc: 0.831954\tvalid_1's binary_logloss: 0.135661\n",
            "[136]\ttraining's auc: 0.903068\ttraining's binary_logloss: 0.115755\tvalid_1's auc: 0.831864\tvalid_1's binary_logloss: 0.135677\n",
            "[137]\ttraining's auc: 0.90326\ttraining's binary_logloss: 0.115656\tvalid_1's auc: 0.831764\tvalid_1's binary_logloss: 0.135692\n",
            "[138]\ttraining's auc: 0.903449\ttraining's binary_logloss: 0.115554\tvalid_1's auc: 0.831839\tvalid_1's binary_logloss: 0.135687\n",
            "[139]\ttraining's auc: 0.903733\ttraining's binary_logloss: 0.115459\tvalid_1's auc: 0.831915\tvalid_1's binary_logloss: 0.135679\n",
            "[140]\ttraining's auc: 0.903941\ttraining's binary_logloss: 0.11535\tvalid_1's auc: 0.831927\tvalid_1's binary_logloss: 0.135683\n",
            "[141]\ttraining's auc: 0.904563\ttraining's binary_logloss: 0.115246\tvalid_1's auc: 0.831967\tvalid_1's binary_logloss: 0.135675\n",
            "[142]\ttraining's auc: 0.904744\ttraining's binary_logloss: 0.115155\tvalid_1's auc: 0.831984\tvalid_1's binary_logloss: 0.135679\n",
            "[143]\ttraining's auc: 0.904897\ttraining's binary_logloss: 0.115077\tvalid_1's auc: 0.8319\tvalid_1's binary_logloss: 0.135696\n",
            "[144]\ttraining's auc: 0.90517\ttraining's binary_logloss: 0.114999\tvalid_1's auc: 0.831859\tvalid_1's binary_logloss: 0.1357\n",
            "[145]\ttraining's auc: 0.90543\ttraining's binary_logloss: 0.114915\tvalid_1's auc: 0.831852\tvalid_1's binary_logloss: 0.135706\n",
            "[146]\ttraining's auc: 0.905619\ttraining's binary_logloss: 0.114827\tvalid_1's auc: 0.831773\tvalid_1's binary_logloss: 0.135719\n",
            "[147]\ttraining's auc: 0.905758\ttraining's binary_logloss: 0.114738\tvalid_1's auc: 0.831851\tvalid_1's binary_logloss: 0.135718\n",
            "[148]\ttraining's auc: 0.905982\ttraining's binary_logloss: 0.11465\tvalid_1's auc: 0.831882\tvalid_1's binary_logloss: 0.135724\n",
            "[149]\ttraining's auc: 0.906244\ttraining's binary_logloss: 0.114567\tvalid_1's auc: 0.831894\tvalid_1's binary_logloss: 0.135725\n",
            "[150]\ttraining's auc: 0.906494\ttraining's binary_logloss: 0.114459\tvalid_1's auc: 0.831825\tvalid_1's binary_logloss: 0.135745\n",
            "[151]\ttraining's auc: 0.906762\ttraining's binary_logloss: 0.11436\tvalid_1's auc: 0.831737\tvalid_1's binary_logloss: 0.135754\n",
            "[152]\ttraining's auc: 0.906929\ttraining's binary_logloss: 0.114281\tvalid_1's auc: 0.831721\tvalid_1's binary_logloss: 0.135754\n",
            "[153]\ttraining's auc: 0.907307\ttraining's binary_logloss: 0.114168\tvalid_1's auc: 0.831596\tvalid_1's binary_logloss: 0.135773\n",
            "[154]\ttraining's auc: 0.907508\ttraining's binary_logloss: 0.114083\tvalid_1's auc: 0.8316\tvalid_1's binary_logloss: 0.135768\n",
            "[155]\ttraining's auc: 0.907669\ttraining's binary_logloss: 0.114003\tvalid_1's auc: 0.831616\tvalid_1's binary_logloss: 0.135775\n",
            "[156]\ttraining's auc: 0.90782\ttraining's binary_logloss: 0.113926\tvalid_1's auc: 0.831683\tvalid_1's binary_logloss: 0.135769\n",
            "[157]\ttraining's auc: 0.908026\ttraining's binary_logloss: 0.113828\tvalid_1's auc: 0.831667\tvalid_1's binary_logloss: 0.135771\n",
            "[158]\ttraining's auc: 0.908296\ttraining's binary_logloss: 0.113712\tvalid_1's auc: 0.831591\tvalid_1's binary_logloss: 0.135773\n",
            "[159]\ttraining's auc: 0.908621\ttraining's binary_logloss: 0.11364\tvalid_1's auc: 0.831489\tvalid_1's binary_logloss: 0.135783\n",
            "[160]\ttraining's auc: 0.908786\ttraining's binary_logloss: 0.113547\tvalid_1's auc: 0.831429\tvalid_1's binary_logloss: 0.135796\n",
            "[161]\ttraining's auc: 0.909033\ttraining's binary_logloss: 0.11344\tvalid_1's auc: 0.831408\tvalid_1's binary_logloss: 0.135796\n",
            "[162]\ttraining's auc: 0.909245\ttraining's binary_logloss: 0.113356\tvalid_1's auc: 0.831382\tvalid_1's binary_logloss: 0.135809\n",
            "[163]\ttraining's auc: 0.909499\ttraining's binary_logloss: 0.113267\tvalid_1's auc: 0.831223\tvalid_1's binary_logloss: 0.135838\n",
            "[164]\ttraining's auc: 0.909678\ttraining's binary_logloss: 0.113188\tvalid_1's auc: 0.831176\tvalid_1's binary_logloss: 0.135839\n",
            "[165]\ttraining's auc: 0.909982\ttraining's binary_logloss: 0.113091\tvalid_1's auc: 0.831168\tvalid_1's binary_logloss: 0.135842\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 32%|███▏      | 16/50 [07:49<12:15, 21.62s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.164561\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.158894\n",
            "[2]\ttraining's auc: 0.822077\ttraining's binary_logloss: 0.162505\tvalid_1's auc: 0.804437\tvalid_1's binary_logloss: 0.157207\n",
            "[3]\ttraining's auc: 0.823558\ttraining's binary_logloss: 0.160651\tvalid_1's auc: 0.804725\tvalid_1's binary_logloss: 0.155711\n",
            "[4]\ttraining's auc: 0.829922\ttraining's binary_logloss: 0.158919\tvalid_1's auc: 0.815662\tvalid_1's binary_logloss: 0.154376\n",
            "[5]\ttraining's auc: 0.832093\ttraining's binary_logloss: 0.157358\tvalid_1's auc: 0.817233\tvalid_1's binary_logloss: 0.153106\n",
            "[6]\ttraining's auc: 0.834238\ttraining's binary_logloss: 0.155896\tvalid_1's auc: 0.81852\tvalid_1's binary_logloss: 0.151964\n",
            "[7]\ttraining's auc: 0.835128\ttraining's binary_logloss: 0.154576\tvalid_1's auc: 0.819053\tvalid_1's binary_logloss: 0.150905\n",
            "[8]\ttraining's auc: 0.835337\ttraining's binary_logloss: 0.153334\tvalid_1's auc: 0.819343\tvalid_1's binary_logloss: 0.149913\n",
            "[9]\ttraining's auc: 0.835977\ttraining's binary_logloss: 0.15218\tvalid_1's auc: 0.819396\tvalid_1's binary_logloss: 0.149011\n",
            "[10]\ttraining's auc: 0.837412\ttraining's binary_logloss: 0.151104\tvalid_1's auc: 0.819988\tvalid_1's binary_logloss: 0.148207\n",
            "[11]\ttraining's auc: 0.840431\ttraining's binary_logloss: 0.150086\tvalid_1's auc: 0.822953\tvalid_1's binary_logloss: 0.147436\n",
            "[12]\ttraining's auc: 0.841003\ttraining's binary_logloss: 0.149132\tvalid_1's auc: 0.823351\tvalid_1's binary_logloss: 0.14673\n",
            "[13]\ttraining's auc: 0.8414\ttraining's binary_logloss: 0.148239\tvalid_1's auc: 0.823519\tvalid_1's binary_logloss: 0.146065\n",
            "[14]\ttraining's auc: 0.843374\ttraining's binary_logloss: 0.147368\tvalid_1's auc: 0.824161\tvalid_1's binary_logloss: 0.145403\n",
            "[15]\ttraining's auc: 0.845691\ttraining's binary_logloss: 0.146564\tvalid_1's auc: 0.825648\tvalid_1's binary_logloss: 0.144797\n",
            "[16]\ttraining's auc: 0.848505\ttraining's binary_logloss: 0.145758\tvalid_1's auc: 0.827798\tvalid_1's binary_logloss: 0.144214\n",
            "[17]\ttraining's auc: 0.848989\ttraining's binary_logloss: 0.144999\tvalid_1's auc: 0.828199\tvalid_1's binary_logloss: 0.14366\n",
            "[18]\ttraining's auc: 0.849786\ttraining's binary_logloss: 0.144282\tvalid_1's auc: 0.828463\tvalid_1's binary_logloss: 0.143136\n",
            "[19]\ttraining's auc: 0.850684\ttraining's binary_logloss: 0.143597\tvalid_1's auc: 0.828649\tvalid_1's binary_logloss: 0.142632\n",
            "[20]\ttraining's auc: 0.851157\ttraining's binary_logloss: 0.142955\tvalid_1's auc: 0.829406\tvalid_1's binary_logloss: 0.142135\n",
            "[21]\ttraining's auc: 0.851836\ttraining's binary_logloss: 0.142337\tvalid_1's auc: 0.829807\tvalid_1's binary_logloss: 0.141679\n",
            "[22]\ttraining's auc: 0.853053\ttraining's binary_logloss: 0.141751\tvalid_1's auc: 0.829722\tvalid_1's binary_logloss: 0.14127\n",
            "[23]\ttraining's auc: 0.853864\ttraining's binary_logloss: 0.141163\tvalid_1's auc: 0.829974\tvalid_1's binary_logloss: 0.140842\n",
            "[24]\ttraining's auc: 0.854567\ttraining's binary_logloss: 0.140603\tvalid_1's auc: 0.830193\tvalid_1's binary_logloss: 0.140457\n",
            "[25]\ttraining's auc: 0.856119\ttraining's binary_logloss: 0.140057\tvalid_1's auc: 0.830865\tvalid_1's binary_logloss: 0.140077\n",
            "[26]\ttraining's auc: 0.85764\ttraining's binary_logloss: 0.139529\tvalid_1's auc: 0.832469\tvalid_1's binary_logloss: 0.139687\n",
            "[27]\ttraining's auc: 0.858056\ttraining's binary_logloss: 0.139028\tvalid_1's auc: 0.833051\tvalid_1's binary_logloss: 0.139318\n",
            "[28]\ttraining's auc: 0.858458\ttraining's binary_logloss: 0.138555\tvalid_1's auc: 0.833161\tvalid_1's binary_logloss: 0.138968\n",
            "[29]\ttraining's auc: 0.858709\ttraining's binary_logloss: 0.138094\tvalid_1's auc: 0.833242\tvalid_1's binary_logloss: 0.138669\n",
            "[30]\ttraining's auc: 0.859146\ttraining's binary_logloss: 0.13764\tvalid_1's auc: 0.833346\tvalid_1's binary_logloss: 0.13838\n",
            "[31]\ttraining's auc: 0.860252\ttraining's binary_logloss: 0.137186\tvalid_1's auc: 0.833319\tvalid_1's binary_logloss: 0.138085\n",
            "[32]\ttraining's auc: 0.860436\ttraining's binary_logloss: 0.136762\tvalid_1's auc: 0.83315\tvalid_1's binary_logloss: 0.137821\n",
            "[33]\ttraining's auc: 0.860878\ttraining's binary_logloss: 0.136349\tvalid_1's auc: 0.833189\tvalid_1's binary_logloss: 0.137558\n",
            "[34]\ttraining's auc: 0.861176\ttraining's binary_logloss: 0.135951\tvalid_1's auc: 0.833087\tvalid_1's binary_logloss: 0.137298\n",
            "[35]\ttraining's auc: 0.862282\ttraining's binary_logloss: 0.135572\tvalid_1's auc: 0.83377\tvalid_1's binary_logloss: 0.137043\n",
            "[36]\ttraining's auc: 0.863231\ttraining's binary_logloss: 0.135196\tvalid_1's auc: 0.834173\tvalid_1's binary_logloss: 0.136803\n",
            "[37]\ttraining's auc: 0.863598\ttraining's binary_logloss: 0.134837\tvalid_1's auc: 0.834183\tvalid_1's binary_logloss: 0.136593\n",
            "[38]\ttraining's auc: 0.864173\ttraining's binary_logloss: 0.134485\tvalid_1's auc: 0.834228\tvalid_1's binary_logloss: 0.136367\n",
            "[39]\ttraining's auc: 0.865505\ttraining's binary_logloss: 0.134125\tvalid_1's auc: 0.834572\tvalid_1's binary_logloss: 0.136151\n",
            "[40]\ttraining's auc: 0.866654\ttraining's binary_logloss: 0.133772\tvalid_1's auc: 0.834806\tvalid_1's binary_logloss: 0.135948\n",
            "[41]\ttraining's auc: 0.867795\ttraining's binary_logloss: 0.133426\tvalid_1's auc: 0.835068\tvalid_1's binary_logloss: 0.135765\n",
            "[42]\ttraining's auc: 0.868545\ttraining's binary_logloss: 0.133095\tvalid_1's auc: 0.835399\tvalid_1's binary_logloss: 0.135557\n",
            "[43]\ttraining's auc: 0.869421\ttraining's binary_logloss: 0.132771\tvalid_1's auc: 0.835586\tvalid_1's binary_logloss: 0.135389\n",
            "[44]\ttraining's auc: 0.870134\ttraining's binary_logloss: 0.132463\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.135228\n",
            "[45]\ttraining's auc: 0.871014\ttraining's binary_logloss: 0.132164\tvalid_1's auc: 0.836028\tvalid_1's binary_logloss: 0.135061\n",
            "[46]\ttraining's auc: 0.871316\ttraining's binary_logloss: 0.131873\tvalid_1's auc: 0.835906\tvalid_1's binary_logloss: 0.134906\n",
            "[47]\ttraining's auc: 0.871725\ttraining's binary_logloss: 0.131571\tvalid_1's auc: 0.835774\tvalid_1's binary_logloss: 0.13478\n",
            "[48]\ttraining's auc: 0.871955\ttraining's binary_logloss: 0.131294\tvalid_1's auc: 0.835699\tvalid_1's binary_logloss: 0.134639\n",
            "[49]\ttraining's auc: 0.872364\ttraining's binary_logloss: 0.131033\tvalid_1's auc: 0.83541\tvalid_1's binary_logloss: 0.134527\n",
            "[50]\ttraining's auc: 0.872579\ttraining's binary_logloss: 0.130772\tvalid_1's auc: 0.835538\tvalid_1's binary_logloss: 0.134401\n",
            "[51]\ttraining's auc: 0.873019\ttraining's binary_logloss: 0.130507\tvalid_1's auc: 0.835347\tvalid_1's binary_logloss: 0.134273\n",
            "[52]\ttraining's auc: 0.873287\ttraining's binary_logloss: 0.130256\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.134141\n",
            "[53]\ttraining's auc: 0.873529\ttraining's binary_logloss: 0.130017\tvalid_1's auc: 0.835404\tvalid_1's binary_logloss: 0.134016\n",
            "[54]\ttraining's auc: 0.873866\ttraining's binary_logloss: 0.129778\tvalid_1's auc: 0.83544\tvalid_1's binary_logloss: 0.133916\n",
            "[55]\ttraining's auc: 0.87412\ttraining's binary_logloss: 0.129542\tvalid_1's auc: 0.835202\tvalid_1's binary_logloss: 0.13383\n",
            "[56]\ttraining's auc: 0.874574\ttraining's binary_logloss: 0.129303\tvalid_1's auc: 0.835413\tvalid_1's binary_logloss: 0.133715\n",
            "[57]\ttraining's auc: 0.874937\ttraining's binary_logloss: 0.129062\tvalid_1's auc: 0.835318\tvalid_1's binary_logloss: 0.133623\n",
            "[58]\ttraining's auc: 0.875229\ttraining's binary_logloss: 0.128833\tvalid_1's auc: 0.835326\tvalid_1's binary_logloss: 0.133525\n",
            "[59]\ttraining's auc: 0.875376\ttraining's binary_logloss: 0.128619\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.133447\n",
            "[60]\ttraining's auc: 0.875813\ttraining's binary_logloss: 0.12837\tvalid_1's auc: 0.835411\tvalid_1's binary_logloss: 0.133322\n",
            "[61]\ttraining's auc: 0.876086\ttraining's binary_logloss: 0.128169\tvalid_1's auc: 0.835417\tvalid_1's binary_logloss: 0.133229\n",
            "[62]\ttraining's auc: 0.876362\ttraining's binary_logloss: 0.127971\tvalid_1's auc: 0.835338\tvalid_1's binary_logloss: 0.133147\n",
            "[63]\ttraining's auc: 0.876597\ttraining's binary_logloss: 0.12776\tvalid_1's auc: 0.835291\tvalid_1's binary_logloss: 0.133073\n",
            "[64]\ttraining's auc: 0.876955\ttraining's binary_logloss: 0.127565\tvalid_1's auc: 0.835344\tvalid_1's binary_logloss: 0.132987\n",
            "[65]\ttraining's auc: 0.877711\ttraining's binary_logloss: 0.127339\tvalid_1's auc: 0.835567\tvalid_1's binary_logloss: 0.132905\n",
            "[66]\ttraining's auc: 0.8781\ttraining's binary_logloss: 0.127134\tvalid_1's auc: 0.835672\tvalid_1's binary_logloss: 0.13282\n",
            "[67]\ttraining's auc: 0.878354\ttraining's binary_logloss: 0.126935\tvalid_1's auc: 0.835604\tvalid_1's binary_logloss: 0.132741\n",
            "[68]\ttraining's auc: 0.878724\ttraining's binary_logloss: 0.12674\tvalid_1's auc: 0.835575\tvalid_1's binary_logloss: 0.132686\n",
            "[69]\ttraining's auc: 0.87902\ttraining's binary_logloss: 0.126538\tvalid_1's auc: 0.835555\tvalid_1's binary_logloss: 0.132618\n",
            "[70]\ttraining's auc: 0.879766\ttraining's binary_logloss: 0.126335\tvalid_1's auc: 0.835583\tvalid_1's binary_logloss: 0.132535\n",
            "[71]\ttraining's auc: 0.880212\ttraining's binary_logloss: 0.126126\tvalid_1's auc: 0.835527\tvalid_1's binary_logloss: 0.132482\n",
            "[72]\ttraining's auc: 0.880517\ttraining's binary_logloss: 0.125943\tvalid_1's auc: 0.835467\tvalid_1's binary_logloss: 0.132421\n",
            "[73]\ttraining's auc: 0.880837\ttraining's binary_logloss: 0.125766\tvalid_1's auc: 0.835397\tvalid_1's binary_logloss: 0.13237\n",
            "[74]\ttraining's auc: 0.881133\ttraining's binary_logloss: 0.125581\tvalid_1's auc: 0.835329\tvalid_1's binary_logloss: 0.132313\n",
            " 32%|███▏      | 16/50 [07:55<12:15, 21.62s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.160842\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.166458\n",
            "[2]\ttraining's auc: 0.830881\ttraining's binary_logloss: 0.158833\tvalid_1's auc: 0.816224\tvalid_1's binary_logloss: 0.164632\n",
            "[3]\ttraining's auc: 0.831548\ttraining's binary_logloss: 0.157057\tvalid_1's auc: 0.814456\tvalid_1's binary_logloss: 0.163075\n",
            "[4]\ttraining's auc: 0.832715\ttraining's binary_logloss: 0.155442\tvalid_1's auc: 0.815069\tvalid_1's binary_logloss: 0.161663\n",
            "[5]\ttraining's auc: 0.83448\ttraining's binary_logloss: 0.153956\tvalid_1's auc: 0.816465\tvalid_1's binary_logloss: 0.160296\n",
            "[6]\ttraining's auc: 0.835365\ttraining's binary_logloss: 0.152544\tvalid_1's auc: 0.815947\tvalid_1's binary_logloss: 0.159088\n",
            "[7]\ttraining's auc: 0.837736\ttraining's binary_logloss: 0.151277\tvalid_1's auc: 0.817942\tvalid_1's binary_logloss: 0.157963\n",
            "[8]\ttraining's auc: 0.838819\ttraining's binary_logloss: 0.150103\tvalid_1's auc: 0.818441\tvalid_1's binary_logloss: 0.156889\n",
            "[9]\ttraining's auc: 0.840157\ttraining's binary_logloss: 0.148977\tvalid_1's auc: 0.81963\tvalid_1's binary_logloss: 0.15589\n",
            "[10]\ttraining's auc: 0.841396\ttraining's binary_logloss: 0.147931\tvalid_1's auc: 0.819886\tvalid_1's binary_logloss: 0.154985\n",
            "[11]\ttraining's auc: 0.843661\ttraining's binary_logloss: 0.146936\tvalid_1's auc: 0.822107\tvalid_1's binary_logloss: 0.154157\n",
            "[12]\ttraining's auc: 0.847427\ttraining's binary_logloss: 0.145968\tvalid_1's auc: 0.825454\tvalid_1's binary_logloss: 0.153333\n",
            "[13]\ttraining's auc: 0.849191\ttraining's binary_logloss: 0.145076\tvalid_1's auc: 0.827166\tvalid_1's binary_logloss: 0.152536\n",
            "[14]\ttraining's auc: 0.849724\ttraining's binary_logloss: 0.144233\tvalid_1's auc: 0.827425\tvalid_1's binary_logloss: 0.151798\n",
            "[15]\ttraining's auc: 0.850549\ttraining's binary_logloss: 0.143436\tvalid_1's auc: 0.827832\tvalid_1's binary_logloss: 0.151138\n",
            "[16]\ttraining's auc: 0.851461\ttraining's binary_logloss: 0.142684\tvalid_1's auc: 0.828035\tvalid_1's binary_logloss: 0.150502\n",
            "[17]\ttraining's auc: 0.851649\ttraining's binary_logloss: 0.141959\tvalid_1's auc: 0.827895\tvalid_1's binary_logloss: 0.149919\n",
            "[18]\ttraining's auc: 0.852245\ttraining's binary_logloss: 0.141285\tvalid_1's auc: 0.828726\tvalid_1's binary_logloss: 0.14935\n",
            "[19]\ttraining's auc: 0.852634\ttraining's binary_logloss: 0.140622\tvalid_1's auc: 0.828675\tvalid_1's binary_logloss: 0.148827\n",
            "[20]\ttraining's auc: 0.85332\ttraining's binary_logloss: 0.139953\tvalid_1's auc: 0.82895\tvalid_1's binary_logloss: 0.148307\n",
            "[21]\ttraining's auc: 0.853531\ttraining's binary_logloss: 0.139332\tvalid_1's auc: 0.829115\tvalid_1's binary_logloss: 0.147816\n",
            "[22]\ttraining's auc: 0.854071\ttraining's binary_logloss: 0.138725\tvalid_1's auc: 0.829236\tvalid_1's binary_logloss: 0.147347\n",
            "[23]\ttraining's auc: 0.854366\ttraining's binary_logloss: 0.138178\tvalid_1's auc: 0.829523\tvalid_1's binary_logloss: 0.146916\n",
            "[24]\ttraining's auc: 0.854682\ttraining's binary_logloss: 0.137607\tvalid_1's auc: 0.829549\tvalid_1's binary_logloss: 0.146494\n",
            "[25]\ttraining's auc: 0.855943\ttraining's binary_logloss: 0.137065\tvalid_1's auc: 0.830098\tvalid_1's binary_logloss: 0.146083\n",
            "[26]\ttraining's auc: 0.856797\ttraining's binary_logloss: 0.136567\tvalid_1's auc: 0.830591\tvalid_1's binary_logloss: 0.145685\n",
            "[27]\ttraining's auc: 0.857123\ttraining's binary_logloss: 0.136073\tvalid_1's auc: 0.830936\tvalid_1's binary_logloss: 0.145307\n",
            "[28]\ttraining's auc: 0.857576\ttraining's binary_logloss: 0.135592\tvalid_1's auc: 0.831247\tvalid_1's binary_logloss: 0.144946\n",
            "[29]\ttraining's auc: 0.857791\ttraining's binary_logloss: 0.135141\tvalid_1's auc: 0.831376\tvalid_1's binary_logloss: 0.144585\n",
            "[30]\ttraining's auc: 0.858145\ttraining's binary_logloss: 0.134706\tvalid_1's auc: 0.831509\tvalid_1's binary_logloss: 0.144263\n",
            "[31]\ttraining's auc: 0.85899\ttraining's binary_logloss: 0.134285\tvalid_1's auc: 0.831481\tvalid_1's binary_logloss: 0.143943\n",
            "[32]\ttraining's auc: 0.859431\ttraining's binary_logloss: 0.133878\tvalid_1's auc: 0.831575\tvalid_1's binary_logloss: 0.143654\n",
            "[33]\ttraining's auc: 0.859901\ttraining's binary_logloss: 0.133476\tvalid_1's auc: 0.831613\tvalid_1's binary_logloss: 0.143361\n",
            "[34]\ttraining's auc: 0.860538\ttraining's binary_logloss: 0.133096\tvalid_1's auc: 0.831979\tvalid_1's binary_logloss: 0.143066\n",
            "[35]\ttraining's auc: 0.861425\ttraining's binary_logloss: 0.132712\tvalid_1's auc: 0.832243\tvalid_1's binary_logloss: 0.142801\n",
            "[36]\ttraining's auc: 0.86266\ttraining's binary_logloss: 0.132358\tvalid_1's auc: 0.832429\tvalid_1's binary_logloss: 0.142551\n",
            "[37]\ttraining's auc: 0.863063\ttraining's binary_logloss: 0.13201\tvalid_1's auc: 0.832445\tvalid_1's binary_logloss: 0.142301\n",
            "[38]\ttraining's auc: 0.863551\ttraining's binary_logloss: 0.13166\tvalid_1's auc: 0.832529\tvalid_1's binary_logloss: 0.142086\n",
            "[39]\ttraining's auc: 0.863952\ttraining's binary_logloss: 0.131341\tvalid_1's auc: 0.832532\tvalid_1's binary_logloss: 0.14187\n",
            "[40]\ttraining's auc: 0.864473\ttraining's binary_logloss: 0.131022\tvalid_1's auc: 0.832482\tvalid_1's binary_logloss: 0.141672\n",
            "[41]\ttraining's auc: 0.864978\ttraining's binary_logloss: 0.130705\tvalid_1's auc: 0.832511\tvalid_1's binary_logloss: 0.14146\n",
            "[42]\ttraining's auc: 0.865282\ttraining's binary_logloss: 0.130412\tvalid_1's auc: 0.832352\tvalid_1's binary_logloss: 0.141297\n",
            "[43]\ttraining's auc: 0.86569\ttraining's binary_logloss: 0.130122\tvalid_1's auc: 0.832244\tvalid_1's binary_logloss: 0.141126\n",
            "[44]\ttraining's auc: 0.866037\ttraining's binary_logloss: 0.129838\tvalid_1's auc: 0.832301\tvalid_1's binary_logloss: 0.140951\n",
            "[45]\ttraining's auc: 0.867472\ttraining's binary_logloss: 0.12954\tvalid_1's auc: 0.83233\tvalid_1's binary_logloss: 0.140776\n",
            "[46]\ttraining's auc: 0.86808\ttraining's binary_logloss: 0.129236\tvalid_1's auc: 0.832468\tvalid_1's binary_logloss: 0.140606\n",
            "[47]\ttraining's auc: 0.869031\ttraining's binary_logloss: 0.128948\tvalid_1's auc: 0.832432\tvalid_1's binary_logloss: 0.140456\n",
            "[48]\ttraining's auc: 0.869878\ttraining's binary_logloss: 0.12868\tvalid_1's auc: 0.832732\tvalid_1's binary_logloss: 0.140305\n",
            "[49]\ttraining's auc: 0.870704\ttraining's binary_logloss: 0.12841\tvalid_1's auc: 0.834308\tvalid_1's binary_logloss: 0.140135\n",
            "[50]\ttraining's auc: 0.871235\ttraining's binary_logloss: 0.128156\tvalid_1's auc: 0.834267\tvalid_1's binary_logloss: 0.139981\n",
            "[51]\ttraining's auc: 0.871687\ttraining's binary_logloss: 0.127913\tvalid_1's auc: 0.83421\tvalid_1's binary_logloss: 0.139844\n",
            "[52]\ttraining's auc: 0.87222\ttraining's binary_logloss: 0.127654\tvalid_1's auc: 0.834333\tvalid_1's binary_logloss: 0.139709\n",
            "[53]\ttraining's auc: 0.872945\ttraining's binary_logloss: 0.127418\tvalid_1's auc: 0.834701\tvalid_1's binary_logloss: 0.139571\n",
            "[54]\ttraining's auc: 0.873266\ttraining's binary_logloss: 0.127187\tvalid_1's auc: 0.834937\tvalid_1's binary_logloss: 0.139444\n",
            "[55]\ttraining's auc: 0.873798\ttraining's binary_logloss: 0.126958\tvalid_1's auc: 0.834911\tvalid_1's binary_logloss: 0.139312\n",
            "[56]\ttraining's auc: 0.874115\ttraining's binary_logloss: 0.126736\tvalid_1's auc: 0.834902\tvalid_1's binary_logloss: 0.139201\n",
            "[57]\ttraining's auc: 0.874714\ttraining's binary_logloss: 0.126494\tvalid_1's auc: 0.834902\tvalid_1's binary_logloss: 0.139106\n",
            "[58]\ttraining's auc: 0.875033\ttraining's binary_logloss: 0.126282\tvalid_1's auc: 0.835192\tvalid_1's binary_logloss: 0.139\n",
            "[59]\ttraining's auc: 0.875511\ttraining's binary_logloss: 0.126052\tvalid_1's auc: 0.835286\tvalid_1's binary_logloss: 0.138893\n",
            "[60]\ttraining's auc: 0.876002\ttraining's binary_logloss: 0.125835\tvalid_1's auc: 0.835387\tvalid_1's binary_logloss: 0.138791\n",
            "[61]\ttraining's auc: 0.876255\ttraining's binary_logloss: 0.12561\tvalid_1's auc: 0.83549\tvalid_1's binary_logloss: 0.138694\n",
            "[62]\ttraining's auc: 0.876452\ttraining's binary_logloss: 0.125407\tvalid_1's auc: 0.835509\tvalid_1's binary_logloss: 0.138594\n",
            "[63]\ttraining's auc: 0.877285\ttraining's binary_logloss: 0.125184\tvalid_1's auc: 0.835441\tvalid_1's binary_logloss: 0.138505\n",
            "[64]\ttraining's auc: 0.878131\ttraining's binary_logloss: 0.124959\tvalid_1's auc: 0.835626\tvalid_1's binary_logloss: 0.138406\n",
            "[65]\ttraining's auc: 0.878659\ttraining's binary_logloss: 0.124751\tvalid_1's auc: 0.835655\tvalid_1's binary_logloss: 0.138315\n",
            "[66]\ttraining's auc: 0.87943\ttraining's binary_logloss: 0.124554\tvalid_1's auc: 0.835901\tvalid_1's binary_logloss: 0.138232\n",
            "[67]\ttraining's auc: 0.880014\ttraining's binary_logloss: 0.124352\tvalid_1's auc: 0.836044\tvalid_1's binary_logloss: 0.138145\n",
            "[68]\ttraining's auc: 0.88029\ttraining's binary_logloss: 0.124173\tvalid_1's auc: 0.836148\tvalid_1's binary_logloss: 0.138064\n",
            "[69]\ttraining's auc: 0.880731\ttraining's binary_logloss: 0.123994\tvalid_1's auc: 0.83628\tvalid_1's binary_logloss: 0.137996\n",
            "[70]\ttraining's auc: 0.881312\ttraining's binary_logloss: 0.123805\tvalid_1's auc: 0.83641\tvalid_1's binary_logloss: 0.137912\n",
            "[71]\ttraining's auc: 0.881848\ttraining's binary_logloss: 0.123627\tvalid_1's auc: 0.836437\tvalid_1's binary_logloss: 0.137844\n",
            "[72]\ttraining's auc: 0.882307\ttraining's binary_logloss: 0.123454\tvalid_1's auc: 0.836544\tvalid_1's binary_logloss: 0.137764\n",
            "[73]\ttraining's auc: 0.88259\ttraining's binary_logloss: 0.123288\tvalid_1's auc: 0.836586\tvalid_1's binary_logloss: 0.137695\n",
            "[74]\ttraining's auc: 0.882951\ttraining's binary_logloss: 0.123112\tvalid_1's auc: 0.836527\tvalid_1's binary_logloss: 0.137632\n",
            "[75]\ttraining's auc: 0.883451\ttraining's binary_logloss: 0.122946\tvalid_1's auc: 0.836539\tvalid_1's binary_logloss: 0.137569\n",
            "[76]\ttraining's auc: 0.884147\ttraining's binary_logloss: 0.122764\tvalid_1's auc: 0.836562\tvalid_1's binary_logloss: 0.137498\n",
            "[77]\ttraining's auc: 0.884564\ttraining's binary_logloss: 0.122578\tvalid_1's auc: 0.83667\tvalid_1's binary_logloss: 0.137437\n",
            "[78]\ttraining's auc: 0.885102\ttraining's binary_logloss: 0.122404\tvalid_1's auc: 0.836418\tvalid_1's binary_logloss: 0.137397\n",
            "[79]\ttraining's auc: 0.885541\ttraining's binary_logloss: 0.122224\tvalid_1's auc: 0.836439\tvalid_1's binary_logloss: 0.137326\n",
            "[80]\ttraining's auc: 0.88597\ttraining's binary_logloss: 0.122045\tvalid_1's auc: 0.836243\tvalid_1's binary_logloss: 0.137305\n",
            "[81]\ttraining's auc: 0.886549\ttraining's binary_logloss: 0.121866\tvalid_1's auc: 0.836595\tvalid_1's binary_logloss: 0.137252\n",
            "[82]\ttraining's auc: 0.886924\ttraining's binary_logloss: 0.121704\tvalid_1's auc: 0.836762\tvalid_1's binary_logloss: 0.137177\n",
            "[83]\ttraining's auc: 0.887254\ttraining's binary_logloss: 0.121551\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.13714\n",
            "[84]\ttraining's auc: 0.887682\ttraining's binary_logloss: 0.121399\tvalid_1's auc: 0.836776\tvalid_1's binary_logloss: 0.137102\n",
            "[85]\ttraining's auc: 0.888014\ttraining's binary_logloss: 0.121242\tvalid_1's auc: 0.837005\tvalid_1's binary_logloss: 0.137039\n",
            "[86]\ttraining's auc: 0.888283\ttraining's binary_logloss: 0.121104\tvalid_1's auc: 0.836961\tvalid_1's binary_logloss: 0.136996\n",
            "[87]\ttraining's auc: 0.888578\ttraining's binary_logloss: 0.120955\tvalid_1's auc: 0.83705\tvalid_1's binary_logloss: 0.136955\n",
            "[88]\ttraining's auc: 0.888851\ttraining's binary_logloss: 0.120825\tvalid_1's auc: 0.836996\tvalid_1's binary_logloss: 0.136921\n",
            "[89]\ttraining's auc: 0.88921\ttraining's binary_logloss: 0.120685\tvalid_1's auc: 0.836827\tvalid_1's binary_logloss: 0.136895\n",
            "[90]\ttraining's auc: 0.889475\ttraining's binary_logloss: 0.120541\tvalid_1's auc: 0.836853\tvalid_1's binary_logloss: 0.136852\n",
            "[91]\ttraining's auc: 0.889779\ttraining's binary_logloss: 0.12041\tvalid_1's auc: 0.836838\tvalid_1's binary_logloss: 0.136828\n",
            "[92]\ttraining's auc: 0.890134\ttraining's binary_logloss: 0.12026\tvalid_1's auc: 0.83683\tvalid_1's binary_logloss: 0.136807\n",
            "[93]\ttraining's auc: 0.890451\ttraining's binary_logloss: 0.12012\tvalid_1's auc: 0.836854\tvalid_1's binary_logloss: 0.136778\n",
            "[94]\ttraining's auc: 0.89074\ttraining's binary_logloss: 0.119972\tvalid_1's auc: 0.836986\tvalid_1's binary_logloss: 0.136744\n",
            "[95]\ttraining's auc: 0.891003\ttraining's binary_logloss: 0.119843\tvalid_1's auc: 0.836855\tvalid_1's binary_logloss: 0.136727\n",
            "[96]\ttraining's auc: 0.891342\ttraining's binary_logloss: 0.119718\tvalid_1's auc: 0.836825\tvalid_1's binary_logloss: 0.136708\n",
            "[97]\ttraining's auc: 0.891541\ttraining's binary_logloss: 0.119596\tvalid_1's auc: 0.836898\tvalid_1's binary_logloss: 0.136672\n",
            "[98]\ttraining's auc: 0.891809\ttraining's binary_logloss: 0.119467\tvalid_1's auc: 0.836863\tvalid_1's binary_logloss: 0.136656\n",
            "[99]\ttraining's auc: 0.8922\ttraining's binary_logloss: 0.119314\tvalid_1's auc: 0.836941\tvalid_1's binary_logloss: 0.136633\n",
            "[100]\ttraining's auc: 0.892492\ttraining's binary_logloss: 0.119191\tvalid_1's auc: 0.836993\tvalid_1's binary_logloss: 0.136602\n",
            "[101]\ttraining's auc: 0.89279\ttraining's binary_logloss: 0.119066\tvalid_1's auc: 0.8369\tvalid_1's binary_logloss: 0.136597\n",
            "[102]\ttraining's auc: 0.892932\ttraining's binary_logloss: 0.118957\tvalid_1's auc: 0.836974\tvalid_1's binary_logloss: 0.13657\n",
            "[103]\ttraining's auc: 0.893132\ttraining's binary_logloss: 0.118862\tvalid_1's auc: 0.837025\tvalid_1's binary_logloss: 0.13653\n",
            "[104]\ttraining's auc: 0.893475\ttraining's binary_logloss: 0.118748\tvalid_1's auc: 0.836876\tvalid_1's binary_logloss: 0.136533\n",
            "[105]\ttraining's auc: 0.893742\ttraining's binary_logloss: 0.11864\tvalid_1's auc: 0.836863\tvalid_1's binary_logloss: 0.136517\n",
            "[106]\ttraining's auc: 0.894025\ttraining's binary_logloss: 0.118531\tvalid_1's auc: 0.83687\tvalid_1's binary_logloss: 0.136498\n",
            "[107]\ttraining's auc: 0.894238\ttraining's binary_logloss: 0.118419\tvalid_1's auc: 0.836811\tvalid_1's binary_logloss: 0.136489\n",
            "[108]\ttraining's auc: 0.894407\ttraining's binary_logloss: 0.118318\tvalid_1's auc: 0.836692\tvalid_1's binary_logloss: 0.136478\n",
            "[109]\ttraining's auc: 0.894627\ttraining's binary_logloss: 0.118215\tvalid_1's auc: 0.836643\tvalid_1's binary_logloss: 0.136476\n",
            "[110]\ttraining's auc: 0.895076\ttraining's binary_logloss: 0.118081\tvalid_1's auc: 0.836683\tvalid_1's binary_logloss: 0.136457\n",
            "[111]\ttraining's auc: 0.895486\ttraining's binary_logloss: 0.117962\tvalid_1's auc: 0.836563\tvalid_1's binary_logloss: 0.136454\n",
            "[112]\ttraining's auc: 0.895829\ttraining's binary_logloss: 0.117835\tvalid_1's auc: 0.836493\tvalid_1's binary_logloss: 0.136441\n",
            "[113]\ttraining's auc: 0.896099\ttraining's binary_logloss: 0.117723\tvalid_1's auc: 0.836418\tvalid_1's binary_logloss: 0.136418\n",
            "[114]\ttraining's auc: 0.896589\ttraining's binary_logloss: 0.117618\tvalid_1's auc: 0.836433\tvalid_1's binary_logloss: 0.136408\n",
            "[115]\ttraining's auc: 0.897084\ttraining's binary_logloss: 0.117478\tvalid_1's auc: 0.836475\tvalid_1's binary_logloss: 0.136392\n",
            "[116]\ttraining's auc: 0.897406\ttraining's binary_logloss: 0.117353\tvalid_1's auc: 0.836459\tvalid_1's binary_logloss: 0.136377\n",
            "[117]\ttraining's auc: 0.897675\ttraining's binary_logloss: 0.117234\tvalid_1's auc: 0.836423\tvalid_1's binary_logloss: 0.13637\n",
            " 34%|███▍      | 17/50 [08:06<13:42, 24.92s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.155069\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.157598\n",
            "[2]\ttraining's auc: 0.833264\ttraining's binary_logloss: 0.14938\tvalid_1's auc: 0.80608\tvalid_1's binary_logloss: 0.153245\n",
            "[3]\ttraining's auc: 0.843008\ttraining's binary_logloss: 0.14528\tvalid_1's auc: 0.81486\tvalid_1's binary_logloss: 0.15009\n",
            "[4]\ttraining's auc: 0.846798\ttraining's binary_logloss: 0.141999\tvalid_1's auc: 0.817586\tvalid_1's binary_logloss: 0.147654\n",
            "[5]\ttraining's auc: 0.851133\ttraining's binary_logloss: 0.139333\tvalid_1's auc: 0.818779\tvalid_1's binary_logloss: 0.145886\n",
            "[6]\ttraining's auc: 0.853828\ttraining's binary_logloss: 0.137005\tvalid_1's auc: 0.820087\tvalid_1's binary_logloss: 0.144286\n",
            "[7]\ttraining's auc: 0.857458\ttraining's binary_logloss: 0.135123\tvalid_1's auc: 0.821754\tvalid_1's binary_logloss: 0.142943\n",
            "[8]\ttraining's auc: 0.859892\ttraining's binary_logloss: 0.133318\tvalid_1's auc: 0.823223\tvalid_1's binary_logloss: 0.14179\n",
            "[9]\ttraining's auc: 0.863716\ttraining's binary_logloss: 0.131752\tvalid_1's auc: 0.824125\tvalid_1's binary_logloss: 0.140887\n",
            "[10]\ttraining's auc: 0.866669\ttraining's binary_logloss: 0.13044\tvalid_1's auc: 0.82568\tvalid_1's binary_logloss: 0.140098\n",
            "[11]\ttraining's auc: 0.868259\ttraining's binary_logloss: 0.129283\tvalid_1's auc: 0.825715\tvalid_1's binary_logloss: 0.139458\n",
            "[12]\ttraining's auc: 0.870626\ttraining's binary_logloss: 0.128203\tvalid_1's auc: 0.826168\tvalid_1's binary_logloss: 0.139003\n",
            "[13]\ttraining's auc: 0.872462\ttraining's binary_logloss: 0.127169\tvalid_1's auc: 0.826477\tvalid_1's binary_logloss: 0.138571\n",
            "[14]\ttraining's auc: 0.874121\ttraining's binary_logloss: 0.126341\tvalid_1's auc: 0.826264\tvalid_1's binary_logloss: 0.138271\n",
            "[15]\ttraining's auc: 0.875318\ttraining's binary_logloss: 0.125459\tvalid_1's auc: 0.826901\tvalid_1's binary_logloss: 0.13798\n",
            "[16]\ttraining's auc: 0.876683\ttraining's binary_logloss: 0.124718\tvalid_1's auc: 0.826735\tvalid_1's binary_logloss: 0.13776\n",
            "[17]\ttraining's auc: 0.878551\ttraining's binary_logloss: 0.123974\tvalid_1's auc: 0.826965\tvalid_1's binary_logloss: 0.137472\n",
            "[18]\ttraining's auc: 0.879622\ttraining's binary_logloss: 0.123323\tvalid_1's auc: 0.827066\tvalid_1's binary_logloss: 0.137285\n",
            "[19]\ttraining's auc: 0.882792\ttraining's binary_logloss: 0.122528\tvalid_1's auc: 0.82713\tvalid_1's binary_logloss: 0.137062\n",
            "[20]\ttraining's auc: 0.883787\ttraining's binary_logloss: 0.121963\tvalid_1's auc: 0.828574\tvalid_1's binary_logloss: 0.136732\n",
            "[21]\ttraining's auc: 0.88527\ttraining's binary_logloss: 0.12136\tvalid_1's auc: 0.828742\tvalid_1's binary_logloss: 0.136612\n",
            "[22]\ttraining's auc: 0.886479\ttraining's binary_logloss: 0.120798\tvalid_1's auc: 0.828804\tvalid_1's binary_logloss: 0.136527\n",
            "[23]\ttraining's auc: 0.888031\ttraining's binary_logloss: 0.120182\tvalid_1's auc: 0.828671\tvalid_1's binary_logloss: 0.136502\n",
            "[24]\ttraining's auc: 0.890915\ttraining's binary_logloss: 0.119563\tvalid_1's auc: 0.829865\tvalid_1's binary_logloss: 0.136256\n",
            "[25]\ttraining's auc: 0.892196\ttraining's binary_logloss: 0.119038\tvalid_1's auc: 0.830004\tvalid_1's binary_logloss: 0.136164\n",
            "[26]\ttraining's auc: 0.893183\ttraining's binary_logloss: 0.118603\tvalid_1's auc: 0.829609\tvalid_1's binary_logloss: 0.136188\n",
            "[27]\ttraining's auc: 0.894365\ttraining's binary_logloss: 0.118131\tvalid_1's auc: 0.829414\tvalid_1's binary_logloss: 0.136181\n",
            "[28]\ttraining's auc: 0.896177\ttraining's binary_logloss: 0.117564\tvalid_1's auc: 0.829814\tvalid_1's binary_logloss: 0.136039\n",
            "[29]\ttraining's auc: 0.897959\ttraining's binary_logloss: 0.117099\tvalid_1's auc: 0.830163\tvalid_1's binary_logloss: 0.135994\n",
            "[30]\ttraining's auc: 0.899196\ttraining's binary_logloss: 0.116642\tvalid_1's auc: 0.830712\tvalid_1's binary_logloss: 0.135919\n",
            "[31]\ttraining's auc: 0.900516\ttraining's binary_logloss: 0.116169\tvalid_1's auc: 0.830863\tvalid_1's binary_logloss: 0.135904\n",
            "[32]\ttraining's auc: 0.90145\ttraining's binary_logloss: 0.115801\tvalid_1's auc: 0.830364\tvalid_1's binary_logloss: 0.135959\n",
            "[33]\ttraining's auc: 0.903171\ttraining's binary_logloss: 0.115361\tvalid_1's auc: 0.830493\tvalid_1's binary_logloss: 0.135927\n",
            "[34]\ttraining's auc: 0.904655\ttraining's binary_logloss: 0.114893\tvalid_1's auc: 0.830506\tvalid_1's binary_logloss: 0.135878\n",
            "[35]\ttraining's auc: 0.905279\ttraining's binary_logloss: 0.114554\tvalid_1's auc: 0.830533\tvalid_1's binary_logloss: 0.135893\n",
            "[36]\ttraining's auc: 0.905885\ttraining's binary_logloss: 0.114267\tvalid_1's auc: 0.830513\tvalid_1's binary_logloss: 0.135901\n",
            "[37]\ttraining's auc: 0.906764\ttraining's binary_logloss: 0.113894\tvalid_1's auc: 0.830563\tvalid_1's binary_logloss: 0.135914\n",
            "[38]\ttraining's auc: 0.907391\ttraining's binary_logloss: 0.113539\tvalid_1's auc: 0.830691\tvalid_1's binary_logloss: 0.135914\n",
            "[39]\ttraining's auc: 0.908167\ttraining's binary_logloss: 0.11318\tvalid_1's auc: 0.830584\tvalid_1's binary_logloss: 0.135931\n",
            "[40]\ttraining's auc: 0.908948\ttraining's binary_logloss: 0.112854\tvalid_1's auc: 0.830477\tvalid_1's binary_logloss: 0.135964\n",
            "[41]\ttraining's auc: 0.909631\ttraining's binary_logloss: 0.112535\tvalid_1's auc: 0.830878\tvalid_1's binary_logloss: 0.135891\n",
            "[42]\ttraining's auc: 0.910412\ttraining's binary_logloss: 0.112238\tvalid_1's auc: 0.830283\tvalid_1's binary_logloss: 0.136017\n",
            "[43]\ttraining's auc: 0.911209\ttraining's binary_logloss: 0.111925\tvalid_1's auc: 0.83007\tvalid_1's binary_logloss: 0.13605\n",
            "[44]\ttraining's auc: 0.911958\ttraining's binary_logloss: 0.111584\tvalid_1's auc: 0.82994\tvalid_1's binary_logloss: 0.136057\n",
            "[45]\ttraining's auc: 0.912742\ttraining's binary_logloss: 0.111264\tvalid_1's auc: 0.829649\tvalid_1's binary_logloss: 0.13613\n",
            "[46]\ttraining's auc: 0.913425\ttraining's binary_logloss: 0.110947\tvalid_1's auc: 0.829818\tvalid_1's binary_logloss: 0.136112\n",
            "[47]\ttraining's auc: 0.914085\ttraining's binary_logloss: 0.110655\tvalid_1's auc: 0.83004\tvalid_1's binary_logloss: 0.136073\n",
            "[48]\ttraining's auc: 0.914349\ttraining's binary_logloss: 0.110446\tvalid_1's auc: 0.830122\tvalid_1's binary_logloss: 0.136081\n",
            "[49]\ttraining's auc: 0.914885\ttraining's binary_logloss: 0.110194\tvalid_1's auc: 0.829882\tvalid_1's binary_logloss: 0.13615\n",
            "[50]\ttraining's auc: 0.9154\ttraining's binary_logloss: 0.109913\tvalid_1's auc: 0.829646\tvalid_1's binary_logloss: 0.136212\n",
            "[51]\ttraining's auc: 0.915742\ttraining's binary_logloss: 0.109715\tvalid_1's auc: 0.829309\tvalid_1's binary_logloss: 0.136282\n",
            "[52]\ttraining's auc: 0.916523\ttraining's binary_logloss: 0.109327\tvalid_1's auc: 0.829178\tvalid_1's binary_logloss: 0.136343\n",
            "[53]\ttraining's auc: 0.917665\ttraining's binary_logloss: 0.109009\tvalid_1's auc: 0.829644\tvalid_1's binary_logloss: 0.136289\n",
            "[54]\ttraining's auc: 0.918223\ttraining's binary_logloss: 0.108709\tvalid_1's auc: 0.829233\tvalid_1's binary_logloss: 0.136315\n",
            "[55]\ttraining's auc: 0.919063\ttraining's binary_logloss: 0.108457\tvalid_1's auc: 0.829284\tvalid_1's binary_logloss: 0.136333\n",
            "[56]\ttraining's auc: 0.919424\ttraining's binary_logloss: 0.108231\tvalid_1's auc: 0.828868\tvalid_1's binary_logloss: 0.136406\n",
            "[57]\ttraining's auc: 0.919654\ttraining's binary_logloss: 0.108069\tvalid_1's auc: 0.828465\tvalid_1's binary_logloss: 0.136499\n",
            "[58]\ttraining's auc: 0.92047\ttraining's binary_logloss: 0.107756\tvalid_1's auc: 0.828409\tvalid_1's binary_logloss: 0.136529\n",
            "[59]\ttraining's auc: 0.921185\ttraining's binary_logloss: 0.107477\tvalid_1's auc: 0.828539\tvalid_1's binary_logloss: 0.136531\n",
            "[60]\ttraining's auc: 0.921431\ttraining's binary_logloss: 0.107288\tvalid_1's auc: 0.828264\tvalid_1's binary_logloss: 0.136647\n",
            "[61]\ttraining's auc: 0.921707\ttraining's binary_logloss: 0.107115\tvalid_1's auc: 0.828105\tvalid_1's binary_logloss: 0.136706\n",
            "[62]\ttraining's auc: 0.922055\ttraining's binary_logloss: 0.106917\tvalid_1's auc: 0.828003\tvalid_1's binary_logloss: 0.136711\n",
            "[63]\ttraining's auc: 0.922741\ttraining's binary_logloss: 0.106702\tvalid_1's auc: 0.827978\tvalid_1's binary_logloss: 0.136737\n",
            "[64]\ttraining's auc: 0.922876\ttraining's binary_logloss: 0.106555\tvalid_1's auc: 0.827757\tvalid_1's binary_logloss: 0.136779\n",
            " 34%|███▍      | 17/50 [08:13<13:42, 24.92s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.157492\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.153542\n",
            "[2]\ttraining's auc: 0.828301\ttraining's binary_logloss: 0.151807\tvalid_1's auc: 0.814899\tvalid_1's binary_logloss: 0.149198\n",
            "[3]\ttraining's auc: 0.837789\ttraining's binary_logloss: 0.147559\tvalid_1's auc: 0.81876\tvalid_1's binary_logloss: 0.146057\n",
            "[4]\ttraining's auc: 0.844319\ttraining's binary_logloss: 0.144263\tvalid_1's auc: 0.824386\tvalid_1's binary_logloss: 0.143636\n",
            "[5]\ttraining's auc: 0.848845\ttraining's binary_logloss: 0.141531\tvalid_1's auc: 0.826671\tvalid_1's binary_logloss: 0.141652\n",
            "[6]\ttraining's auc: 0.852023\ttraining's binary_logloss: 0.139193\tvalid_1's auc: 0.82927\tvalid_1's binary_logloss: 0.140029\n",
            "[7]\ttraining's auc: 0.854493\ttraining's binary_logloss: 0.137211\tvalid_1's auc: 0.830645\tvalid_1's binary_logloss: 0.13871\n",
            "[8]\ttraining's auc: 0.857836\ttraining's binary_logloss: 0.135486\tvalid_1's auc: 0.830434\tvalid_1's binary_logloss: 0.137723\n",
            "[9]\ttraining's auc: 0.860257\ttraining's binary_logloss: 0.13393\tvalid_1's auc: 0.830183\tvalid_1's binary_logloss: 0.136843\n",
            "[10]\ttraining's auc: 0.864911\ttraining's binary_logloss: 0.132504\tvalid_1's auc: 0.831919\tvalid_1's binary_logloss: 0.136033\n",
            "[11]\ttraining's auc: 0.868145\ttraining's binary_logloss: 0.131273\tvalid_1's auc: 0.83224\tvalid_1's binary_logloss: 0.135379\n",
            "[12]\ttraining's auc: 0.870727\ttraining's binary_logloss: 0.130142\tvalid_1's auc: 0.832069\tvalid_1's binary_logloss: 0.134915\n",
            "[13]\ttraining's auc: 0.871728\ttraining's binary_logloss: 0.12914\tvalid_1's auc: 0.832515\tvalid_1's binary_logloss: 0.134405\n",
            "[14]\ttraining's auc: 0.872594\ttraining's binary_logloss: 0.128242\tvalid_1's auc: 0.832179\tvalid_1's binary_logloss: 0.134043\n",
            "[15]\ttraining's auc: 0.874065\ttraining's binary_logloss: 0.127422\tvalid_1's auc: 0.832231\tvalid_1's binary_logloss: 0.133738\n",
            "[16]\ttraining's auc: 0.876735\ttraining's binary_logloss: 0.126582\tvalid_1's auc: 0.832767\tvalid_1's binary_logloss: 0.133468\n",
            "[17]\ttraining's auc: 0.878166\ttraining's binary_logloss: 0.125814\tvalid_1's auc: 0.832845\tvalid_1's binary_logloss: 0.133224\n",
            "[18]\ttraining's auc: 0.879237\ttraining's binary_logloss: 0.125162\tvalid_1's auc: 0.832449\tvalid_1's binary_logloss: 0.133037\n",
            "[19]\ttraining's auc: 0.880697\ttraining's binary_logloss: 0.124472\tvalid_1's auc: 0.832838\tvalid_1's binary_logloss: 0.132766\n",
            "[20]\ttraining's auc: 0.881604\ttraining's binary_logloss: 0.123873\tvalid_1's auc: 0.832556\tvalid_1's binary_logloss: 0.132646\n",
            "[21]\ttraining's auc: 0.884212\ttraining's binary_logloss: 0.123199\tvalid_1's auc: 0.832421\tvalid_1's binary_logloss: 0.132541\n",
            "[22]\ttraining's auc: 0.885996\ttraining's binary_logloss: 0.122543\tvalid_1's auc: 0.832844\tvalid_1's binary_logloss: 0.132405\n",
            "[23]\ttraining's auc: 0.888038\ttraining's binary_logloss: 0.121914\tvalid_1's auc: 0.832985\tvalid_1's binary_logloss: 0.132282\n",
            "[24]\ttraining's auc: 0.889482\ttraining's binary_logloss: 0.12129\tvalid_1's auc: 0.834199\tvalid_1's binary_logloss: 0.132112\n",
            "[25]\ttraining's auc: 0.890676\ttraining's binary_logloss: 0.120752\tvalid_1's auc: 0.834182\tvalid_1's binary_logloss: 0.132015\n",
            "[26]\ttraining's auc: 0.891761\ttraining's binary_logloss: 0.120197\tvalid_1's auc: 0.834227\tvalid_1's binary_logloss: 0.131947\n",
            "[27]\ttraining's auc: 0.893191\ttraining's binary_logloss: 0.119723\tvalid_1's auc: 0.834078\tvalid_1's binary_logloss: 0.13188\n",
            "[28]\ttraining's auc: 0.894001\ttraining's binary_logloss: 0.119292\tvalid_1's auc: 0.834326\tvalid_1's binary_logloss: 0.13181\n",
            "[29]\ttraining's auc: 0.895184\ttraining's binary_logloss: 0.118873\tvalid_1's auc: 0.83407\tvalid_1's binary_logloss: 0.131816\n",
            "[30]\ttraining's auc: 0.896379\ttraining's binary_logloss: 0.118434\tvalid_1's auc: 0.833824\tvalid_1's binary_logloss: 0.13183\n",
            "[31]\ttraining's auc: 0.897928\ttraining's binary_logloss: 0.117965\tvalid_1's auc: 0.833803\tvalid_1's binary_logloss: 0.131801\n",
            "[32]\ttraining's auc: 0.89946\ttraining's binary_logloss: 0.117505\tvalid_1's auc: 0.834051\tvalid_1's binary_logloss: 0.131761\n",
            "[33]\ttraining's auc: 0.900348\ttraining's binary_logloss: 0.117224\tvalid_1's auc: 0.833991\tvalid_1's binary_logloss: 0.131752\n",
            "[34]\ttraining's auc: 0.901198\ttraining's binary_logloss: 0.116827\tvalid_1's auc: 0.833817\tvalid_1's binary_logloss: 0.131744\n",
            "[35]\ttraining's auc: 0.90189\ttraining's binary_logloss: 0.116481\tvalid_1's auc: 0.834075\tvalid_1's binary_logloss: 0.13171\n",
            "[36]\ttraining's auc: 0.902694\ttraining's binary_logloss: 0.116137\tvalid_1's auc: 0.833981\tvalid_1's binary_logloss: 0.131693\n",
            "[37]\ttraining's auc: 0.903751\ttraining's binary_logloss: 0.115701\tvalid_1's auc: 0.833764\tvalid_1's binary_logloss: 0.131694\n",
            "[38]\ttraining's auc: 0.905445\ttraining's binary_logloss: 0.115272\tvalid_1's auc: 0.833766\tvalid_1's binary_logloss: 0.131679\n",
            "[39]\ttraining's auc: 0.906554\ttraining's binary_logloss: 0.114812\tvalid_1's auc: 0.833818\tvalid_1's binary_logloss: 0.131669\n",
            "[40]\ttraining's auc: 0.907543\ttraining's binary_logloss: 0.114451\tvalid_1's auc: 0.833544\tvalid_1's binary_logloss: 0.131692\n",
            "[41]\ttraining's auc: 0.909108\ttraining's binary_logloss: 0.113954\tvalid_1's auc: 0.833529\tvalid_1's binary_logloss: 0.131684\n",
            "[42]\ttraining's auc: 0.909932\ttraining's binary_logloss: 0.113565\tvalid_1's auc: 0.833718\tvalid_1's binary_logloss: 0.13168\n",
            "[43]\ttraining's auc: 0.910831\ttraining's binary_logloss: 0.11321\tvalid_1's auc: 0.833617\tvalid_1's binary_logloss: 0.131706\n",
            "[44]\ttraining's auc: 0.911503\ttraining's binary_logloss: 0.112864\tvalid_1's auc: 0.833924\tvalid_1's binary_logloss: 0.131644\n",
            "[45]\ttraining's auc: 0.912123\ttraining's binary_logloss: 0.11253\tvalid_1's auc: 0.833895\tvalid_1's binary_logloss: 0.131647\n",
            "[46]\ttraining's auc: 0.913123\ttraining's binary_logloss: 0.11218\tvalid_1's auc: 0.834232\tvalid_1's binary_logloss: 0.131594\n",
            "[47]\ttraining's auc: 0.913598\ttraining's binary_logloss: 0.111885\tvalid_1's auc: 0.833929\tvalid_1's binary_logloss: 0.131619\n",
            "[48]\ttraining's auc: 0.913938\ttraining's binary_logloss: 0.111615\tvalid_1's auc: 0.83377\tvalid_1's binary_logloss: 0.131664\n",
            "[49]\ttraining's auc: 0.914383\ttraining's binary_logloss: 0.111358\tvalid_1's auc: 0.833729\tvalid_1's binary_logloss: 0.131679\n",
            "[50]\ttraining's auc: 0.915962\ttraining's binary_logloss: 0.110837\tvalid_1's auc: 0.833718\tvalid_1's binary_logloss: 0.131723\n",
            "[51]\ttraining's auc: 0.916494\ttraining's binary_logloss: 0.110611\tvalid_1's auc: 0.83361\tvalid_1's binary_logloss: 0.131746\n",
            "[52]\ttraining's auc: 0.917118\ttraining's binary_logloss: 0.110309\tvalid_1's auc: 0.83353\tvalid_1's binary_logloss: 0.131781\n",
            "[53]\ttraining's auc: 0.917794\ttraining's binary_logloss: 0.110083\tvalid_1's auc: 0.833519\tvalid_1's binary_logloss: 0.131798\n",
            "[54]\ttraining's auc: 0.918169\ttraining's binary_logloss: 0.109829\tvalid_1's auc: 0.833453\tvalid_1's binary_logloss: 0.131819\n",
            "[55]\ttraining's auc: 0.918431\ttraining's binary_logloss: 0.109649\tvalid_1's auc: 0.833356\tvalid_1's binary_logloss: 0.131842\n",
            "[56]\ttraining's auc: 0.918883\ttraining's binary_logloss: 0.109436\tvalid_1's auc: 0.832984\tvalid_1's binary_logloss: 0.131893\n",
            "[57]\ttraining's auc: 0.920659\ttraining's binary_logloss: 0.109004\tvalid_1's auc: 0.832997\tvalid_1's binary_logloss: 0.131902\n",
            "[58]\ttraining's auc: 0.921782\ttraining's binary_logloss: 0.108652\tvalid_1's auc: 0.832813\tvalid_1's binary_logloss: 0.131946\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 34%|███▍      | 17/50 [08:20<13:42, 24.92s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.154207\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.160525\n",
            "[2]\ttraining's auc: 0.832651\ttraining's binary_logloss: 0.148639\tvalid_1's auc: 0.8153\tvalid_1's binary_logloss: 0.155531\n",
            "[3]\ttraining's auc: 0.840128\ttraining's binary_logloss: 0.144552\tvalid_1's auc: 0.820938\tvalid_1's binary_logloss: 0.152032\n",
            "[4]\ttraining's auc: 0.844861\ttraining's binary_logloss: 0.141385\tvalid_1's auc: 0.82273\tvalid_1's binary_logloss: 0.14945\n",
            "[5]\ttraining's auc: 0.849977\ttraining's binary_logloss: 0.13863\tvalid_1's auc: 0.826033\tvalid_1's binary_logloss: 0.147315\n",
            "[6]\ttraining's auc: 0.852248\ttraining's binary_logloss: 0.136373\tvalid_1's auc: 0.827636\tvalid_1's binary_logloss: 0.145609\n",
            "[7]\ttraining's auc: 0.854646\ttraining's binary_logloss: 0.134514\tvalid_1's auc: 0.828974\tvalid_1's binary_logloss: 0.144225\n",
            "[8]\ttraining's auc: 0.857006\ttraining's binary_logloss: 0.13285\tvalid_1's auc: 0.829732\tvalid_1's binary_logloss: 0.14307\n",
            "[9]\ttraining's auc: 0.860563\ttraining's binary_logloss: 0.13133\tvalid_1's auc: 0.830027\tvalid_1's binary_logloss: 0.142112\n",
            "[10]\ttraining's auc: 0.863093\ttraining's binary_logloss: 0.130037\tvalid_1's auc: 0.83047\tvalid_1's binary_logloss: 0.141303\n",
            "[11]\ttraining's auc: 0.866941\ttraining's binary_logloss: 0.128822\tvalid_1's auc: 0.831593\tvalid_1's binary_logloss: 0.140512\n",
            "[12]\ttraining's auc: 0.869648\ttraining's binary_logloss: 0.127732\tvalid_1's auc: 0.833488\tvalid_1's binary_logloss: 0.139918\n",
            "[13]\ttraining's auc: 0.87242\ttraining's binary_logloss: 0.126726\tvalid_1's auc: 0.834365\tvalid_1's binary_logloss: 0.139446\n",
            "[14]\ttraining's auc: 0.873675\ttraining's binary_logloss: 0.125846\tvalid_1's auc: 0.834815\tvalid_1's binary_logloss: 0.139018\n",
            "[15]\ttraining's auc: 0.875678\ttraining's binary_logloss: 0.12499\tvalid_1's auc: 0.834246\tvalid_1's binary_logloss: 0.138696\n",
            "[16]\ttraining's auc: 0.877093\ttraining's binary_logloss: 0.124209\tvalid_1's auc: 0.834321\tvalid_1's binary_logloss: 0.138387\n",
            "[17]\ttraining's auc: 0.879281\ttraining's binary_logloss: 0.123481\tvalid_1's auc: 0.834851\tvalid_1's binary_logloss: 0.138104\n",
            "[18]\ttraining's auc: 0.881611\ttraining's binary_logloss: 0.122663\tvalid_1's auc: 0.83487\tvalid_1's binary_logloss: 0.137834\n",
            "[19]\ttraining's auc: 0.883985\ttraining's binary_logloss: 0.12188\tvalid_1's auc: 0.834505\tvalid_1's binary_logloss: 0.137669\n",
            "[20]\ttraining's auc: 0.88603\ttraining's binary_logloss: 0.121255\tvalid_1's auc: 0.834607\tvalid_1's binary_logloss: 0.137514\n",
            "[21]\ttraining's auc: 0.888078\ttraining's binary_logloss: 0.12063\tvalid_1's auc: 0.834562\tvalid_1's binary_logloss: 0.137371\n",
            "[22]\ttraining's auc: 0.889691\ttraining's binary_logloss: 0.120004\tvalid_1's auc: 0.834712\tvalid_1's binary_logloss: 0.137265\n",
            "[23]\ttraining's auc: 0.891317\ttraining's binary_logloss: 0.119417\tvalid_1's auc: 0.834425\tvalid_1's binary_logloss: 0.137196\n",
            "[24]\ttraining's auc: 0.892285\ttraining's binary_logloss: 0.118901\tvalid_1's auc: 0.83518\tvalid_1's binary_logloss: 0.137003\n",
            "[25]\ttraining's auc: 0.893444\ttraining's binary_logloss: 0.118417\tvalid_1's auc: 0.835097\tvalid_1's binary_logloss: 0.136935\n",
            "[26]\ttraining's auc: 0.894396\ttraining's binary_logloss: 0.117957\tvalid_1's auc: 0.834747\tvalid_1's binary_logloss: 0.136927\n",
            "[27]\ttraining's auc: 0.896015\ttraining's binary_logloss: 0.117409\tvalid_1's auc: 0.834624\tvalid_1's binary_logloss: 0.136884\n",
            "[28]\ttraining's auc: 0.896781\ttraining's binary_logloss: 0.117002\tvalid_1's auc: 0.834908\tvalid_1's binary_logloss: 0.136828\n",
            "[29]\ttraining's auc: 0.897699\ttraining's binary_logloss: 0.116603\tvalid_1's auc: 0.835107\tvalid_1's binary_logloss: 0.136737\n",
            "[30]\ttraining's auc: 0.89861\ttraining's binary_logloss: 0.116232\tvalid_1's auc: 0.834747\tvalid_1's binary_logloss: 0.136755\n",
            "[31]\ttraining's auc: 0.899887\ttraining's binary_logloss: 0.115747\tvalid_1's auc: 0.834399\tvalid_1's binary_logloss: 0.136754\n",
            "[32]\ttraining's auc: 0.901018\ttraining's binary_logloss: 0.115364\tvalid_1's auc: 0.834215\tvalid_1's binary_logloss: 0.136763\n",
            "[33]\ttraining's auc: 0.901761\ttraining's binary_logloss: 0.115025\tvalid_1's auc: 0.834501\tvalid_1's binary_logloss: 0.136726\n",
            "[34]\ttraining's auc: 0.903134\ttraining's binary_logloss: 0.114645\tvalid_1's auc: 0.834363\tvalid_1's binary_logloss: 0.136706\n",
            "[35]\ttraining's auc: 0.904471\ttraining's binary_logloss: 0.114166\tvalid_1's auc: 0.834406\tvalid_1's binary_logloss: 0.136679\n",
            "[36]\ttraining's auc: 0.90526\ttraining's binary_logloss: 0.113843\tvalid_1's auc: 0.834217\tvalid_1's binary_logloss: 0.136717\n",
            "[37]\ttraining's auc: 0.906083\ttraining's binary_logloss: 0.113452\tvalid_1's auc: 0.834204\tvalid_1's binary_logloss: 0.136723\n",
            "[38]\ttraining's auc: 0.907041\ttraining's binary_logloss: 0.113013\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.136755\n",
            "[39]\ttraining's auc: 0.908139\ttraining's binary_logloss: 0.112613\tvalid_1's auc: 0.833987\tvalid_1's binary_logloss: 0.136793\n",
            "[40]\ttraining's auc: 0.909196\ttraining's binary_logloss: 0.112129\tvalid_1's auc: 0.834202\tvalid_1's binary_logloss: 0.136777\n",
            "[41]\ttraining's auc: 0.90967\ttraining's binary_logloss: 0.111869\tvalid_1's auc: 0.834398\tvalid_1's binary_logloss: 0.136748\n",
            "[42]\ttraining's auc: 0.910379\ttraining's binary_logloss: 0.111554\tvalid_1's auc: 0.834288\tvalid_1's binary_logloss: 0.136773\n",
            "[43]\ttraining's auc: 0.911046\ttraining's binary_logloss: 0.111287\tvalid_1's auc: 0.834284\tvalid_1's binary_logloss: 0.136798\n",
            "[44]\ttraining's auc: 0.911683\ttraining's binary_logloss: 0.110983\tvalid_1's auc: 0.834498\tvalid_1's binary_logloss: 0.136776\n",
            "[45]\ttraining's auc: 0.912427\ttraining's binary_logloss: 0.110605\tvalid_1's auc: 0.834628\tvalid_1's binary_logloss: 0.136752\n",
            "[46]\ttraining's auc: 0.913057\ttraining's binary_logloss: 0.110275\tvalid_1's auc: 0.834619\tvalid_1's binary_logloss: 0.136787\n",
            "[47]\ttraining's auc: 0.913418\ttraining's binary_logloss: 0.110056\tvalid_1's auc: 0.834394\tvalid_1's binary_logloss: 0.136842\n",
            "[48]\ttraining's auc: 0.91456\ttraining's binary_logloss: 0.109616\tvalid_1's auc: 0.834329\tvalid_1's binary_logloss: 0.136881\n",
            "[49]\ttraining's auc: 0.915285\ttraining's binary_logloss: 0.109287\tvalid_1's auc: 0.83441\tvalid_1's binary_logloss: 0.136897\n",
            "[50]\ttraining's auc: 0.915849\ttraining's binary_logloss: 0.109017\tvalid_1's auc: 0.834452\tvalid_1's binary_logloss: 0.136902\n",
            "[51]\ttraining's auc: 0.916734\ttraining's binary_logloss: 0.108658\tvalid_1's auc: 0.834141\tvalid_1's binary_logloss: 0.136964\n",
            "[52]\ttraining's auc: 0.91751\ttraining's binary_logloss: 0.108305\tvalid_1's auc: 0.834345\tvalid_1's binary_logloss: 0.136961\n",
            "[53]\ttraining's auc: 0.917987\ttraining's binary_logloss: 0.10799\tvalid_1's auc: 0.834075\tvalid_1's binary_logloss: 0.136985\n",
            "[54]\ttraining's auc: 0.918445\ttraining's binary_logloss: 0.107761\tvalid_1's auc: 0.833642\tvalid_1's binary_logloss: 0.137106\n",
            " 36%|███▌      | 18/50 [08:24<12:08, 22.76s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.149396\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.153117\n",
            "[2]\ttraining's auc: 0.838091\ttraining's binary_logloss: 0.142804\tvalid_1's auc: 0.81002\tvalid_1's binary_logloss: 0.148221\n",
            "[3]\ttraining's auc: 0.848467\ttraining's binary_logloss: 0.138303\tvalid_1's auc: 0.816745\tvalid_1's binary_logloss: 0.145089\n",
            "[4]\ttraining's auc: 0.852497\ttraining's binary_logloss: 0.134925\tvalid_1's auc: 0.817722\tvalid_1's binary_logloss: 0.143063\n",
            "[5]\ttraining's auc: 0.856907\ttraining's binary_logloss: 0.132142\tvalid_1's auc: 0.818495\tvalid_1's binary_logloss: 0.141646\n",
            "[6]\ttraining's auc: 0.863975\ttraining's binary_logloss: 0.130021\tvalid_1's auc: 0.823176\tvalid_1's binary_logloss: 0.140256\n",
            "[7]\ttraining's auc: 0.868447\ttraining's binary_logloss: 0.128233\tvalid_1's auc: 0.824641\tvalid_1's binary_logloss: 0.139262\n",
            "[8]\ttraining's auc: 0.871416\ttraining's binary_logloss: 0.126509\tvalid_1's auc: 0.826097\tvalid_1's binary_logloss: 0.138418\n",
            "[9]\ttraining's auc: 0.873345\ttraining's binary_logloss: 0.125196\tvalid_1's auc: 0.825684\tvalid_1's binary_logloss: 0.137928\n",
            "[10]\ttraining's auc: 0.876488\ttraining's binary_logloss: 0.123978\tvalid_1's auc: 0.826069\tvalid_1's binary_logloss: 0.137559\n",
            "[11]\ttraining's auc: 0.879577\ttraining's binary_logloss: 0.122831\tvalid_1's auc: 0.82524\tvalid_1's binary_logloss: 0.137412\n",
            "[12]\ttraining's auc: 0.881815\ttraining's binary_logloss: 0.121703\tvalid_1's auc: 0.825631\tvalid_1's binary_logloss: 0.13706\n",
            "[13]\ttraining's auc: 0.884212\ttraining's binary_logloss: 0.120765\tvalid_1's auc: 0.826446\tvalid_1's binary_logloss: 0.136825\n",
            "[14]\ttraining's auc: 0.886844\ttraining's binary_logloss: 0.119889\tvalid_1's auc: 0.827825\tvalid_1's binary_logloss: 0.136514\n",
            "[15]\ttraining's auc: 0.889637\ttraining's binary_logloss: 0.118959\tvalid_1's auc: 0.82751\tvalid_1's binary_logloss: 0.136475\n",
            "[16]\ttraining's auc: 0.891511\ttraining's binary_logloss: 0.118162\tvalid_1's auc: 0.827027\tvalid_1's binary_logloss: 0.136586\n",
            "[17]\ttraining's auc: 0.893908\ttraining's binary_logloss: 0.117282\tvalid_1's auc: 0.826243\tvalid_1's binary_logloss: 0.136753\n",
            "[18]\ttraining's auc: 0.895551\ttraining's binary_logloss: 0.116613\tvalid_1's auc: 0.825794\tvalid_1's binary_logloss: 0.136849\n",
            "[19]\ttraining's auc: 0.897518\ttraining's binary_logloss: 0.115871\tvalid_1's auc: 0.826325\tvalid_1's binary_logloss: 0.136775\n",
            "[20]\ttraining's auc: 0.900184\ttraining's binary_logloss: 0.114986\tvalid_1's auc: 0.825683\tvalid_1's binary_logloss: 0.136884\n",
            "[21]\ttraining's auc: 0.902034\ttraining's binary_logloss: 0.114287\tvalid_1's auc: 0.825235\tvalid_1's binary_logloss: 0.136942\n",
            "[22]\ttraining's auc: 0.903404\ttraining's binary_logloss: 0.113687\tvalid_1's auc: 0.826322\tvalid_1's binary_logloss: 0.136786\n",
            "[23]\ttraining's auc: 0.905856\ttraining's binary_logloss: 0.113166\tvalid_1's auc: 0.825965\tvalid_1's binary_logloss: 0.136835\n",
            "[24]\ttraining's auc: 0.906952\ttraining's binary_logloss: 0.112611\tvalid_1's auc: 0.82599\tvalid_1's binary_logloss: 0.136831\n",
            "[25]\ttraining's auc: 0.908469\ttraining's binary_logloss: 0.111864\tvalid_1's auc: 0.826063\tvalid_1's binary_logloss: 0.136912\n",
            "[26]\ttraining's auc: 0.909563\ttraining's binary_logloss: 0.111366\tvalid_1's auc: 0.825837\tvalid_1's binary_logloss: 0.136957\n",
            "[27]\ttraining's auc: 0.910613\ttraining's binary_logloss: 0.11087\tvalid_1's auc: 0.82596\tvalid_1's binary_logloss: 0.136939\n",
            "[28]\ttraining's auc: 0.911306\ttraining's binary_logloss: 0.110445\tvalid_1's auc: 0.825436\tvalid_1's binary_logloss: 0.137071\n",
            "[29]\ttraining's auc: 0.914186\ttraining's binary_logloss: 0.109811\tvalid_1's auc: 0.825904\tvalid_1's binary_logloss: 0.136997\n",
            "[30]\ttraining's auc: 0.914995\ttraining's binary_logloss: 0.109376\tvalid_1's auc: 0.826016\tvalid_1's binary_logloss: 0.137022\n",
            "[31]\ttraining's auc: 0.916173\ttraining's binary_logloss: 0.108882\tvalid_1's auc: 0.82562\tvalid_1's binary_logloss: 0.137155\n",
            "[32]\ttraining's auc: 0.916642\ttraining's binary_logloss: 0.108566\tvalid_1's auc: 0.825737\tvalid_1's binary_logloss: 0.1372\n",
            "[33]\ttraining's auc: 0.917291\ttraining's binary_logloss: 0.108186\tvalid_1's auc: 0.82532\tvalid_1's binary_logloss: 0.137287\n",
            "[34]\ttraining's auc: 0.917911\ttraining's binary_logloss: 0.107835\tvalid_1's auc: 0.824921\tvalid_1's binary_logloss: 0.137442\n",
            "[35]\ttraining's auc: 0.918866\ttraining's binary_logloss: 0.107404\tvalid_1's auc: 0.824342\tvalid_1's binary_logloss: 0.137588\n",
            "[36]\ttraining's auc: 0.919572\ttraining's binary_logloss: 0.106984\tvalid_1's auc: 0.823575\tvalid_1's binary_logloss: 0.137736\n",
            "[37]\ttraining's auc: 0.920329\ttraining's binary_logloss: 0.106624\tvalid_1's auc: 0.822821\tvalid_1's binary_logloss: 0.137927\n",
            "[38]\ttraining's auc: 0.92069\ttraining's binary_logloss: 0.106357\tvalid_1's auc: 0.822245\tvalid_1's binary_logloss: 0.138053\n",
            "[39]\ttraining's auc: 0.921344\ttraining's binary_logloss: 0.105979\tvalid_1's auc: 0.821544\tvalid_1's binary_logloss: 0.138239\n",
            "[40]\ttraining's auc: 0.92214\ttraining's binary_logloss: 0.10564\tvalid_1's auc: 0.821287\tvalid_1's binary_logloss: 0.138322\n",
            "[41]\ttraining's auc: 0.92264\ttraining's binary_logloss: 0.10535\tvalid_1's auc: 0.821436\tvalid_1's binary_logloss: 0.138329\n",
            "[42]\ttraining's auc: 0.923603\ttraining's binary_logloss: 0.104886\tvalid_1's auc: 0.821855\tvalid_1's binary_logloss: 0.138341\n",
            "[43]\ttraining's auc: 0.924229\ttraining's binary_logloss: 0.104476\tvalid_1's auc: 0.821689\tvalid_1's binary_logloss: 0.138446\n",
            "[44]\ttraining's auc: 0.92518\ttraining's binary_logloss: 0.10402\tvalid_1's auc: 0.821838\tvalid_1's binary_logloss: 0.138418\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 36%|███▌      | 18/50 [08:32<12:08, 22.76s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.151869\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.149508\n",
            "[2]\ttraining's auc: 0.83612\ttraining's binary_logloss: 0.145049\tvalid_1's auc: 0.81846\tvalid_1's binary_logloss: 0.144439\n",
            "[3]\ttraining's auc: 0.847181\ttraining's binary_logloss: 0.140322\tvalid_1's auc: 0.823954\tvalid_1's binary_logloss: 0.141435\n",
            "[4]\ttraining's auc: 0.852617\ttraining's binary_logloss: 0.136957\tvalid_1's auc: 0.828892\tvalid_1's binary_logloss: 0.139095\n",
            "[5]\ttraining's auc: 0.855695\ttraining's binary_logloss: 0.134335\tvalid_1's auc: 0.828446\tvalid_1's binary_logloss: 0.137634\n",
            "[6]\ttraining's auc: 0.860856\ttraining's binary_logloss: 0.132205\tvalid_1's auc: 0.829889\tvalid_1's binary_logloss: 0.136405\n",
            "[7]\ttraining's auc: 0.867104\ttraining's binary_logloss: 0.130283\tvalid_1's auc: 0.830656\tvalid_1's binary_logloss: 0.135555\n",
            "[8]\ttraining's auc: 0.869303\ttraining's binary_logloss: 0.128692\tvalid_1's auc: 0.830288\tvalid_1's binary_logloss: 0.134922\n",
            "[9]\ttraining's auc: 0.872128\ttraining's binary_logloss: 0.127317\tvalid_1's auc: 0.830898\tvalid_1's binary_logloss: 0.134168\n",
            "[10]\ttraining's auc: 0.875348\ttraining's binary_logloss: 0.125877\tvalid_1's auc: 0.830507\tvalid_1's binary_logloss: 0.133786\n",
            "[11]\ttraining's auc: 0.877721\ttraining's binary_logloss: 0.124687\tvalid_1's auc: 0.830623\tvalid_1's binary_logloss: 0.133471\n",
            "[12]\ttraining's auc: 0.880164\ttraining's binary_logloss: 0.123615\tvalid_1's auc: 0.831133\tvalid_1's binary_logloss: 0.133264\n",
            "[13]\ttraining's auc: 0.882848\ttraining's binary_logloss: 0.122649\tvalid_1's auc: 0.831915\tvalid_1's binary_logloss: 0.132982\n",
            "[14]\ttraining's auc: 0.885677\ttraining's binary_logloss: 0.12164\tvalid_1's auc: 0.831469\tvalid_1's binary_logloss: 0.132884\n",
            "[15]\ttraining's auc: 0.888583\ttraining's binary_logloss: 0.120723\tvalid_1's auc: 0.83217\tvalid_1's binary_logloss: 0.132748\n",
            "[16]\ttraining's auc: 0.890658\ttraining's binary_logloss: 0.119892\tvalid_1's auc: 0.832136\tvalid_1's binary_logloss: 0.132619\n",
            "[17]\ttraining's auc: 0.893593\ttraining's binary_logloss: 0.119049\tvalid_1's auc: 0.831975\tvalid_1's binary_logloss: 0.132561\n",
            "[18]\ttraining's auc: 0.895623\ttraining's binary_logloss: 0.118339\tvalid_1's auc: 0.832829\tvalid_1's binary_logloss: 0.13247\n",
            "[19]\ttraining's auc: 0.897488\ttraining's binary_logloss: 0.117683\tvalid_1's auc: 0.832093\tvalid_1's binary_logloss: 0.132553\n",
            "[20]\ttraining's auc: 0.899209\ttraining's binary_logloss: 0.117111\tvalid_1's auc: 0.832071\tvalid_1's binary_logloss: 0.132535\n",
            "[21]\ttraining's auc: 0.90051\ttraining's binary_logloss: 0.116455\tvalid_1's auc: 0.832055\tvalid_1's binary_logloss: 0.132505\n",
            "[22]\ttraining's auc: 0.901807\ttraining's binary_logloss: 0.1158\tvalid_1's auc: 0.831973\tvalid_1's binary_logloss: 0.132566\n",
            "[23]\ttraining's auc: 0.903245\ttraining's binary_logloss: 0.115316\tvalid_1's auc: 0.831742\tvalid_1's binary_logloss: 0.132527\n",
            "[24]\ttraining's auc: 0.905372\ttraining's binary_logloss: 0.114674\tvalid_1's auc: 0.831079\tvalid_1's binary_logloss: 0.132669\n",
            "[25]\ttraining's auc: 0.90702\ttraining's binary_logloss: 0.114009\tvalid_1's auc: 0.830655\tvalid_1's binary_logloss: 0.132773\n",
            "[26]\ttraining's auc: 0.909339\ttraining's binary_logloss: 0.113209\tvalid_1's auc: 0.830165\tvalid_1's binary_logloss: 0.13294\n",
            "[27]\ttraining's auc: 0.910705\ttraining's binary_logloss: 0.112531\tvalid_1's auc: 0.829942\tvalid_1's binary_logloss: 0.132957\n",
            "[28]\ttraining's auc: 0.911419\ttraining's binary_logloss: 0.112113\tvalid_1's auc: 0.829897\tvalid_1's binary_logloss: 0.13294\n",
            "[29]\ttraining's auc: 0.912357\ttraining's binary_logloss: 0.111655\tvalid_1's auc: 0.83008\tvalid_1's binary_logloss: 0.13293\n",
            "[30]\ttraining's auc: 0.914053\ttraining's binary_logloss: 0.111132\tvalid_1's auc: 0.830322\tvalid_1's binary_logloss: 0.132931\n",
            "[31]\ttraining's auc: 0.915062\ttraining's binary_logloss: 0.110606\tvalid_1's auc: 0.830595\tvalid_1's binary_logloss: 0.132892\n",
            "[32]\ttraining's auc: 0.915913\ttraining's binary_logloss: 0.110221\tvalid_1's auc: 0.830275\tvalid_1's binary_logloss: 0.132985\n",
            "[33]\ttraining's auc: 0.917046\ttraining's binary_logloss: 0.109681\tvalid_1's auc: 0.830213\tvalid_1's binary_logloss: 0.1329\n",
            "[34]\ttraining's auc: 0.918421\ttraining's binary_logloss: 0.109069\tvalid_1's auc: 0.829976\tvalid_1's binary_logloss: 0.132943\n",
            "[35]\ttraining's auc: 0.920004\ttraining's binary_logloss: 0.108513\tvalid_1's auc: 0.829708\tvalid_1's binary_logloss: 0.133014\n",
            "[36]\ttraining's auc: 0.921037\ttraining's binary_logloss: 0.107995\tvalid_1's auc: 0.829303\tvalid_1's binary_logloss: 0.133128\n",
            "[37]\ttraining's auc: 0.921851\ttraining's binary_logloss: 0.107601\tvalid_1's auc: 0.829215\tvalid_1's binary_logloss: 0.133137\n",
            "[38]\ttraining's auc: 0.922747\ttraining's binary_logloss: 0.10729\tvalid_1's auc: 0.82943\tvalid_1's binary_logloss: 0.133158\n",
            "[39]\ttraining's auc: 0.923462\ttraining's binary_logloss: 0.107015\tvalid_1's auc: 0.829467\tvalid_1's binary_logloss: 0.133195\n",
            "[40]\ttraining's auc: 0.924426\ttraining's binary_logloss: 0.106566\tvalid_1's auc: 0.8292\tvalid_1's binary_logloss: 0.133244\n",
            "[41]\ttraining's auc: 0.926129\ttraining's binary_logloss: 0.105922\tvalid_1's auc: 0.828986\tvalid_1's binary_logloss: 0.133271\n",
            "[42]\ttraining's auc: 0.927003\ttraining's binary_logloss: 0.105411\tvalid_1's auc: 0.829179\tvalid_1's binary_logloss: 0.133254\n",
            "[43]\ttraining's auc: 0.92742\ttraining's binary_logloss: 0.105139\tvalid_1's auc: 0.829253\tvalid_1's binary_logloss: 0.133282\n",
            "[44]\ttraining's auc: 0.928375\ttraining's binary_logloss: 0.104712\tvalid_1's auc: 0.828694\tvalid_1's binary_logloss: 0.133399\n",
            "[45]\ttraining's auc: 0.928692\ttraining's binary_logloss: 0.104455\tvalid_1's auc: 0.829021\tvalid_1's binary_logloss: 0.133399\n",
            "[46]\ttraining's auc: 0.929335\ttraining's binary_logloss: 0.104138\tvalid_1's auc: 0.829247\tvalid_1's binary_logloss: 0.133365\n",
            "[47]\ttraining's auc: 0.930242\ttraining's binary_logloss: 0.103762\tvalid_1's auc: 0.829304\tvalid_1's binary_logloss: 0.133393\n",
            "[48]\ttraining's auc: 0.930494\ttraining's binary_logloss: 0.103498\tvalid_1's auc: 0.829125\tvalid_1's binary_logloss: 0.133439\n",
            " 36%|███▌      | 18/50 [08:35<12:08, 22.76s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.148856\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.155844\n",
            "[2]\ttraining's auc: 0.838358\ttraining's binary_logloss: 0.142298\tvalid_1's auc: 0.82161\tvalid_1's binary_logloss: 0.15042\n",
            "[3]\ttraining's auc: 0.84617\ttraining's binary_logloss: 0.137734\tvalid_1's auc: 0.82457\tvalid_1's binary_logloss: 0.147187\n",
            "[4]\ttraining's auc: 0.851423\ttraining's binary_logloss: 0.134473\tvalid_1's auc: 0.828023\tvalid_1's binary_logloss: 0.14461\n",
            "[5]\ttraining's auc: 0.854163\ttraining's binary_logloss: 0.131873\tvalid_1's auc: 0.828394\tvalid_1's binary_logloss: 0.142787\n",
            "[6]\ttraining's auc: 0.861719\ttraining's binary_logloss: 0.129621\tvalid_1's auc: 0.830097\tvalid_1's binary_logloss: 0.141344\n",
            "[7]\ttraining's auc: 0.8655\ttraining's binary_logloss: 0.127759\tvalid_1's auc: 0.829627\tvalid_1's binary_logloss: 0.140443\n",
            "[8]\ttraining's auc: 0.86906\ttraining's binary_logloss: 0.126235\tvalid_1's auc: 0.832243\tvalid_1's binary_logloss: 0.139693\n",
            "[9]\ttraining's auc: 0.871686\ttraining's binary_logloss: 0.124916\tvalid_1's auc: 0.832511\tvalid_1's binary_logloss: 0.139202\n",
            "[10]\ttraining's auc: 0.873816\ttraining's binary_logloss: 0.123719\tvalid_1's auc: 0.832589\tvalid_1's binary_logloss: 0.138764\n",
            "[11]\ttraining's auc: 0.876189\ttraining's binary_logloss: 0.122661\tvalid_1's auc: 0.833221\tvalid_1's binary_logloss: 0.138301\n",
            "[12]\ttraining's auc: 0.8791\ttraining's binary_logloss: 0.121671\tvalid_1's auc: 0.833333\tvalid_1's binary_logloss: 0.137963\n",
            "[13]\ttraining's auc: 0.882477\ttraining's binary_logloss: 0.120487\tvalid_1's auc: 0.833256\tvalid_1's binary_logloss: 0.13796\n",
            "[14]\ttraining's auc: 0.885344\ttraining's binary_logloss: 0.119565\tvalid_1's auc: 0.833403\tvalid_1's binary_logloss: 0.137736\n",
            "[15]\ttraining's auc: 0.888548\ttraining's binary_logloss: 0.118565\tvalid_1's auc: 0.833143\tvalid_1's binary_logloss: 0.137709\n",
            "[16]\ttraining's auc: 0.891602\ttraining's binary_logloss: 0.11765\tvalid_1's auc: 0.832629\tvalid_1's binary_logloss: 0.137718\n",
            "[17]\ttraining's auc: 0.893538\ttraining's binary_logloss: 0.116852\tvalid_1's auc: 0.832249\tvalid_1's binary_logloss: 0.137711\n",
            "[18]\ttraining's auc: 0.895972\ttraining's binary_logloss: 0.116123\tvalid_1's auc: 0.832105\tvalid_1's binary_logloss: 0.137788\n",
            "[19]\ttraining's auc: 0.897744\ttraining's binary_logloss: 0.115471\tvalid_1's auc: 0.832072\tvalid_1's binary_logloss: 0.137751\n",
            "[20]\ttraining's auc: 0.899217\ttraining's binary_logloss: 0.114876\tvalid_1's auc: 0.831228\tvalid_1's binary_logloss: 0.137853\n",
            "[21]\ttraining's auc: 0.900838\ttraining's binary_logloss: 0.114272\tvalid_1's auc: 0.831576\tvalid_1's binary_logloss: 0.137774\n",
            "[22]\ttraining's auc: 0.903131\ttraining's binary_logloss: 0.113551\tvalid_1's auc: 0.830615\tvalid_1's binary_logloss: 0.138043\n",
            "[23]\ttraining's auc: 0.904832\ttraining's binary_logloss: 0.112968\tvalid_1's auc: 0.830658\tvalid_1's binary_logloss: 0.138058\n",
            "[24]\ttraining's auc: 0.906363\ttraining's binary_logloss: 0.112333\tvalid_1's auc: 0.830724\tvalid_1's binary_logloss: 0.138065\n",
            "[25]\ttraining's auc: 0.907208\ttraining's binary_logloss: 0.111865\tvalid_1's auc: 0.830776\tvalid_1's binary_logloss: 0.138137\n",
            "[26]\ttraining's auc: 0.90877\ttraining's binary_logloss: 0.1112\tvalid_1's auc: 0.830878\tvalid_1's binary_logloss: 0.138083\n",
            "[27]\ttraining's auc: 0.910797\ttraining's binary_logloss: 0.110491\tvalid_1's auc: 0.830595\tvalid_1's binary_logloss: 0.138149\n",
            "[28]\ttraining's auc: 0.912289\ttraining's binary_logloss: 0.109902\tvalid_1's auc: 0.831345\tvalid_1's binary_logloss: 0.138065\n",
            "[29]\ttraining's auc: 0.913658\ttraining's binary_logloss: 0.109239\tvalid_1's auc: 0.831285\tvalid_1's binary_logloss: 0.138121\n",
            "[30]\ttraining's auc: 0.914475\ttraining's binary_logloss: 0.108799\tvalid_1's auc: 0.831072\tvalid_1's binary_logloss: 0.138185\n",
            "[31]\ttraining's auc: 0.915728\ttraining's binary_logloss: 0.108384\tvalid_1's auc: 0.830709\tvalid_1's binary_logloss: 0.138304\n",
            "[32]\ttraining's auc: 0.917078\ttraining's binary_logloss: 0.107792\tvalid_1's auc: 0.830484\tvalid_1's binary_logloss: 0.138358\n",
            "[33]\ttraining's auc: 0.917971\ttraining's binary_logloss: 0.107278\tvalid_1's auc: 0.830537\tvalid_1's binary_logloss: 0.13838\n",
            "[34]\ttraining's auc: 0.918967\ttraining's binary_logloss: 0.106788\tvalid_1's auc: 0.830316\tvalid_1's binary_logloss: 0.138451\n",
            "[35]\ttraining's auc: 0.919644\ttraining's binary_logloss: 0.106407\tvalid_1's auc: 0.830166\tvalid_1's binary_logloss: 0.138532\n",
            "[36]\ttraining's auc: 0.920442\ttraining's binary_logloss: 0.105999\tvalid_1's auc: 0.830146\tvalid_1's binary_logloss: 0.138554\n",
            "[37]\ttraining's auc: 0.921553\ttraining's binary_logloss: 0.105455\tvalid_1's auc: 0.829729\tvalid_1's binary_logloss: 0.138812\n",
            "[38]\ttraining's auc: 0.922391\ttraining's binary_logloss: 0.10499\tvalid_1's auc: 0.829427\tvalid_1's binary_logloss: 0.138882\n",
            "[39]\ttraining's auc: 0.923157\ttraining's binary_logloss: 0.104585\tvalid_1's auc: 0.829079\tvalid_1's binary_logloss: 0.13902\n",
            "[40]\ttraining's auc: 0.923826\ttraining's binary_logloss: 0.104164\tvalid_1's auc: 0.828821\tvalid_1's binary_logloss: 0.139099\n",
            "[41]\ttraining's auc: 0.925\ttraining's binary_logloss: 0.103567\tvalid_1's auc: 0.828423\tvalid_1's binary_logloss: 0.13927\n",
            "[42]\ttraining's auc: 0.926233\ttraining's binary_logloss: 0.102974\tvalid_1's auc: 0.828474\tvalid_1's binary_logloss: 0.139329\n",
            "[43]\ttraining's auc: 0.927242\ttraining's binary_logloss: 0.102453\tvalid_1's auc: 0.828326\tvalid_1's binary_logloss: 0.139504\n",
            "[44]\ttraining's auc: 0.927702\ttraining's binary_logloss: 0.102143\tvalid_1's auc: 0.827882\tvalid_1's binary_logloss: 0.139626\n",
            " 38%|███▊      | 19/50 [08:40<10:41, 20.70s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.162168\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.163436\n",
            "[2]\ttraining's auc: 0.827172\ttraining's binary_logloss: 0.160036\tvalid_1's auc: 0.80445\tvalid_1's binary_logloss: 0.161703\n",
            "[3]\ttraining's auc: 0.833323\ttraining's binary_logloss: 0.158148\tvalid_1's auc: 0.80783\tvalid_1's binary_logloss: 0.160193\n",
            "[4]\ttraining's auc: 0.834123\ttraining's binary_logloss: 0.156459\tvalid_1's auc: 0.807906\tvalid_1's binary_logloss: 0.158876\n",
            "[5]\ttraining's auc: 0.835936\ttraining's binary_logloss: 0.154904\tvalid_1's auc: 0.809267\tvalid_1's binary_logloss: 0.157651\n",
            "[6]\ttraining's auc: 0.836231\ttraining's binary_logloss: 0.153496\tvalid_1's auc: 0.808724\tvalid_1's binary_logloss: 0.156544\n",
            "[7]\ttraining's auc: 0.837444\ttraining's binary_logloss: 0.152153\tvalid_1's auc: 0.809866\tvalid_1's binary_logloss: 0.155478\n",
            "[8]\ttraining's auc: 0.839037\ttraining's binary_logloss: 0.150937\tvalid_1's auc: 0.811142\tvalid_1's binary_logloss: 0.154535\n",
            "[9]\ttraining's auc: 0.844019\ttraining's binary_logloss: 0.149768\tvalid_1's auc: 0.815647\tvalid_1's binary_logloss: 0.153623\n",
            "[10]\ttraining's auc: 0.844687\ttraining's binary_logloss: 0.148705\tvalid_1's auc: 0.815184\tvalid_1's binary_logloss: 0.152781\n",
            "[11]\ttraining's auc: 0.845993\ttraining's binary_logloss: 0.147695\tvalid_1's auc: 0.815273\tvalid_1's binary_logloss: 0.152067\n",
            "[12]\ttraining's auc: 0.846627\ttraining's binary_logloss: 0.14676\tvalid_1's auc: 0.816511\tvalid_1's binary_logloss: 0.151337\n",
            "[13]\ttraining's auc: 0.847915\ttraining's binary_logloss: 0.145869\tvalid_1's auc: 0.817823\tvalid_1's binary_logloss: 0.150621\n",
            "[14]\ttraining's auc: 0.849236\ttraining's binary_logloss: 0.144984\tvalid_1's auc: 0.818802\tvalid_1's binary_logloss: 0.149953\n",
            "[15]\ttraining's auc: 0.849692\ttraining's binary_logloss: 0.144164\tvalid_1's auc: 0.819237\tvalid_1's binary_logloss: 0.149325\n",
            "[16]\ttraining's auc: 0.850183\ttraining's binary_logloss: 0.143364\tvalid_1's auc: 0.819962\tvalid_1's binary_logloss: 0.148749\n",
            "[17]\ttraining's auc: 0.85085\ttraining's binary_logloss: 0.142627\tvalid_1's auc: 0.820159\tvalid_1's binary_logloss: 0.148195\n",
            "[18]\ttraining's auc: 0.851664\ttraining's binary_logloss: 0.141913\tvalid_1's auc: 0.820643\tvalid_1's binary_logloss: 0.147655\n",
            "[19]\ttraining's auc: 0.85344\ttraining's binary_logloss: 0.141234\tvalid_1's auc: 0.822007\tvalid_1's binary_logloss: 0.147148\n",
            "[20]\ttraining's auc: 0.853787\ttraining's binary_logloss: 0.140583\tvalid_1's auc: 0.822427\tvalid_1's binary_logloss: 0.146676\n",
            "[21]\ttraining's auc: 0.854257\ttraining's binary_logloss: 0.139978\tvalid_1's auc: 0.822752\tvalid_1's binary_logloss: 0.146251\n",
            "[22]\ttraining's auc: 0.854651\ttraining's binary_logloss: 0.139395\tvalid_1's auc: 0.822676\tvalid_1's binary_logloss: 0.14585\n",
            "[23]\ttraining's auc: 0.854909\ttraining's binary_logloss: 0.138833\tvalid_1's auc: 0.822554\tvalid_1's binary_logloss: 0.145475\n",
            "[24]\ttraining's auc: 0.855741\ttraining's binary_logloss: 0.138284\tvalid_1's auc: 0.82284\tvalid_1's binary_logloss: 0.145081\n",
            "[25]\ttraining's auc: 0.856153\ttraining's binary_logloss: 0.137732\tvalid_1's auc: 0.822935\tvalid_1's binary_logloss: 0.144717\n",
            "[26]\ttraining's auc: 0.858042\ttraining's binary_logloss: 0.137222\tvalid_1's auc: 0.824096\tvalid_1's binary_logloss: 0.144337\n",
            "[27]\ttraining's auc: 0.85842\ttraining's binary_logloss: 0.136724\tvalid_1's auc: 0.8241\tvalid_1's binary_logloss: 0.143989\n",
            "[28]\ttraining's auc: 0.859272\ttraining's binary_logloss: 0.13625\tvalid_1's auc: 0.824407\tvalid_1's binary_logloss: 0.143664\n",
            "[29]\ttraining's auc: 0.859506\ttraining's binary_logloss: 0.135799\tvalid_1's auc: 0.824426\tvalid_1's binary_logloss: 0.143358\n",
            "[30]\ttraining's auc: 0.860534\ttraining's binary_logloss: 0.135325\tvalid_1's auc: 0.824827\tvalid_1's binary_logloss: 0.143026\n",
            "[31]\ttraining's auc: 0.86147\ttraining's binary_logloss: 0.134893\tvalid_1's auc: 0.825118\tvalid_1's binary_logloss: 0.142766\n",
            "[32]\ttraining's auc: 0.862492\ttraining's binary_logloss: 0.13447\tvalid_1's auc: 0.825323\tvalid_1's binary_logloss: 0.142483\n",
            "[33]\ttraining's auc: 0.862655\ttraining's binary_logloss: 0.134078\tvalid_1's auc: 0.825264\tvalid_1's binary_logloss: 0.142227\n",
            "[34]\ttraining's auc: 0.862661\ttraining's binary_logloss: 0.133692\tvalid_1's auc: 0.825185\tvalid_1's binary_logloss: 0.141979\n",
            "[35]\ttraining's auc: 0.863689\ttraining's binary_logloss: 0.133318\tvalid_1's auc: 0.825656\tvalid_1's binary_logloss: 0.141709\n",
            "[36]\ttraining's auc: 0.863973\ttraining's binary_logloss: 0.132954\tvalid_1's auc: 0.826242\tvalid_1's binary_logloss: 0.141466\n",
            "[37]\ttraining's auc: 0.864227\ttraining's binary_logloss: 0.132587\tvalid_1's auc: 0.826435\tvalid_1's binary_logloss: 0.141263\n",
            "[38]\ttraining's auc: 0.864882\ttraining's binary_logloss: 0.132255\tvalid_1's auc: 0.826724\tvalid_1's binary_logloss: 0.141053\n",
            "[39]\ttraining's auc: 0.865628\ttraining's binary_logloss: 0.131918\tvalid_1's auc: 0.827137\tvalid_1's binary_logloss: 0.140846\n",
            "[40]\ttraining's auc: 0.865932\ttraining's binary_logloss: 0.131589\tvalid_1's auc: 0.827201\tvalid_1's binary_logloss: 0.14065\n",
            "[41]\ttraining's auc: 0.866436\ttraining's binary_logloss: 0.131278\tvalid_1's auc: 0.827449\tvalid_1's binary_logloss: 0.140452\n",
            "[42]\ttraining's auc: 0.867084\ttraining's binary_logloss: 0.130965\tvalid_1's auc: 0.827832\tvalid_1's binary_logloss: 0.140282\n",
            "[43]\ttraining's auc: 0.867585\ttraining's binary_logloss: 0.130647\tvalid_1's auc: 0.827828\tvalid_1's binary_logloss: 0.140098\n",
            "[44]\ttraining's auc: 0.868526\ttraining's binary_logloss: 0.13035\tvalid_1's auc: 0.828031\tvalid_1's binary_logloss: 0.139928\n",
            "[45]\ttraining's auc: 0.868967\ttraining's binary_logloss: 0.130069\tvalid_1's auc: 0.82808\tvalid_1's binary_logloss: 0.139777\n",
            "[46]\ttraining's auc: 0.869525\ttraining's binary_logloss: 0.129783\tvalid_1's auc: 0.8283\tvalid_1's binary_logloss: 0.13962\n",
            "[47]\ttraining's auc: 0.869861\ttraining's binary_logloss: 0.12952\tvalid_1's auc: 0.828309\tvalid_1's binary_logloss: 0.13949\n",
            "[48]\ttraining's auc: 0.870123\ttraining's binary_logloss: 0.129241\tvalid_1's auc: 0.828266\tvalid_1's binary_logloss: 0.139346\n",
            "[49]\ttraining's auc: 0.87083\ttraining's binary_logloss: 0.128976\tvalid_1's auc: 0.828343\tvalid_1's binary_logloss: 0.139221\n",
            "[50]\ttraining's auc: 0.871094\ttraining's binary_logloss: 0.12873\tvalid_1's auc: 0.828318\tvalid_1's binary_logloss: 0.139118\n",
            "[51]\ttraining's auc: 0.871464\ttraining's binary_logloss: 0.128477\tvalid_1's auc: 0.828254\tvalid_1's binary_logloss: 0.138987\n",
            "[52]\ttraining's auc: 0.871894\ttraining's binary_logloss: 0.128223\tvalid_1's auc: 0.828282\tvalid_1's binary_logloss: 0.138864\n",
            "[53]\ttraining's auc: 0.872102\ttraining's binary_logloss: 0.128001\tvalid_1's auc: 0.828374\tvalid_1's binary_logloss: 0.138732\n",
            "[54]\ttraining's auc: 0.872797\ttraining's binary_logloss: 0.127745\tvalid_1's auc: 0.828528\tvalid_1's binary_logloss: 0.138614\n",
            "[55]\ttraining's auc: 0.873156\ttraining's binary_logloss: 0.127502\tvalid_1's auc: 0.828673\tvalid_1's binary_logloss: 0.138505\n",
            "[56]\ttraining's auc: 0.873713\ttraining's binary_logloss: 0.127253\tvalid_1's auc: 0.828669\tvalid_1's binary_logloss: 0.1384\n",
            "[57]\ttraining's auc: 0.874064\ttraining's binary_logloss: 0.127024\tvalid_1's auc: 0.828721\tvalid_1's binary_logloss: 0.138309\n",
            "[58]\ttraining's auc: 0.874797\ttraining's binary_logloss: 0.126787\tvalid_1's auc: 0.828701\tvalid_1's binary_logloss: 0.13822\n",
            "[59]\ttraining's auc: 0.875157\ttraining's binary_logloss: 0.126569\tvalid_1's auc: 0.828974\tvalid_1's binary_logloss: 0.138119\n",
            "[60]\ttraining's auc: 0.87553\ttraining's binary_logloss: 0.126353\tvalid_1's auc: 0.828913\tvalid_1's binary_logloss: 0.138035\n",
            "[61]\ttraining's auc: 0.876153\ttraining's binary_logloss: 0.126129\tvalid_1's auc: 0.828964\tvalid_1's binary_logloss: 0.137942\n",
            "[62]\ttraining's auc: 0.876495\ttraining's binary_logloss: 0.125929\tvalid_1's auc: 0.828837\tvalid_1's binary_logloss: 0.13788\n",
            "[63]\ttraining's auc: 0.877472\ttraining's binary_logloss: 0.125703\tvalid_1's auc: 0.828784\tvalid_1's binary_logloss: 0.137804\n",
            "[64]\ttraining's auc: 0.877756\ttraining's binary_logloss: 0.125512\tvalid_1's auc: 0.82889\tvalid_1's binary_logloss: 0.137724\n",
            "[65]\ttraining's auc: 0.878046\ttraining's binary_logloss: 0.125332\tvalid_1's auc: 0.829092\tvalid_1's binary_logloss: 0.137649\n",
            "[66]\ttraining's auc: 0.878589\ttraining's binary_logloss: 0.125135\tvalid_1's auc: 0.828946\tvalid_1's binary_logloss: 0.137597\n",
            "[67]\ttraining's auc: 0.878824\ttraining's binary_logloss: 0.124959\tvalid_1's auc: 0.828932\tvalid_1's binary_logloss: 0.137534\n",
            "[68]\ttraining's auc: 0.879543\ttraining's binary_logloss: 0.124749\tvalid_1's auc: 0.828905\tvalid_1's binary_logloss: 0.137473\n",
            "[69]\ttraining's auc: 0.879761\ttraining's binary_logloss: 0.124574\tvalid_1's auc: 0.829138\tvalid_1's binary_logloss: 0.137402\n",
            "[70]\ttraining's auc: 0.879997\ttraining's binary_logloss: 0.124399\tvalid_1's auc: 0.829209\tvalid_1's binary_logloss: 0.137338\n",
            "[71]\ttraining's auc: 0.880291\ttraining's binary_logloss: 0.124231\tvalid_1's auc: 0.829264\tvalid_1's binary_logloss: 0.137279\n",
            "[72]\ttraining's auc: 0.880826\ttraining's binary_logloss: 0.124051\tvalid_1's auc: 0.829597\tvalid_1's binary_logloss: 0.137194\n",
            "[73]\ttraining's auc: 0.881057\ttraining's binary_logloss: 0.123872\tvalid_1's auc: 0.829754\tvalid_1's binary_logloss: 0.137133\n",
            "[74]\ttraining's auc: 0.88173\ttraining's binary_logloss: 0.123684\tvalid_1's auc: 0.829664\tvalid_1's binary_logloss: 0.137081\n",
            "[75]\ttraining's auc: 0.88233\ttraining's binary_logloss: 0.123495\tvalid_1's auc: 0.829604\tvalid_1's binary_logloss: 0.137032\n",
            "[76]\ttraining's auc: 0.882662\ttraining's binary_logloss: 0.123326\tvalid_1's auc: 0.829717\tvalid_1's binary_logloss: 0.136984\n",
            "[77]\ttraining's auc: 0.882958\ttraining's binary_logloss: 0.123158\tvalid_1's auc: 0.829726\tvalid_1's binary_logloss: 0.136952\n",
            "[78]\ttraining's auc: 0.883484\ttraining's binary_logloss: 0.122972\tvalid_1's auc: 0.829615\tvalid_1's binary_logloss: 0.136925\n",
            "[79]\ttraining's auc: 0.884133\ttraining's binary_logloss: 0.12279\tvalid_1's auc: 0.829864\tvalid_1's binary_logloss: 0.136857\n",
            "[80]\ttraining's auc: 0.8845\ttraining's binary_logloss: 0.122633\tvalid_1's auc: 0.82987\tvalid_1's binary_logloss: 0.136806\n",
            "[81]\ttraining's auc: 0.884859\ttraining's binary_logloss: 0.122478\tvalid_1's auc: 0.829867\tvalid_1's binary_logloss: 0.136766\n",
            "[82]\ttraining's auc: 0.885186\ttraining's binary_logloss: 0.122323\tvalid_1's auc: 0.829852\tvalid_1's binary_logloss: 0.136737\n",
            "[83]\ttraining's auc: 0.885727\ttraining's binary_logloss: 0.122151\tvalid_1's auc: 0.829915\tvalid_1's binary_logloss: 0.136686\n",
            "[84]\ttraining's auc: 0.886356\ttraining's binary_logloss: 0.121958\tvalid_1's auc: 0.82992\tvalid_1's binary_logloss: 0.136657\n",
            "[85]\ttraining's auc: 0.886624\ttraining's binary_logloss: 0.121816\tvalid_1's auc: 0.830019\tvalid_1's binary_logloss: 0.136625\n",
            "[86]\ttraining's auc: 0.887015\ttraining's binary_logloss: 0.121669\tvalid_1's auc: 0.830167\tvalid_1's binary_logloss: 0.136574\n",
            "[87]\ttraining's auc: 0.88738\ttraining's binary_logloss: 0.12151\tvalid_1's auc: 0.830134\tvalid_1's binary_logloss: 0.136547\n",
            "[88]\ttraining's auc: 0.88815\ttraining's binary_logloss: 0.121331\tvalid_1's auc: 0.830269\tvalid_1's binary_logloss: 0.13651\n",
            "[89]\ttraining's auc: 0.888611\ttraining's binary_logloss: 0.121159\tvalid_1's auc: 0.830305\tvalid_1's binary_logloss: 0.136496\n",
            "[90]\ttraining's auc: 0.888943\ttraining's binary_logloss: 0.121\tvalid_1's auc: 0.830331\tvalid_1's binary_logloss: 0.136484\n",
            "[91]\ttraining's auc: 0.889226\ttraining's binary_logloss: 0.12086\tvalid_1's auc: 0.830275\tvalid_1's binary_logloss: 0.136472\n",
            "[92]\ttraining's auc: 0.889717\ttraining's binary_logloss: 0.120709\tvalid_1's auc: 0.830327\tvalid_1's binary_logloss: 0.136441\n",
            "[93]\ttraining's auc: 0.889972\ttraining's binary_logloss: 0.12058\tvalid_1's auc: 0.830423\tvalid_1's binary_logloss: 0.136416\n",
            "[94]\ttraining's auc: 0.89072\ttraining's binary_logloss: 0.120416\tvalid_1's auc: 0.830502\tvalid_1's binary_logloss: 0.136383\n",
            "[95]\ttraining's auc: 0.890904\ttraining's binary_logloss: 0.120288\tvalid_1's auc: 0.830389\tvalid_1's binary_logloss: 0.136362\n",
            "[96]\ttraining's auc: 0.891177\ttraining's binary_logloss: 0.120157\tvalid_1's auc: 0.830366\tvalid_1's binary_logloss: 0.136356\n",
            "[97]\ttraining's auc: 0.891815\ttraining's binary_logloss: 0.119997\tvalid_1's auc: 0.830354\tvalid_1's binary_logloss: 0.136313\n",
            "[98]\ttraining's auc: 0.892037\ttraining's binary_logloss: 0.119869\tvalid_1's auc: 0.830439\tvalid_1's binary_logloss: 0.136302\n",
            "[99]\ttraining's auc: 0.892244\ttraining's binary_logloss: 0.119751\tvalid_1's auc: 0.830435\tvalid_1's binary_logloss: 0.136277\n",
            "[100]\ttraining's auc: 0.892649\ttraining's binary_logloss: 0.119629\tvalid_1's auc: 0.830477\tvalid_1's binary_logloss: 0.136262\n",
            "[101]\ttraining's auc: 0.893313\ttraining's binary_logloss: 0.11948\tvalid_1's auc: 0.830676\tvalid_1's binary_logloss: 0.136208\n",
            "[102]\ttraining's auc: 0.893559\ttraining's binary_logloss: 0.119361\tvalid_1's auc: 0.830613\tvalid_1's binary_logloss: 0.136191\n",
            "[103]\ttraining's auc: 0.893947\ttraining's binary_logloss: 0.119238\tvalid_1's auc: 0.830806\tvalid_1's binary_logloss: 0.136153\n",
            "[104]\ttraining's auc: 0.894132\ttraining's binary_logloss: 0.119127\tvalid_1's auc: 0.830703\tvalid_1's binary_logloss: 0.136151\n",
            "[105]\ttraining's auc: 0.894355\ttraining's binary_logloss: 0.119013\tvalid_1's auc: 0.83074\tvalid_1's binary_logloss: 0.136133\n",
            "[106]\ttraining's auc: 0.894691\ttraining's binary_logloss: 0.118898\tvalid_1's auc: 0.830794\tvalid_1's binary_logloss: 0.136123\n",
            "[107]\ttraining's auc: 0.895017\ttraining's binary_logloss: 0.118777\tvalid_1's auc: 0.831031\tvalid_1's binary_logloss: 0.136074\n",
            "[108]\ttraining's auc: 0.895426\ttraining's binary_logloss: 0.118645\tvalid_1's auc: 0.830961\tvalid_1's binary_logloss: 0.136079\n",
            "[109]\ttraining's auc: 0.895658\ttraining's binary_logloss: 0.118538\tvalid_1's auc: 0.830818\tvalid_1's binary_logloss: 0.136074\n",
            "[110]\ttraining's auc: 0.895921\ttraining's binary_logloss: 0.118422\tvalid_1's auc: 0.830953\tvalid_1's binary_logloss: 0.136038\n",
            "[111]\ttraining's auc: 0.896057\ttraining's binary_logloss: 0.118324\tvalid_1's auc: 0.830872\tvalid_1's binary_logloss: 0.13603\n",
            "[112]\ttraining's auc: 0.896346\ttraining's binary_logloss: 0.118213\tvalid_1's auc: 0.830951\tvalid_1's binary_logloss: 0.136013\n",
            "[113]\ttraining's auc: 0.896501\ttraining's binary_logloss: 0.118109\tvalid_1's auc: 0.83113\tvalid_1's binary_logloss: 0.135985\n",
            "[114]\ttraining's auc: 0.896852\ttraining's binary_logloss: 0.117994\tvalid_1's auc: 0.831003\tvalid_1's binary_logloss: 0.135998\n",
            "[115]\ttraining's auc: 0.89707\ttraining's binary_logloss: 0.117877\tvalid_1's auc: 0.830923\tvalid_1's binary_logloss: 0.136005\n",
            "[116]\ttraining's auc: 0.897583\ttraining's binary_logloss: 0.117747\tvalid_1's auc: 0.831091\tvalid_1's binary_logloss: 0.135976\n",
            "[117]\ttraining's auc: 0.898101\ttraining's binary_logloss: 0.117625\tvalid_1's auc: 0.831297\tvalid_1's binary_logloss: 0.135947\n",
            "[118]\ttraining's auc: 0.898361\ttraining's binary_logloss: 0.117512\tvalid_1's auc: 0.831232\tvalid_1's binary_logloss: 0.135944\n",
            "[119]\ttraining's auc: 0.89869\ttraining's binary_logloss: 0.117396\tvalid_1's auc: 0.831282\tvalid_1's binary_logloss: 0.135935\n",
            "[120]\ttraining's auc: 0.89892\ttraining's binary_logloss: 0.117284\tvalid_1's auc: 0.831287\tvalid_1's binary_logloss: 0.135926\n",
            "[121]\ttraining's auc: 0.899089\ttraining's binary_logloss: 0.117189\tvalid_1's auc: 0.83128\tvalid_1's binary_logloss: 0.135914\n",
            "[122]\ttraining's auc: 0.899315\ttraining's binary_logloss: 0.117082\tvalid_1's auc: 0.831333\tvalid_1's binary_logloss: 0.135902\n",
            "[123]\ttraining's auc: 0.899565\ttraining's binary_logloss: 0.116983\tvalid_1's auc: 0.831288\tvalid_1's binary_logloss: 0.135909\n",
            "[124]\ttraining's auc: 0.899874\ttraining's binary_logloss: 0.116887\tvalid_1's auc: 0.8313\tvalid_1's binary_logloss: 0.135897\n",
            "[125]\ttraining's auc: 0.900084\ttraining's binary_logloss: 0.116789\tvalid_1's auc: 0.831306\tvalid_1's binary_logloss: 0.13588\n",
            "[126]\ttraining's auc: 0.900302\ttraining's binary_logloss: 0.116691\tvalid_1's auc: 0.831364\tvalid_1's binary_logloss: 0.135873\n",
            "[127]\ttraining's auc: 0.900572\ttraining's binary_logloss: 0.1166\tvalid_1's auc: 0.831291\tvalid_1's binary_logloss: 0.13588\n",
            "[128]\ttraining's auc: 0.901017\ttraining's binary_logloss: 0.116487\tvalid_1's auc: 0.831438\tvalid_1's binary_logloss: 0.135847\n",
            "[129]\ttraining's auc: 0.901337\ttraining's binary_logloss: 0.116388\tvalid_1's auc: 0.831513\tvalid_1's binary_logloss: 0.135826\n",
            "[130]\ttraining's auc: 0.901567\ttraining's binary_logloss: 0.116284\tvalid_1's auc: 0.83147\tvalid_1's binary_logloss: 0.135832\n",
            "[131]\ttraining's auc: 0.901789\ttraining's binary_logloss: 0.116195\tvalid_1's auc: 0.831425\tvalid_1's binary_logloss: 0.135831\n",
            "[132]\ttraining's auc: 0.901983\ttraining's binary_logloss: 0.116088\tvalid_1's auc: 0.831331\tvalid_1's binary_logloss: 0.135843\n",
            "[133]\ttraining's auc: 0.902242\ttraining's binary_logloss: 0.115998\tvalid_1's auc: 0.831357\tvalid_1's binary_logloss: 0.13584\n",
            "[134]\ttraining's auc: 0.902518\ttraining's binary_logloss: 0.115914\tvalid_1's auc: 0.83133\tvalid_1's binary_logloss: 0.135835\n",
            "[135]\ttraining's auc: 0.902757\ttraining's binary_logloss: 0.115803\tvalid_1's auc: 0.831274\tvalid_1's binary_logloss: 0.135838\n",
            "[136]\ttraining's auc: 0.903389\ttraining's binary_logloss: 0.115681\tvalid_1's auc: 0.831388\tvalid_1's binary_logloss: 0.135823\n",
            "[137]\ttraining's auc: 0.903559\ttraining's binary_logloss: 0.115572\tvalid_1's auc: 0.831398\tvalid_1's binary_logloss: 0.135826\n",
            "[138]\ttraining's auc: 0.903697\ttraining's binary_logloss: 0.115489\tvalid_1's auc: 0.831385\tvalid_1's binary_logloss: 0.135826\n",
            "[139]\ttraining's auc: 0.903931\ttraining's binary_logloss: 0.1154\tvalid_1's auc: 0.831531\tvalid_1's binary_logloss: 0.135807\n",
            "[140]\ttraining's auc: 0.90411\ttraining's binary_logloss: 0.115298\tvalid_1's auc: 0.831561\tvalid_1's binary_logloss: 0.135818\n",
            "[141]\ttraining's auc: 0.904289\ttraining's binary_logloss: 0.115209\tvalid_1's auc: 0.831437\tvalid_1's binary_logloss: 0.135834\n",
            "[142]\ttraining's auc: 0.904665\ttraining's binary_logloss: 0.11512\tvalid_1's auc: 0.831548\tvalid_1's binary_logloss: 0.135824\n",
            "[143]\ttraining's auc: 0.90483\ttraining's binary_logloss: 0.115021\tvalid_1's auc: 0.831532\tvalid_1's binary_logloss: 0.135828\n",
            "[144]\ttraining's auc: 0.905023\ttraining's binary_logloss: 0.114933\tvalid_1's auc: 0.831605\tvalid_1's binary_logloss: 0.135809\n",
            "[145]\ttraining's auc: 0.9053\ttraining's binary_logloss: 0.114857\tvalid_1's auc: 0.831541\tvalid_1's binary_logloss: 0.135818\n",
            "[146]\ttraining's auc: 0.905566\ttraining's binary_logloss: 0.114755\tvalid_1's auc: 0.831463\tvalid_1's binary_logloss: 0.135829\n",
            "[147]\ttraining's auc: 0.905822\ttraining's binary_logloss: 0.114681\tvalid_1's auc: 0.831375\tvalid_1's binary_logloss: 0.13583\n",
            "[148]\ttraining's auc: 0.905966\ttraining's binary_logloss: 0.11459\tvalid_1's auc: 0.831273\tvalid_1's binary_logloss: 0.135834\n",
            "[149]\ttraining's auc: 0.906102\ttraining's binary_logloss: 0.114501\tvalid_1's auc: 0.831326\tvalid_1's binary_logloss: 0.135835\n",
            "[150]\ttraining's auc: 0.906322\ttraining's binary_logloss: 0.114414\tvalid_1's auc: 0.831346\tvalid_1's binary_logloss: 0.135839\n",
            "[151]\ttraining's auc: 0.906479\ttraining's binary_logloss: 0.114332\tvalid_1's auc: 0.83134\tvalid_1's binary_logloss: 0.135843\n",
            "[152]\ttraining's auc: 0.906708\ttraining's binary_logloss: 0.114227\tvalid_1's auc: 0.831258\tvalid_1's binary_logloss: 0.135851\n",
            "[153]\ttraining's auc: 0.906973\ttraining's binary_logloss: 0.114139\tvalid_1's auc: 0.83117\tvalid_1's binary_logloss: 0.135867\n",
            "[154]\ttraining's auc: 0.907143\ttraining's binary_logloss: 0.114052\tvalid_1's auc: 0.831251\tvalid_1's binary_logloss: 0.135867\n",
            "[155]\ttraining's auc: 0.907286\ttraining's binary_logloss: 0.11397\tvalid_1's auc: 0.831256\tvalid_1's binary_logloss: 0.135869\n",
            "[156]\ttraining's auc: 0.90742\ttraining's binary_logloss: 0.113887\tvalid_1's auc: 0.831273\tvalid_1's binary_logloss: 0.13587\n",
            "[157]\ttraining's auc: 0.90776\ttraining's binary_logloss: 0.113788\tvalid_1's auc: 0.831207\tvalid_1's binary_logloss: 0.135878\n",
            "[158]\ttraining's auc: 0.907902\ttraining's binary_logloss: 0.113703\tvalid_1's auc: 0.831241\tvalid_1's binary_logloss: 0.135863\n",
            "[159]\ttraining's auc: 0.908138\ttraining's binary_logloss: 0.113595\tvalid_1's auc: 0.831228\tvalid_1's binary_logloss: 0.135859\n",
            "[160]\ttraining's auc: 0.908467\ttraining's binary_logloss: 0.113504\tvalid_1's auc: 0.831097\tvalid_1's binary_logloss: 0.135878\n",
            "[161]\ttraining's auc: 0.908707\ttraining's binary_logloss: 0.113428\tvalid_1's auc: 0.83108\tvalid_1's binary_logloss: 0.135879\n",
            "[162]\ttraining's auc: 0.908843\ttraining's binary_logloss: 0.113357\tvalid_1's auc: 0.831091\tvalid_1's binary_logloss: 0.135874\n",
            "[163]\ttraining's auc: 0.909044\ttraining's binary_logloss: 0.11328\tvalid_1's auc: 0.831117\tvalid_1's binary_logloss: 0.135871\n",
            "[164]\ttraining's auc: 0.909198\ttraining's binary_logloss: 0.113195\tvalid_1's auc: 0.831112\tvalid_1's binary_logloss: 0.135865\n",
            "[165]\ttraining's auc: 0.909428\ttraining's binary_logloss: 0.113091\tvalid_1's auc: 0.831081\tvalid_1's binary_logloss: 0.135868\n",
            "[166]\ttraining's auc: 0.909587\ttraining's binary_logloss: 0.113021\tvalid_1's auc: 0.831027\tvalid_1's binary_logloss: 0.135889\n",
            "[167]\ttraining's auc: 0.90975\ttraining's binary_logloss: 0.112941\tvalid_1's auc: 0.830978\tvalid_1's binary_logloss: 0.135908\n",
            "[168]\ttraining's auc: 0.909843\ttraining's binary_logloss: 0.112873\tvalid_1's auc: 0.830914\tvalid_1's binary_logloss: 0.135923\n",
            "[169]\ttraining's auc: 0.910119\ttraining's binary_logloss: 0.112787\tvalid_1's auc: 0.830966\tvalid_1's binary_logloss: 0.135904\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 38%|███▊      | 19/50 [08:56<10:41, 20.70s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.164547\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.158883\n",
            "[2]\ttraining's auc: 0.822077\ttraining's binary_logloss: 0.162481\tvalid_1's auc: 0.804437\tvalid_1's binary_logloss: 0.157188\n",
            "[3]\ttraining's auc: 0.823557\ttraining's binary_logloss: 0.160618\tvalid_1's auc: 0.804723\tvalid_1's binary_logloss: 0.155685\n",
            "[4]\ttraining's auc: 0.829921\ttraining's binary_logloss: 0.158879\tvalid_1's auc: 0.81566\tvalid_1's binary_logloss: 0.154345\n",
            "[5]\ttraining's auc: 0.832017\ttraining's binary_logloss: 0.157314\tvalid_1's auc: 0.817016\tvalid_1's binary_logloss: 0.15308\n",
            "[6]\ttraining's auc: 0.834113\ttraining's binary_logloss: 0.155845\tvalid_1's auc: 0.818339\tvalid_1's binary_logloss: 0.151936\n",
            "[7]\ttraining's auc: 0.835059\ttraining's binary_logloss: 0.154518\tvalid_1's auc: 0.818892\tvalid_1's binary_logloss: 0.150873\n",
            "[8]\ttraining's auc: 0.835394\ttraining's binary_logloss: 0.153272\tvalid_1's auc: 0.819231\tvalid_1's binary_logloss: 0.149879\n",
            "[9]\ttraining's auc: 0.837052\ttraining's binary_logloss: 0.152104\tvalid_1's auc: 0.819877\tvalid_1's binary_logloss: 0.148997\n",
            "[10]\ttraining's auc: 0.8375\ttraining's binary_logloss: 0.151031\tvalid_1's auc: 0.819855\tvalid_1's binary_logloss: 0.14816\n",
            "[11]\ttraining's auc: 0.840499\ttraining's binary_logloss: 0.150009\tvalid_1's auc: 0.822456\tvalid_1's binary_logloss: 0.147405\n",
            "[12]\ttraining's auc: 0.841093\ttraining's binary_logloss: 0.149055\tvalid_1's auc: 0.822622\tvalid_1's binary_logloss: 0.146695\n",
            "[13]\ttraining's auc: 0.841563\ttraining's binary_logloss: 0.148148\tvalid_1's auc: 0.822811\tvalid_1's binary_logloss: 0.146025\n",
            "[14]\ttraining's auc: 0.844102\ttraining's binary_logloss: 0.147273\tvalid_1's auc: 0.824001\tvalid_1's binary_logloss: 0.145362\n",
            "[15]\ttraining's auc: 0.846191\ttraining's binary_logloss: 0.146455\tvalid_1's auc: 0.825203\tvalid_1's binary_logloss: 0.14473\n",
            "[16]\ttraining's auc: 0.849065\ttraining's binary_logloss: 0.145654\tvalid_1's auc: 0.827448\tvalid_1's binary_logloss: 0.144149\n",
            "[17]\ttraining's auc: 0.849659\ttraining's binary_logloss: 0.144912\tvalid_1's auc: 0.827254\tvalid_1's binary_logloss: 0.143603\n",
            "[18]\ttraining's auc: 0.850074\ttraining's binary_logloss: 0.144206\tvalid_1's auc: 0.827879\tvalid_1's binary_logloss: 0.143078\n",
            "[19]\ttraining's auc: 0.850982\ttraining's binary_logloss: 0.143512\tvalid_1's auc: 0.828045\tvalid_1's binary_logloss: 0.142559\n",
            "[20]\ttraining's auc: 0.852307\ttraining's binary_logloss: 0.142866\tvalid_1's auc: 0.828217\tvalid_1's binary_logloss: 0.142095\n",
            "[21]\ttraining's auc: 0.853087\ttraining's binary_logloss: 0.142248\tvalid_1's auc: 0.828631\tvalid_1's binary_logloss: 0.141655\n",
            "[22]\ttraining's auc: 0.85355\ttraining's binary_logloss: 0.141642\tvalid_1's auc: 0.828957\tvalid_1's binary_logloss: 0.141216\n",
            "[23]\ttraining's auc: 0.854714\ttraining's binary_logloss: 0.141072\tvalid_1's auc: 0.829057\tvalid_1's binary_logloss: 0.140809\n",
            "[24]\ttraining's auc: 0.85595\ttraining's binary_logloss: 0.140512\tvalid_1's auc: 0.830758\tvalid_1's binary_logloss: 0.140361\n",
            "[25]\ttraining's auc: 0.856851\ttraining's binary_logloss: 0.139979\tvalid_1's auc: 0.832437\tvalid_1's binary_logloss: 0.139939\n",
            "[26]\ttraining's auc: 0.857579\ttraining's binary_logloss: 0.139466\tvalid_1's auc: 0.832502\tvalid_1's binary_logloss: 0.139565\n",
            "[27]\ttraining's auc: 0.858052\ttraining's binary_logloss: 0.138973\tvalid_1's auc: 0.832548\tvalid_1's binary_logloss: 0.139233\n",
            "[28]\ttraining's auc: 0.858368\ttraining's binary_logloss: 0.138484\tvalid_1's auc: 0.8327\tvalid_1's binary_logloss: 0.138887\n",
            "[29]\ttraining's auc: 0.859038\ttraining's binary_logloss: 0.138012\tvalid_1's auc: 0.832852\tvalid_1's binary_logloss: 0.138572\n",
            "[30]\ttraining's auc: 0.859725\ttraining's binary_logloss: 0.137557\tvalid_1's auc: 0.832695\tvalid_1's binary_logloss: 0.138293\n",
            "[31]\ttraining's auc: 0.860226\ttraining's binary_logloss: 0.137111\tvalid_1's auc: 0.832485\tvalid_1's binary_logloss: 0.138009\n",
            "[32]\ttraining's auc: 0.860478\ttraining's binary_logloss: 0.136688\tvalid_1's auc: 0.832534\tvalid_1's binary_logloss: 0.137721\n",
            "[33]\ttraining's auc: 0.861902\ttraining's binary_logloss: 0.136281\tvalid_1's auc: 0.833314\tvalid_1's binary_logloss: 0.137429\n",
            "[34]\ttraining's auc: 0.862254\ttraining's binary_logloss: 0.135877\tvalid_1's auc: 0.833275\tvalid_1's binary_logloss: 0.137189\n",
            "[35]\ttraining's auc: 0.862776\ttraining's binary_logloss: 0.135508\tvalid_1's auc: 0.833379\tvalid_1's binary_logloss: 0.136936\n",
            "[36]\ttraining's auc: 0.863348\ttraining's binary_logloss: 0.135129\tvalid_1's auc: 0.833276\tvalid_1's binary_logloss: 0.13668\n",
            "[37]\ttraining's auc: 0.864112\ttraining's binary_logloss: 0.13475\tvalid_1's auc: 0.83338\tvalid_1's binary_logloss: 0.136442\n",
            "[38]\ttraining's auc: 0.864641\ttraining's binary_logloss: 0.134397\tvalid_1's auc: 0.833513\tvalid_1's binary_logloss: 0.136218\n",
            "[39]\ttraining's auc: 0.866045\ttraining's binary_logloss: 0.134033\tvalid_1's auc: 0.833946\tvalid_1's binary_logloss: 0.135993\n",
            "[40]\ttraining's auc: 0.867088\ttraining's binary_logloss: 0.133672\tvalid_1's auc: 0.83417\tvalid_1's binary_logloss: 0.135787\n",
            "[41]\ttraining's auc: 0.867979\ttraining's binary_logloss: 0.133336\tvalid_1's auc: 0.834387\tvalid_1's binary_logloss: 0.135583\n",
            "[42]\ttraining's auc: 0.868311\ttraining's binary_logloss: 0.133024\tvalid_1's auc: 0.834837\tvalid_1's binary_logloss: 0.135408\n",
            "[43]\ttraining's auc: 0.869012\ttraining's binary_logloss: 0.132694\tvalid_1's auc: 0.834991\tvalid_1's binary_logloss: 0.135254\n",
            "[44]\ttraining's auc: 0.870042\ttraining's binary_logloss: 0.132376\tvalid_1's auc: 0.834694\tvalid_1's binary_logloss: 0.135116\n",
            "[45]\ttraining's auc: 0.870566\ttraining's binary_logloss: 0.132068\tvalid_1's auc: 0.83467\tvalid_1's binary_logloss: 0.134961\n",
            "[46]\ttraining's auc: 0.871258\ttraining's binary_logloss: 0.13177\tvalid_1's auc: 0.83459\tvalid_1's binary_logloss: 0.134799\n",
            "[47]\ttraining's auc: 0.871713\ttraining's binary_logloss: 0.131466\tvalid_1's auc: 0.834572\tvalid_1's binary_logloss: 0.134677\n",
            "[48]\ttraining's auc: 0.871952\ttraining's binary_logloss: 0.131196\tvalid_1's auc: 0.834393\tvalid_1's binary_logloss: 0.134552\n",
            "[49]\ttraining's auc: 0.872293\ttraining's binary_logloss: 0.130922\tvalid_1's auc: 0.834234\tvalid_1's binary_logloss: 0.134416\n",
            "[50]\ttraining's auc: 0.872638\ttraining's binary_logloss: 0.130656\tvalid_1's auc: 0.83412\tvalid_1's binary_logloss: 0.134268\n",
            "[51]\ttraining's auc: 0.873075\ttraining's binary_logloss: 0.1304\tvalid_1's auc: 0.834292\tvalid_1's binary_logloss: 0.134125\n",
            "[52]\ttraining's auc: 0.873234\ttraining's binary_logloss: 0.130147\tvalid_1's auc: 0.83438\tvalid_1's binary_logloss: 0.134004\n",
            "[53]\ttraining's auc: 0.873704\ttraining's binary_logloss: 0.129901\tvalid_1's auc: 0.834405\tvalid_1's binary_logloss: 0.133889\n",
            "[54]\ttraining's auc: 0.874009\ttraining's binary_logloss: 0.129664\tvalid_1's auc: 0.834312\tvalid_1's binary_logloss: 0.133791\n",
            "[55]\ttraining's auc: 0.874348\ttraining's binary_logloss: 0.129411\tvalid_1's auc: 0.834304\tvalid_1's binary_logloss: 0.133689\n",
            "[56]\ttraining's auc: 0.874623\ttraining's binary_logloss: 0.129181\tvalid_1's auc: 0.83416\tvalid_1's binary_logloss: 0.133599\n",
            "[57]\ttraining's auc: 0.874901\ttraining's binary_logloss: 0.128947\tvalid_1's auc: 0.834337\tvalid_1's binary_logloss: 0.133495\n",
            "[58]\ttraining's auc: 0.875258\ttraining's binary_logloss: 0.128733\tvalid_1's auc: 0.834226\tvalid_1's binary_logloss: 0.133393\n",
            "[59]\ttraining's auc: 0.875504\ttraining's binary_logloss: 0.128524\tvalid_1's auc: 0.834061\tvalid_1's binary_logloss: 0.133306\n",
            "[60]\ttraining's auc: 0.875711\ttraining's binary_logloss: 0.128314\tvalid_1's auc: 0.834142\tvalid_1's binary_logloss: 0.133216\n",
            "[61]\ttraining's auc: 0.875984\ttraining's binary_logloss: 0.128109\tvalid_1's auc: 0.83414\tvalid_1's binary_logloss: 0.133125\n",
            "[62]\ttraining's auc: 0.876502\ttraining's binary_logloss: 0.127885\tvalid_1's auc: 0.83429\tvalid_1's binary_logloss: 0.133021\n",
            "[63]\ttraining's auc: 0.876745\ttraining's binary_logloss: 0.127689\tvalid_1's auc: 0.834449\tvalid_1's binary_logloss: 0.132929\n",
            "[64]\ttraining's auc: 0.877033\ttraining's binary_logloss: 0.127478\tvalid_1's auc: 0.83458\tvalid_1's binary_logloss: 0.132843\n",
            "[65]\ttraining's auc: 0.877594\ttraining's binary_logloss: 0.12727\tvalid_1's auc: 0.834698\tvalid_1's binary_logloss: 0.132774\n",
            "[66]\ttraining's auc: 0.878153\ttraining's binary_logloss: 0.127053\tvalid_1's auc: 0.834784\tvalid_1's binary_logloss: 0.132689\n",
            "[67]\ttraining's auc: 0.878552\ttraining's binary_logloss: 0.126854\tvalid_1's auc: 0.83476\tvalid_1's binary_logloss: 0.132636\n",
            "[68]\ttraining's auc: 0.878921\ttraining's binary_logloss: 0.12665\tvalid_1's auc: 0.834843\tvalid_1's binary_logloss: 0.132567\n",
            "[69]\ttraining's auc: 0.879496\ttraining's binary_logloss: 0.126427\tvalid_1's auc: 0.834778\tvalid_1's binary_logloss: 0.13247\n",
            "[70]\ttraining's auc: 0.879733\ttraining's binary_logloss: 0.126235\tvalid_1's auc: 0.834842\tvalid_1's binary_logloss: 0.132398\n",
            "[71]\ttraining's auc: 0.880247\ttraining's binary_logloss: 0.126033\tvalid_1's auc: 0.834884\tvalid_1's binary_logloss: 0.132334\n",
            "[72]\ttraining's auc: 0.880479\ttraining's binary_logloss: 0.125859\tvalid_1's auc: 0.834817\tvalid_1's binary_logloss: 0.132276\n",
            "[73]\ttraining's auc: 0.880893\ttraining's binary_logloss: 0.125672\tvalid_1's auc: 0.834787\tvalid_1's binary_logloss: 0.132214\n",
            " 38%|███▊      | 19/50 [09:07<10:41, 20.70s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.160829\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.166446\n",
            "[2]\ttraining's auc: 0.83088\ttraining's binary_logloss: 0.158809\tvalid_1's auc: 0.816226\tvalid_1's binary_logloss: 0.164611\n",
            "[3]\ttraining's auc: 0.831548\ttraining's binary_logloss: 0.157025\tvalid_1's auc: 0.814456\tvalid_1's binary_logloss: 0.163046\n",
            "[4]\ttraining's auc: 0.832718\ttraining's binary_logloss: 0.155404\tvalid_1's auc: 0.81507\tvalid_1's binary_logloss: 0.161629\n",
            "[5]\ttraining's auc: 0.834482\ttraining's binary_logloss: 0.153912\tvalid_1's auc: 0.816464\tvalid_1's binary_logloss: 0.160257\n",
            "[6]\ttraining's auc: 0.835365\ttraining's binary_logloss: 0.152495\tvalid_1's auc: 0.81595\tvalid_1's binary_logloss: 0.159045\n",
            "[7]\ttraining's auc: 0.837739\ttraining's binary_logloss: 0.151225\tvalid_1's auc: 0.817934\tvalid_1's binary_logloss: 0.157917\n",
            "[8]\ttraining's auc: 0.838823\ttraining's binary_logloss: 0.150047\tvalid_1's auc: 0.818445\tvalid_1's binary_logloss: 0.15684\n",
            "[9]\ttraining's auc: 0.840297\ttraining's binary_logloss: 0.148887\tvalid_1's auc: 0.819668\tvalid_1's binary_logloss: 0.155827\n",
            "[10]\ttraining's auc: 0.841579\ttraining's binary_logloss: 0.147834\tvalid_1's auc: 0.819787\tvalid_1's binary_logloss: 0.154921\n",
            "[11]\ttraining's auc: 0.844235\ttraining's binary_logloss: 0.146832\tvalid_1's auc: 0.822544\tvalid_1's binary_logloss: 0.15406\n",
            "[12]\ttraining's auc: 0.848463\ttraining's binary_logloss: 0.145863\tvalid_1's auc: 0.826323\tvalid_1's binary_logloss: 0.153232\n",
            "[13]\ttraining's auc: 0.849771\ttraining's binary_logloss: 0.144963\tvalid_1's auc: 0.827539\tvalid_1's binary_logloss: 0.152428\n",
            "[14]\ttraining's auc: 0.850243\ttraining's binary_logloss: 0.144115\tvalid_1's auc: 0.827749\tvalid_1's binary_logloss: 0.151709\n",
            "[15]\ttraining's auc: 0.851012\ttraining's binary_logloss: 0.143318\tvalid_1's auc: 0.828086\tvalid_1's binary_logloss: 0.151047\n",
            "[16]\ttraining's auc: 0.851582\ttraining's binary_logloss: 0.142565\tvalid_1's auc: 0.828104\tvalid_1's binary_logloss: 0.150433\n",
            "[17]\ttraining's auc: 0.851994\ttraining's binary_logloss: 0.141847\tvalid_1's auc: 0.828201\tvalid_1's binary_logloss: 0.149839\n",
            "[18]\ttraining's auc: 0.852777\ttraining's binary_logloss: 0.141169\tvalid_1's auc: 0.829001\tvalid_1's binary_logloss: 0.149261\n",
            "[19]\ttraining's auc: 0.852715\ttraining's binary_logloss: 0.140508\tvalid_1's auc: 0.829414\tvalid_1's binary_logloss: 0.148701\n",
            "[20]\ttraining's auc: 0.853583\ttraining's binary_logloss: 0.139863\tvalid_1's auc: 0.829283\tvalid_1's binary_logloss: 0.148185\n",
            "[21]\ttraining's auc: 0.853913\ttraining's binary_logloss: 0.139222\tvalid_1's auc: 0.829701\tvalid_1's binary_logloss: 0.147696\n",
            "[22]\ttraining's auc: 0.854528\ttraining's binary_logloss: 0.138641\tvalid_1's auc: 0.829844\tvalid_1's binary_logloss: 0.14722\n",
            "[23]\ttraining's auc: 0.854872\ttraining's binary_logloss: 0.13807\tvalid_1's auc: 0.830126\tvalid_1's binary_logloss: 0.146773\n",
            "[24]\ttraining's auc: 0.855096\ttraining's binary_logloss: 0.137531\tvalid_1's auc: 0.829917\tvalid_1's binary_logloss: 0.146361\n",
            "[25]\ttraining's auc: 0.855715\ttraining's binary_logloss: 0.136999\tvalid_1's auc: 0.830604\tvalid_1's binary_logloss: 0.145931\n",
            "[26]\ttraining's auc: 0.856423\ttraining's binary_logloss: 0.136491\tvalid_1's auc: 0.831128\tvalid_1's binary_logloss: 0.145545\n",
            "[27]\ttraining's auc: 0.856901\ttraining's binary_logloss: 0.135985\tvalid_1's auc: 0.831145\tvalid_1's binary_logloss: 0.145163\n",
            "[28]\ttraining's auc: 0.857394\ttraining's binary_logloss: 0.13552\tvalid_1's auc: 0.831336\tvalid_1's binary_logloss: 0.144794\n",
            "[29]\ttraining's auc: 0.857722\ttraining's binary_logloss: 0.135066\tvalid_1's auc: 0.83156\tvalid_1's binary_logloss: 0.144442\n",
            "[30]\ttraining's auc: 0.858645\ttraining's binary_logloss: 0.134638\tvalid_1's auc: 0.831643\tvalid_1's binary_logloss: 0.144122\n",
            "[31]\ttraining's auc: 0.859002\ttraining's binary_logloss: 0.134204\tvalid_1's auc: 0.831912\tvalid_1's binary_logloss: 0.143787\n",
            "[32]\ttraining's auc: 0.859407\ttraining's binary_logloss: 0.133803\tvalid_1's auc: 0.831703\tvalid_1's binary_logloss: 0.143481\n",
            "[33]\ttraining's auc: 0.860153\ttraining's binary_logloss: 0.133422\tvalid_1's auc: 0.831992\tvalid_1's binary_logloss: 0.143178\n",
            "[34]\ttraining's auc: 0.860466\ttraining's binary_logloss: 0.133037\tvalid_1's auc: 0.831978\tvalid_1's binary_logloss: 0.142899\n",
            "[35]\ttraining's auc: 0.861558\ttraining's binary_logloss: 0.132676\tvalid_1's auc: 0.832147\tvalid_1's binary_logloss: 0.142629\n",
            "[36]\ttraining's auc: 0.862267\ttraining's binary_logloss: 0.132303\tvalid_1's auc: 0.832156\tvalid_1's binary_logloss: 0.142386\n",
            "[37]\ttraining's auc: 0.862727\ttraining's binary_logloss: 0.13196\tvalid_1's auc: 0.832144\tvalid_1's binary_logloss: 0.142152\n",
            "[38]\ttraining's auc: 0.863439\ttraining's binary_logloss: 0.131611\tvalid_1's auc: 0.832177\tvalid_1's binary_logloss: 0.141924\n",
            "[39]\ttraining's auc: 0.863728\ttraining's binary_logloss: 0.131292\tvalid_1's auc: 0.832054\tvalid_1's binary_logloss: 0.141706\n",
            "[40]\ttraining's auc: 0.864104\ttraining's binary_logloss: 0.130975\tvalid_1's auc: 0.832062\tvalid_1's binary_logloss: 0.141512\n",
            "[41]\ttraining's auc: 0.864459\ttraining's binary_logloss: 0.130669\tvalid_1's auc: 0.832036\tvalid_1's binary_logloss: 0.141306\n",
            "[42]\ttraining's auc: 0.865997\ttraining's binary_logloss: 0.130352\tvalid_1's auc: 0.832302\tvalid_1's binary_logloss: 0.141111\n",
            "[43]\ttraining's auc: 0.866571\ttraining's binary_logloss: 0.130052\tvalid_1's auc: 0.832509\tvalid_1's binary_logloss: 0.14094\n",
            "[44]\ttraining's auc: 0.867359\ttraining's binary_logloss: 0.129762\tvalid_1's auc: 0.832567\tvalid_1's binary_logloss: 0.140761\n",
            "[45]\ttraining's auc: 0.86778\ttraining's binary_logloss: 0.129477\tvalid_1's auc: 0.832573\tvalid_1's binary_logloss: 0.140596\n",
            "[46]\ttraining's auc: 0.86828\ttraining's binary_logloss: 0.129193\tvalid_1's auc: 0.832545\tvalid_1's binary_logloss: 0.140435\n",
            "[47]\ttraining's auc: 0.868893\ttraining's binary_logloss: 0.128909\tvalid_1's auc: 0.832653\tvalid_1's binary_logloss: 0.140282\n",
            "[48]\ttraining's auc: 0.869436\ttraining's binary_logloss: 0.128633\tvalid_1's auc: 0.832595\tvalid_1's binary_logloss: 0.140142\n",
            "[49]\ttraining's auc: 0.870658\ttraining's binary_logloss: 0.128354\tvalid_1's auc: 0.834013\tvalid_1's binary_logloss: 0.140002\n",
            "[50]\ttraining's auc: 0.871617\ttraining's binary_logloss: 0.128088\tvalid_1's auc: 0.834579\tvalid_1's binary_logloss: 0.139859\n",
            "[51]\ttraining's auc: 0.871997\ttraining's binary_logloss: 0.127845\tvalid_1's auc: 0.834686\tvalid_1's binary_logloss: 0.139711\n",
            "[52]\ttraining's auc: 0.872395\ttraining's binary_logloss: 0.127588\tvalid_1's auc: 0.834492\tvalid_1's binary_logloss: 0.13959\n",
            "[53]\ttraining's auc: 0.87298\ttraining's binary_logloss: 0.127338\tvalid_1's auc: 0.834525\tvalid_1's binary_logloss: 0.139463\n",
            "[54]\ttraining's auc: 0.873516\ttraining's binary_logloss: 0.127101\tvalid_1's auc: 0.834826\tvalid_1's binary_logloss: 0.13933\n",
            "[55]\ttraining's auc: 0.873919\ttraining's binary_logloss: 0.126864\tvalid_1's auc: 0.834938\tvalid_1's binary_logloss: 0.139211\n",
            "[56]\ttraining's auc: 0.874412\ttraining's binary_logloss: 0.126628\tvalid_1's auc: 0.835354\tvalid_1's binary_logloss: 0.139091\n",
            "[57]\ttraining's auc: 0.874658\ttraining's binary_logloss: 0.126411\tvalid_1's auc: 0.835354\tvalid_1's binary_logloss: 0.138979\n",
            "[58]\ttraining's auc: 0.874975\ttraining's binary_logloss: 0.126201\tvalid_1's auc: 0.835324\tvalid_1's binary_logloss: 0.138875\n",
            "[59]\ttraining's auc: 0.875549\ttraining's binary_logloss: 0.125985\tvalid_1's auc: 0.835379\tvalid_1's binary_logloss: 0.138772\n",
            "[60]\ttraining's auc: 0.875859\ttraining's binary_logloss: 0.12577\tvalid_1's auc: 0.835389\tvalid_1's binary_logloss: 0.13869\n",
            "[61]\ttraining's auc: 0.876641\ttraining's binary_logloss: 0.125544\tvalid_1's auc: 0.835149\tvalid_1's binary_logloss: 0.138608\n",
            "[62]\ttraining's auc: 0.877751\ttraining's binary_logloss: 0.125313\tvalid_1's auc: 0.835255\tvalid_1's binary_logloss: 0.138493\n",
            "[63]\ttraining's auc: 0.878248\ttraining's binary_logloss: 0.125098\tvalid_1's auc: 0.835465\tvalid_1's binary_logloss: 0.138382\n",
            "[64]\ttraining's auc: 0.878723\ttraining's binary_logloss: 0.124893\tvalid_1's auc: 0.835566\tvalid_1's binary_logloss: 0.138302\n",
            "[65]\ttraining's auc: 0.879115\ttraining's binary_logloss: 0.124711\tvalid_1's auc: 0.83559\tvalid_1's binary_logloss: 0.138214\n",
            "[66]\ttraining's auc: 0.879612\ttraining's binary_logloss: 0.1245\tvalid_1's auc: 0.835717\tvalid_1's binary_logloss: 0.138135\n",
            "[67]\ttraining's auc: 0.88001\ttraining's binary_logloss: 0.124301\tvalid_1's auc: 0.835779\tvalid_1's binary_logloss: 0.138044\n",
            "[68]\ttraining's auc: 0.880608\ttraining's binary_logloss: 0.124112\tvalid_1's auc: 0.836084\tvalid_1's binary_logloss: 0.137968\n",
            "[69]\ttraining's auc: 0.880887\ttraining's binary_logloss: 0.123932\tvalid_1's auc: 0.836064\tvalid_1's binary_logloss: 0.137905\n",
            "[70]\ttraining's auc: 0.881358\ttraining's binary_logloss: 0.123738\tvalid_1's auc: 0.836017\tvalid_1's binary_logloss: 0.137835\n",
            "[71]\ttraining's auc: 0.882067\ttraining's binary_logloss: 0.123525\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.137784\n",
            "[72]\ttraining's auc: 0.882712\ttraining's binary_logloss: 0.123345\tvalid_1's auc: 0.835926\tvalid_1's binary_logloss: 0.137725\n",
            "[73]\ttraining's auc: 0.882987\ttraining's binary_logloss: 0.123177\tvalid_1's auc: 0.836\tvalid_1's binary_logloss: 0.137666\n",
            "[74]\ttraining's auc: 0.883483\ttraining's binary_logloss: 0.123001\tvalid_1's auc: 0.836092\tvalid_1's binary_logloss: 0.137591\n",
            "[75]\ttraining's auc: 0.883936\ttraining's binary_logloss: 0.122824\tvalid_1's auc: 0.836189\tvalid_1's binary_logloss: 0.13751\n",
            "[76]\ttraining's auc: 0.884578\ttraining's binary_logloss: 0.122654\tvalid_1's auc: 0.836257\tvalid_1's binary_logloss: 0.137442\n",
            "[77]\ttraining's auc: 0.88485\ttraining's binary_logloss: 0.12249\tvalid_1's auc: 0.83637\tvalid_1's binary_logloss: 0.137375\n",
            "[78]\ttraining's auc: 0.885164\ttraining's binary_logloss: 0.122324\tvalid_1's auc: 0.836383\tvalid_1's binary_logloss: 0.137309\n",
            "[79]\ttraining's auc: 0.885779\ttraining's binary_logloss: 0.122145\tvalid_1's auc: 0.836379\tvalid_1's binary_logloss: 0.137262\n",
            "[80]\ttraining's auc: 0.886074\ttraining's binary_logloss: 0.12198\tvalid_1's auc: 0.836301\tvalid_1's binary_logloss: 0.137214\n",
            "[81]\ttraining's auc: 0.88662\ttraining's binary_logloss: 0.121809\tvalid_1's auc: 0.836568\tvalid_1's binary_logloss: 0.137164\n",
            "[82]\ttraining's auc: 0.886987\ttraining's binary_logloss: 0.121656\tvalid_1's auc: 0.8365\tvalid_1's binary_logloss: 0.137129\n",
            "[83]\ttraining's auc: 0.887295\ttraining's binary_logloss: 0.121502\tvalid_1's auc: 0.836549\tvalid_1's binary_logloss: 0.137079\n",
            "[84]\ttraining's auc: 0.887615\ttraining's binary_logloss: 0.121363\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.137038\n",
            "[85]\ttraining's auc: 0.88788\ttraining's binary_logloss: 0.121215\tvalid_1's auc: 0.836592\tvalid_1's binary_logloss: 0.136967\n",
            "[86]\ttraining's auc: 0.888151\ttraining's binary_logloss: 0.121069\tvalid_1's auc: 0.83659\tvalid_1's binary_logloss: 0.136938\n",
            "[87]\ttraining's auc: 0.888408\ttraining's binary_logloss: 0.120944\tvalid_1's auc: 0.836667\tvalid_1's binary_logloss: 0.136887\n",
            "[88]\ttraining's auc: 0.888805\ttraining's binary_logloss: 0.120783\tvalid_1's auc: 0.836703\tvalid_1's binary_logloss: 0.136865\n",
            "[89]\ttraining's auc: 0.889168\ttraining's binary_logloss: 0.120636\tvalid_1's auc: 0.836627\tvalid_1's binary_logloss: 0.136838\n",
            "[90]\ttraining's auc: 0.889433\ttraining's binary_logloss: 0.120506\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.136817\n",
            "[91]\ttraining's auc: 0.889684\ttraining's binary_logloss: 0.120362\tvalid_1's auc: 0.836591\tvalid_1's binary_logloss: 0.136793\n",
            "[92]\ttraining's auc: 0.89007\ttraining's binary_logloss: 0.120214\tvalid_1's auc: 0.836512\tvalid_1's binary_logloss: 0.136763\n",
            "[93]\ttraining's auc: 0.890489\ttraining's binary_logloss: 0.12007\tvalid_1's auc: 0.83661\tvalid_1's binary_logloss: 0.13673\n",
            "[94]\ttraining's auc: 0.890799\ttraining's binary_logloss: 0.119943\tvalid_1's auc: 0.836606\tvalid_1's binary_logloss: 0.136699\n",
            "[95]\ttraining's auc: 0.891054\ttraining's binary_logloss: 0.119819\tvalid_1's auc: 0.83657\tvalid_1's binary_logloss: 0.136683\n",
            "[96]\ttraining's auc: 0.891375\ttraining's binary_logloss: 0.119673\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.136644\n",
            "[97]\ttraining's auc: 0.891636\ttraining's binary_logloss: 0.119554\tvalid_1's auc: 0.836566\tvalid_1's binary_logloss: 0.136616\n",
            "[98]\ttraining's auc: 0.891893\ttraining's binary_logloss: 0.119436\tvalid_1's auc: 0.836468\tvalid_1's binary_logloss: 0.136606\n",
            "[99]\ttraining's auc: 0.892265\ttraining's binary_logloss: 0.119302\tvalid_1's auc: 0.836588\tvalid_1's binary_logloss: 0.136564\n",
            "[100]\ttraining's auc: 0.892537\ttraining's binary_logloss: 0.119184\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.136535\n",
            "[101]\ttraining's auc: 0.892852\ttraining's binary_logloss: 0.119058\tvalid_1's auc: 0.836584\tvalid_1's binary_logloss: 0.136508\n",
            "[102]\ttraining's auc: 0.893203\ttraining's binary_logloss: 0.118931\tvalid_1's auc: 0.836524\tvalid_1's binary_logloss: 0.136501\n",
            "[103]\ttraining's auc: 0.893642\ttraining's binary_logloss: 0.118797\tvalid_1's auc: 0.836544\tvalid_1's binary_logloss: 0.136478\n",
            "[104]\ttraining's auc: 0.893999\ttraining's binary_logloss: 0.118673\tvalid_1's auc: 0.836667\tvalid_1's binary_logloss: 0.136438\n",
            "[105]\ttraining's auc: 0.894215\ttraining's binary_logloss: 0.11857\tvalid_1's auc: 0.836716\tvalid_1's binary_logloss: 0.136412\n",
            "[106]\ttraining's auc: 0.894589\ttraining's binary_logloss: 0.118443\tvalid_1's auc: 0.836639\tvalid_1's binary_logloss: 0.136407\n",
            "[107]\ttraining's auc: 0.894862\ttraining's binary_logloss: 0.118322\tvalid_1's auc: 0.836553\tvalid_1's binary_logloss: 0.136398\n",
            "[108]\ttraining's auc: 0.895034\ttraining's binary_logloss: 0.118222\tvalid_1's auc: 0.836477\tvalid_1's binary_logloss: 0.136397\n",
            "[109]\ttraining's auc: 0.895512\ttraining's binary_logloss: 0.118111\tvalid_1's auc: 0.83641\tvalid_1's binary_logloss: 0.136396\n",
            "[110]\ttraining's auc: 0.895802\ttraining's binary_logloss: 0.117978\tvalid_1's auc: 0.836388\tvalid_1's binary_logloss: 0.136392\n",
            "[111]\ttraining's auc: 0.896161\ttraining's binary_logloss: 0.117867\tvalid_1's auc: 0.836338\tvalid_1's binary_logloss: 0.136369\n",
            "[112]\ttraining's auc: 0.89659\ttraining's binary_logloss: 0.117744\tvalid_1's auc: 0.836334\tvalid_1's binary_logloss: 0.136349\n",
            "[113]\ttraining's auc: 0.896917\ttraining's binary_logloss: 0.117632\tvalid_1's auc: 0.836354\tvalid_1's binary_logloss: 0.136338\n",
            "[114]\ttraining's auc: 0.89725\ttraining's binary_logloss: 0.117524\tvalid_1's auc: 0.836413\tvalid_1's binary_logloss: 0.136316\n",
            "[115]\ttraining's auc: 0.897647\ttraining's binary_logloss: 0.117396\tvalid_1's auc: 0.836258\tvalid_1's binary_logloss: 0.13631\n",
            "[116]\ttraining's auc: 0.897904\ttraining's binary_logloss: 0.117288\tvalid_1's auc: 0.836182\tvalid_1's binary_logloss: 0.136303\n",
            "[117]\ttraining's auc: 0.898368\ttraining's binary_logloss: 0.117177\tvalid_1's auc: 0.836116\tvalid_1's binary_logloss: 0.1363\n",
            "[118]\ttraining's auc: 0.898624\ttraining's binary_logloss: 0.117078\tvalid_1's auc: 0.836063\tvalid_1's binary_logloss: 0.136289\n",
            "[119]\ttraining's auc: 0.898866\ttraining's binary_logloss: 0.116985\tvalid_1's auc: 0.835998\tvalid_1's binary_logloss: 0.136284\n",
            "[120]\ttraining's auc: 0.899009\ttraining's binary_logloss: 0.116902\tvalid_1's auc: 0.835995\tvalid_1's binary_logloss: 0.136282\n",
            "[121]\ttraining's auc: 0.899209\ttraining's binary_logloss: 0.116792\tvalid_1's auc: 0.835962\tvalid_1's binary_logloss: 0.136275\n",
            "[122]\ttraining's auc: 0.899398\ttraining's binary_logloss: 0.116695\tvalid_1's auc: 0.835964\tvalid_1's binary_logloss: 0.136275\n",
            "[123]\ttraining's auc: 0.899714\ttraining's binary_logloss: 0.116578\tvalid_1's auc: 0.835988\tvalid_1's binary_logloss: 0.136257\n",
            "[124]\ttraining's auc: 0.900016\ttraining's binary_logloss: 0.116475\tvalid_1's auc: 0.836015\tvalid_1's binary_logloss: 0.136239\n",
            "[125]\ttraining's auc: 0.900318\ttraining's binary_logloss: 0.116383\tvalid_1's auc: 0.835965\tvalid_1's binary_logloss: 0.136239\n",
            "[126]\ttraining's auc: 0.900558\ttraining's binary_logloss: 0.116291\tvalid_1's auc: 0.83593\tvalid_1's binary_logloss: 0.136238\n",
            "[127]\ttraining's auc: 0.90064\ttraining's binary_logloss: 0.116203\tvalid_1's auc: 0.835821\tvalid_1's binary_logloss: 0.136244\n",
            "[128]\ttraining's auc: 0.90096\ttraining's binary_logloss: 0.116087\tvalid_1's auc: 0.835808\tvalid_1's binary_logloss: 0.136233\n",
            "[129]\ttraining's auc: 0.901272\ttraining's binary_logloss: 0.115978\tvalid_1's auc: 0.835806\tvalid_1's binary_logloss: 0.136229\n",
            "[130]\ttraining's auc: 0.901538\ttraining's binary_logloss: 0.115886\tvalid_1's auc: 0.835854\tvalid_1's binary_logloss: 0.136227\n",
            "[131]\ttraining's auc: 0.901874\ttraining's binary_logloss: 0.115789\tvalid_1's auc: 0.835617\tvalid_1's binary_logloss: 0.136233\n",
            "[132]\ttraining's auc: 0.90218\ttraining's binary_logloss: 0.11569\tvalid_1's auc: 0.835478\tvalid_1's binary_logloss: 0.136224\n",
            "[133]\ttraining's auc: 0.90242\ttraining's binary_logloss: 0.115601\tvalid_1's auc: 0.835472\tvalid_1's binary_logloss: 0.136227\n",
            "[134]\ttraining's auc: 0.902644\ttraining's binary_logloss: 0.11551\tvalid_1's auc: 0.835538\tvalid_1's binary_logloss: 0.136221\n",
            "[135]\ttraining's auc: 0.902808\ttraining's binary_logloss: 0.115424\tvalid_1's auc: 0.835535\tvalid_1's binary_logloss: 0.136217\n",
            " 40%|████      | 20/50 [09:21<13:25, 26.84s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.160849\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.16234\n",
            "[2]\ttraining's auc: 0.832436\ttraining's binary_logloss: 0.157792\tvalid_1's auc: 0.806997\tvalid_1's binary_logloss: 0.159924\n",
            "[3]\ttraining's auc: 0.834461\ttraining's binary_logloss: 0.155175\tvalid_1's auc: 0.807908\tvalid_1's binary_logloss: 0.157851\n",
            "[4]\ttraining's auc: 0.836364\ttraining's binary_logloss: 0.152941\tvalid_1's auc: 0.808681\tvalid_1's binary_logloss: 0.156045\n",
            "[5]\ttraining's auc: 0.83813\ttraining's binary_logloss: 0.150974\tvalid_1's auc: 0.810152\tvalid_1's binary_logloss: 0.15443\n",
            "[6]\ttraining's auc: 0.841381\ttraining's binary_logloss: 0.149212\tvalid_1's auc: 0.812069\tvalid_1's binary_logloss: 0.15304\n",
            "[7]\ttraining's auc: 0.844417\ttraining's binary_logloss: 0.147631\tvalid_1's auc: 0.814391\tvalid_1's binary_logloss: 0.151844\n",
            "[8]\ttraining's auc: 0.846197\ttraining's binary_logloss: 0.146179\tvalid_1's auc: 0.816541\tvalid_1's binary_logloss: 0.150782\n",
            "[9]\ttraining's auc: 0.847792\ttraining's binary_logloss: 0.144816\tvalid_1's auc: 0.818266\tvalid_1's binary_logloss: 0.149738\n",
            "[10]\ttraining's auc: 0.849021\ttraining's binary_logloss: 0.143542\tvalid_1's auc: 0.819073\tvalid_1's binary_logloss: 0.1488\n",
            "[11]\ttraining's auc: 0.85032\ttraining's binary_logloss: 0.142391\tvalid_1's auc: 0.819675\tvalid_1's binary_logloss: 0.147952\n",
            "[12]\ttraining's auc: 0.851402\ttraining's binary_logloss: 0.141319\tvalid_1's auc: 0.820906\tvalid_1's binary_logloss: 0.147165\n",
            "[13]\ttraining's auc: 0.853148\ttraining's binary_logloss: 0.14031\tvalid_1's auc: 0.821638\tvalid_1's binary_logloss: 0.14646\n",
            "[14]\ttraining's auc: 0.853831\ttraining's binary_logloss: 0.139366\tvalid_1's auc: 0.822011\tvalid_1's binary_logloss: 0.145819\n",
            "[15]\ttraining's auc: 0.854257\ttraining's binary_logloss: 0.138498\tvalid_1's auc: 0.822434\tvalid_1's binary_logloss: 0.145161\n",
            "[16]\ttraining's auc: 0.854874\ttraining's binary_logloss: 0.137647\tvalid_1's auc: 0.822499\tvalid_1's binary_logloss: 0.144596\n",
            "[17]\ttraining's auc: 0.857102\ttraining's binary_logloss: 0.136844\tvalid_1's auc: 0.823609\tvalid_1's binary_logloss: 0.144051\n",
            "[18]\ttraining's auc: 0.858209\ttraining's binary_logloss: 0.136071\tvalid_1's auc: 0.823633\tvalid_1's binary_logloss: 0.143606\n",
            "[19]\ttraining's auc: 0.858727\ttraining's binary_logloss: 0.135369\tvalid_1's auc: 0.823055\tvalid_1's binary_logloss: 0.143138\n",
            "[20]\ttraining's auc: 0.860256\ttraining's binary_logloss: 0.134718\tvalid_1's auc: 0.823927\tvalid_1's binary_logloss: 0.142695\n",
            "[21]\ttraining's auc: 0.860993\ttraining's binary_logloss: 0.134073\tvalid_1's auc: 0.82462\tvalid_1's binary_logloss: 0.142257\n",
            "[22]\ttraining's auc: 0.86177\ttraining's binary_logloss: 0.133474\tvalid_1's auc: 0.824907\tvalid_1's binary_logloss: 0.141842\n",
            "[23]\ttraining's auc: 0.862341\ttraining's binary_logloss: 0.1329\tvalid_1's auc: 0.824888\tvalid_1's binary_logloss: 0.141485\n",
            "[24]\ttraining's auc: 0.863613\ttraining's binary_logloss: 0.132355\tvalid_1's auc: 0.825306\tvalid_1's binary_logloss: 0.141145\n",
            "[25]\ttraining's auc: 0.86474\ttraining's binary_logloss: 0.131827\tvalid_1's auc: 0.825884\tvalid_1's binary_logloss: 0.140836\n",
            "[26]\ttraining's auc: 0.86535\ttraining's binary_logloss: 0.131296\tvalid_1's auc: 0.826083\tvalid_1's binary_logloss: 0.140542\n",
            "[27]\ttraining's auc: 0.86615\ttraining's binary_logloss: 0.130806\tvalid_1's auc: 0.82625\tvalid_1's binary_logloss: 0.140252\n",
            "[28]\ttraining's auc: 0.867715\ttraining's binary_logloss: 0.13034\tvalid_1's auc: 0.826796\tvalid_1's binary_logloss: 0.139966\n",
            "[29]\ttraining's auc: 0.868846\ttraining's binary_logloss: 0.129872\tvalid_1's auc: 0.827111\tvalid_1's binary_logloss: 0.139717\n",
            "[30]\ttraining's auc: 0.869336\ttraining's binary_logloss: 0.129455\tvalid_1's auc: 0.827123\tvalid_1's binary_logloss: 0.139524\n",
            "[31]\ttraining's auc: 0.869903\ttraining's binary_logloss: 0.129031\tvalid_1's auc: 0.827159\tvalid_1's binary_logloss: 0.139293\n",
            "[32]\ttraining's auc: 0.870469\ttraining's binary_logloss: 0.128638\tvalid_1's auc: 0.827132\tvalid_1's binary_logloss: 0.139121\n",
            "[33]\ttraining's auc: 0.871098\ttraining's binary_logloss: 0.128255\tvalid_1's auc: 0.827219\tvalid_1's binary_logloss: 0.138921\n",
            "[34]\ttraining's auc: 0.87147\ttraining's binary_logloss: 0.127911\tvalid_1's auc: 0.827429\tvalid_1's binary_logloss: 0.138721\n",
            "[35]\ttraining's auc: 0.872322\ttraining's binary_logloss: 0.127516\tvalid_1's auc: 0.827332\tvalid_1's binary_logloss: 0.138555\n",
            "[36]\ttraining's auc: 0.873087\ttraining's binary_logloss: 0.127139\tvalid_1's auc: 0.82747\tvalid_1's binary_logloss: 0.1384\n",
            "[37]\ttraining's auc: 0.873857\ttraining's binary_logloss: 0.126772\tvalid_1's auc: 0.827427\tvalid_1's binary_logloss: 0.138236\n",
            "[38]\ttraining's auc: 0.874893\ttraining's binary_logloss: 0.126431\tvalid_1's auc: 0.827534\tvalid_1's binary_logloss: 0.138122\n",
            "[39]\ttraining's auc: 0.87549\ttraining's binary_logloss: 0.126094\tvalid_1's auc: 0.827529\tvalid_1's binary_logloss: 0.137996\n",
            "[40]\ttraining's auc: 0.876801\ttraining's binary_logloss: 0.125765\tvalid_1's auc: 0.827456\tvalid_1's binary_logloss: 0.137892\n",
            "[41]\ttraining's auc: 0.87742\ttraining's binary_logloss: 0.12546\tvalid_1's auc: 0.827567\tvalid_1's binary_logloss: 0.137768\n",
            "[42]\ttraining's auc: 0.878473\ttraining's binary_logloss: 0.125154\tvalid_1's auc: 0.827549\tvalid_1's binary_logloss: 0.137667\n",
            "[43]\ttraining's auc: 0.879029\ttraining's binary_logloss: 0.124877\tvalid_1's auc: 0.827769\tvalid_1's binary_logloss: 0.137525\n",
            "[44]\ttraining's auc: 0.879486\ttraining's binary_logloss: 0.124587\tvalid_1's auc: 0.82786\tvalid_1's binary_logloss: 0.13741\n",
            "[45]\ttraining's auc: 0.880025\ttraining's binary_logloss: 0.124294\tvalid_1's auc: 0.828366\tvalid_1's binary_logloss: 0.137281\n",
            "[46]\ttraining's auc: 0.881038\ttraining's binary_logloss: 0.123995\tvalid_1's auc: 0.828393\tvalid_1's binary_logloss: 0.137196\n",
            "[47]\ttraining's auc: 0.882072\ttraining's binary_logloss: 0.123689\tvalid_1's auc: 0.828489\tvalid_1's binary_logloss: 0.137123\n",
            "[48]\ttraining's auc: 0.882704\ttraining's binary_logloss: 0.123422\tvalid_1's auc: 0.828245\tvalid_1's binary_logloss: 0.137072\n",
            "[49]\ttraining's auc: 0.883353\ttraining's binary_logloss: 0.123165\tvalid_1's auc: 0.828341\tvalid_1's binary_logloss: 0.136989\n",
            "[50]\ttraining's auc: 0.884254\ttraining's binary_logloss: 0.122887\tvalid_1's auc: 0.828869\tvalid_1's binary_logloss: 0.136882\n",
            "[51]\ttraining's auc: 0.884706\ttraining's binary_logloss: 0.122655\tvalid_1's auc: 0.828838\tvalid_1's binary_logloss: 0.136834\n",
            "[52]\ttraining's auc: 0.885184\ttraining's binary_logloss: 0.1224\tvalid_1's auc: 0.829321\tvalid_1's binary_logloss: 0.136736\n",
            "[53]\ttraining's auc: 0.885665\ttraining's binary_logloss: 0.122161\tvalid_1's auc: 0.829359\tvalid_1's binary_logloss: 0.136676\n",
            "[54]\ttraining's auc: 0.886022\ttraining's binary_logloss: 0.121942\tvalid_1's auc: 0.829249\tvalid_1's binary_logloss: 0.136639\n",
            "[55]\ttraining's auc: 0.886798\ttraining's binary_logloss: 0.121662\tvalid_1's auc: 0.82941\tvalid_1's binary_logloss: 0.136595\n",
            "[56]\ttraining's auc: 0.887387\ttraining's binary_logloss: 0.121428\tvalid_1's auc: 0.829395\tvalid_1's binary_logloss: 0.136552\n",
            "[57]\ttraining's auc: 0.888031\ttraining's binary_logloss: 0.1212\tvalid_1's auc: 0.829737\tvalid_1's binary_logloss: 0.136458\n",
            "[58]\ttraining's auc: 0.888486\ttraining's binary_logloss: 0.120989\tvalid_1's auc: 0.829697\tvalid_1's binary_logloss: 0.136416\n",
            "[59]\ttraining's auc: 0.889146\ttraining's binary_logloss: 0.12079\tvalid_1's auc: 0.829946\tvalid_1's binary_logloss: 0.136349\n",
            "[60]\ttraining's auc: 0.889705\ttraining's binary_logloss: 0.120568\tvalid_1's auc: 0.829995\tvalid_1's binary_logloss: 0.136291\n",
            "[61]\ttraining's auc: 0.890169\ttraining's binary_logloss: 0.120341\tvalid_1's auc: 0.829971\tvalid_1's binary_logloss: 0.136279\n",
            "[62]\ttraining's auc: 0.890487\ttraining's binary_logloss: 0.120138\tvalid_1's auc: 0.829977\tvalid_1's binary_logloss: 0.136254\n",
            "[63]\ttraining's auc: 0.891622\ttraining's binary_logloss: 0.119874\tvalid_1's auc: 0.830541\tvalid_1's binary_logloss: 0.13613\n",
            "[64]\ttraining's auc: 0.891946\ttraining's binary_logloss: 0.119675\tvalid_1's auc: 0.83049\tvalid_1's binary_logloss: 0.136101\n",
            "[65]\ttraining's auc: 0.892313\ttraining's binary_logloss: 0.119482\tvalid_1's auc: 0.830566\tvalid_1's binary_logloss: 0.13607\n",
            "[66]\ttraining's auc: 0.892646\ttraining's binary_logloss: 0.119317\tvalid_1's auc: 0.830481\tvalid_1's binary_logloss: 0.136031\n",
            "[67]\ttraining's auc: 0.893454\ttraining's binary_logloss: 0.119119\tvalid_1's auc: 0.830817\tvalid_1's binary_logloss: 0.135982\n",
            "[68]\ttraining's auc: 0.893847\ttraining's binary_logloss: 0.118932\tvalid_1's auc: 0.830932\tvalid_1's binary_logloss: 0.135949\n",
            "[69]\ttraining's auc: 0.894367\ttraining's binary_logloss: 0.11875\tvalid_1's auc: 0.830844\tvalid_1's binary_logloss: 0.13593\n",
            "[70]\ttraining's auc: 0.894913\ttraining's binary_logloss: 0.118556\tvalid_1's auc: 0.831038\tvalid_1's binary_logloss: 0.135881\n",
            "[71]\ttraining's auc: 0.895242\ttraining's binary_logloss: 0.118383\tvalid_1's auc: 0.831016\tvalid_1's binary_logloss: 0.135874\n",
            "[72]\ttraining's auc: 0.895623\ttraining's binary_logloss: 0.118232\tvalid_1's auc: 0.830963\tvalid_1's binary_logloss: 0.135865\n",
            "[73]\ttraining's auc: 0.896063\ttraining's binary_logloss: 0.118067\tvalid_1's auc: 0.831076\tvalid_1's binary_logloss: 0.135815\n",
            "[74]\ttraining's auc: 0.896377\ttraining's binary_logloss: 0.117897\tvalid_1's auc: 0.831091\tvalid_1's binary_logloss: 0.135797\n",
            "[75]\ttraining's auc: 0.896952\ttraining's binary_logloss: 0.117698\tvalid_1's auc: 0.8312\tvalid_1's binary_logloss: 0.135762\n",
            "[76]\ttraining's auc: 0.897495\ttraining's binary_logloss: 0.117519\tvalid_1's auc: 0.831195\tvalid_1's binary_logloss: 0.13576\n",
            "[77]\ttraining's auc: 0.897969\ttraining's binary_logloss: 0.117368\tvalid_1's auc: 0.83124\tvalid_1's binary_logloss: 0.135734\n",
            "[78]\ttraining's auc: 0.898197\ttraining's binary_logloss: 0.117211\tvalid_1's auc: 0.831302\tvalid_1's binary_logloss: 0.135718\n",
            "[79]\ttraining's auc: 0.898616\ttraining's binary_logloss: 0.117052\tvalid_1's auc: 0.831271\tvalid_1's binary_logloss: 0.135718\n",
            "[80]\ttraining's auc: 0.899521\ttraining's binary_logloss: 0.116857\tvalid_1's auc: 0.831464\tvalid_1's binary_logloss: 0.135665\n",
            "[81]\ttraining's auc: 0.899957\ttraining's binary_logloss: 0.116697\tvalid_1's auc: 0.831437\tvalid_1's binary_logloss: 0.135655\n",
            "[82]\ttraining's auc: 0.90025\ttraining's binary_logloss: 0.116543\tvalid_1's auc: 0.831263\tvalid_1's binary_logloss: 0.135672\n",
            "[83]\ttraining's auc: 0.900917\ttraining's binary_logloss: 0.116366\tvalid_1's auc: 0.831503\tvalid_1's binary_logloss: 0.135618\n",
            "[84]\ttraining's auc: 0.901365\ttraining's binary_logloss: 0.116193\tvalid_1's auc: 0.831326\tvalid_1's binary_logloss: 0.135645\n",
            "[85]\ttraining's auc: 0.901812\ttraining's binary_logloss: 0.116054\tvalid_1's auc: 0.831472\tvalid_1's binary_logloss: 0.135617\n",
            "[86]\ttraining's auc: 0.902067\ttraining's binary_logloss: 0.115916\tvalid_1's auc: 0.831353\tvalid_1's binary_logloss: 0.135638\n",
            "[87]\ttraining's auc: 0.902528\ttraining's binary_logloss: 0.115773\tvalid_1's auc: 0.831479\tvalid_1's binary_logloss: 0.135602\n",
            "[88]\ttraining's auc: 0.902796\ttraining's binary_logloss: 0.115645\tvalid_1's auc: 0.83146\tvalid_1's binary_logloss: 0.135617\n",
            "[89]\ttraining's auc: 0.9032\ttraining's binary_logloss: 0.115518\tvalid_1's auc: 0.831695\tvalid_1's binary_logloss: 0.135567\n",
            "[90]\ttraining's auc: 0.903689\ttraining's binary_logloss: 0.115338\tvalid_1's auc: 0.831695\tvalid_1's binary_logloss: 0.135567\n",
            "[91]\ttraining's auc: 0.904\ttraining's binary_logloss: 0.115207\tvalid_1's auc: 0.831666\tvalid_1's binary_logloss: 0.135578\n",
            "[92]\ttraining's auc: 0.904318\ttraining's binary_logloss: 0.115071\tvalid_1's auc: 0.831619\tvalid_1's binary_logloss: 0.135588\n",
            "[93]\ttraining's auc: 0.904708\ttraining's binary_logloss: 0.11495\tvalid_1's auc: 0.831497\tvalid_1's binary_logloss: 0.135607\n",
            "[94]\ttraining's auc: 0.904996\ttraining's binary_logloss: 0.114809\tvalid_1's auc: 0.831508\tvalid_1's binary_logloss: 0.135613\n",
            "[95]\ttraining's auc: 0.905255\ttraining's binary_logloss: 0.114686\tvalid_1's auc: 0.831523\tvalid_1's binary_logloss: 0.135617\n",
            "[96]\ttraining's auc: 0.905686\ttraining's binary_logloss: 0.114549\tvalid_1's auc: 0.83146\tvalid_1's binary_logloss: 0.135625\n",
            "[97]\ttraining's auc: 0.906084\ttraining's binary_logloss: 0.114384\tvalid_1's auc: 0.831287\tvalid_1's binary_logloss: 0.135635\n",
            "[98]\ttraining's auc: 0.906421\ttraining's binary_logloss: 0.114258\tvalid_1's auc: 0.831303\tvalid_1's binary_logloss: 0.135629\n",
            "[99]\ttraining's auc: 0.906696\ttraining's binary_logloss: 0.11412\tvalid_1's auc: 0.831385\tvalid_1's binary_logloss: 0.135607\n",
            "[100]\ttraining's auc: 0.907089\ttraining's binary_logloss: 0.113953\tvalid_1's auc: 0.831363\tvalid_1's binary_logloss: 0.135603\n",
            "[101]\ttraining's auc: 0.907417\ttraining's binary_logloss: 0.113811\tvalid_1's auc: 0.831452\tvalid_1's binary_logloss: 0.135593\n",
            "[102]\ttraining's auc: 0.907739\ttraining's binary_logloss: 0.113692\tvalid_1's auc: 0.83131\tvalid_1's binary_logloss: 0.13563\n",
            "[103]\ttraining's auc: 0.908049\ttraining's binary_logloss: 0.113547\tvalid_1's auc: 0.831163\tvalid_1's binary_logloss: 0.135665\n",
            "[104]\ttraining's auc: 0.908217\ttraining's binary_logloss: 0.11342\tvalid_1's auc: 0.831262\tvalid_1's binary_logloss: 0.135643\n",
            "[105]\ttraining's auc: 0.908596\ttraining's binary_logloss: 0.113298\tvalid_1's auc: 0.83122\tvalid_1's binary_logloss: 0.135659\n",
            "[106]\ttraining's auc: 0.908973\ttraining's binary_logloss: 0.11317\tvalid_1's auc: 0.831156\tvalid_1's binary_logloss: 0.135678\n",
            "[107]\ttraining's auc: 0.909319\ttraining's binary_logloss: 0.113033\tvalid_1's auc: 0.831088\tvalid_1's binary_logloss: 0.135694\n",
            "[108]\ttraining's auc: 0.909628\ttraining's binary_logloss: 0.112872\tvalid_1's auc: 0.83103\tvalid_1's binary_logloss: 0.135701\n",
            "[109]\ttraining's auc: 0.909854\ttraining's binary_logloss: 0.112742\tvalid_1's auc: 0.831048\tvalid_1's binary_logloss: 0.135699\n",
            "[110]\ttraining's auc: 0.910026\ttraining's binary_logloss: 0.112638\tvalid_1's auc: 0.831042\tvalid_1's binary_logloss: 0.135721\n",
            "[111]\ttraining's auc: 0.910329\ttraining's binary_logloss: 0.112528\tvalid_1's auc: 0.830957\tvalid_1's binary_logloss: 0.135737\n",
            "[112]\ttraining's auc: 0.910688\ttraining's binary_logloss: 0.112377\tvalid_1's auc: 0.830955\tvalid_1's binary_logloss: 0.135741\n",
            "[113]\ttraining's auc: 0.911404\ttraining's binary_logloss: 0.112224\tvalid_1's auc: 0.830792\tvalid_1's binary_logloss: 0.135763\n",
            "[114]\ttraining's auc: 0.911825\ttraining's binary_logloss: 0.112074\tvalid_1's auc: 0.830644\tvalid_1's binary_logloss: 0.135797\n",
            "[115]\ttraining's auc: 0.911989\ttraining's binary_logloss: 0.111968\tvalid_1's auc: 0.830578\tvalid_1's binary_logloss: 0.135799\n",
            "[116]\ttraining's auc: 0.912485\ttraining's binary_logloss: 0.111809\tvalid_1's auc: 0.830682\tvalid_1's binary_logloss: 0.135793\n",
            "[117]\ttraining's auc: 0.912789\ttraining's binary_logloss: 0.11167\tvalid_1's auc: 0.830602\tvalid_1's binary_logloss: 0.135808\n",
            "[118]\ttraining's auc: 0.91302\ttraining's binary_logloss: 0.111554\tvalid_1's auc: 0.830673\tvalid_1's binary_logloss: 0.135809\n",
            "[119]\ttraining's auc: 0.913259\ttraining's binary_logloss: 0.11144\tvalid_1's auc: 0.830539\tvalid_1's binary_logloss: 0.135834\n",
            " 40%|████      | 20/50 [09:33<13:25, 26.84s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.163236\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.157876\n",
            "[2]\ttraining's auc: 0.822974\ttraining's binary_logloss: 0.16024\tvalid_1's auc: 0.804261\tvalid_1's binary_logloss: 0.155462\n",
            "[3]\ttraining's auc: 0.8297\ttraining's binary_logloss: 0.157625\tvalid_1's auc: 0.816671\tvalid_1's binary_logloss: 0.153344\n",
            "[4]\ttraining's auc: 0.833781\ttraining's binary_logloss: 0.155333\tvalid_1's auc: 0.818408\tvalid_1's binary_logloss: 0.151596\n",
            "[5]\ttraining's auc: 0.834911\ttraining's binary_logloss: 0.153341\tvalid_1's auc: 0.819067\tvalid_1's binary_logloss: 0.15\n",
            "[6]\ttraining's auc: 0.835511\ttraining's binary_logloss: 0.151569\tvalid_1's auc: 0.819767\tvalid_1's binary_logloss: 0.148539\n",
            "[7]\ttraining's auc: 0.837434\ttraining's binary_logloss: 0.149939\tvalid_1's auc: 0.820917\tvalid_1's binary_logloss: 0.147296\n",
            "[8]\ttraining's auc: 0.841105\ttraining's binary_logloss: 0.148453\tvalid_1's auc: 0.82324\tvalid_1's binary_logloss: 0.146192\n",
            "[9]\ttraining's auc: 0.841522\ttraining's binary_logloss: 0.147099\tvalid_1's auc: 0.823472\tvalid_1's binary_logloss: 0.145182\n",
            "[10]\ttraining's auc: 0.845422\ttraining's binary_logloss: 0.145818\tvalid_1's auc: 0.825732\tvalid_1's binary_logloss: 0.144241\n",
            "[11]\ttraining's auc: 0.848338\ttraining's binary_logloss: 0.144629\tvalid_1's auc: 0.827999\tvalid_1's binary_logloss: 0.143381\n",
            "[12]\ttraining's auc: 0.849608\ttraining's binary_logloss: 0.14355\tvalid_1's auc: 0.828445\tvalid_1's binary_logloss: 0.142581\n",
            "[13]\ttraining's auc: 0.851261\ttraining's binary_logloss: 0.142519\tvalid_1's auc: 0.828936\tvalid_1's binary_logloss: 0.141835\n",
            "[14]\ttraining's auc: 0.852869\ttraining's binary_logloss: 0.141572\tvalid_1's auc: 0.829658\tvalid_1's binary_logloss: 0.141128\n",
            "[15]\ttraining's auc: 0.853851\ttraining's binary_logloss: 0.140663\tvalid_1's auc: 0.830175\tvalid_1's binary_logloss: 0.140472\n",
            "[16]\ttraining's auc: 0.855003\ttraining's binary_logloss: 0.139805\tvalid_1's auc: 0.830754\tvalid_1's binary_logloss: 0.139834\n",
            "[17]\ttraining's auc: 0.857098\ttraining's binary_logloss: 0.139035\tvalid_1's auc: 0.832648\tvalid_1's binary_logloss: 0.139299\n",
            "[18]\ttraining's auc: 0.858199\ttraining's binary_logloss: 0.138274\tvalid_1's auc: 0.832751\tvalid_1's binary_logloss: 0.138769\n",
            "[19]\ttraining's auc: 0.859177\ttraining's binary_logloss: 0.137556\tvalid_1's auc: 0.832891\tvalid_1's binary_logloss: 0.138295\n",
            "[20]\ttraining's auc: 0.859805\ttraining's binary_logloss: 0.136876\tvalid_1's auc: 0.832619\tvalid_1's binary_logloss: 0.137861\n",
            "[21]\ttraining's auc: 0.861172\ttraining's binary_logloss: 0.136185\tvalid_1's auc: 0.832412\tvalid_1's binary_logloss: 0.137453\n",
            "[22]\ttraining's auc: 0.86164\ttraining's binary_logloss: 0.135579\tvalid_1's auc: 0.832423\tvalid_1's binary_logloss: 0.137051\n",
            "[23]\ttraining's auc: 0.861873\ttraining's binary_logloss: 0.134991\tvalid_1's auc: 0.832405\tvalid_1's binary_logloss: 0.136694\n",
            "[24]\ttraining's auc: 0.863344\ttraining's binary_logloss: 0.134399\tvalid_1's auc: 0.833044\tvalid_1's binary_logloss: 0.136353\n",
            "[25]\ttraining's auc: 0.865485\ttraining's binary_logloss: 0.133811\tvalid_1's auc: 0.833186\tvalid_1's binary_logloss: 0.136029\n",
            "[26]\ttraining's auc: 0.866534\ttraining's binary_logloss: 0.133282\tvalid_1's auc: 0.83383\tvalid_1's binary_logloss: 0.135705\n",
            "[27]\ttraining's auc: 0.867724\ttraining's binary_logloss: 0.132754\tvalid_1's auc: 0.834181\tvalid_1's binary_logloss: 0.13542\n",
            "[28]\ttraining's auc: 0.869216\ttraining's binary_logloss: 0.132246\tvalid_1's auc: 0.834126\tvalid_1's binary_logloss: 0.135179\n",
            "[29]\ttraining's auc: 0.870322\ttraining's binary_logloss: 0.13177\tvalid_1's auc: 0.834814\tvalid_1's binary_logloss: 0.134912\n",
            "[30]\ttraining's auc: 0.871149\ttraining's binary_logloss: 0.131316\tvalid_1's auc: 0.834681\tvalid_1's binary_logloss: 0.134685\n",
            "[31]\ttraining's auc: 0.871957\ttraining's binary_logloss: 0.130893\tvalid_1's auc: 0.835121\tvalid_1's binary_logloss: 0.13445\n",
            "[32]\ttraining's auc: 0.872315\ttraining's binary_logloss: 0.130495\tvalid_1's auc: 0.834839\tvalid_1's binary_logloss: 0.134254\n",
            "[33]\ttraining's auc: 0.872945\ttraining's binary_logloss: 0.130113\tvalid_1's auc: 0.83491\tvalid_1's binary_logloss: 0.134062\n",
            "[34]\ttraining's auc: 0.873768\ttraining's binary_logloss: 0.129723\tvalid_1's auc: 0.834888\tvalid_1's binary_logloss: 0.133865\n",
            "[35]\ttraining's auc: 0.874294\ttraining's binary_logloss: 0.129365\tvalid_1's auc: 0.834936\tvalid_1's binary_logloss: 0.13369\n",
            "[36]\ttraining's auc: 0.874766\ttraining's binary_logloss: 0.128993\tvalid_1's auc: 0.834774\tvalid_1's binary_logloss: 0.133535\n",
            "[37]\ttraining's auc: 0.875304\ttraining's binary_logloss: 0.128654\tvalid_1's auc: 0.835124\tvalid_1's binary_logloss: 0.133339\n",
            "[38]\ttraining's auc: 0.875856\ttraining's binary_logloss: 0.128297\tvalid_1's auc: 0.835052\tvalid_1's binary_logloss: 0.133198\n",
            "[39]\ttraining's auc: 0.876282\ttraining's binary_logloss: 0.127966\tvalid_1's auc: 0.83512\tvalid_1's binary_logloss: 0.133069\n",
            "[40]\ttraining's auc: 0.876576\ttraining's binary_logloss: 0.127647\tvalid_1's auc: 0.834822\tvalid_1's binary_logloss: 0.132973\n",
            "[41]\ttraining's auc: 0.877934\ttraining's binary_logloss: 0.127326\tvalid_1's auc: 0.83555\tvalid_1's binary_logloss: 0.132854\n",
            "[42]\ttraining's auc: 0.878506\ttraining's binary_logloss: 0.127018\tvalid_1's auc: 0.835224\tvalid_1's binary_logloss: 0.132744\n",
            "[43]\ttraining's auc: 0.879009\ttraining's binary_logloss: 0.126667\tvalid_1's auc: 0.835213\tvalid_1's binary_logloss: 0.132645\n",
            "[44]\ttraining's auc: 0.879659\ttraining's binary_logloss: 0.126367\tvalid_1's auc: 0.835052\tvalid_1's binary_logloss: 0.132543\n",
            "[45]\ttraining's auc: 0.880603\ttraining's binary_logloss: 0.126049\tvalid_1's auc: 0.835213\tvalid_1's binary_logloss: 0.132435\n",
            "[46]\ttraining's auc: 0.880963\ttraining's binary_logloss: 0.125768\tvalid_1's auc: 0.835112\tvalid_1's binary_logloss: 0.13235\n",
            "[47]\ttraining's auc: 0.881403\ttraining's binary_logloss: 0.125489\tvalid_1's auc: 0.835292\tvalid_1's binary_logloss: 0.13225\n",
            "[48]\ttraining's auc: 0.881765\ttraining's binary_logloss: 0.125214\tvalid_1's auc: 0.835117\tvalid_1's binary_logloss: 0.132184\n",
            "[49]\ttraining's auc: 0.882638\ttraining's binary_logloss: 0.124933\tvalid_1's auc: 0.835188\tvalid_1's binary_logloss: 0.132077\n",
            "[50]\ttraining's auc: 0.882998\ttraining's binary_logloss: 0.124703\tvalid_1's auc: 0.834989\tvalid_1's binary_logloss: 0.132023\n",
            "[51]\ttraining's auc: 0.883502\ttraining's binary_logloss: 0.124446\tvalid_1's auc: 0.835087\tvalid_1's binary_logloss: 0.131939\n",
            "[52]\ttraining's auc: 0.884151\ttraining's binary_logloss: 0.124181\tvalid_1's auc: 0.835168\tvalid_1's binary_logloss: 0.131873\n",
            "[53]\ttraining's auc: 0.885033\ttraining's binary_logloss: 0.123937\tvalid_1's auc: 0.835366\tvalid_1's binary_logloss: 0.131805\n",
            "[54]\ttraining's auc: 0.885399\ttraining's binary_logloss: 0.123706\tvalid_1's auc: 0.835523\tvalid_1's binary_logloss: 0.131732\n",
            "[55]\ttraining's auc: 0.886091\ttraining's binary_logloss: 0.123433\tvalid_1's auc: 0.835566\tvalid_1's binary_logloss: 0.13167\n",
            "[56]\ttraining's auc: 0.886336\ttraining's binary_logloss: 0.123227\tvalid_1's auc: 0.835592\tvalid_1's binary_logloss: 0.131614\n",
            "[57]\ttraining's auc: 0.886761\ttraining's binary_logloss: 0.123006\tvalid_1's auc: 0.835711\tvalid_1's binary_logloss: 0.131558\n",
            "[58]\ttraining's auc: 0.88749\ttraining's binary_logloss: 0.122773\tvalid_1's auc: 0.835813\tvalid_1's binary_logloss: 0.131507\n",
            "[59]\ttraining's auc: 0.887758\ttraining's binary_logloss: 0.122571\tvalid_1's auc: 0.835663\tvalid_1's binary_logloss: 0.131472\n",
            "[60]\ttraining's auc: 0.888264\ttraining's binary_logloss: 0.122349\tvalid_1's auc: 0.835599\tvalid_1's binary_logloss: 0.131425\n",
            "[61]\ttraining's auc: 0.888802\ttraining's binary_logloss: 0.12215\tvalid_1's auc: 0.835592\tvalid_1's binary_logloss: 0.13138\n",
            "[62]\ttraining's auc: 0.889231\ttraining's binary_logloss: 0.121973\tvalid_1's auc: 0.83602\tvalid_1's binary_logloss: 0.131356\n",
            "[63]\ttraining's auc: 0.889729\ttraining's binary_logloss: 0.121753\tvalid_1's auc: 0.83604\tvalid_1's binary_logloss: 0.131325\n",
            "[64]\ttraining's auc: 0.889926\ttraining's binary_logloss: 0.121574\tvalid_1's auc: 0.835887\tvalid_1's binary_logloss: 0.131318\n",
            "[65]\ttraining's auc: 0.891001\ttraining's binary_logloss: 0.121342\tvalid_1's auc: 0.835941\tvalid_1's binary_logloss: 0.131281\n",
            "[66]\ttraining's auc: 0.891358\ttraining's binary_logloss: 0.121141\tvalid_1's auc: 0.836062\tvalid_1's binary_logloss: 0.131243\n",
            "[67]\ttraining's auc: 0.891823\ttraining's binary_logloss: 0.120936\tvalid_1's auc: 0.836198\tvalid_1's binary_logloss: 0.131182\n",
            "[68]\ttraining's auc: 0.892528\ttraining's binary_logloss: 0.120737\tvalid_1's auc: 0.836187\tvalid_1's binary_logloss: 0.131163\n",
            "[69]\ttraining's auc: 0.892881\ttraining's binary_logloss: 0.120569\tvalid_1's auc: 0.836336\tvalid_1's binary_logloss: 0.13114\n",
            "[70]\ttraining's auc: 0.893184\ttraining's binary_logloss: 0.120393\tvalid_1's auc: 0.836424\tvalid_1's binary_logloss: 0.131085\n",
            "[71]\ttraining's auc: 0.893624\ttraining's binary_logloss: 0.120218\tvalid_1's auc: 0.836369\tvalid_1's binary_logloss: 0.131069\n",
            "[72]\ttraining's auc: 0.894192\ttraining's binary_logloss: 0.120029\tvalid_1's auc: 0.83679\tvalid_1's binary_logloss: 0.131011\n",
            "[73]\ttraining's auc: 0.894517\ttraining's binary_logloss: 0.11987\tvalid_1's auc: 0.836753\tvalid_1's binary_logloss: 0.130986\n",
            "[74]\ttraining's auc: 0.895159\ttraining's binary_logloss: 0.119652\tvalid_1's auc: 0.836757\tvalid_1's binary_logloss: 0.130965\n",
            "[75]\ttraining's auc: 0.895676\ttraining's binary_logloss: 0.119486\tvalid_1's auc: 0.836707\tvalid_1's binary_logloss: 0.13095\n",
            "[76]\ttraining's auc: 0.896034\ttraining's binary_logloss: 0.119314\tvalid_1's auc: 0.836743\tvalid_1's binary_logloss: 0.130918\n",
            "[77]\ttraining's auc: 0.89657\ttraining's binary_logloss: 0.119159\tvalid_1's auc: 0.836732\tvalid_1's binary_logloss: 0.130903\n",
            "[78]\ttraining's auc: 0.896868\ttraining's binary_logloss: 0.119007\tvalid_1's auc: 0.8368\tvalid_1's binary_logloss: 0.13087\n",
            "[79]\ttraining's auc: 0.897485\ttraining's binary_logloss: 0.118836\tvalid_1's auc: 0.836819\tvalid_1's binary_logloss: 0.130845\n",
            "[80]\ttraining's auc: 0.897738\ttraining's binary_logloss: 0.118678\tvalid_1's auc: 0.836769\tvalid_1's binary_logloss: 0.13083\n",
            "[81]\ttraining's auc: 0.898087\ttraining's binary_logloss: 0.118515\tvalid_1's auc: 0.836832\tvalid_1's binary_logloss: 0.130815\n",
            "[82]\ttraining's auc: 0.89876\ttraining's binary_logloss: 0.118325\tvalid_1's auc: 0.836894\tvalid_1's binary_logloss: 0.130781\n",
            "[83]\ttraining's auc: 0.899129\ttraining's binary_logloss: 0.118193\tvalid_1's auc: 0.836912\tvalid_1's binary_logloss: 0.130772\n",
            "[84]\ttraining's auc: 0.89963\ttraining's binary_logloss: 0.11803\tvalid_1's auc: 0.837017\tvalid_1's binary_logloss: 0.130745\n",
            "[85]\ttraining's auc: 0.900532\ttraining's binary_logloss: 0.117819\tvalid_1's auc: 0.836931\tvalid_1's binary_logloss: 0.130745\n",
            "[86]\ttraining's auc: 0.901274\ttraining's binary_logloss: 0.117632\tvalid_1's auc: 0.836841\tvalid_1's binary_logloss: 0.130727\n",
            "[87]\ttraining's auc: 0.90199\ttraining's binary_logloss: 0.117457\tvalid_1's auc: 0.836967\tvalid_1's binary_logloss: 0.130706\n",
            "[88]\ttraining's auc: 0.902408\ttraining's binary_logloss: 0.117318\tvalid_1's auc: 0.83696\tvalid_1's binary_logloss: 0.1307\n",
            "[89]\ttraining's auc: 0.902865\ttraining's binary_logloss: 0.117138\tvalid_1's auc: 0.836884\tvalid_1's binary_logloss: 0.130695\n",
            "[90]\ttraining's auc: 0.903224\ttraining's binary_logloss: 0.117017\tvalid_1's auc: 0.836877\tvalid_1's binary_logloss: 0.130691\n",
            "[91]\ttraining's auc: 0.903644\ttraining's binary_logloss: 0.11687\tvalid_1's auc: 0.836911\tvalid_1's binary_logloss: 0.130681\n",
            "[92]\ttraining's auc: 0.903862\ttraining's binary_logloss: 0.116734\tvalid_1's auc: 0.836948\tvalid_1's binary_logloss: 0.130669\n",
            "[93]\ttraining's auc: 0.904205\ttraining's binary_logloss: 0.116577\tvalid_1's auc: 0.836862\tvalid_1's binary_logloss: 0.130676\n",
            "[94]\ttraining's auc: 0.904519\ttraining's binary_logloss: 0.116451\tvalid_1's auc: 0.836795\tvalid_1's binary_logloss: 0.130671\n",
            "[95]\ttraining's auc: 0.904735\ttraining's binary_logloss: 0.116342\tvalid_1's auc: 0.836875\tvalid_1's binary_logloss: 0.130659\n",
            "[96]\ttraining's auc: 0.905364\ttraining's binary_logloss: 0.116165\tvalid_1's auc: 0.836858\tvalid_1's binary_logloss: 0.130655\n",
            "[97]\ttraining's auc: 0.90597\ttraining's binary_logloss: 0.116016\tvalid_1's auc: 0.836737\tvalid_1's binary_logloss: 0.130674\n",
            "[98]\ttraining's auc: 0.906266\ttraining's binary_logloss: 0.115902\tvalid_1's auc: 0.83675\tvalid_1's binary_logloss: 0.130669\n",
            "[99]\ttraining's auc: 0.906579\ttraining's binary_logloss: 0.115755\tvalid_1's auc: 0.836799\tvalid_1's binary_logloss: 0.130652\n",
            "[100]\ttraining's auc: 0.906826\ttraining's binary_logloss: 0.115649\tvalid_1's auc: 0.836763\tvalid_1's binary_logloss: 0.130663\n",
            "[101]\ttraining's auc: 0.907221\ttraining's binary_logloss: 0.115492\tvalid_1's auc: 0.836608\tvalid_1's binary_logloss: 0.130686\n",
            "[102]\ttraining's auc: 0.90748\ttraining's binary_logloss: 0.115385\tvalid_1's auc: 0.836663\tvalid_1's binary_logloss: 0.130682\n",
            "[103]\ttraining's auc: 0.907911\ttraining's binary_logloss: 0.115218\tvalid_1's auc: 0.836747\tvalid_1's binary_logloss: 0.130665\n",
            "[104]\ttraining's auc: 0.90811\ttraining's binary_logloss: 0.115094\tvalid_1's auc: 0.836849\tvalid_1's binary_logloss: 0.130634\n",
            "[105]\ttraining's auc: 0.90855\ttraining's binary_logloss: 0.114948\tvalid_1's auc: 0.836778\tvalid_1's binary_logloss: 0.130628\n",
            "[106]\ttraining's auc: 0.908856\ttraining's binary_logloss: 0.114791\tvalid_1's auc: 0.836919\tvalid_1's binary_logloss: 0.130601\n",
            "[107]\ttraining's auc: 0.909284\ttraining's binary_logloss: 0.114621\tvalid_1's auc: 0.836963\tvalid_1's binary_logloss: 0.130596\n",
            "[108]\ttraining's auc: 0.909537\ttraining's binary_logloss: 0.114486\tvalid_1's auc: 0.837009\tvalid_1's binary_logloss: 0.130584\n",
            "[109]\ttraining's auc: 0.909781\ttraining's binary_logloss: 0.114355\tvalid_1's auc: 0.837018\tvalid_1's binary_logloss: 0.130575\n",
            "[110]\ttraining's auc: 0.909994\ttraining's binary_logloss: 0.114269\tvalid_1's auc: 0.837034\tvalid_1's binary_logloss: 0.130567\n",
            "[111]\ttraining's auc: 0.91025\ttraining's binary_logloss: 0.114132\tvalid_1's auc: 0.837044\tvalid_1's binary_logloss: 0.130566\n",
            "[112]\ttraining's auc: 0.910415\ttraining's binary_logloss: 0.114011\tvalid_1's auc: 0.837031\tvalid_1's binary_logloss: 0.130561\n",
            "[113]\ttraining's auc: 0.910622\ttraining's binary_logloss: 0.113881\tvalid_1's auc: 0.837053\tvalid_1's binary_logloss: 0.130559\n",
            "[114]\ttraining's auc: 0.910856\ttraining's binary_logloss: 0.113765\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.130557\n",
            "[115]\ttraining's auc: 0.91097\ttraining's binary_logloss: 0.113685\tvalid_1's auc: 0.836969\tvalid_1's binary_logloss: 0.130561\n",
            "[116]\ttraining's auc: 0.911328\ttraining's binary_logloss: 0.113552\tvalid_1's auc: 0.837046\tvalid_1's binary_logloss: 0.130562\n",
            "[117]\ttraining's auc: 0.911636\ttraining's binary_logloss: 0.113418\tvalid_1's auc: 0.837085\tvalid_1's binary_logloss: 0.13056\n",
            "[118]\ttraining's auc: 0.91203\ttraining's binary_logloss: 0.113301\tvalid_1's auc: 0.837114\tvalid_1's binary_logloss: 0.130547\n",
            "[119]\ttraining's auc: 0.91218\ttraining's binary_logloss: 0.113195\tvalid_1's auc: 0.837201\tvalid_1's binary_logloss: 0.130531\n",
            "[120]\ttraining's auc: 0.912347\ttraining's binary_logloss: 0.113092\tvalid_1's auc: 0.837225\tvalid_1's binary_logloss: 0.130531\n",
            "[121]\ttraining's auc: 0.912702\ttraining's binary_logloss: 0.112963\tvalid_1's auc: 0.837157\tvalid_1's binary_logloss: 0.130533\n",
            "[122]\ttraining's auc: 0.912897\ttraining's binary_logloss: 0.112848\tvalid_1's auc: 0.837062\tvalid_1's binary_logloss: 0.130544\n",
            "[123]\ttraining's auc: 0.913125\ttraining's binary_logloss: 0.112742\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.130564\n",
            "[124]\ttraining's auc: 0.91342\ttraining's binary_logloss: 0.112614\tvalid_1's auc: 0.837039\tvalid_1's binary_logloss: 0.130565\n",
            "[125]\ttraining's auc: 0.913692\ttraining's binary_logloss: 0.112506\tvalid_1's auc: 0.836965\tvalid_1's binary_logloss: 0.130574\n",
            "[126]\ttraining's auc: 0.913854\ttraining's binary_logloss: 0.112412\tvalid_1's auc: 0.836864\tvalid_1's binary_logloss: 0.130594\n",
            "[127]\ttraining's auc: 0.914565\ttraining's binary_logloss: 0.112242\tvalid_1's auc: 0.836833\tvalid_1's binary_logloss: 0.130587\n",
            "[128]\ttraining's auc: 0.914725\ttraining's binary_logloss: 0.11215\tvalid_1's auc: 0.836797\tvalid_1's binary_logloss: 0.130597\n",
            "[129]\ttraining's auc: 0.915044\ttraining's binary_logloss: 0.112017\tvalid_1's auc: 0.836774\tvalid_1's binary_logloss: 0.130609\n",
            "[130]\ttraining's auc: 0.915225\ttraining's binary_logloss: 0.111926\tvalid_1's auc: 0.83684\tvalid_1's binary_logloss: 0.13061\n",
            "[131]\ttraining's auc: 0.915417\ttraining's binary_logloss: 0.111828\tvalid_1's auc: 0.836736\tvalid_1's binary_logloss: 0.13062\n",
            "[132]\ttraining's auc: 0.915586\ttraining's binary_logloss: 0.111727\tvalid_1's auc: 0.836729\tvalid_1's binary_logloss: 0.130616\n",
            "[133]\ttraining's auc: 0.915798\ttraining's binary_logloss: 0.111611\tvalid_1's auc: 0.83671\tvalid_1's binary_logloss: 0.130632\n",
            "[134]\ttraining's auc: 0.915981\ttraining's binary_logloss: 0.111504\tvalid_1's auc: 0.836709\tvalid_1's binary_logloss: 0.130624\n",
            "[135]\ttraining's auc: 0.916102\ttraining's binary_logloss: 0.111422\tvalid_1's auc: 0.836654\tvalid_1's binary_logloss: 0.130627\n",
            "[136]\ttraining's auc: 0.916315\ttraining's binary_logloss: 0.111323\tvalid_1's auc: 0.83668\tvalid_1's binary_logloss: 0.130625\n",
            "[137]\ttraining's auc: 0.91653\ttraining's binary_logloss: 0.111226\tvalid_1's auc: 0.836687\tvalid_1's binary_logloss: 0.130622\n",
            "[138]\ttraining's auc: 0.916823\ttraining's binary_logloss: 0.111135\tvalid_1's auc: 0.836687\tvalid_1's binary_logloss: 0.130621\n",
            "[139]\ttraining's auc: 0.916976\ttraining's binary_logloss: 0.111053\tvalid_1's auc: 0.83665\tvalid_1's binary_logloss: 0.130637\n",
            "[140]\ttraining's auc: 0.917125\ttraining's binary_logloss: 0.110962\tvalid_1's auc: 0.836693\tvalid_1's binary_logloss: 0.13061\n",
            "[141]\ttraining's auc: 0.917199\ttraining's binary_logloss: 0.11089\tvalid_1's auc: 0.836629\tvalid_1's binary_logloss: 0.130616\n",
            "[142]\ttraining's auc: 0.917407\ttraining's binary_logloss: 0.110781\tvalid_1's auc: 0.836673\tvalid_1's binary_logloss: 0.130601\n",
            "[143]\ttraining's auc: 0.917729\ttraining's binary_logloss: 0.110669\tvalid_1's auc: 0.836706\tvalid_1's binary_logloss: 0.130595\n",
            "[144]\ttraining's auc: 0.917902\ttraining's binary_logloss: 0.110594\tvalid_1's auc: 0.836654\tvalid_1's binary_logloss: 0.1306\n",
            "[145]\ttraining's auc: 0.918137\ttraining's binary_logloss: 0.110511\tvalid_1's auc: 0.836596\tvalid_1's binary_logloss: 0.130615\n",
            "[146]\ttraining's auc: 0.918235\ttraining's binary_logloss: 0.110436\tvalid_1's auc: 0.836551\tvalid_1's binary_logloss: 0.130606\n",
            "[147]\ttraining's auc: 0.918455\ttraining's binary_logloss: 0.110317\tvalid_1's auc: 0.836552\tvalid_1's binary_logloss: 0.130589\n",
            "[148]\ttraining's auc: 0.918688\ttraining's binary_logloss: 0.110226\tvalid_1's auc: 0.836634\tvalid_1's binary_logloss: 0.130587\n",
            "[149]\ttraining's auc: 0.918853\ttraining's binary_logloss: 0.110139\tvalid_1's auc: 0.836663\tvalid_1's binary_logloss: 0.130575\n",
            "[150]\ttraining's auc: 0.919038\ttraining's binary_logloss: 0.110048\tvalid_1's auc: 0.836782\tvalid_1's binary_logloss: 0.130557\n",
            " 40%|████      | 20/50 [09:48<13:25, 26.84s/trial, best loss: -0.8350732491983806]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.159601\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.165341\n",
            "[2]\ttraining's auc: 0.830951\ttraining's binary_logloss: 0.156672\tvalid_1's auc: 0.816285\tvalid_1's binary_logloss: 0.162666\n",
            "[3]\ttraining's auc: 0.832249\ttraining's binary_logloss: 0.15419\tvalid_1's auc: 0.814785\tvalid_1's binary_logloss: 0.160556\n",
            "[4]\ttraining's auc: 0.834407\ttraining's binary_logloss: 0.15202\tvalid_1's auc: 0.816241\tvalid_1's binary_logloss: 0.158585\n",
            "[5]\ttraining's auc: 0.837108\ttraining's binary_logloss: 0.150075\tvalid_1's auc: 0.818404\tvalid_1's binary_logloss: 0.156884\n",
            "[6]\ttraining's auc: 0.838595\ttraining's binary_logloss: 0.148311\tvalid_1's auc: 0.818399\tvalid_1's binary_logloss: 0.155391\n",
            "[7]\ttraining's auc: 0.840363\ttraining's binary_logloss: 0.146783\tvalid_1's auc: 0.818552\tvalid_1's binary_logloss: 0.154103\n",
            "[8]\ttraining's auc: 0.846476\ttraining's binary_logloss: 0.145267\tvalid_1's auc: 0.823284\tvalid_1's binary_logloss: 0.152834\n",
            "[9]\ttraining's auc: 0.848775\ttraining's binary_logloss: 0.143931\tvalid_1's auc: 0.82561\tvalid_1's binary_logloss: 0.151657\n",
            "[10]\ttraining's auc: 0.850666\ttraining's binary_logloss: 0.142723\tvalid_1's auc: 0.827354\tvalid_1's binary_logloss: 0.15059\n",
            "[11]\ttraining's auc: 0.851413\ttraining's binary_logloss: 0.141613\tvalid_1's auc: 0.827535\tvalid_1's binary_logloss: 0.149664\n",
            "[12]\ttraining's auc: 0.85161\ttraining's binary_logloss: 0.140556\tvalid_1's auc: 0.828256\tvalid_1's binary_logloss: 0.14876\n",
            "[13]\ttraining's auc: 0.852293\ttraining's binary_logloss: 0.139579\tvalid_1's auc: 0.828589\tvalid_1's binary_logloss: 0.147952\n",
            "[14]\ttraining's auc: 0.853502\ttraining's binary_logloss: 0.138598\tvalid_1's auc: 0.829537\tvalid_1's binary_logloss: 0.147203\n",
            "[15]\ttraining's auc: 0.854193\ttraining's binary_logloss: 0.137687\tvalid_1's auc: 0.82954\tvalid_1's binary_logloss: 0.146522\n",
            "[16]\ttraining's auc: 0.856016\ttraining's binary_logloss: 0.136861\tvalid_1's auc: 0.829997\tvalid_1's binary_logloss: 0.145885\n",
            "[17]\ttraining's auc: 0.856668\ttraining's binary_logloss: 0.136073\tvalid_1's auc: 0.830129\tvalid_1's binary_logloss: 0.145303\n",
            "[18]\ttraining's auc: 0.857329\ttraining's binary_logloss: 0.135351\tvalid_1's auc: 0.830963\tvalid_1's binary_logloss: 0.144727\n",
            "[19]\ttraining's auc: 0.857907\ttraining's binary_logloss: 0.134658\tvalid_1's auc: 0.830634\tvalid_1's binary_logloss: 0.144201\n",
            "[20]\ttraining's auc: 0.85899\ttraining's binary_logloss: 0.134005\tvalid_1's auc: 0.830826\tvalid_1's binary_logloss: 0.143702\n",
            "[21]\ttraining's auc: 0.859678\ttraining's binary_logloss: 0.133382\tvalid_1's auc: 0.831013\tvalid_1's binary_logloss: 0.143251\n",
            "[22]\ttraining's auc: 0.860196\ttraining's binary_logloss: 0.132798\tvalid_1's auc: 0.830944\tvalid_1's binary_logloss: 0.14284\n",
            "[23]\ttraining's auc: 0.861817\ttraining's binary_logloss: 0.132216\tvalid_1's auc: 0.831408\tvalid_1's binary_logloss: 0.14242\n",
            "[24]\ttraining's auc: 0.863039\ttraining's binary_logloss: 0.131651\tvalid_1's auc: 0.831357\tvalid_1's binary_logloss: 0.142094\n",
            "[25]\ttraining's auc: 0.863684\ttraining's binary_logloss: 0.131128\tvalid_1's auc: 0.831365\tvalid_1's binary_logloss: 0.141782\n",
            "[26]\ttraining's auc: 0.86449\ttraining's binary_logloss: 0.130629\tvalid_1's auc: 0.831563\tvalid_1's binary_logloss: 0.141457\n",
            "[27]\ttraining's auc: 0.866029\ttraining's binary_logloss: 0.130145\tvalid_1's auc: 0.831891\tvalid_1's binary_logloss: 0.141152\n",
            "[28]\ttraining's auc: 0.867272\ttraining's binary_logloss: 0.129673\tvalid_1's auc: 0.832008\tvalid_1's binary_logloss: 0.140882\n",
            "[29]\ttraining's auc: 0.868557\ttraining's binary_logloss: 0.129219\tvalid_1's auc: 0.832085\tvalid_1's binary_logloss: 0.140626\n",
            "[30]\ttraining's auc: 0.868983\ttraining's binary_logloss: 0.128779\tvalid_1's auc: 0.832142\tvalid_1's binary_logloss: 0.140383\n",
            "[31]\ttraining's auc: 0.87051\ttraining's binary_logloss: 0.128368\tvalid_1's auc: 0.834049\tvalid_1's binary_logloss: 0.140132\n",
            "[32]\ttraining's auc: 0.871562\ttraining's binary_logloss: 0.127942\tvalid_1's auc: 0.833946\tvalid_1's binary_logloss: 0.139947\n",
            "[33]\ttraining's auc: 0.87262\ttraining's binary_logloss: 0.127551\tvalid_1's auc: 0.834488\tvalid_1's binary_logloss: 0.139734\n",
            "[34]\ttraining's auc: 0.873035\ttraining's binary_logloss: 0.127158\tvalid_1's auc: 0.834591\tvalid_1's binary_logloss: 0.139534\n",
            "[35]\ttraining's auc: 0.87376\ttraining's binary_logloss: 0.126774\tvalid_1's auc: 0.83465\tvalid_1's binary_logloss: 0.139363\n",
            "[36]\ttraining's auc: 0.874608\ttraining's binary_logloss: 0.126425\tvalid_1's auc: 0.834999\tvalid_1's binary_logloss: 0.13918\n",
            "[37]\ttraining's auc: 0.875243\ttraining's binary_logloss: 0.126085\tvalid_1's auc: 0.835025\tvalid_1's binary_logloss: 0.139038\n",
            "[38]\ttraining's auc: 0.87585\ttraining's binary_logloss: 0.125729\tvalid_1's auc: 0.83499\tvalid_1's binary_logloss: 0.138888\n",
            "[39]\ttraining's auc: 0.876635\ttraining's binary_logloss: 0.125373\tvalid_1's auc: 0.835309\tvalid_1's binary_logloss: 0.138719\n",
            "[40]\ttraining's auc: 0.87698\ttraining's binary_logloss: 0.125069\tvalid_1's auc: 0.835337\tvalid_1's binary_logloss: 0.138543\n",
            "[41]\ttraining's auc: 0.878251\ttraining's binary_logloss: 0.124733\tvalid_1's auc: 0.835238\tvalid_1's binary_logloss: 0.138418\n",
            "[42]\ttraining's auc: 0.879697\ttraining's binary_logloss: 0.124394\tvalid_1's auc: 0.835558\tvalid_1's binary_logloss: 0.13827\n",
            "[43]\ttraining's auc: 0.880415\ttraining's binary_logloss: 0.124091\tvalid_1's auc: 0.835664\tvalid_1's binary_logloss: 0.138147\n",
            "[44]\ttraining's auc: 0.8812\ttraining's binary_logloss: 0.123804\tvalid_1's auc: 0.83631\tvalid_1's binary_logloss: 0.138008\n",
            "[45]\ttraining's auc: 0.881732\ttraining's binary_logloss: 0.123516\tvalid_1's auc: 0.836413\tvalid_1's binary_logloss: 0.137892\n",
            "[46]\ttraining's auc: 0.882056\ttraining's binary_logloss: 0.123256\tvalid_1's auc: 0.836594\tvalid_1's binary_logloss: 0.137752\n",
            "[47]\ttraining's auc: 0.883481\ttraining's binary_logloss: 0.122957\tvalid_1's auc: 0.836385\tvalid_1's binary_logloss: 0.137656\n",
            "[48]\ttraining's auc: 0.884073\ttraining's binary_logloss: 0.122702\tvalid_1's auc: 0.836387\tvalid_1's binary_logloss: 0.137537\n",
            "[49]\ttraining's auc: 0.88469\ttraining's binary_logloss: 0.122421\tvalid_1's auc: 0.836477\tvalid_1's binary_logloss: 0.137436\n",
            "[50]\ttraining's auc: 0.885276\ttraining's binary_logloss: 0.122158\tvalid_1's auc: 0.836299\tvalid_1's binary_logloss: 0.137359\n",
            "[51]\ttraining's auc: 0.886066\ttraining's binary_logloss: 0.121866\tvalid_1's auc: 0.836095\tvalid_1's binary_logloss: 0.137336\n",
            "[52]\ttraining's auc: 0.886658\ttraining's binary_logloss: 0.12161\tvalid_1's auc: 0.836581\tvalid_1's binary_logloss: 0.13722\n",
            "[53]\ttraining's auc: 0.887351\ttraining's binary_logloss: 0.121357\tvalid_1's auc: 0.836539\tvalid_1's binary_logloss: 0.137154\n",
            "[54]\ttraining's auc: 0.887944\ttraining's binary_logloss: 0.12109\tvalid_1's auc: 0.836752\tvalid_1's binary_logloss: 0.13709\n",
            "[55]\ttraining's auc: 0.88842\ttraining's binary_logloss: 0.120849\tvalid_1's auc: 0.836906\tvalid_1's binary_logloss: 0.136994\n",
            "[56]\ttraining's auc: 0.888941\ttraining's binary_logloss: 0.120632\tvalid_1's auc: 0.837051\tvalid_1's binary_logloss: 0.136909\n",
            "[57]\ttraining's auc: 0.889383\ttraining's binary_logloss: 0.120397\tvalid_1's auc: 0.836845\tvalid_1's binary_logloss: 0.136885\n",
            "[58]\ttraining's auc: 0.889866\ttraining's binary_logloss: 0.120205\tvalid_1's auc: 0.836735\tvalid_1's binary_logloss: 0.13685\n",
            "[59]\ttraining's auc: 0.890339\ttraining's binary_logloss: 0.11999\tvalid_1's auc: 0.836826\tvalid_1's binary_logloss: 0.136776\n",
            "[60]\ttraining's auc: 0.890766\ttraining's binary_logloss: 0.119795\tvalid_1's auc: 0.836767\tvalid_1's binary_logloss: 0.136753\n",
            "[61]\ttraining's auc: 0.891293\ttraining's binary_logloss: 0.119579\tvalid_1's auc: 0.836999\tvalid_1's binary_logloss: 0.136683\n",
            "[62]\ttraining's auc: 0.891814\ttraining's binary_logloss: 0.119357\tvalid_1's auc: 0.837098\tvalid_1's binary_logloss: 0.136651\n",
            "[63]\ttraining's auc: 0.892357\ttraining's binary_logloss: 0.11913\tvalid_1's auc: 0.836901\tvalid_1's binary_logloss: 0.136625\n",
            "[64]\ttraining's auc: 0.892948\ttraining's binary_logloss: 0.118939\tvalid_1's auc: 0.836726\tvalid_1's binary_logloss: 0.136622\n",
            "[65]\ttraining's auc: 0.893342\ttraining's binary_logloss: 0.118766\tvalid_1's auc: 0.836793\tvalid_1's binary_logloss: 0.136589\n",
            "[66]\ttraining's auc: 0.893928\ttraining's binary_logloss: 0.118587\tvalid_1's auc: 0.836821\tvalid_1's binary_logloss: 0.136554\n",
            "[67]\ttraining's auc: 0.894494\ttraining's binary_logloss: 0.118376\tvalid_1's auc: 0.836837\tvalid_1's binary_logloss: 0.136532\n",
            "[68]\ttraining's auc: 0.894842\ttraining's binary_logloss: 0.118205\tvalid_1's auc: 0.836751\tvalid_1's binary_logloss: 0.136525\n",
            "[69]\ttraining's auc: 0.895439\ttraining's binary_logloss: 0.117981\tvalid_1's auc: 0.836854\tvalid_1's binary_logloss: 0.136497\n",
            "[70]\ttraining's auc: 0.895997\ttraining's binary_logloss: 0.117798\tvalid_1's auc: 0.83691\tvalid_1's binary_logloss: 0.136469\n",
            "[71]\ttraining's auc: 0.896552\ttraining's binary_logloss: 0.117611\tvalid_1's auc: 0.836829\tvalid_1's binary_logloss: 0.136457\n",
            "[72]\ttraining's auc: 0.896858\ttraining's binary_logloss: 0.11746\tvalid_1's auc: 0.836759\tvalid_1's binary_logloss: 0.136438\n",
            "[73]\ttraining's auc: 0.897297\ttraining's binary_logloss: 0.117299\tvalid_1's auc: 0.836661\tvalid_1's binary_logloss: 0.136442\n",
            "[74]\ttraining's auc: 0.897753\ttraining's binary_logloss: 0.117131\tvalid_1's auc: 0.836553\tvalid_1's binary_logloss: 0.136419\n",
            "[75]\ttraining's auc: 0.898302\ttraining's binary_logloss: 0.116926\tvalid_1's auc: 0.836406\tvalid_1's binary_logloss: 0.136417\n",
            "[76]\ttraining's auc: 0.89866\ttraining's binary_logloss: 0.116757\tvalid_1's auc: 0.836426\tvalid_1's binary_logloss: 0.136396\n",
            "[77]\ttraining's auc: 0.899078\ttraining's binary_logloss: 0.116587\tvalid_1's auc: 0.836387\tvalid_1's binary_logloss: 0.136382\n",
            "[78]\ttraining's auc: 0.899544\ttraining's binary_logloss: 0.116416\tvalid_1's auc: 0.83624\tvalid_1's binary_logloss: 0.136383\n",
            "[79]\ttraining's auc: 0.899949\ttraining's binary_logloss: 0.116251\tvalid_1's auc: 0.836397\tvalid_1's binary_logloss: 0.136355\n",
            "[80]\ttraining's auc: 0.900397\ttraining's binary_logloss: 0.116091\tvalid_1's auc: 0.836378\tvalid_1's binary_logloss: 0.136343\n",
            "[81]\ttraining's auc: 0.900709\ttraining's binary_logloss: 0.115955\tvalid_1's auc: 0.836305\tvalid_1's binary_logloss: 0.136334\n",
            "[82]\ttraining's auc: 0.900935\ttraining's binary_logloss: 0.115827\tvalid_1's auc: 0.836341\tvalid_1's binary_logloss: 0.13632\n",
            "[83]\ttraining's auc: 0.90131\ttraining's binary_logloss: 0.115694\tvalid_1's auc: 0.836276\tvalid_1's binary_logloss: 0.136312\n",
            "[84]\ttraining's auc: 0.901819\ttraining's binary_logloss: 0.115551\tvalid_1's auc: 0.835983\tvalid_1's binary_logloss: 0.13632\n",
            "[85]\ttraining's auc: 0.902332\ttraining's binary_logloss: 0.115415\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.136321\n",
            "[86]\ttraining's auc: 0.902579\ttraining's binary_logloss: 0.115303\tvalid_1's auc: 0.836036\tvalid_1's binary_logloss: 0.136287\n",
            "[87]\ttraining's auc: 0.903019\ttraining's binary_logloss: 0.115154\tvalid_1's auc: 0.836022\tvalid_1's binary_logloss: 0.136288\n",
            "[88]\ttraining's auc: 0.903533\ttraining's binary_logloss: 0.115\tvalid_1's auc: 0.836118\tvalid_1's binary_logloss: 0.136273\n",
            "[89]\ttraining's auc: 0.90403\ttraining's binary_logloss: 0.114844\tvalid_1's auc: 0.836082\tvalid_1's binary_logloss: 0.13628\n",
            "[90]\ttraining's auc: 0.904371\ttraining's binary_logloss: 0.114682\tvalid_1's auc: 0.83608\tvalid_1's binary_logloss: 0.136276\n",
            "[91]\ttraining's auc: 0.904621\ttraining's binary_logloss: 0.114529\tvalid_1's auc: 0.83611\tvalid_1's binary_logloss: 0.136264\n",
            "[92]\ttraining's auc: 0.904985\ttraining's binary_logloss: 0.114356\tvalid_1's auc: 0.836103\tvalid_1's binary_logloss: 0.136287\n",
            " 42%|████▏     | 21/50 [09:59<14:36, 30.24s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.156862\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.159057\n",
            "[2]\ttraining's auc: 0.833093\ttraining's binary_logloss: 0.151791\tvalid_1's auc: 0.806272\tvalid_1's binary_logloss: 0.155093\n",
            "[3]\ttraining's auc: 0.838273\ttraining's binary_logloss: 0.147963\tvalid_1's auc: 0.809703\tvalid_1's binary_logloss: 0.152209\n",
            "[4]\ttraining's auc: 0.842794\ttraining's binary_logloss: 0.144873\tvalid_1's auc: 0.812293\tvalid_1's binary_logloss: 0.149925\n",
            "[5]\ttraining's auc: 0.847185\ttraining's binary_logloss: 0.142247\tvalid_1's auc: 0.816464\tvalid_1's binary_logloss: 0.147964\n",
            "[6]\ttraining's auc: 0.851619\ttraining's binary_logloss: 0.140059\tvalid_1's auc: 0.820169\tvalid_1's binary_logloss: 0.146345\n",
            "[7]\ttraining's auc: 0.853211\ttraining's binary_logloss: 0.138112\tvalid_1's auc: 0.820424\tvalid_1's binary_logloss: 0.145039\n",
            "[8]\ttraining's auc: 0.854745\ttraining's binary_logloss: 0.136423\tvalid_1's auc: 0.82098\tvalid_1's binary_logloss: 0.143798\n",
            "[9]\ttraining's auc: 0.856549\ttraining's binary_logloss: 0.134974\tvalid_1's auc: 0.821187\tvalid_1's binary_logloss: 0.142906\n",
            "[10]\ttraining's auc: 0.858355\ttraining's binary_logloss: 0.133671\tvalid_1's auc: 0.822013\tvalid_1's binary_logloss: 0.142037\n",
            "[11]\ttraining's auc: 0.861793\ttraining's binary_logloss: 0.132393\tvalid_1's auc: 0.822264\tvalid_1's binary_logloss: 0.141348\n",
            "[12]\ttraining's auc: 0.862936\ttraining's binary_logloss: 0.131262\tvalid_1's auc: 0.823558\tvalid_1's binary_logloss: 0.140726\n",
            "[13]\ttraining's auc: 0.865508\ttraining's binary_logloss: 0.130316\tvalid_1's auc: 0.825408\tvalid_1's binary_logloss: 0.140125\n",
            "[14]\ttraining's auc: 0.867832\ttraining's binary_logloss: 0.129351\tvalid_1's auc: 0.826293\tvalid_1's binary_logloss: 0.139644\n",
            "[15]\ttraining's auc: 0.869884\ttraining's binary_logloss: 0.128437\tvalid_1's auc: 0.827219\tvalid_1's binary_logloss: 0.139089\n",
            "[16]\ttraining's auc: 0.871104\ttraining's binary_logloss: 0.127657\tvalid_1's auc: 0.827576\tvalid_1's binary_logloss: 0.138748\n",
            "[17]\ttraining's auc: 0.872535\ttraining's binary_logloss: 0.126879\tvalid_1's auc: 0.827736\tvalid_1's binary_logloss: 0.138369\n",
            "[18]\ttraining's auc: 0.874053\ttraining's binary_logloss: 0.126131\tvalid_1's auc: 0.827548\tvalid_1's binary_logloss: 0.138116\n",
            "[19]\ttraining's auc: 0.875423\ttraining's binary_logloss: 0.12551\tvalid_1's auc: 0.827766\tvalid_1's binary_logloss: 0.137836\n",
            "[20]\ttraining's auc: 0.876807\ttraining's binary_logloss: 0.124879\tvalid_1's auc: 0.827904\tvalid_1's binary_logloss: 0.137608\n",
            "[21]\ttraining's auc: 0.879054\ttraining's binary_logloss: 0.124249\tvalid_1's auc: 0.82793\tvalid_1's binary_logloss: 0.137462\n",
            "[22]\ttraining's auc: 0.879869\ttraining's binary_logloss: 0.123713\tvalid_1's auc: 0.828498\tvalid_1's binary_logloss: 0.137213\n",
            "[23]\ttraining's auc: 0.880584\ttraining's binary_logloss: 0.123201\tvalid_1's auc: 0.828722\tvalid_1's binary_logloss: 0.137034\n",
            "[24]\ttraining's auc: 0.881718\ttraining's binary_logloss: 0.122671\tvalid_1's auc: 0.828664\tvalid_1's binary_logloss: 0.136886\n",
            "[25]\ttraining's auc: 0.883393\ttraining's binary_logloss: 0.122127\tvalid_1's auc: 0.82854\tvalid_1's binary_logloss: 0.136763\n",
            "[26]\ttraining's auc: 0.885\ttraining's binary_logloss: 0.121557\tvalid_1's auc: 0.828601\tvalid_1's binary_logloss: 0.136674\n",
            "[27]\ttraining's auc: 0.886231\ttraining's binary_logloss: 0.121154\tvalid_1's auc: 0.829054\tvalid_1's binary_logloss: 0.136564\n",
            "[28]\ttraining's auc: 0.887389\ttraining's binary_logloss: 0.120651\tvalid_1's auc: 0.828927\tvalid_1's binary_logloss: 0.136532\n",
            "[29]\ttraining's auc: 0.889202\ttraining's binary_logloss: 0.120146\tvalid_1's auc: 0.829778\tvalid_1's binary_logloss: 0.136366\n",
            "[30]\ttraining's auc: 0.889977\ttraining's binary_logloss: 0.119755\tvalid_1's auc: 0.830259\tvalid_1's binary_logloss: 0.136307\n",
            "[31]\ttraining's auc: 0.890837\ttraining's binary_logloss: 0.11936\tvalid_1's auc: 0.829657\tvalid_1's binary_logloss: 0.136374\n",
            "[32]\ttraining's auc: 0.893336\ttraining's binary_logloss: 0.118789\tvalid_1's auc: 0.830338\tvalid_1's binary_logloss: 0.136143\n",
            "[33]\ttraining's auc: 0.894682\ttraining's binary_logloss: 0.118323\tvalid_1's auc: 0.830256\tvalid_1's binary_logloss: 0.136104\n",
            "[34]\ttraining's auc: 0.895908\ttraining's binary_logloss: 0.117952\tvalid_1's auc: 0.830446\tvalid_1's binary_logloss: 0.136041\n",
            "[35]\ttraining's auc: 0.897093\ttraining's binary_logloss: 0.117572\tvalid_1's auc: 0.830542\tvalid_1's binary_logloss: 0.135995\n",
            "[36]\ttraining's auc: 0.897746\ttraining's binary_logloss: 0.117226\tvalid_1's auc: 0.830468\tvalid_1's binary_logloss: 0.135986\n",
            "[37]\ttraining's auc: 0.898711\ttraining's binary_logloss: 0.11684\tvalid_1's auc: 0.830388\tvalid_1's binary_logloss: 0.135953\n",
            "[38]\ttraining's auc: 0.899248\ttraining's binary_logloss: 0.11655\tvalid_1's auc: 0.830223\tvalid_1's binary_logloss: 0.135978\n",
            "[39]\ttraining's auc: 0.899988\ttraining's binary_logloss: 0.116221\tvalid_1's auc: 0.830656\tvalid_1's binary_logloss: 0.135912\n",
            "[40]\ttraining's auc: 0.901028\ttraining's binary_logloss: 0.115885\tvalid_1's auc: 0.830499\tvalid_1's binary_logloss: 0.13592\n",
            "[41]\ttraining's auc: 0.901726\ttraining's binary_logloss: 0.115595\tvalid_1's auc: 0.830475\tvalid_1's binary_logloss: 0.135939\n",
            "[42]\ttraining's auc: 0.903206\ttraining's binary_logloss: 0.115231\tvalid_1's auc: 0.831184\tvalid_1's binary_logloss: 0.13584\n",
            "[43]\ttraining's auc: 0.903958\ttraining's binary_logloss: 0.114926\tvalid_1's auc: 0.831313\tvalid_1's binary_logloss: 0.13582\n",
            "[44]\ttraining's auc: 0.904496\ttraining's binary_logloss: 0.114654\tvalid_1's auc: 0.831244\tvalid_1's binary_logloss: 0.135793\n",
            "[45]\ttraining's auc: 0.905566\ttraining's binary_logloss: 0.11428\tvalid_1's auc: 0.831245\tvalid_1's binary_logloss: 0.135785\n",
            "[46]\ttraining's auc: 0.90648\ttraining's binary_logloss: 0.113979\tvalid_1's auc: 0.831159\tvalid_1's binary_logloss: 0.135802\n",
            "[47]\ttraining's auc: 0.906976\ttraining's binary_logloss: 0.113698\tvalid_1's auc: 0.831024\tvalid_1's binary_logloss: 0.135819\n",
            "[48]\ttraining's auc: 0.907905\ttraining's binary_logloss: 0.11334\tvalid_1's auc: 0.831134\tvalid_1's binary_logloss: 0.135776\n",
            "[49]\ttraining's auc: 0.908516\ttraining's binary_logloss: 0.113079\tvalid_1's auc: 0.831117\tvalid_1's binary_logloss: 0.135757\n",
            "[50]\ttraining's auc: 0.909711\ttraining's binary_logloss: 0.112713\tvalid_1's auc: 0.830749\tvalid_1's binary_logloss: 0.135842\n",
            "[51]\ttraining's auc: 0.910356\ttraining's binary_logloss: 0.112401\tvalid_1's auc: 0.830775\tvalid_1's binary_logloss: 0.135825\n",
            "[52]\ttraining's auc: 0.910871\ttraining's binary_logloss: 0.112181\tvalid_1's auc: 0.830437\tvalid_1's binary_logloss: 0.135871\n",
            "[53]\ttraining's auc: 0.9112\ttraining's binary_logloss: 0.111935\tvalid_1's auc: 0.830311\tvalid_1's binary_logloss: 0.135914\n",
            "[54]\ttraining's auc: 0.91182\ttraining's binary_logloss: 0.111638\tvalid_1's auc: 0.830122\tvalid_1's binary_logloss: 0.135978\n",
            "[55]\ttraining's auc: 0.912506\ttraining's binary_logloss: 0.111359\tvalid_1's auc: 0.830328\tvalid_1's binary_logloss: 0.135966\n",
            "[56]\ttraining's auc: 0.913137\ttraining's binary_logloss: 0.111108\tvalid_1's auc: 0.830005\tvalid_1's binary_logloss: 0.136029\n",
            "[57]\ttraining's auc: 0.913735\ttraining's binary_logloss: 0.1109\tvalid_1's auc: 0.829744\tvalid_1's binary_logloss: 0.136064\n",
            "[58]\ttraining's auc: 0.914233\ttraining's binary_logloss: 0.110697\tvalid_1's auc: 0.829457\tvalid_1's binary_logloss: 0.136114\n",
            "[59]\ttraining's auc: 0.914806\ttraining's binary_logloss: 0.110471\tvalid_1's auc: 0.829389\tvalid_1's binary_logloss: 0.136143\n",
            "[60]\ttraining's auc: 0.915261\ttraining's binary_logloss: 0.110254\tvalid_1's auc: 0.82916\tvalid_1's binary_logloss: 0.136188\n",
            "[61]\ttraining's auc: 0.915553\ttraining's binary_logloss: 0.110081\tvalid_1's auc: 0.828855\tvalid_1's binary_logloss: 0.136217\n",
            "[62]\ttraining's auc: 0.916416\ttraining's binary_logloss: 0.109878\tvalid_1's auc: 0.828849\tvalid_1's binary_logloss: 0.136221\n",
            "[63]\ttraining's auc: 0.916857\ttraining's binary_logloss: 0.109664\tvalid_1's auc: 0.828307\tvalid_1's binary_logloss: 0.136321\n",
            "[64]\ttraining's auc: 0.917573\ttraining's binary_logloss: 0.109399\tvalid_1's auc: 0.828212\tvalid_1's binary_logloss: 0.136365\n",
            "[65]\ttraining's auc: 0.918169\ttraining's binary_logloss: 0.109151\tvalid_1's auc: 0.828338\tvalid_1's binary_logloss: 0.136373\n",
            "[66]\ttraining's auc: 0.918435\ttraining's binary_logloss: 0.108986\tvalid_1's auc: 0.82815\tvalid_1's binary_logloss: 0.136402\n",
            "[67]\ttraining's auc: 0.919156\ttraining's binary_logloss: 0.108699\tvalid_1's auc: 0.82828\tvalid_1's binary_logloss: 0.13635\n",
            "[68]\ttraining's auc: 0.920041\ttraining's binary_logloss: 0.108467\tvalid_1's auc: 0.82823\tvalid_1's binary_logloss: 0.13637\n",
            "[69]\ttraining's auc: 0.920805\ttraining's binary_logloss: 0.108211\tvalid_1's auc: 0.828135\tvalid_1's binary_logloss: 0.136407\n",
            "[70]\ttraining's auc: 0.921003\ttraining's binary_logloss: 0.108059\tvalid_1's auc: 0.827948\tvalid_1's binary_logloss: 0.136458\n",
            "[71]\ttraining's auc: 0.92138\ttraining's binary_logloss: 0.107842\tvalid_1's auc: 0.827905\tvalid_1's binary_logloss: 0.13647\n",
            "[72]\ttraining's auc: 0.921613\ttraining's binary_logloss: 0.107655\tvalid_1's auc: 0.827853\tvalid_1's binary_logloss: 0.136503\n",
            "[73]\ttraining's auc: 0.922162\ttraining's binary_logloss: 0.107416\tvalid_1's auc: 0.827752\tvalid_1's binary_logloss: 0.136528\n",
            " 42%|████▏     | 21/50 [10:06<14:36, 30.24s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.159274\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.154871\n",
            "[2]\ttraining's auc: 0.826975\ttraining's binary_logloss: 0.154123\tvalid_1's auc: 0.815772\tvalid_1's binary_logloss: 0.150941\n",
            "[3]\ttraining's auc: 0.833441\ttraining's binary_logloss: 0.150189\tvalid_1's auc: 0.818232\tvalid_1's binary_logloss: 0.147877\n",
            "[4]\ttraining's auc: 0.840059\ttraining's binary_logloss: 0.147006\tvalid_1's auc: 0.822253\tvalid_1's binary_logloss: 0.145514\n",
            "[5]\ttraining's auc: 0.845222\ttraining's binary_logloss: 0.144402\tvalid_1's auc: 0.826273\tvalid_1's binary_logloss: 0.143502\n",
            "[6]\ttraining's auc: 0.850043\ttraining's binary_logloss: 0.142114\tvalid_1's auc: 0.829851\tvalid_1's binary_logloss: 0.141801\n",
            "[7]\ttraining's auc: 0.852582\ttraining's binary_logloss: 0.140179\tvalid_1's auc: 0.830422\tvalid_1's binary_logloss: 0.140403\n",
            "[8]\ttraining's auc: 0.854792\ttraining's binary_logloss: 0.138425\tvalid_1's auc: 0.83077\tvalid_1's binary_logloss: 0.139216\n",
            "[9]\ttraining's auc: 0.857104\ttraining's binary_logloss: 0.136896\tvalid_1's auc: 0.831773\tvalid_1's binary_logloss: 0.138175\n",
            "[10]\ttraining's auc: 0.858261\ttraining's binary_logloss: 0.135549\tvalid_1's auc: 0.831669\tvalid_1's binary_logloss: 0.137314\n",
            "[11]\ttraining's auc: 0.861492\ttraining's binary_logloss: 0.134259\tvalid_1's auc: 0.832807\tvalid_1's binary_logloss: 0.136585\n",
            "[12]\ttraining's auc: 0.863988\ttraining's binary_logloss: 0.133081\tvalid_1's auc: 0.832907\tvalid_1's binary_logloss: 0.135905\n",
            "[13]\ttraining's auc: 0.867956\ttraining's binary_logloss: 0.131932\tvalid_1's auc: 0.833279\tvalid_1's binary_logloss: 0.135359\n",
            "[14]\ttraining's auc: 0.86993\ttraining's binary_logloss: 0.130981\tvalid_1's auc: 0.833733\tvalid_1's binary_logloss: 0.134915\n",
            "[15]\ttraining's auc: 0.871588\ttraining's binary_logloss: 0.130047\tvalid_1's auc: 0.833639\tvalid_1's binary_logloss: 0.13453\n",
            "[16]\ttraining's auc: 0.873657\ttraining's binary_logloss: 0.129163\tvalid_1's auc: 0.834007\tvalid_1's binary_logloss: 0.13411\n",
            "[17]\ttraining's auc: 0.874464\ttraining's binary_logloss: 0.128396\tvalid_1's auc: 0.833949\tvalid_1's binary_logloss: 0.133749\n",
            "[18]\ttraining's auc: 0.875822\ttraining's binary_logloss: 0.127701\tvalid_1's auc: 0.833748\tvalid_1's binary_logloss: 0.133502\n",
            "[19]\ttraining's auc: 0.876951\ttraining's binary_logloss: 0.127008\tvalid_1's auc: 0.83358\tvalid_1's binary_logloss: 0.133233\n",
            "[20]\ttraining's auc: 0.878107\ttraining's binary_logloss: 0.126328\tvalid_1's auc: 0.833548\tvalid_1's binary_logloss: 0.133012\n",
            "[21]\ttraining's auc: 0.879585\ttraining's binary_logloss: 0.125702\tvalid_1's auc: 0.833577\tvalid_1's binary_logloss: 0.132766\n",
            "[22]\ttraining's auc: 0.880293\ttraining's binary_logloss: 0.125122\tvalid_1's auc: 0.833861\tvalid_1's binary_logloss: 0.132551\n",
            "[23]\ttraining's auc: 0.881323\ttraining's binary_logloss: 0.124558\tvalid_1's auc: 0.833617\tvalid_1's binary_logloss: 0.132409\n",
            "[24]\ttraining's auc: 0.882154\ttraining's binary_logloss: 0.124035\tvalid_1's auc: 0.833711\tvalid_1's binary_logloss: 0.132253\n",
            "[25]\ttraining's auc: 0.88382\ttraining's binary_logloss: 0.12353\tvalid_1's auc: 0.833713\tvalid_1's binary_logloss: 0.132171\n",
            "[26]\ttraining's auc: 0.88501\ttraining's binary_logloss: 0.123062\tvalid_1's auc: 0.834098\tvalid_1's binary_logloss: 0.13203\n",
            "[27]\ttraining's auc: 0.886342\ttraining's binary_logloss: 0.122574\tvalid_1's auc: 0.833998\tvalid_1's binary_logloss: 0.131912\n",
            "[28]\ttraining's auc: 0.887192\ttraining's binary_logloss: 0.122115\tvalid_1's auc: 0.834148\tvalid_1's binary_logloss: 0.13181\n",
            "[29]\ttraining's auc: 0.888454\ttraining's binary_logloss: 0.121626\tvalid_1's auc: 0.834782\tvalid_1's binary_logloss: 0.131622\n",
            "[30]\ttraining's auc: 0.889804\ttraining's binary_logloss: 0.121161\tvalid_1's auc: 0.835094\tvalid_1's binary_logloss: 0.131548\n",
            "[31]\ttraining's auc: 0.890894\ttraining's binary_logloss: 0.1207\tvalid_1's auc: 0.834884\tvalid_1's binary_logloss: 0.131531\n",
            "[32]\ttraining's auc: 0.891532\ttraining's binary_logloss: 0.120326\tvalid_1's auc: 0.835002\tvalid_1's binary_logloss: 0.13146\n",
            "[33]\ttraining's auc: 0.892239\ttraining's binary_logloss: 0.119981\tvalid_1's auc: 0.834913\tvalid_1's binary_logloss: 0.131409\n",
            "[34]\ttraining's auc: 0.893038\ttraining's binary_logloss: 0.119611\tvalid_1's auc: 0.835107\tvalid_1's binary_logloss: 0.131302\n",
            "[35]\ttraining's auc: 0.893567\ttraining's binary_logloss: 0.119307\tvalid_1's auc: 0.835235\tvalid_1's binary_logloss: 0.131263\n",
            "[36]\ttraining's auc: 0.895063\ttraining's binary_logloss: 0.118919\tvalid_1's auc: 0.835168\tvalid_1's binary_logloss: 0.13124\n",
            "[37]\ttraining's auc: 0.896491\ttraining's binary_logloss: 0.118576\tvalid_1's auc: 0.834961\tvalid_1's binary_logloss: 0.131237\n",
            "[38]\ttraining's auc: 0.897731\ttraining's binary_logloss: 0.118166\tvalid_1's auc: 0.835368\tvalid_1's binary_logloss: 0.131175\n",
            "[39]\ttraining's auc: 0.898832\ttraining's binary_logloss: 0.117825\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.131149\n",
            "[40]\ttraining's auc: 0.899322\ttraining's binary_logloss: 0.117536\tvalid_1's auc: 0.835536\tvalid_1's binary_logloss: 0.131087\n",
            "[41]\ttraining's auc: 0.900336\ttraining's binary_logloss: 0.11715\tvalid_1's auc: 0.835578\tvalid_1's binary_logloss: 0.131046\n",
            "[42]\ttraining's auc: 0.901518\ttraining's binary_logloss: 0.11683\tvalid_1's auc: 0.83557\tvalid_1's binary_logloss: 0.131019\n",
            "[43]\ttraining's auc: 0.903103\ttraining's binary_logloss: 0.116396\tvalid_1's auc: 0.835469\tvalid_1's binary_logloss: 0.131033\n",
            "[44]\ttraining's auc: 0.903595\ttraining's binary_logloss: 0.116163\tvalid_1's auc: 0.835545\tvalid_1's binary_logloss: 0.13099\n",
            "[45]\ttraining's auc: 0.904098\ttraining's binary_logloss: 0.115855\tvalid_1's auc: 0.835708\tvalid_1's binary_logloss: 0.130982\n",
            "[46]\ttraining's auc: 0.904654\ttraining's binary_logloss: 0.115526\tvalid_1's auc: 0.835696\tvalid_1's binary_logloss: 0.130977\n",
            "[47]\ttraining's auc: 0.905217\ttraining's binary_logloss: 0.115236\tvalid_1's auc: 0.835669\tvalid_1's binary_logloss: 0.130993\n",
            "[48]\ttraining's auc: 0.905672\ttraining's binary_logloss: 0.115027\tvalid_1's auc: 0.835814\tvalid_1's binary_logloss: 0.13096\n",
            "[49]\ttraining's auc: 0.90635\ttraining's binary_logloss: 0.11472\tvalid_1's auc: 0.836223\tvalid_1's binary_logloss: 0.130898\n",
            "[50]\ttraining's auc: 0.906943\ttraining's binary_logloss: 0.114434\tvalid_1's auc: 0.836408\tvalid_1's binary_logloss: 0.13087\n",
            "[51]\ttraining's auc: 0.908185\ttraining's binary_logloss: 0.114067\tvalid_1's auc: 0.836382\tvalid_1's binary_logloss: 0.130862\n",
            "[52]\ttraining's auc: 0.908955\ttraining's binary_logloss: 0.113786\tvalid_1's auc: 0.836532\tvalid_1's binary_logloss: 0.130844\n",
            "[53]\ttraining's auc: 0.909326\ttraining's binary_logloss: 0.113542\tvalid_1's auc: 0.836681\tvalid_1's binary_logloss: 0.13083\n",
            "[54]\ttraining's auc: 0.909968\ttraining's binary_logloss: 0.113284\tvalid_1's auc: 0.836745\tvalid_1's binary_logloss: 0.13083\n",
            "[55]\ttraining's auc: 0.9106\ttraining's binary_logloss: 0.113042\tvalid_1's auc: 0.836576\tvalid_1's binary_logloss: 0.130854\n",
            "[56]\ttraining's auc: 0.911267\ttraining's binary_logloss: 0.11284\tvalid_1's auc: 0.836572\tvalid_1's binary_logloss: 0.130875\n",
            "[57]\ttraining's auc: 0.911842\ttraining's binary_logloss: 0.112563\tvalid_1's auc: 0.836419\tvalid_1's binary_logloss: 0.130929\n",
            "[58]\ttraining's auc: 0.912152\ttraining's binary_logloss: 0.112349\tvalid_1's auc: 0.836279\tvalid_1's binary_logloss: 0.130936\n",
            "[59]\ttraining's auc: 0.912818\ttraining's binary_logloss: 0.112049\tvalid_1's auc: 0.83613\tvalid_1's binary_logloss: 0.130978\n",
            "[60]\ttraining's auc: 0.913215\ttraining's binary_logloss: 0.111863\tvalid_1's auc: 0.836155\tvalid_1's binary_logloss: 0.130974\n",
            "[61]\ttraining's auc: 0.913467\ttraining's binary_logloss: 0.111688\tvalid_1's auc: 0.836178\tvalid_1's binary_logloss: 0.130942\n",
            "[62]\ttraining's auc: 0.913876\ttraining's binary_logloss: 0.111466\tvalid_1's auc: 0.836287\tvalid_1's binary_logloss: 0.130931\n",
            "[63]\ttraining's auc: 0.914653\ttraining's binary_logloss: 0.111202\tvalid_1's auc: 0.836299\tvalid_1's binary_logloss: 0.130921\n",
            "[64]\ttraining's auc: 0.914963\ttraining's binary_logloss: 0.11101\tvalid_1's auc: 0.836169\tvalid_1's binary_logloss: 0.130955\n",
            "[65]\ttraining's auc: 0.915369\ttraining's binary_logloss: 0.110815\tvalid_1's auc: 0.836048\tvalid_1's binary_logloss: 0.130957\n",
            "[66]\ttraining's auc: 0.915736\ttraining's binary_logloss: 0.110649\tvalid_1's auc: 0.836053\tvalid_1's binary_logloss: 0.130951\n",
            "[67]\ttraining's auc: 0.916133\ttraining's binary_logloss: 0.110419\tvalid_1's auc: 0.83614\tvalid_1's binary_logloss: 0.130938\n",
            "[68]\ttraining's auc: 0.916568\ttraining's binary_logloss: 0.110205\tvalid_1's auc: 0.836118\tvalid_1's binary_logloss: 0.130941\n",
            "[69]\ttraining's auc: 0.917055\ttraining's binary_logloss: 0.109976\tvalid_1's auc: 0.835969\tvalid_1's binary_logloss: 0.130986\n",
            "[70]\ttraining's auc: 0.917437\ttraining's binary_logloss: 0.109769\tvalid_1's auc: 0.835622\tvalid_1's binary_logloss: 0.131039\n",
            "[71]\ttraining's auc: 0.917672\ttraining's binary_logloss: 0.109595\tvalid_1's auc: 0.835506\tvalid_1's binary_logloss: 0.131052\n",
            "[72]\ttraining's auc: 0.918106\ttraining's binary_logloss: 0.109377\tvalid_1's auc: 0.835681\tvalid_1's binary_logloss: 0.131016\n",
            "[73]\ttraining's auc: 0.918919\ttraining's binary_logloss: 0.109115\tvalid_1's auc: 0.835947\tvalid_1's binary_logloss: 0.130962\n",
            "[74]\ttraining's auc: 0.91924\ttraining's binary_logloss: 0.108956\tvalid_1's auc: 0.835883\tvalid_1's binary_logloss: 0.130955\n",
            "[75]\ttraining's auc: 0.919752\ttraining's binary_logloss: 0.108728\tvalid_1's auc: 0.835822\tvalid_1's binary_logloss: 0.130968\n",
            "[76]\ttraining's auc: 0.920256\ttraining's binary_logloss: 0.108525\tvalid_1's auc: 0.835656\tvalid_1's binary_logloss: 0.131027\n",
            "[77]\ttraining's auc: 0.920918\ttraining's binary_logloss: 0.108317\tvalid_1's auc: 0.835599\tvalid_1's binary_logloss: 0.13102\n",
            "[78]\ttraining's auc: 0.921264\ttraining's binary_logloss: 0.108122\tvalid_1's auc: 0.835549\tvalid_1's binary_logloss: 0.131024\n",
            "[79]\ttraining's auc: 0.92171\ttraining's binary_logloss: 0.107906\tvalid_1's auc: 0.835246\tvalid_1's binary_logloss: 0.131077\n",
            "[80]\ttraining's auc: 0.922436\ttraining's binary_logloss: 0.107603\tvalid_1's auc: 0.835049\tvalid_1's binary_logloss: 0.131115\n",
            "[81]\ttraining's auc: 0.92293\ttraining's binary_logloss: 0.107417\tvalid_1's auc: 0.834722\tvalid_1's binary_logloss: 0.13115\n",
            "[82]\ttraining's auc: 0.924076\ttraining's binary_logloss: 0.1071\tvalid_1's auc: 0.834842\tvalid_1's binary_logloss: 0.131128\n",
            "[83]\ttraining's auc: 0.924454\ttraining's binary_logloss: 0.106924\tvalid_1's auc: 0.834684\tvalid_1's binary_logloss: 0.131164\n",
            "[84]\ttraining's auc: 0.924624\ttraining's binary_logloss: 0.10678\tvalid_1's auc: 0.834375\tvalid_1's binary_logloss: 0.1312\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 42%|████▏     | 21/50 [10:17<14:36, 30.24s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.155884\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.162014\n",
            "[2]\ttraining's auc: 0.833054\ttraining's binary_logloss: 0.150842\tvalid_1's auc: 0.815836\tvalid_1's binary_logloss: 0.157393\n",
            "[3]\ttraining's auc: 0.838285\ttraining's binary_logloss: 0.147163\tvalid_1's auc: 0.81783\tvalid_1's binary_logloss: 0.154212\n",
            "[4]\ttraining's auc: 0.845659\ttraining's binary_logloss: 0.143882\tvalid_1's auc: 0.823188\tvalid_1's binary_logloss: 0.151674\n",
            "[5]\ttraining's auc: 0.848753\ttraining's binary_logloss: 0.141313\tvalid_1's auc: 0.824704\tvalid_1's binary_logloss: 0.149633\n",
            "[6]\ttraining's auc: 0.851058\ttraining's binary_logloss: 0.139119\tvalid_1's auc: 0.826075\tvalid_1's binary_logloss: 0.147799\n",
            "[7]\ttraining's auc: 0.853507\ttraining's binary_logloss: 0.137175\tvalid_1's auc: 0.827596\tvalid_1's binary_logloss: 0.146354\n",
            "[8]\ttraining's auc: 0.856225\ttraining's binary_logloss: 0.135528\tvalid_1's auc: 0.82864\tvalid_1's binary_logloss: 0.145129\n",
            "[9]\ttraining's auc: 0.857573\ttraining's binary_logloss: 0.134026\tvalid_1's auc: 0.828571\tvalid_1's binary_logloss: 0.144083\n",
            "[10]\ttraining's auc: 0.859281\ttraining's binary_logloss: 0.132759\tvalid_1's auc: 0.829561\tvalid_1's binary_logloss: 0.143122\n",
            "[11]\ttraining's auc: 0.860521\ttraining's binary_logloss: 0.131552\tvalid_1's auc: 0.829368\tvalid_1's binary_logloss: 0.142325\n",
            "[12]\ttraining's auc: 0.863005\ttraining's binary_logloss: 0.130493\tvalid_1's auc: 0.829568\tvalid_1's binary_logloss: 0.141669\n",
            "[13]\ttraining's auc: 0.865227\ttraining's binary_logloss: 0.129428\tvalid_1's auc: 0.829742\tvalid_1's binary_logloss: 0.141088\n",
            "[14]\ttraining's auc: 0.867254\ttraining's binary_logloss: 0.128504\tvalid_1's auc: 0.829921\tvalid_1's binary_logloss: 0.140543\n",
            "[15]\ttraining's auc: 0.869611\ttraining's binary_logloss: 0.127615\tvalid_1's auc: 0.83241\tvalid_1's binary_logloss: 0.140037\n",
            "[16]\ttraining's auc: 0.872664\ttraining's binary_logloss: 0.126703\tvalid_1's auc: 0.832906\tvalid_1's binary_logloss: 0.13961\n",
            "[17]\ttraining's auc: 0.874369\ttraining's binary_logloss: 0.125973\tvalid_1's auc: 0.833256\tvalid_1's binary_logloss: 0.139239\n",
            "[18]\ttraining's auc: 0.876199\ttraining's binary_logloss: 0.125266\tvalid_1's auc: 0.833905\tvalid_1's binary_logloss: 0.138861\n",
            "[19]\ttraining's auc: 0.877319\ttraining's binary_logloss: 0.124575\tvalid_1's auc: 0.83396\tvalid_1's binary_logloss: 0.138577\n",
            "[20]\ttraining's auc: 0.878518\ttraining's binary_logloss: 0.123965\tvalid_1's auc: 0.833608\tvalid_1's binary_logloss: 0.138391\n",
            "[21]\ttraining's auc: 0.879802\ttraining's binary_logloss: 0.123369\tvalid_1's auc: 0.8336\tvalid_1's binary_logloss: 0.13819\n",
            "[22]\ttraining's auc: 0.88117\ttraining's binary_logloss: 0.122758\tvalid_1's auc: 0.833687\tvalid_1's binary_logloss: 0.137987\n",
            "[23]\ttraining's auc: 0.883541\ttraining's binary_logloss: 0.122065\tvalid_1's auc: 0.833577\tvalid_1's binary_logloss: 0.137836\n",
            "[24]\ttraining's auc: 0.885041\ttraining's binary_logloss: 0.121545\tvalid_1's auc: 0.83364\tvalid_1's binary_logloss: 0.137651\n",
            "[25]\ttraining's auc: 0.886345\ttraining's binary_logloss: 0.121035\tvalid_1's auc: 0.833604\tvalid_1's binary_logloss: 0.137552\n",
            "[26]\ttraining's auc: 0.88828\ttraining's binary_logloss: 0.120503\tvalid_1's auc: 0.833639\tvalid_1's binary_logloss: 0.137416\n",
            "[27]\ttraining's auc: 0.889174\ttraining's binary_logloss: 0.120071\tvalid_1's auc: 0.833282\tvalid_1's binary_logloss: 0.137368\n",
            "[28]\ttraining's auc: 0.890466\ttraining's binary_logloss: 0.119619\tvalid_1's auc: 0.83333\tvalid_1's binary_logloss: 0.13725\n",
            "[29]\ttraining's auc: 0.891153\ttraining's binary_logloss: 0.119189\tvalid_1's auc: 0.834045\tvalid_1's binary_logloss: 0.137066\n",
            "[30]\ttraining's auc: 0.893202\ttraining's binary_logloss: 0.118726\tvalid_1's auc: 0.833992\tvalid_1's binary_logloss: 0.136998\n",
            "[31]\ttraining's auc: 0.89368\ttraining's binary_logloss: 0.118394\tvalid_1's auc: 0.833869\tvalid_1's binary_logloss: 0.136925\n",
            "[32]\ttraining's auc: 0.894347\ttraining's binary_logloss: 0.118073\tvalid_1's auc: 0.833714\tvalid_1's binary_logloss: 0.136892\n",
            "[33]\ttraining's auc: 0.895354\ttraining's binary_logloss: 0.11773\tvalid_1's auc: 0.833491\tvalid_1's binary_logloss: 0.136896\n",
            "[34]\ttraining's auc: 0.896866\ttraining's binary_logloss: 0.117291\tvalid_1's auc: 0.833506\tvalid_1's binary_logloss: 0.136865\n",
            "[35]\ttraining's auc: 0.897784\ttraining's binary_logloss: 0.11688\tvalid_1's auc: 0.833511\tvalid_1's binary_logloss: 0.136839\n",
            "[36]\ttraining's auc: 0.898511\ttraining's binary_logloss: 0.116543\tvalid_1's auc: 0.833497\tvalid_1's binary_logloss: 0.136803\n",
            "[37]\ttraining's auc: 0.899018\ttraining's binary_logloss: 0.116207\tvalid_1's auc: 0.833258\tvalid_1's binary_logloss: 0.136803\n",
            "[38]\ttraining's auc: 0.899993\ttraining's binary_logloss: 0.115871\tvalid_1's auc: 0.833088\tvalid_1's binary_logloss: 0.136801\n",
            "[39]\ttraining's auc: 0.901386\ttraining's binary_logloss: 0.115472\tvalid_1's auc: 0.832791\tvalid_1's binary_logloss: 0.136801\n",
            "[40]\ttraining's auc: 0.902068\ttraining's binary_logloss: 0.11515\tvalid_1's auc: 0.832551\tvalid_1's binary_logloss: 0.13683\n",
            "[41]\ttraining's auc: 0.902795\ttraining's binary_logloss: 0.114877\tvalid_1's auc: 0.832918\tvalid_1's binary_logloss: 0.136803\n",
            "[42]\ttraining's auc: 0.903739\ttraining's binary_logloss: 0.114572\tvalid_1's auc: 0.832589\tvalid_1's binary_logloss: 0.136858\n",
            "[43]\ttraining's auc: 0.904727\ttraining's binary_logloss: 0.114214\tvalid_1's auc: 0.832215\tvalid_1's binary_logloss: 0.136898\n",
            "[44]\ttraining's auc: 0.905277\ttraining's binary_logloss: 0.113897\tvalid_1's auc: 0.832111\tvalid_1's binary_logloss: 0.136959\n",
            "[45]\ttraining's auc: 0.906253\ttraining's binary_logloss: 0.113528\tvalid_1's auc: 0.832059\tvalid_1's binary_logloss: 0.136949\n",
            "[46]\ttraining's auc: 0.907102\ttraining's binary_logloss: 0.113184\tvalid_1's auc: 0.831759\tvalid_1's binary_logloss: 0.136994\n",
            "[47]\ttraining's auc: 0.907956\ttraining's binary_logloss: 0.112812\tvalid_1's auc: 0.8318\tvalid_1's binary_logloss: 0.137032\n",
            "[48]\ttraining's auc: 0.908389\ttraining's binary_logloss: 0.112546\tvalid_1's auc: 0.83183\tvalid_1's binary_logloss: 0.137036\n",
            "[49]\ttraining's auc: 0.909064\ttraining's binary_logloss: 0.112288\tvalid_1's auc: 0.831794\tvalid_1's binary_logloss: 0.137056\n",
            "[50]\ttraining's auc: 0.909688\ttraining's binary_logloss: 0.112004\tvalid_1's auc: 0.831955\tvalid_1's binary_logloss: 0.137037\n",
            "[51]\ttraining's auc: 0.910395\ttraining's binary_logloss: 0.111661\tvalid_1's auc: 0.83228\tvalid_1's binary_logloss: 0.137023\n",
            "[52]\ttraining's auc: 0.910911\ttraining's binary_logloss: 0.111409\tvalid_1's auc: 0.832271\tvalid_1's binary_logloss: 0.137044\n",
            "[53]\ttraining's auc: 0.911558\ttraining's binary_logloss: 0.111143\tvalid_1's auc: 0.832024\tvalid_1's binary_logloss: 0.137104\n",
            "[54]\ttraining's auc: 0.912055\ttraining's binary_logloss: 0.110897\tvalid_1's auc: 0.831882\tvalid_1's binary_logloss: 0.137131\n",
            "[55]\ttraining's auc: 0.912666\ttraining's binary_logloss: 0.110634\tvalid_1's auc: 0.832031\tvalid_1's binary_logloss: 0.137116\n",
            "[56]\ttraining's auc: 0.912925\ttraining's binary_logloss: 0.110462\tvalid_1's auc: 0.832105\tvalid_1's binary_logloss: 0.137109\n",
            "[57]\ttraining's auc: 0.914071\ttraining's binary_logloss: 0.110181\tvalid_1's auc: 0.832407\tvalid_1's binary_logloss: 0.137079\n",
            "[58]\ttraining's auc: 0.914761\ttraining's binary_logloss: 0.109914\tvalid_1's auc: 0.832406\tvalid_1's binary_logloss: 0.137076\n",
            "[59]\ttraining's auc: 0.915029\ttraining's binary_logloss: 0.109749\tvalid_1's auc: 0.832138\tvalid_1's binary_logloss: 0.137147\n",
            " 44%|████▍     | 22/50 [10:23<13:14, 28.36s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.16013\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.161745\n",
            "[2]\ttraining's auc: 0.832694\ttraining's binary_logloss: 0.156609\tvalid_1's auc: 0.805532\tvalid_1's binary_logloss: 0.159058\n",
            "[3]\ttraining's auc: 0.834193\ttraining's binary_logloss: 0.153705\tvalid_1's auc: 0.807333\tvalid_1's binary_logloss: 0.156754\n",
            "[4]\ttraining's auc: 0.836814\ttraining's binary_logloss: 0.15125\tvalid_1's auc: 0.808112\tvalid_1's binary_logloss: 0.15482\n",
            "[5]\ttraining's auc: 0.842224\ttraining's binary_logloss: 0.149099\tvalid_1's auc: 0.812161\tvalid_1's binary_logloss: 0.153072\n",
            "[6]\ttraining's auc: 0.845214\ttraining's binary_logloss: 0.147179\tvalid_1's auc: 0.816588\tvalid_1's binary_logloss: 0.151596\n",
            "[7]\ttraining's auc: 0.846628\ttraining's binary_logloss: 0.145482\tvalid_1's auc: 0.817594\tvalid_1's binary_logloss: 0.150337\n",
            "[8]\ttraining's auc: 0.848736\ttraining's binary_logloss: 0.1439\tvalid_1's auc: 0.819134\tvalid_1's binary_logloss: 0.149152\n",
            "[9]\ttraining's auc: 0.850549\ttraining's binary_logloss: 0.142449\tvalid_1's auc: 0.819837\tvalid_1's binary_logloss: 0.148056\n",
            "[10]\ttraining's auc: 0.852989\ttraining's binary_logloss: 0.141161\tvalid_1's auc: 0.82168\tvalid_1's binary_logloss: 0.147098\n",
            "[11]\ttraining's auc: 0.853926\ttraining's binary_logloss: 0.139964\tvalid_1's auc: 0.822174\tvalid_1's binary_logloss: 0.14622\n",
            "[12]\ttraining's auc: 0.854354\ttraining's binary_logloss: 0.138884\tvalid_1's auc: 0.82187\tvalid_1's binary_logloss: 0.145484\n",
            "[13]\ttraining's auc: 0.854603\ttraining's binary_logloss: 0.137857\tvalid_1's auc: 0.821894\tvalid_1's binary_logloss: 0.144797\n",
            "[14]\ttraining's auc: 0.855372\ttraining's binary_logloss: 0.136887\tvalid_1's auc: 0.822248\tvalid_1's binary_logloss: 0.144098\n",
            "[15]\ttraining's auc: 0.858513\ttraining's binary_logloss: 0.135989\tvalid_1's auc: 0.82327\tvalid_1's binary_logloss: 0.143466\n",
            "[16]\ttraining's auc: 0.860649\ttraining's binary_logloss: 0.135184\tvalid_1's auc: 0.8243\tvalid_1's binary_logloss: 0.14288\n",
            "[17]\ttraining's auc: 0.861328\ttraining's binary_logloss: 0.134408\tvalid_1's auc: 0.824432\tvalid_1's binary_logloss: 0.142357\n",
            "[18]\ttraining's auc: 0.862033\ttraining's binary_logloss: 0.133681\tvalid_1's auc: 0.824961\tvalid_1's binary_logloss: 0.141871\n",
            "[19]\ttraining's auc: 0.863226\ttraining's binary_logloss: 0.132974\tvalid_1's auc: 0.824759\tvalid_1's binary_logloss: 0.141469\n",
            "[20]\ttraining's auc: 0.864455\ttraining's binary_logloss: 0.132298\tvalid_1's auc: 0.825163\tvalid_1's binary_logloss: 0.14108\n",
            "[21]\ttraining's auc: 0.8653\ttraining's binary_logloss: 0.131605\tvalid_1's auc: 0.825138\tvalid_1's binary_logloss: 0.140693\n",
            "[22]\ttraining's auc: 0.865572\ttraining's binary_logloss: 0.131016\tvalid_1's auc: 0.825412\tvalid_1's binary_logloss: 0.1404\n",
            "[23]\ttraining's auc: 0.866924\ttraining's binary_logloss: 0.130454\tvalid_1's auc: 0.826427\tvalid_1's binary_logloss: 0.140072\n",
            "[24]\ttraining's auc: 0.868334\ttraining's binary_logloss: 0.129888\tvalid_1's auc: 0.82675\tvalid_1's binary_logloss: 0.139773\n",
            "[25]\ttraining's auc: 0.869526\ttraining's binary_logloss: 0.129367\tvalid_1's auc: 0.827006\tvalid_1's binary_logloss: 0.139528\n",
            "[26]\ttraining's auc: 0.870632\ttraining's binary_logloss: 0.128837\tvalid_1's auc: 0.827205\tvalid_1's binary_logloss: 0.139241\n",
            "[27]\ttraining's auc: 0.871626\ttraining's binary_logloss: 0.128359\tvalid_1's auc: 0.827325\tvalid_1's binary_logloss: 0.139058\n",
            "[28]\ttraining's auc: 0.872397\ttraining's binary_logloss: 0.127875\tvalid_1's auc: 0.827492\tvalid_1's binary_logloss: 0.138843\n",
            "[29]\ttraining's auc: 0.87285\ttraining's binary_logloss: 0.127481\tvalid_1's auc: 0.827411\tvalid_1's binary_logloss: 0.138655\n",
            "[30]\ttraining's auc: 0.873239\ttraining's binary_logloss: 0.127085\tvalid_1's auc: 0.827335\tvalid_1's binary_logloss: 0.138459\n",
            "[31]\ttraining's auc: 0.874088\ttraining's binary_logloss: 0.126683\tvalid_1's auc: 0.827281\tvalid_1's binary_logloss: 0.138302\n",
            "[32]\ttraining's auc: 0.874898\ttraining's binary_logloss: 0.126304\tvalid_1's auc: 0.827328\tvalid_1's binary_logloss: 0.138122\n",
            "[33]\ttraining's auc: 0.876173\ttraining's binary_logloss: 0.125895\tvalid_1's auc: 0.827643\tvalid_1's binary_logloss: 0.137972\n",
            "[34]\ttraining's auc: 0.877153\ttraining's binary_logloss: 0.125504\tvalid_1's auc: 0.827548\tvalid_1's binary_logloss: 0.137847\n",
            "[35]\ttraining's auc: 0.878127\ttraining's binary_logloss: 0.125118\tvalid_1's auc: 0.827422\tvalid_1's binary_logloss: 0.137703\n",
            "[36]\ttraining's auc: 0.87861\ttraining's binary_logloss: 0.12477\tvalid_1's auc: 0.827999\tvalid_1's binary_logloss: 0.137603\n",
            "[37]\ttraining's auc: 0.879247\ttraining's binary_logloss: 0.124431\tvalid_1's auc: 0.828126\tvalid_1's binary_logloss: 0.137482\n",
            "[38]\ttraining's auc: 0.879849\ttraining's binary_logloss: 0.124081\tvalid_1's auc: 0.828663\tvalid_1's binary_logloss: 0.137325\n",
            "[39]\ttraining's auc: 0.880446\ttraining's binary_logloss: 0.123763\tvalid_1's auc: 0.829074\tvalid_1's binary_logloss: 0.137212\n",
            "[40]\ttraining's auc: 0.881972\ttraining's binary_logloss: 0.123395\tvalid_1's auc: 0.829235\tvalid_1's binary_logloss: 0.13709\n",
            "[41]\ttraining's auc: 0.883396\ttraining's binary_logloss: 0.123034\tvalid_1's auc: 0.829357\tvalid_1's binary_logloss: 0.136991\n",
            "[42]\ttraining's auc: 0.88402\ttraining's binary_logloss: 0.122732\tvalid_1's auc: 0.829467\tvalid_1's binary_logloss: 0.136918\n",
            "[43]\ttraining's auc: 0.884743\ttraining's binary_logloss: 0.122436\tvalid_1's auc: 0.829425\tvalid_1's binary_logloss: 0.136872\n",
            "[44]\ttraining's auc: 0.885553\ttraining's binary_logloss: 0.12211\tvalid_1's auc: 0.829426\tvalid_1's binary_logloss: 0.136783\n",
            "[45]\ttraining's auc: 0.886433\ttraining's binary_logloss: 0.121816\tvalid_1's auc: 0.829785\tvalid_1's binary_logloss: 0.136695\n",
            "[46]\ttraining's auc: 0.887478\ttraining's binary_logloss: 0.121462\tvalid_1's auc: 0.829783\tvalid_1's binary_logloss: 0.136649\n",
            "[47]\ttraining's auc: 0.888069\ttraining's binary_logloss: 0.121187\tvalid_1's auc: 0.830013\tvalid_1's binary_logloss: 0.136578\n",
            "[48]\ttraining's auc: 0.88863\ttraining's binary_logloss: 0.120922\tvalid_1's auc: 0.830054\tvalid_1's binary_logloss: 0.13651\n",
            "[49]\ttraining's auc: 0.889121\ttraining's binary_logloss: 0.120676\tvalid_1's auc: 0.829899\tvalid_1's binary_logloss: 0.136468\n",
            "[50]\ttraining's auc: 0.889645\ttraining's binary_logloss: 0.120424\tvalid_1's auc: 0.830155\tvalid_1's binary_logloss: 0.136423\n",
            "[51]\ttraining's auc: 0.890126\ttraining's binary_logloss: 0.120156\tvalid_1's auc: 0.830297\tvalid_1's binary_logloss: 0.136338\n",
            "[52]\ttraining's auc: 0.890592\ttraining's binary_logloss: 0.119917\tvalid_1's auc: 0.830291\tvalid_1's binary_logloss: 0.136322\n",
            "[53]\ttraining's auc: 0.891167\ttraining's binary_logloss: 0.119685\tvalid_1's auc: 0.830356\tvalid_1's binary_logloss: 0.136288\n",
            "[54]\ttraining's auc: 0.892032\ttraining's binary_logloss: 0.119415\tvalid_1's auc: 0.830849\tvalid_1's binary_logloss: 0.136182\n",
            "[55]\ttraining's auc: 0.892453\ttraining's binary_logloss: 0.119184\tvalid_1's auc: 0.830676\tvalid_1's binary_logloss: 0.136171\n",
            "[56]\ttraining's auc: 0.892993\ttraining's binary_logloss: 0.118981\tvalid_1's auc: 0.8307\tvalid_1's binary_logloss: 0.136129\n",
            "[57]\ttraining's auc: 0.893789\ttraining's binary_logloss: 0.11873\tvalid_1's auc: 0.830928\tvalid_1's binary_logloss: 0.136067\n",
            "[58]\ttraining's auc: 0.8945\ttraining's binary_logloss: 0.118494\tvalid_1's auc: 0.830837\tvalid_1's binary_logloss: 0.136066\n",
            "[59]\ttraining's auc: 0.894842\ttraining's binary_logloss: 0.118292\tvalid_1's auc: 0.830756\tvalid_1's binary_logloss: 0.136033\n",
            "[60]\ttraining's auc: 0.895255\ttraining's binary_logloss: 0.118085\tvalid_1's auc: 0.830819\tvalid_1's binary_logloss: 0.135994\n",
            "[61]\ttraining's auc: 0.895858\ttraining's binary_logloss: 0.1179\tvalid_1's auc: 0.830743\tvalid_1's binary_logloss: 0.135995\n",
            "[62]\ttraining's auc: 0.896233\ttraining's binary_logloss: 0.117705\tvalid_1's auc: 0.830714\tvalid_1's binary_logloss: 0.135976\n",
            "[63]\ttraining's auc: 0.89682\ttraining's binary_logloss: 0.117505\tvalid_1's auc: 0.830805\tvalid_1's binary_logloss: 0.13592\n",
            "[64]\ttraining's auc: 0.897408\ttraining's binary_logloss: 0.117291\tvalid_1's auc: 0.830913\tvalid_1's binary_logloss: 0.135909\n",
            "[65]\ttraining's auc: 0.898048\ttraining's binary_logloss: 0.117079\tvalid_1's auc: 0.83091\tvalid_1's binary_logloss: 0.135886\n",
            "[66]\ttraining's auc: 0.899242\ttraining's binary_logloss: 0.116828\tvalid_1's auc: 0.831294\tvalid_1's binary_logloss: 0.135815\n",
            "[67]\ttraining's auc: 0.899814\ttraining's binary_logloss: 0.116639\tvalid_1's auc: 0.831424\tvalid_1's binary_logloss: 0.135793\n",
            "[68]\ttraining's auc: 0.90028\ttraining's binary_logloss: 0.116449\tvalid_1's auc: 0.831341\tvalid_1's binary_logloss: 0.135804\n",
            "[69]\ttraining's auc: 0.900708\ttraining's binary_logloss: 0.116264\tvalid_1's auc: 0.831296\tvalid_1's binary_logloss: 0.135805\n",
            "[70]\ttraining's auc: 0.901444\ttraining's binary_logloss: 0.116061\tvalid_1's auc: 0.83142\tvalid_1's binary_logloss: 0.135766\n",
            "[71]\ttraining's auc: 0.901937\ttraining's binary_logloss: 0.115882\tvalid_1's auc: 0.831686\tvalid_1's binary_logloss: 0.13572\n",
            "[72]\ttraining's auc: 0.902594\ttraining's binary_logloss: 0.115698\tvalid_1's auc: 0.831728\tvalid_1's binary_logloss: 0.135709\n",
            "[73]\ttraining's auc: 0.902854\ttraining's binary_logloss: 0.115539\tvalid_1's auc: 0.83186\tvalid_1's binary_logloss: 0.135713\n",
            "[74]\ttraining's auc: 0.903596\ttraining's binary_logloss: 0.115362\tvalid_1's auc: 0.831768\tvalid_1's binary_logloss: 0.135727\n",
            "[75]\ttraining's auc: 0.903962\ttraining's binary_logloss: 0.115158\tvalid_1's auc: 0.831864\tvalid_1's binary_logloss: 0.135726\n",
            "[76]\ttraining's auc: 0.904485\ttraining's binary_logloss: 0.115004\tvalid_1's auc: 0.831769\tvalid_1's binary_logloss: 0.135738\n",
            "[77]\ttraining's auc: 0.904828\ttraining's binary_logloss: 0.114811\tvalid_1's auc: 0.83178\tvalid_1's binary_logloss: 0.135737\n",
            "[78]\ttraining's auc: 0.905209\ttraining's binary_logloss: 0.114626\tvalid_1's auc: 0.831693\tvalid_1's binary_logloss: 0.135747\n",
            "[79]\ttraining's auc: 0.905744\ttraining's binary_logloss: 0.114466\tvalid_1's auc: 0.831907\tvalid_1's binary_logloss: 0.135718\n",
            "[80]\ttraining's auc: 0.906082\ttraining's binary_logloss: 0.114287\tvalid_1's auc: 0.831904\tvalid_1's binary_logloss: 0.135711\n",
            "[81]\ttraining's auc: 0.906363\ttraining's binary_logloss: 0.11413\tvalid_1's auc: 0.831825\tvalid_1's binary_logloss: 0.135733\n",
            "[82]\ttraining's auc: 0.90667\ttraining's binary_logloss: 0.113972\tvalid_1's auc: 0.831904\tvalid_1's binary_logloss: 0.135722\n",
            "[83]\ttraining's auc: 0.90708\ttraining's binary_logloss: 0.113794\tvalid_1's auc: 0.831885\tvalid_1's binary_logloss: 0.135743\n",
            "[84]\ttraining's auc: 0.907811\ttraining's binary_logloss: 0.113592\tvalid_1's auc: 0.831853\tvalid_1's binary_logloss: 0.135753\n",
            "[85]\ttraining's auc: 0.90825\ttraining's binary_logloss: 0.113443\tvalid_1's auc: 0.831707\tvalid_1's binary_logloss: 0.135783\n",
            "[86]\ttraining's auc: 0.908575\ttraining's binary_logloss: 0.113308\tvalid_1's auc: 0.831668\tvalid_1's binary_logloss: 0.135782\n",
            "[87]\ttraining's auc: 0.909186\ttraining's binary_logloss: 0.113101\tvalid_1's auc: 0.831572\tvalid_1's binary_logloss: 0.135796\n",
            "[88]\ttraining's auc: 0.909675\ttraining's binary_logloss: 0.112936\tvalid_1's auc: 0.831619\tvalid_1's binary_logloss: 0.1358\n",
            "[89]\ttraining's auc: 0.909972\ttraining's binary_logloss: 0.112786\tvalid_1's auc: 0.831654\tvalid_1's binary_logloss: 0.135801\n",
            "[90]\ttraining's auc: 0.910344\ttraining's binary_logloss: 0.112642\tvalid_1's auc: 0.83159\tvalid_1's binary_logloss: 0.135808\n",
            "[91]\ttraining's auc: 0.910736\ttraining's binary_logloss: 0.112458\tvalid_1's auc: 0.831507\tvalid_1's binary_logloss: 0.135815\n",
            "[92]\ttraining's auc: 0.910996\ttraining's binary_logloss: 0.112309\tvalid_1's auc: 0.831487\tvalid_1's binary_logloss: 0.135815\n",
            "[93]\ttraining's auc: 0.911526\ttraining's binary_logloss: 0.112141\tvalid_1's auc: 0.831588\tvalid_1's binary_logloss: 0.135811\n",
            "[94]\ttraining's auc: 0.912001\ttraining's binary_logloss: 0.111973\tvalid_1's auc: 0.831573\tvalid_1's binary_logloss: 0.135823\n",
            "[95]\ttraining's auc: 0.912297\ttraining's binary_logloss: 0.11184\tvalid_1's auc: 0.83155\tvalid_1's binary_logloss: 0.135829\n",
            "[96]\ttraining's auc: 0.91272\ttraining's binary_logloss: 0.111714\tvalid_1's auc: 0.831587\tvalid_1's binary_logloss: 0.135813\n",
            "[97]\ttraining's auc: 0.913047\ttraining's binary_logloss: 0.111572\tvalid_1's auc: 0.83148\tvalid_1's binary_logloss: 0.13583\n",
            "[98]\ttraining's auc: 0.913529\ttraining's binary_logloss: 0.111412\tvalid_1's auc: 0.83137\tvalid_1's binary_logloss: 0.135856\n",
            "[99]\ttraining's auc: 0.913779\ttraining's binary_logloss: 0.111262\tvalid_1's auc: 0.831283\tvalid_1's binary_logloss: 0.13589\n",
            "[100]\ttraining's auc: 0.914154\ttraining's binary_logloss: 0.111125\tvalid_1's auc: 0.831199\tvalid_1's binary_logloss: 0.135908\n",
            "[101]\ttraining's auc: 0.914467\ttraining's binary_logloss: 0.110993\tvalid_1's auc: 0.831126\tvalid_1's binary_logloss: 0.135934\n",
            "[102]\ttraining's auc: 0.914598\ttraining's binary_logloss: 0.110885\tvalid_1's auc: 0.830998\tvalid_1's binary_logloss: 0.135966\n",
            " 44%|████▍     | 22/50 [10:33<13:14, 28.36s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.162521\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.15733\n",
            "[2]\ttraining's auc: 0.823421\ttraining's binary_logloss: 0.159073\tvalid_1's auc: 0.804257\tvalid_1's binary_logloss: 0.154567\n",
            "[3]\ttraining's auc: 0.83066\ttraining's binary_logloss: 0.1561\tvalid_1's auc: 0.81604\tvalid_1's binary_logloss: 0.152175\n",
            "[4]\ttraining's auc: 0.835039\ttraining's binary_logloss: 0.153582\tvalid_1's auc: 0.819022\tvalid_1's binary_logloss: 0.150207\n",
            "[5]\ttraining's auc: 0.835779\ttraining's binary_logloss: 0.15141\tvalid_1's auc: 0.819159\tvalid_1's binary_logloss: 0.148527\n",
            "[6]\ttraining's auc: 0.837595\ttraining's binary_logloss: 0.149511\tvalid_1's auc: 0.820215\tvalid_1's binary_logloss: 0.147041\n",
            "[7]\ttraining's auc: 0.842008\ttraining's binary_logloss: 0.147799\tvalid_1's auc: 0.823987\tvalid_1's binary_logloss: 0.145698\n",
            "[8]\ttraining's auc: 0.844188\ttraining's binary_logloss: 0.146228\tvalid_1's auc: 0.824724\tvalid_1's binary_logloss: 0.144529\n",
            "[9]\ttraining's auc: 0.848162\ttraining's binary_logloss: 0.144772\tvalid_1's auc: 0.827664\tvalid_1's binary_logloss: 0.143467\n",
            "[10]\ttraining's auc: 0.84979\ttraining's binary_logloss: 0.143471\tvalid_1's auc: 0.828892\tvalid_1's binary_logloss: 0.1425\n",
            "[11]\ttraining's auc: 0.851168\ttraining's binary_logloss: 0.142265\tvalid_1's auc: 0.829433\tvalid_1's binary_logloss: 0.141658\n",
            "[12]\ttraining's auc: 0.852886\ttraining's binary_logloss: 0.141143\tvalid_1's auc: 0.82895\tvalid_1's binary_logloss: 0.140859\n",
            "[13]\ttraining's auc: 0.854517\ttraining's binary_logloss: 0.140096\tvalid_1's auc: 0.83003\tvalid_1's binary_logloss: 0.140103\n",
            "[14]\ttraining's auc: 0.857289\ttraining's binary_logloss: 0.139129\tvalid_1's auc: 0.831913\tvalid_1's binary_logloss: 0.139439\n",
            "[15]\ttraining's auc: 0.858192\ttraining's binary_logloss: 0.138257\tvalid_1's auc: 0.832721\tvalid_1's binary_logloss: 0.138831\n",
            "[16]\ttraining's auc: 0.859157\ttraining's binary_logloss: 0.137406\tvalid_1's auc: 0.832452\tvalid_1's binary_logloss: 0.13828\n",
            "[17]\ttraining's auc: 0.860143\ttraining's binary_logloss: 0.136555\tvalid_1's auc: 0.83262\tvalid_1's binary_logloss: 0.137757\n",
            "[18]\ttraining's auc: 0.86054\ttraining's binary_logloss: 0.135807\tvalid_1's auc: 0.832552\tvalid_1's binary_logloss: 0.137257\n",
            "[19]\ttraining's auc: 0.861127\ttraining's binary_logloss: 0.135096\tvalid_1's auc: 0.832284\tvalid_1's binary_logloss: 0.136865\n",
            "[20]\ttraining's auc: 0.863633\ttraining's binary_logloss: 0.134379\tvalid_1's auc: 0.832939\tvalid_1's binary_logloss: 0.136478\n",
            "[21]\ttraining's auc: 0.864929\ttraining's binary_logloss: 0.133727\tvalid_1's auc: 0.832971\tvalid_1's binary_logloss: 0.13612\n",
            "[22]\ttraining's auc: 0.866596\ttraining's binary_logloss: 0.133091\tvalid_1's auc: 0.832868\tvalid_1's binary_logloss: 0.135779\n",
            "[23]\ttraining's auc: 0.867853\ttraining's binary_logloss: 0.13249\tvalid_1's auc: 0.834063\tvalid_1's binary_logloss: 0.13545\n",
            "[24]\ttraining's auc: 0.869345\ttraining's binary_logloss: 0.131927\tvalid_1's auc: 0.834244\tvalid_1's binary_logloss: 0.135102\n",
            "[25]\ttraining's auc: 0.870397\ttraining's binary_logloss: 0.131385\tvalid_1's auc: 0.834284\tvalid_1's binary_logloss: 0.134849\n",
            "[26]\ttraining's auc: 0.870803\ttraining's binary_logloss: 0.130886\tvalid_1's auc: 0.834539\tvalid_1's binary_logloss: 0.134562\n",
            "[27]\ttraining's auc: 0.871602\ttraining's binary_logloss: 0.130389\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.134332\n",
            "[28]\ttraining's auc: 0.87203\ttraining's binary_logloss: 0.129934\tvalid_1's auc: 0.834471\tvalid_1's binary_logloss: 0.13409\n",
            "[29]\ttraining's auc: 0.872876\ttraining's binary_logloss: 0.129465\tvalid_1's auc: 0.834325\tvalid_1's binary_logloss: 0.133903\n",
            "[30]\ttraining's auc: 0.873372\ttraining's binary_logloss: 0.129027\tvalid_1's auc: 0.833977\tvalid_1's binary_logloss: 0.13376\n",
            "[31]\ttraining's auc: 0.87391\ttraining's binary_logloss: 0.128585\tvalid_1's auc: 0.833791\tvalid_1's binary_logloss: 0.133591\n",
            "[32]\ttraining's auc: 0.875324\ttraining's binary_logloss: 0.12817\tvalid_1's auc: 0.834422\tvalid_1's binary_logloss: 0.133421\n",
            "[33]\ttraining's auc: 0.875562\ttraining's binary_logloss: 0.127797\tvalid_1's auc: 0.834018\tvalid_1's binary_logloss: 0.133296\n",
            "[34]\ttraining's auc: 0.876219\ttraining's binary_logloss: 0.127428\tvalid_1's auc: 0.833969\tvalid_1's binary_logloss: 0.133148\n",
            "[35]\ttraining's auc: 0.876956\ttraining's binary_logloss: 0.127076\tvalid_1's auc: 0.834265\tvalid_1's binary_logloss: 0.132989\n",
            "[36]\ttraining's auc: 0.87762\ttraining's binary_logloss: 0.126702\tvalid_1's auc: 0.834458\tvalid_1's binary_logloss: 0.132846\n",
            "[37]\ttraining's auc: 0.87838\ttraining's binary_logloss: 0.126343\tvalid_1's auc: 0.834557\tvalid_1's binary_logloss: 0.132724\n",
            "[38]\ttraining's auc: 0.879064\ttraining's binary_logloss: 0.125964\tvalid_1's auc: 0.834359\tvalid_1's binary_logloss: 0.132636\n",
            "[39]\ttraining's auc: 0.879739\ttraining's binary_logloss: 0.125615\tvalid_1's auc: 0.834305\tvalid_1's binary_logloss: 0.132532\n",
            "[40]\ttraining's auc: 0.880414\ttraining's binary_logloss: 0.125325\tvalid_1's auc: 0.834232\tvalid_1's binary_logloss: 0.132457\n",
            "[41]\ttraining's auc: 0.880717\ttraining's binary_logloss: 0.125033\tvalid_1's auc: 0.834192\tvalid_1's binary_logloss: 0.132367\n",
            "[42]\ttraining's auc: 0.881305\ttraining's binary_logloss: 0.124719\tvalid_1's auc: 0.833815\tvalid_1's binary_logloss: 0.132308\n",
            "[43]\ttraining's auc: 0.882366\ttraining's binary_logloss: 0.12441\tvalid_1's auc: 0.833902\tvalid_1's binary_logloss: 0.132236\n",
            "[44]\ttraining's auc: 0.883219\ttraining's binary_logloss: 0.124094\tvalid_1's auc: 0.833971\tvalid_1's binary_logloss: 0.132148\n",
            "[45]\ttraining's auc: 0.884028\ttraining's binary_logloss: 0.123825\tvalid_1's auc: 0.833947\tvalid_1's binary_logloss: 0.132071\n",
            "[46]\ttraining's auc: 0.885132\ttraining's binary_logloss: 0.123491\tvalid_1's auc: 0.834112\tvalid_1's binary_logloss: 0.131982\n",
            "[47]\ttraining's auc: 0.88583\ttraining's binary_logloss: 0.123199\tvalid_1's auc: 0.834236\tvalid_1's binary_logloss: 0.1319\n",
            "[48]\ttraining's auc: 0.886294\ttraining's binary_logloss: 0.122943\tvalid_1's auc: 0.834308\tvalid_1's binary_logloss: 0.131836\n",
            "[49]\ttraining's auc: 0.887008\ttraining's binary_logloss: 0.122645\tvalid_1's auc: 0.834505\tvalid_1's binary_logloss: 0.131763\n",
            "[50]\ttraining's auc: 0.887761\ttraining's binary_logloss: 0.122374\tvalid_1's auc: 0.835502\tvalid_1's binary_logloss: 0.131685\n",
            "[51]\ttraining's auc: 0.888509\ttraining's binary_logloss: 0.122125\tvalid_1's auc: 0.83545\tvalid_1's binary_logloss: 0.13164\n",
            "[52]\ttraining's auc: 0.889211\ttraining's binary_logloss: 0.121838\tvalid_1's auc: 0.835327\tvalid_1's binary_logloss: 0.131615\n",
            "[53]\ttraining's auc: 0.890629\ttraining's binary_logloss: 0.121541\tvalid_1's auc: 0.83516\tvalid_1's binary_logloss: 0.131578\n",
            "[54]\ttraining's auc: 0.891591\ttraining's binary_logloss: 0.121274\tvalid_1's auc: 0.835383\tvalid_1's binary_logloss: 0.131523\n",
            "[55]\ttraining's auc: 0.89202\ttraining's binary_logloss: 0.121051\tvalid_1's auc: 0.835598\tvalid_1's binary_logloss: 0.131458\n",
            "[56]\ttraining's auc: 0.892399\ttraining's binary_logloss: 0.120837\tvalid_1's auc: 0.83591\tvalid_1's binary_logloss: 0.131394\n",
            "[57]\ttraining's auc: 0.892869\ttraining's binary_logloss: 0.120632\tvalid_1's auc: 0.83575\tvalid_1's binary_logloss: 0.131362\n",
            "[58]\ttraining's auc: 0.893209\ttraining's binary_logloss: 0.120434\tvalid_1's auc: 0.835803\tvalid_1's binary_logloss: 0.131311\n",
            "[59]\ttraining's auc: 0.893734\ttraining's binary_logloss: 0.120241\tvalid_1's auc: 0.835618\tvalid_1's binary_logloss: 0.131287\n",
            "[60]\ttraining's auc: 0.894027\ttraining's binary_logloss: 0.120051\tvalid_1's auc: 0.835796\tvalid_1's binary_logloss: 0.131247\n",
            "[61]\ttraining's auc: 0.894903\ttraining's binary_logloss: 0.119812\tvalid_1's auc: 0.835778\tvalid_1's binary_logloss: 0.13123\n",
            "[62]\ttraining's auc: 0.895658\ttraining's binary_logloss: 0.119597\tvalid_1's auc: 0.835638\tvalid_1's binary_logloss: 0.131222\n",
            "[63]\ttraining's auc: 0.896215\ttraining's binary_logloss: 0.119374\tvalid_1's auc: 0.835589\tvalid_1's binary_logloss: 0.131218\n",
            "[64]\ttraining's auc: 0.896638\ttraining's binary_logloss: 0.119196\tvalid_1's auc: 0.835718\tvalid_1's binary_logloss: 0.13118\n",
            "[65]\ttraining's auc: 0.8973\ttraining's binary_logloss: 0.119005\tvalid_1's auc: 0.835709\tvalid_1's binary_logloss: 0.13116\n",
            "[66]\ttraining's auc: 0.897751\ttraining's binary_logloss: 0.118823\tvalid_1's auc: 0.835806\tvalid_1's binary_logloss: 0.131135\n",
            "[67]\ttraining's auc: 0.898564\ttraining's binary_logloss: 0.118574\tvalid_1's auc: 0.835682\tvalid_1's binary_logloss: 0.131125\n",
            "[68]\ttraining's auc: 0.899089\ttraining's binary_logloss: 0.118405\tvalid_1's auc: 0.835644\tvalid_1's binary_logloss: 0.131117\n",
            "[69]\ttraining's auc: 0.899945\ttraining's binary_logloss: 0.118218\tvalid_1's auc: 0.835563\tvalid_1's binary_logloss: 0.131109\n",
            "[70]\ttraining's auc: 0.900521\ttraining's binary_logloss: 0.11802\tvalid_1's auc: 0.835593\tvalid_1's binary_logloss: 0.131082\n",
            "[71]\ttraining's auc: 0.90128\ttraining's binary_logloss: 0.117795\tvalid_1's auc: 0.835608\tvalid_1's binary_logloss: 0.131066\n",
            "[72]\ttraining's auc: 0.901713\ttraining's binary_logloss: 0.117618\tvalid_1's auc: 0.835514\tvalid_1's binary_logloss: 0.131065\n",
            "[73]\ttraining's auc: 0.902071\ttraining's binary_logloss: 0.117444\tvalid_1's auc: 0.835471\tvalid_1's binary_logloss: 0.131047\n",
            "[74]\ttraining's auc: 0.902746\ttraining's binary_logloss: 0.117249\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.131055\n",
            "[75]\ttraining's auc: 0.903349\ttraining's binary_logloss: 0.117054\tvalid_1's auc: 0.835566\tvalid_1's binary_logloss: 0.131001\n",
            "[76]\ttraining's auc: 0.904149\ttraining's binary_logloss: 0.116842\tvalid_1's auc: 0.8354\tvalid_1's binary_logloss: 0.131011\n",
            "[77]\ttraining's auc: 0.904447\ttraining's binary_logloss: 0.116691\tvalid_1's auc: 0.835372\tvalid_1's binary_logloss: 0.131013\n",
            "[78]\ttraining's auc: 0.905111\ttraining's binary_logloss: 0.116508\tvalid_1's auc: 0.835398\tvalid_1's binary_logloss: 0.131003\n",
            "[79]\ttraining's auc: 0.905389\ttraining's binary_logloss: 0.116388\tvalid_1's auc: 0.835431\tvalid_1's binary_logloss: 0.13099\n",
            "[80]\ttraining's auc: 0.90595\ttraining's binary_logloss: 0.116222\tvalid_1's auc: 0.83554\tvalid_1's binary_logloss: 0.130975\n",
            "[81]\ttraining's auc: 0.906401\ttraining's binary_logloss: 0.116024\tvalid_1's auc: 0.835493\tvalid_1's binary_logloss: 0.130979\n",
            "[82]\ttraining's auc: 0.906844\ttraining's binary_logloss: 0.115855\tvalid_1's auc: 0.835656\tvalid_1's binary_logloss: 0.130955\n",
            "[83]\ttraining's auc: 0.907446\ttraining's binary_logloss: 0.11565\tvalid_1's auc: 0.835765\tvalid_1's binary_logloss: 0.130948\n",
            "[84]\ttraining's auc: 0.907706\ttraining's binary_logloss: 0.115508\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.130953\n",
            "[85]\ttraining's auc: 0.908112\ttraining's binary_logloss: 0.115318\tvalid_1's auc: 0.835602\tvalid_1's binary_logloss: 0.130965\n",
            "[86]\ttraining's auc: 0.908523\ttraining's binary_logloss: 0.115146\tvalid_1's auc: 0.835613\tvalid_1's binary_logloss: 0.130965\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 44%|████▍     | 22/50 [10:44<13:14, 28.36s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.158932\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.16474\n",
            "[2]\ttraining's auc: 0.830828\ttraining's binary_logloss: 0.155597\tvalid_1's auc: 0.815229\tvalid_1's binary_logloss: 0.161693\n",
            "[3]\ttraining's auc: 0.833764\ttraining's binary_logloss: 0.152806\tvalid_1's auc: 0.815105\tvalid_1's binary_logloss: 0.159294\n",
            "[4]\ttraining's auc: 0.836876\ttraining's binary_logloss: 0.150382\tvalid_1's auc: 0.817505\tvalid_1's binary_logloss: 0.157155\n",
            "[5]\ttraining's auc: 0.838175\ttraining's binary_logloss: 0.14828\tvalid_1's auc: 0.81745\tvalid_1's binary_logloss: 0.155388\n",
            "[6]\ttraining's auc: 0.842137\ttraining's binary_logloss: 0.146386\tvalid_1's auc: 0.821392\tvalid_1's binary_logloss: 0.153753\n",
            "[7]\ttraining's auc: 0.847796\ttraining's binary_logloss: 0.144623\tvalid_1's auc: 0.825756\tvalid_1's binary_logloss: 0.152308\n",
            "[8]\ttraining's auc: 0.849015\ttraining's binary_logloss: 0.143102\tvalid_1's auc: 0.826003\tvalid_1's binary_logloss: 0.151029\n",
            "[9]\ttraining's auc: 0.849552\ttraining's binary_logloss: 0.141752\tvalid_1's auc: 0.826442\tvalid_1's binary_logloss: 0.14986\n",
            "[10]\ttraining's auc: 0.850958\ttraining's binary_logloss: 0.140413\tvalid_1's auc: 0.827459\tvalid_1's binary_logloss: 0.148828\n",
            "[11]\ttraining's auc: 0.851946\ttraining's binary_logloss: 0.139235\tvalid_1's auc: 0.827863\tvalid_1's binary_logloss: 0.14789\n",
            "[12]\ttraining's auc: 0.852693\ttraining's binary_logloss: 0.138105\tvalid_1's auc: 0.828337\tvalid_1's binary_logloss: 0.146965\n",
            "[13]\ttraining's auc: 0.854765\ttraining's binary_logloss: 0.13707\tvalid_1's auc: 0.828666\tvalid_1's binary_logloss: 0.146183\n",
            "[14]\ttraining's auc: 0.856079\ttraining's binary_logloss: 0.136114\tvalid_1's auc: 0.829384\tvalid_1's binary_logloss: 0.145433\n",
            "[15]\ttraining's auc: 0.856682\ttraining's binary_logloss: 0.135235\tvalid_1's auc: 0.829625\tvalid_1's binary_logloss: 0.144765\n",
            "[16]\ttraining's auc: 0.856881\ttraining's binary_logloss: 0.134423\tvalid_1's auc: 0.829829\tvalid_1's binary_logloss: 0.144154\n",
            "[17]\ttraining's auc: 0.857811\ttraining's binary_logloss: 0.133633\tvalid_1's auc: 0.830521\tvalid_1's binary_logloss: 0.143583\n",
            "[18]\ttraining's auc: 0.859062\ttraining's binary_logloss: 0.132916\tvalid_1's auc: 0.830746\tvalid_1's binary_logloss: 0.143071\n",
            "[19]\ttraining's auc: 0.861359\ttraining's binary_logloss: 0.132217\tvalid_1's auc: 0.83096\tvalid_1's binary_logloss: 0.142594\n",
            "[20]\ttraining's auc: 0.86238\ttraining's binary_logloss: 0.131556\tvalid_1's auc: 0.830948\tvalid_1's binary_logloss: 0.142197\n",
            "[21]\ttraining's auc: 0.863119\ttraining's binary_logloss: 0.130921\tvalid_1's auc: 0.83066\tvalid_1's binary_logloss: 0.14182\n",
            "[22]\ttraining's auc: 0.86403\ttraining's binary_logloss: 0.130336\tvalid_1's auc: 0.831108\tvalid_1's binary_logloss: 0.141446\n",
            "[23]\ttraining's auc: 0.866111\ttraining's binary_logloss: 0.129758\tvalid_1's auc: 0.831181\tvalid_1's binary_logloss: 0.141092\n",
            "[24]\ttraining's auc: 0.867361\ttraining's binary_logloss: 0.129229\tvalid_1's auc: 0.831306\tvalid_1's binary_logloss: 0.140758\n",
            "[25]\ttraining's auc: 0.868926\ttraining's binary_logloss: 0.128714\tvalid_1's auc: 0.831155\tvalid_1's binary_logloss: 0.140482\n",
            "[26]\ttraining's auc: 0.870635\ttraining's binary_logloss: 0.128192\tvalid_1's auc: 0.831179\tvalid_1's binary_logloss: 0.140221\n",
            "[27]\ttraining's auc: 0.872286\ttraining's binary_logloss: 0.127727\tvalid_1's auc: 0.833519\tvalid_1's binary_logloss: 0.139928\n",
            "[28]\ttraining's auc: 0.872843\ttraining's binary_logloss: 0.127276\tvalid_1's auc: 0.833879\tvalid_1's binary_logloss: 0.139654\n",
            "[29]\ttraining's auc: 0.873451\ttraining's binary_logloss: 0.126818\tvalid_1's auc: 0.833803\tvalid_1's binary_logloss: 0.139458\n",
            "[30]\ttraining's auc: 0.874075\ttraining's binary_logloss: 0.126366\tvalid_1's auc: 0.834049\tvalid_1's binary_logloss: 0.139269\n",
            "[31]\ttraining's auc: 0.875206\ttraining's binary_logloss: 0.125959\tvalid_1's auc: 0.834531\tvalid_1's binary_logloss: 0.139041\n",
            "[32]\ttraining's auc: 0.876365\ttraining's binary_logloss: 0.125531\tvalid_1's auc: 0.834818\tvalid_1's binary_logloss: 0.138847\n",
            "[33]\ttraining's auc: 0.877664\ttraining's binary_logloss: 0.125101\tvalid_1's auc: 0.834625\tvalid_1's binary_logloss: 0.138684\n",
            "[34]\ttraining's auc: 0.878944\ttraining's binary_logloss: 0.124705\tvalid_1's auc: 0.834745\tvalid_1's binary_logloss: 0.138521\n",
            "[35]\ttraining's auc: 0.879766\ttraining's binary_logloss: 0.124331\tvalid_1's auc: 0.834944\tvalid_1's binary_logloss: 0.138364\n",
            "[36]\ttraining's auc: 0.880445\ttraining's binary_logloss: 0.123971\tvalid_1's auc: 0.835122\tvalid_1's binary_logloss: 0.138189\n",
            "[37]\ttraining's auc: 0.881075\ttraining's binary_logloss: 0.123626\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.138033\n",
            "[38]\ttraining's auc: 0.882291\ttraining's binary_logloss: 0.123254\tvalid_1's auc: 0.835066\tvalid_1's binary_logloss: 0.137939\n",
            "[39]\ttraining's auc: 0.88316\ttraining's binary_logloss: 0.122916\tvalid_1's auc: 0.835079\tvalid_1's binary_logloss: 0.13781\n",
            "[40]\ttraining's auc: 0.883801\ttraining's binary_logloss: 0.122575\tvalid_1's auc: 0.835059\tvalid_1's binary_logloss: 0.137697\n",
            "[41]\ttraining's auc: 0.88466\ttraining's binary_logloss: 0.122276\tvalid_1's auc: 0.834876\tvalid_1's binary_logloss: 0.137604\n",
            "[42]\ttraining's auc: 0.885557\ttraining's binary_logloss: 0.121949\tvalid_1's auc: 0.834931\tvalid_1's binary_logloss: 0.137512\n",
            "[43]\ttraining's auc: 0.886391\ttraining's binary_logloss: 0.121665\tvalid_1's auc: 0.835232\tvalid_1's binary_logloss: 0.13738\n",
            "[44]\ttraining's auc: 0.887228\ttraining's binary_logloss: 0.121365\tvalid_1's auc: 0.835675\tvalid_1's binary_logloss: 0.137292\n",
            "[45]\ttraining's auc: 0.887844\ttraining's binary_logloss: 0.121074\tvalid_1's auc: 0.835718\tvalid_1's binary_logloss: 0.137186\n",
            "[46]\ttraining's auc: 0.888581\ttraining's binary_logloss: 0.120814\tvalid_1's auc: 0.835826\tvalid_1's binary_logloss: 0.137073\n",
            "[47]\ttraining's auc: 0.889494\ttraining's binary_logloss: 0.120507\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.137007\n",
            "[48]\ttraining's auc: 0.890116\ttraining's binary_logloss: 0.12024\tvalid_1's auc: 0.835564\tvalid_1's binary_logloss: 0.136966\n",
            "[49]\ttraining's auc: 0.890576\ttraining's binary_logloss: 0.120003\tvalid_1's auc: 0.835482\tvalid_1's binary_logloss: 0.136916\n",
            "[50]\ttraining's auc: 0.890995\ttraining's binary_logloss: 0.119781\tvalid_1's auc: 0.835587\tvalid_1's binary_logloss: 0.136848\n",
            "[51]\ttraining's auc: 0.891374\ttraining's binary_logloss: 0.119575\tvalid_1's auc: 0.835443\tvalid_1's binary_logloss: 0.136828\n",
            "[52]\ttraining's auc: 0.892397\ttraining's binary_logloss: 0.119287\tvalid_1's auc: 0.835596\tvalid_1's binary_logloss: 0.136767\n",
            "[53]\ttraining's auc: 0.893195\ttraining's binary_logloss: 0.119019\tvalid_1's auc: 0.835558\tvalid_1's binary_logloss: 0.136751\n",
            "[54]\ttraining's auc: 0.893861\ttraining's binary_logloss: 0.118761\tvalid_1's auc: 0.835658\tvalid_1's binary_logloss: 0.136719\n",
            "[55]\ttraining's auc: 0.894158\ttraining's binary_logloss: 0.118567\tvalid_1's auc: 0.835665\tvalid_1's binary_logloss: 0.136676\n",
            "[56]\ttraining's auc: 0.89464\ttraining's binary_logloss: 0.118315\tvalid_1's auc: 0.835663\tvalid_1's binary_logloss: 0.136655\n",
            "[57]\ttraining's auc: 0.895017\ttraining's binary_logloss: 0.11811\tvalid_1's auc: 0.835789\tvalid_1's binary_logloss: 0.136628\n",
            "[58]\ttraining's auc: 0.895863\ttraining's binary_logloss: 0.117863\tvalid_1's auc: 0.835723\tvalid_1's binary_logloss: 0.136607\n",
            "[59]\ttraining's auc: 0.896589\ttraining's binary_logloss: 0.11763\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.136617\n",
            "[60]\ttraining's auc: 0.897423\ttraining's binary_logloss: 0.117383\tvalid_1's auc: 0.835259\tvalid_1's binary_logloss: 0.136626\n",
            "[61]\ttraining's auc: 0.898307\ttraining's binary_logloss: 0.117146\tvalid_1's auc: 0.835477\tvalid_1's binary_logloss: 0.136585\n",
            "[62]\ttraining's auc: 0.898624\ttraining's binary_logloss: 0.116941\tvalid_1's auc: 0.835436\tvalid_1's binary_logloss: 0.136536\n",
            "[63]\ttraining's auc: 0.898974\ttraining's binary_logloss: 0.116718\tvalid_1's auc: 0.83527\tvalid_1's binary_logloss: 0.136534\n",
            "[64]\ttraining's auc: 0.899388\ttraining's binary_logloss: 0.116527\tvalid_1's auc: 0.835186\tvalid_1's binary_logloss: 0.136516\n",
            "[65]\ttraining's auc: 0.899905\ttraining's binary_logloss: 0.11632\tvalid_1's auc: 0.835012\tvalid_1's binary_logloss: 0.136513\n",
            "[66]\ttraining's auc: 0.900619\ttraining's binary_logloss: 0.116122\tvalid_1's auc: 0.834831\tvalid_1's binary_logloss: 0.136517\n",
            "[67]\ttraining's auc: 0.901183\ttraining's binary_logloss: 0.115932\tvalid_1's auc: 0.834847\tvalid_1's binary_logloss: 0.13651\n",
            "[68]\ttraining's auc: 0.901871\ttraining's binary_logloss: 0.115712\tvalid_1's auc: 0.834837\tvalid_1's binary_logloss: 0.13651\n",
            "[69]\ttraining's auc: 0.90234\ttraining's binary_logloss: 0.11555\tvalid_1's auc: 0.835\tvalid_1's binary_logloss: 0.136489\n",
            "[70]\ttraining's auc: 0.902871\ttraining's binary_logloss: 0.115377\tvalid_1's auc: 0.834845\tvalid_1's binary_logloss: 0.136494\n",
            "[71]\ttraining's auc: 0.903425\ttraining's binary_logloss: 0.115142\tvalid_1's auc: 0.835133\tvalid_1's binary_logloss: 0.136419\n",
            "[72]\ttraining's auc: 0.903833\ttraining's binary_logloss: 0.114969\tvalid_1's auc: 0.834965\tvalid_1's binary_logloss: 0.136426\n",
            "[73]\ttraining's auc: 0.904151\ttraining's binary_logloss: 0.114818\tvalid_1's auc: 0.83494\tvalid_1's binary_logloss: 0.136424\n",
            "[74]\ttraining's auc: 0.904473\ttraining's binary_logloss: 0.114617\tvalid_1's auc: 0.834926\tvalid_1's binary_logloss: 0.136423\n",
            "[75]\ttraining's auc: 0.904904\ttraining's binary_logloss: 0.114411\tvalid_1's auc: 0.834664\tvalid_1's binary_logloss: 0.136449\n",
            "[76]\ttraining's auc: 0.905439\ttraining's binary_logloss: 0.114211\tvalid_1's auc: 0.834561\tvalid_1's binary_logloss: 0.136461\n",
            " 46%|████▌     | 23/50 [10:51<12:41, 28.21s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.160625\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.162155\n",
            "[2]\ttraining's auc: 0.83249\ttraining's binary_logloss: 0.157424\tvalid_1's auc: 0.806979\tvalid_1's binary_logloss: 0.159632\n",
            "[3]\ttraining's auc: 0.834472\ttraining's binary_logloss: 0.154706\tvalid_1's auc: 0.807866\tvalid_1's binary_logloss: 0.157482\n",
            "[4]\ttraining's auc: 0.836531\ttraining's binary_logloss: 0.152396\tvalid_1's auc: 0.808631\tvalid_1's binary_logloss: 0.155642\n",
            "[5]\ttraining's auc: 0.839575\ttraining's binary_logloss: 0.150362\tvalid_1's auc: 0.810221\tvalid_1's binary_logloss: 0.154068\n",
            "[6]\ttraining's auc: 0.843229\ttraining's binary_logloss: 0.148548\tvalid_1's auc: 0.814685\tvalid_1's binary_logloss: 0.152677\n",
            "[7]\ttraining's auc: 0.844707\ttraining's binary_logloss: 0.146949\tvalid_1's auc: 0.815596\tvalid_1's binary_logloss: 0.151383\n",
            "[8]\ttraining's auc: 0.84785\ttraining's binary_logloss: 0.145458\tvalid_1's auc: 0.817419\tvalid_1's binary_logloss: 0.150313\n",
            "[9]\ttraining's auc: 0.848536\ttraining's binary_logloss: 0.144099\tvalid_1's auc: 0.816777\tvalid_1's binary_logloss: 0.149379\n",
            "[10]\ttraining's auc: 0.850303\ttraining's binary_logloss: 0.14278\tvalid_1's auc: 0.818694\tvalid_1's binary_logloss: 0.148389\n",
            "[11]\ttraining's auc: 0.851343\ttraining's binary_logloss: 0.141606\tvalid_1's auc: 0.81981\tvalid_1's binary_logloss: 0.147516\n",
            "[12]\ttraining's auc: 0.853058\ttraining's binary_logloss: 0.14051\tvalid_1's auc: 0.82074\tvalid_1's binary_logloss: 0.146724\n",
            "[13]\ttraining's auc: 0.854239\ttraining's binary_logloss: 0.139439\tvalid_1's auc: 0.821619\tvalid_1's binary_logloss: 0.146081\n",
            "[14]\ttraining's auc: 0.855131\ttraining's binary_logloss: 0.138515\tvalid_1's auc: 0.821913\tvalid_1's binary_logloss: 0.145456\n",
            "[15]\ttraining's auc: 0.855766\ttraining's binary_logloss: 0.137593\tvalid_1's auc: 0.82176\tvalid_1's binary_logloss: 0.144832\n",
            "[16]\ttraining's auc: 0.856816\ttraining's binary_logloss: 0.136715\tvalid_1's auc: 0.821772\tvalid_1's binary_logloss: 0.144322\n",
            "[17]\ttraining's auc: 0.859252\ttraining's binary_logloss: 0.135938\tvalid_1's auc: 0.822204\tvalid_1's binary_logloss: 0.143783\n",
            "[18]\ttraining's auc: 0.860507\ttraining's binary_logloss: 0.135114\tvalid_1's auc: 0.822435\tvalid_1's binary_logloss: 0.143244\n",
            "[19]\ttraining's auc: 0.862174\ttraining's binary_logloss: 0.134387\tvalid_1's auc: 0.823214\tvalid_1's binary_logloss: 0.142762\n",
            "[20]\ttraining's auc: 0.862562\ttraining's binary_logloss: 0.133734\tvalid_1's auc: 0.823434\tvalid_1's binary_logloss: 0.142331\n",
            "[21]\ttraining's auc: 0.862832\ttraining's binary_logloss: 0.133116\tvalid_1's auc: 0.823713\tvalid_1's binary_logloss: 0.141917\n",
            "[22]\ttraining's auc: 0.864121\ttraining's binary_logloss: 0.132532\tvalid_1's auc: 0.824156\tvalid_1's binary_logloss: 0.141519\n",
            "[23]\ttraining's auc: 0.865139\ttraining's binary_logloss: 0.131957\tvalid_1's auc: 0.824472\tvalid_1's binary_logloss: 0.141164\n",
            "[24]\ttraining's auc: 0.865974\ttraining's binary_logloss: 0.131406\tvalid_1's auc: 0.824978\tvalid_1's binary_logloss: 0.140867\n",
            "[25]\ttraining's auc: 0.866762\ttraining's binary_logloss: 0.130881\tvalid_1's auc: 0.824892\tvalid_1's binary_logloss: 0.140578\n",
            "[26]\ttraining's auc: 0.868107\ttraining's binary_logloss: 0.130381\tvalid_1's auc: 0.825626\tvalid_1's binary_logloss: 0.140273\n",
            "[27]\ttraining's auc: 0.868949\ttraining's binary_logloss: 0.129917\tvalid_1's auc: 0.826098\tvalid_1's binary_logloss: 0.140031\n",
            "[28]\ttraining's auc: 0.869745\ttraining's binary_logloss: 0.129425\tvalid_1's auc: 0.826215\tvalid_1's binary_logloss: 0.139787\n",
            "[29]\ttraining's auc: 0.870572\ttraining's binary_logloss: 0.128981\tvalid_1's auc: 0.826589\tvalid_1's binary_logloss: 0.139586\n",
            "[30]\ttraining's auc: 0.871686\ttraining's binary_logloss: 0.12852\tvalid_1's auc: 0.827107\tvalid_1's binary_logloss: 0.139349\n",
            "[31]\ttraining's auc: 0.872056\ttraining's binary_logloss: 0.128134\tvalid_1's auc: 0.82711\tvalid_1's binary_logloss: 0.139146\n",
            "[32]\ttraining's auc: 0.872839\ttraining's binary_logloss: 0.127719\tvalid_1's auc: 0.827427\tvalid_1's binary_logloss: 0.138923\n",
            "[33]\ttraining's auc: 0.873771\ttraining's binary_logloss: 0.127299\tvalid_1's auc: 0.827603\tvalid_1's binary_logloss: 0.138738\n",
            "[34]\ttraining's auc: 0.874289\ttraining's binary_logloss: 0.126947\tvalid_1's auc: 0.827879\tvalid_1's binary_logloss: 0.138605\n",
            "[35]\ttraining's auc: 0.874868\ttraining's binary_logloss: 0.126565\tvalid_1's auc: 0.828003\tvalid_1's binary_logloss: 0.13844\n",
            "[36]\ttraining's auc: 0.875572\ttraining's binary_logloss: 0.126205\tvalid_1's auc: 0.828111\tvalid_1's binary_logloss: 0.138286\n",
            "[37]\ttraining's auc: 0.87601\ttraining's binary_logloss: 0.125863\tvalid_1's auc: 0.828118\tvalid_1's binary_logloss: 0.138169\n",
            "[38]\ttraining's auc: 0.877545\ttraining's binary_logloss: 0.1255\tvalid_1's auc: 0.82832\tvalid_1's binary_logloss: 0.138035\n",
            "[39]\ttraining's auc: 0.878104\ttraining's binary_logloss: 0.125187\tvalid_1's auc: 0.82828\tvalid_1's binary_logloss: 0.137919\n",
            "[40]\ttraining's auc: 0.878899\ttraining's binary_logloss: 0.124868\tvalid_1's auc: 0.828327\tvalid_1's binary_logloss: 0.137817\n",
            "[41]\ttraining's auc: 0.880663\ttraining's binary_logloss: 0.124488\tvalid_1's auc: 0.828339\tvalid_1's binary_logloss: 0.137704\n",
            "[42]\ttraining's auc: 0.881062\ttraining's binary_logloss: 0.124205\tvalid_1's auc: 0.828467\tvalid_1's binary_logloss: 0.137615\n",
            "[43]\ttraining's auc: 0.881498\ttraining's binary_logloss: 0.123924\tvalid_1's auc: 0.828911\tvalid_1's binary_logloss: 0.13749\n",
            "[44]\ttraining's auc: 0.882401\ttraining's binary_logloss: 0.123639\tvalid_1's auc: 0.828764\tvalid_1's binary_logloss: 0.13741\n",
            "[45]\ttraining's auc: 0.883009\ttraining's binary_logloss: 0.123361\tvalid_1's auc: 0.828834\tvalid_1's binary_logloss: 0.137309\n",
            "[46]\ttraining's auc: 0.883789\ttraining's binary_logloss: 0.123074\tvalid_1's auc: 0.82877\tvalid_1's binary_logloss: 0.137244\n",
            "[47]\ttraining's auc: 0.884606\ttraining's binary_logloss: 0.122785\tvalid_1's auc: 0.828697\tvalid_1's binary_logloss: 0.137179\n",
            "[48]\ttraining's auc: 0.885117\ttraining's binary_logloss: 0.122536\tvalid_1's auc: 0.828759\tvalid_1's binary_logloss: 0.137131\n",
            "[49]\ttraining's auc: 0.885401\ttraining's binary_logloss: 0.122285\tvalid_1's auc: 0.828815\tvalid_1's binary_logloss: 0.137103\n",
            "[50]\ttraining's auc: 0.885917\ttraining's binary_logloss: 0.122038\tvalid_1's auc: 0.828546\tvalid_1's binary_logloss: 0.137068\n",
            "[51]\ttraining's auc: 0.886608\ttraining's binary_logloss: 0.121787\tvalid_1's auc: 0.828662\tvalid_1's binary_logloss: 0.137001\n",
            "[52]\ttraining's auc: 0.887428\ttraining's binary_logloss: 0.121494\tvalid_1's auc: 0.828663\tvalid_1's binary_logloss: 0.136961\n",
            "[53]\ttraining's auc: 0.887895\ttraining's binary_logloss: 0.12126\tvalid_1's auc: 0.828506\tvalid_1's binary_logloss: 0.136935\n",
            "[54]\ttraining's auc: 0.888901\ttraining's binary_logloss: 0.120992\tvalid_1's auc: 0.829041\tvalid_1's binary_logloss: 0.136827\n",
            "[55]\ttraining's auc: 0.889212\ttraining's binary_logloss: 0.120788\tvalid_1's auc: 0.828997\tvalid_1's binary_logloss: 0.136795\n",
            "[56]\ttraining's auc: 0.889694\ttraining's binary_logloss: 0.12056\tvalid_1's auc: 0.828813\tvalid_1's binary_logloss: 0.136769\n",
            "[57]\ttraining's auc: 0.889851\ttraining's binary_logloss: 0.120361\tvalid_1's auc: 0.828752\tvalid_1's binary_logloss: 0.136745\n",
            "[58]\ttraining's auc: 0.89044\ttraining's binary_logloss: 0.120143\tvalid_1's auc: 0.829251\tvalid_1's binary_logloss: 0.136667\n",
            "[59]\ttraining's auc: 0.891019\ttraining's binary_logloss: 0.119898\tvalid_1's auc: 0.829236\tvalid_1's binary_logloss: 0.136659\n",
            "[60]\ttraining's auc: 0.891534\ttraining's binary_logloss: 0.119699\tvalid_1's auc: 0.829107\tvalid_1's binary_logloss: 0.136622\n",
            "[61]\ttraining's auc: 0.891959\ttraining's binary_logloss: 0.1195\tvalid_1's auc: 0.828569\tvalid_1's binary_logloss: 0.136661\n",
            "[62]\ttraining's auc: 0.892726\ttraining's binary_logloss: 0.119272\tvalid_1's auc: 0.828729\tvalid_1's binary_logloss: 0.136601\n",
            "[63]\ttraining's auc: 0.893117\ttraining's binary_logloss: 0.119092\tvalid_1's auc: 0.828813\tvalid_1's binary_logloss: 0.136585\n",
            "[64]\ttraining's auc: 0.893449\ttraining's binary_logloss: 0.118911\tvalid_1's auc: 0.828861\tvalid_1's binary_logloss: 0.136562\n",
            "[65]\ttraining's auc: 0.894352\ttraining's binary_logloss: 0.118683\tvalid_1's auc: 0.829457\tvalid_1's binary_logloss: 0.136475\n",
            "[66]\ttraining's auc: 0.894939\ttraining's binary_logloss: 0.118473\tvalid_1's auc: 0.82968\tvalid_1's binary_logloss: 0.136422\n",
            "[67]\ttraining's auc: 0.89558\ttraining's binary_logloss: 0.11826\tvalid_1's auc: 0.82974\tvalid_1's binary_logloss: 0.136356\n",
            "[68]\ttraining's auc: 0.896116\ttraining's binary_logloss: 0.118068\tvalid_1's auc: 0.829736\tvalid_1's binary_logloss: 0.136321\n",
            "[69]\ttraining's auc: 0.89641\ttraining's binary_logloss: 0.11789\tvalid_1's auc: 0.82979\tvalid_1's binary_logloss: 0.136304\n",
            "[70]\ttraining's auc: 0.896951\ttraining's binary_logloss: 0.117709\tvalid_1's auc: 0.829981\tvalid_1's binary_logloss: 0.136242\n",
            "[71]\ttraining's auc: 0.897366\ttraining's binary_logloss: 0.117532\tvalid_1's auc: 0.830028\tvalid_1's binary_logloss: 0.136222\n",
            "[72]\ttraining's auc: 0.897847\ttraining's binary_logloss: 0.117349\tvalid_1's auc: 0.830083\tvalid_1's binary_logloss: 0.136195\n",
            "[73]\ttraining's auc: 0.898231\ttraining's binary_logloss: 0.117147\tvalid_1's auc: 0.830097\tvalid_1's binary_logloss: 0.136186\n",
            "[74]\ttraining's auc: 0.898523\ttraining's binary_logloss: 0.116969\tvalid_1's auc: 0.830114\tvalid_1's binary_logloss: 0.136183\n",
            "[75]\ttraining's auc: 0.899244\ttraining's binary_logloss: 0.116798\tvalid_1's auc: 0.830183\tvalid_1's binary_logloss: 0.136172\n",
            "[76]\ttraining's auc: 0.899675\ttraining's binary_logloss: 0.116638\tvalid_1's auc: 0.830032\tvalid_1's binary_logloss: 0.136166\n",
            "[77]\ttraining's auc: 0.899958\ttraining's binary_logloss: 0.116485\tvalid_1's auc: 0.829872\tvalid_1's binary_logloss: 0.136183\n",
            "[78]\ttraining's auc: 0.900401\ttraining's binary_logloss: 0.116306\tvalid_1's auc: 0.829916\tvalid_1's binary_logloss: 0.136181\n",
            "[79]\ttraining's auc: 0.901359\ttraining's binary_logloss: 0.116106\tvalid_1's auc: 0.83004\tvalid_1's binary_logloss: 0.13613\n",
            "[80]\ttraining's auc: 0.90175\ttraining's binary_logloss: 0.115944\tvalid_1's auc: 0.830091\tvalid_1's binary_logloss: 0.136116\n",
            "[81]\ttraining's auc: 0.902158\ttraining's binary_logloss: 0.115789\tvalid_1's auc: 0.83014\tvalid_1's binary_logloss: 0.136109\n",
            "[82]\ttraining's auc: 0.902668\ttraining's binary_logloss: 0.11564\tvalid_1's auc: 0.830005\tvalid_1's binary_logloss: 0.136139\n",
            "[83]\ttraining's auc: 0.903337\ttraining's binary_logloss: 0.115465\tvalid_1's auc: 0.830271\tvalid_1's binary_logloss: 0.136097\n",
            "[84]\ttraining's auc: 0.903804\ttraining's binary_logloss: 0.115321\tvalid_1's auc: 0.830475\tvalid_1's binary_logloss: 0.136061\n",
            "[85]\ttraining's auc: 0.904163\ttraining's binary_logloss: 0.115169\tvalid_1's auc: 0.830458\tvalid_1's binary_logloss: 0.136079\n",
            "[86]\ttraining's auc: 0.904611\ttraining's binary_logloss: 0.114983\tvalid_1's auc: 0.830483\tvalid_1's binary_logloss: 0.136055\n",
            "[87]\ttraining's auc: 0.905162\ttraining's binary_logloss: 0.114835\tvalid_1's auc: 0.830375\tvalid_1's binary_logloss: 0.136058\n",
            "[88]\ttraining's auc: 0.905451\ttraining's binary_logloss: 0.114685\tvalid_1's auc: 0.830304\tvalid_1's binary_logloss: 0.136083\n",
            "[89]\ttraining's auc: 0.905772\ttraining's binary_logloss: 0.11453\tvalid_1's auc: 0.830182\tvalid_1's binary_logloss: 0.136107\n",
            "[90]\ttraining's auc: 0.90605\ttraining's binary_logloss: 0.11437\tvalid_1's auc: 0.830126\tvalid_1's binary_logloss: 0.136135\n",
            "[91]\ttraining's auc: 0.906359\ttraining's binary_logloss: 0.114214\tvalid_1's auc: 0.83007\tvalid_1's binary_logloss: 0.136147\n",
            "[92]\ttraining's auc: 0.906852\ttraining's binary_logloss: 0.114068\tvalid_1's auc: 0.83012\tvalid_1's binary_logloss: 0.136153\n",
            "[93]\ttraining's auc: 0.907237\ttraining's binary_logloss: 0.113909\tvalid_1's auc: 0.830052\tvalid_1's binary_logloss: 0.136154\n",
            "[94]\ttraining's auc: 0.90744\ttraining's binary_logloss: 0.11378\tvalid_1's auc: 0.829951\tvalid_1's binary_logloss: 0.136181\n",
            "[95]\ttraining's auc: 0.907802\ttraining's binary_logloss: 0.113617\tvalid_1's auc: 0.830071\tvalid_1's binary_logloss: 0.13614\n",
            "[96]\ttraining's auc: 0.908179\ttraining's binary_logloss: 0.113482\tvalid_1's auc: 0.830103\tvalid_1's binary_logloss: 0.136138\n",
            "[97]\ttraining's auc: 0.908725\ttraining's binary_logloss: 0.113314\tvalid_1's auc: 0.829985\tvalid_1's binary_logloss: 0.136159\n",
            "[98]\ttraining's auc: 0.908915\ttraining's binary_logloss: 0.113183\tvalid_1's auc: 0.829962\tvalid_1's binary_logloss: 0.136174\n",
            "[99]\ttraining's auc: 0.909336\ttraining's binary_logloss: 0.113048\tvalid_1's auc: 0.829955\tvalid_1's binary_logloss: 0.136173\n",
            "[100]\ttraining's auc: 0.909684\ttraining's binary_logloss: 0.112928\tvalid_1's auc: 0.829981\tvalid_1's binary_logloss: 0.136181\n",
            "[101]\ttraining's auc: 0.909996\ttraining's binary_logloss: 0.112774\tvalid_1's auc: 0.829979\tvalid_1's binary_logloss: 0.136184\n",
            "[102]\ttraining's auc: 0.910303\ttraining's binary_logloss: 0.112637\tvalid_1's auc: 0.829855\tvalid_1's binary_logloss: 0.13621\n",
            "[103]\ttraining's auc: 0.910563\ttraining's binary_logloss: 0.112521\tvalid_1's auc: 0.829854\tvalid_1's binary_logloss: 0.136215\n",
            "[104]\ttraining's auc: 0.911091\ttraining's binary_logloss: 0.11236\tvalid_1's auc: 0.829681\tvalid_1's binary_logloss: 0.136249\n",
            "[105]\ttraining's auc: 0.911409\ttraining's binary_logloss: 0.112201\tvalid_1's auc: 0.829703\tvalid_1's binary_logloss: 0.136238\n",
            "[106]\ttraining's auc: 0.911764\ttraining's binary_logloss: 0.112048\tvalid_1's auc: 0.829593\tvalid_1's binary_logloss: 0.136251\n",
            "[107]\ttraining's auc: 0.912841\ttraining's binary_logloss: 0.111858\tvalid_1's auc: 0.829497\tvalid_1's binary_logloss: 0.136269\n",
            "[108]\ttraining's auc: 0.913182\ttraining's binary_logloss: 0.111725\tvalid_1's auc: 0.82931\tvalid_1's binary_logloss: 0.136297\n",
            "[109]\ttraining's auc: 0.913345\ttraining's binary_logloss: 0.111639\tvalid_1's auc: 0.829171\tvalid_1's binary_logloss: 0.136325\n",
            "[110]\ttraining's auc: 0.913792\ttraining's binary_logloss: 0.111514\tvalid_1's auc: 0.829162\tvalid_1's binary_logloss: 0.13633\n",
            "[111]\ttraining's auc: 0.914031\ttraining's binary_logloss: 0.111396\tvalid_1's auc: 0.829114\tvalid_1's binary_logloss: 0.136349\n",
            "[112]\ttraining's auc: 0.914191\ttraining's binary_logloss: 0.111284\tvalid_1's auc: 0.829069\tvalid_1's binary_logloss: 0.136373\n",
            "[113]\ttraining's auc: 0.914592\ttraining's binary_logloss: 0.111183\tvalid_1's auc: 0.82904\tvalid_1's binary_logloss: 0.136379\n",
            "[114]\ttraining's auc: 0.914823\ttraining's binary_logloss: 0.111054\tvalid_1's auc: 0.828872\tvalid_1's binary_logloss: 0.136414\n",
            "[115]\ttraining's auc: 0.91525\ttraining's binary_logloss: 0.110908\tvalid_1's auc: 0.828809\tvalid_1's binary_logloss: 0.136418\n",
            "[116]\ttraining's auc: 0.915423\ttraining's binary_logloss: 0.110814\tvalid_1's auc: 0.8288\tvalid_1's binary_logloss: 0.136412\n",
            " 46%|████▌     | 23/50 [11:06<12:41, 28.21s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.163013\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.157706\n",
            "[2]\ttraining's auc: 0.822974\ttraining's binary_logloss: 0.159875\tvalid_1's auc: 0.804264\tvalid_1's binary_logloss: 0.155179\n",
            "[3]\ttraining's auc: 0.829696\ttraining's binary_logloss: 0.15716\tvalid_1's auc: 0.816641\tvalid_1's binary_logloss: 0.15298\n",
            "[4]\ttraining's auc: 0.834524\ttraining's binary_logloss: 0.154798\tvalid_1's auc: 0.818837\tvalid_1's binary_logloss: 0.151132\n",
            "[5]\ttraining's auc: 0.834782\ttraining's binary_logloss: 0.152757\tvalid_1's auc: 0.819445\tvalid_1's binary_logloss: 0.149488\n",
            "[6]\ttraining's auc: 0.836886\ttraining's binary_logloss: 0.150922\tvalid_1's auc: 0.820435\tvalid_1's binary_logloss: 0.148053\n",
            "[7]\ttraining's auc: 0.840237\ttraining's binary_logloss: 0.14926\tvalid_1's auc: 0.823299\tvalid_1's binary_logloss: 0.146786\n",
            "[8]\ttraining's auc: 0.841638\ttraining's binary_logloss: 0.147779\tvalid_1's auc: 0.823767\tvalid_1's binary_logloss: 0.145672\n",
            "[9]\ttraining's auc: 0.84398\ttraining's binary_logloss: 0.146355\tvalid_1's auc: 0.824627\tvalid_1's binary_logloss: 0.144659\n",
            "[10]\ttraining's auc: 0.848304\ttraining's binary_logloss: 0.145042\tvalid_1's auc: 0.827217\tvalid_1's binary_logloss: 0.143722\n",
            "[11]\ttraining's auc: 0.849391\ttraining's binary_logloss: 0.14385\tvalid_1's auc: 0.828098\tvalid_1's binary_logloss: 0.142859\n",
            "[12]\ttraining's auc: 0.850512\ttraining's binary_logloss: 0.142756\tvalid_1's auc: 0.829129\tvalid_1's binary_logloss: 0.142033\n",
            "[13]\ttraining's auc: 0.852272\ttraining's binary_logloss: 0.141731\tvalid_1's auc: 0.829799\tvalid_1's binary_logloss: 0.141308\n",
            "[14]\ttraining's auc: 0.854249\ttraining's binary_logloss: 0.140765\tvalid_1's auc: 0.829956\tvalid_1's binary_logloss: 0.140562\n",
            "[15]\ttraining's auc: 0.855632\ttraining's binary_logloss: 0.139891\tvalid_1's auc: 0.830032\tvalid_1's binary_logloss: 0.139975\n",
            "[16]\ttraining's auc: 0.857301\ttraining's binary_logloss: 0.139045\tvalid_1's auc: 0.832378\tvalid_1's binary_logloss: 0.139321\n",
            "[17]\ttraining's auc: 0.858075\ttraining's binary_logloss: 0.138235\tvalid_1's auc: 0.832635\tvalid_1's binary_logloss: 0.138716\n",
            "[18]\ttraining's auc: 0.858788\ttraining's binary_logloss: 0.137458\tvalid_1's auc: 0.832351\tvalid_1's binary_logloss: 0.138223\n",
            "[19]\ttraining's auc: 0.859416\ttraining's binary_logloss: 0.136723\tvalid_1's auc: 0.832577\tvalid_1's binary_logloss: 0.137775\n",
            "[20]\ttraining's auc: 0.861715\ttraining's binary_logloss: 0.136052\tvalid_1's auc: 0.833218\tvalid_1's binary_logloss: 0.137335\n",
            "[21]\ttraining's auc: 0.862454\ttraining's binary_logloss: 0.135393\tvalid_1's auc: 0.833606\tvalid_1's binary_logloss: 0.136907\n",
            "[22]\ttraining's auc: 0.863032\ttraining's binary_logloss: 0.13479\tvalid_1's auc: 0.833733\tvalid_1's binary_logloss: 0.136547\n",
            "[23]\ttraining's auc: 0.864036\ttraining's binary_logloss: 0.134185\tvalid_1's auc: 0.833618\tvalid_1's binary_logloss: 0.136223\n",
            "[24]\ttraining's auc: 0.865927\ttraining's binary_logloss: 0.133589\tvalid_1's auc: 0.834143\tvalid_1's binary_logloss: 0.135878\n",
            "[25]\ttraining's auc: 0.867174\ttraining's binary_logloss: 0.133051\tvalid_1's auc: 0.834076\tvalid_1's binary_logloss: 0.135592\n",
            "[26]\ttraining's auc: 0.868495\ttraining's binary_logloss: 0.132523\tvalid_1's auc: 0.834459\tvalid_1's binary_logloss: 0.135306\n",
            "[27]\ttraining's auc: 0.87034\ttraining's binary_logloss: 0.132015\tvalid_1's auc: 0.835191\tvalid_1's binary_logloss: 0.135008\n",
            "[28]\ttraining's auc: 0.871129\ttraining's binary_logloss: 0.131515\tvalid_1's auc: 0.834985\tvalid_1's binary_logloss: 0.134768\n",
            "[29]\ttraining's auc: 0.871855\ttraining's binary_logloss: 0.131054\tvalid_1's auc: 0.835024\tvalid_1's binary_logloss: 0.134547\n",
            "[30]\ttraining's auc: 0.872481\ttraining's binary_logloss: 0.130614\tvalid_1's auc: 0.834868\tvalid_1's binary_logloss: 0.134324\n",
            "[31]\ttraining's auc: 0.873134\ttraining's binary_logloss: 0.13017\tvalid_1's auc: 0.834798\tvalid_1's binary_logloss: 0.134136\n",
            "[32]\ttraining's auc: 0.873806\ttraining's binary_logloss: 0.129749\tvalid_1's auc: 0.834541\tvalid_1's binary_logloss: 0.133967\n",
            "[33]\ttraining's auc: 0.874068\ttraining's binary_logloss: 0.12937\tvalid_1's auc: 0.83473\tvalid_1's binary_logloss: 0.133796\n",
            "[34]\ttraining's auc: 0.874661\ttraining's binary_logloss: 0.129001\tvalid_1's auc: 0.834757\tvalid_1's binary_logloss: 0.13363\n",
            "[35]\ttraining's auc: 0.875452\ttraining's binary_logloss: 0.128588\tvalid_1's auc: 0.834556\tvalid_1's binary_logloss: 0.133473\n",
            "[36]\ttraining's auc: 0.875791\ttraining's binary_logloss: 0.128229\tvalid_1's auc: 0.834449\tvalid_1's binary_logloss: 0.133349\n",
            "[37]\ttraining's auc: 0.876131\ttraining's binary_logloss: 0.127902\tvalid_1's auc: 0.83477\tvalid_1's binary_logloss: 0.133191\n",
            "[38]\ttraining's auc: 0.876749\ttraining's binary_logloss: 0.12755\tvalid_1's auc: 0.834775\tvalid_1's binary_logloss: 0.133074\n",
            "[39]\ttraining's auc: 0.877745\ttraining's binary_logloss: 0.127201\tvalid_1's auc: 0.834769\tvalid_1's binary_logloss: 0.132944\n",
            "[40]\ttraining's auc: 0.878034\ttraining's binary_logloss: 0.126863\tvalid_1's auc: 0.834773\tvalid_1's binary_logloss: 0.132829\n",
            "[41]\ttraining's auc: 0.878883\ttraining's binary_logloss: 0.126528\tvalid_1's auc: 0.834898\tvalid_1's binary_logloss: 0.132708\n",
            "[42]\ttraining's auc: 0.879476\ttraining's binary_logloss: 0.126206\tvalid_1's auc: 0.834857\tvalid_1's binary_logloss: 0.132616\n",
            "[43]\ttraining's auc: 0.879867\ttraining's binary_logloss: 0.125926\tvalid_1's auc: 0.834971\tvalid_1's binary_logloss: 0.132522\n",
            "[44]\ttraining's auc: 0.880187\ttraining's binary_logloss: 0.125635\tvalid_1's auc: 0.834943\tvalid_1's binary_logloss: 0.132421\n",
            "[45]\ttraining's auc: 0.881009\ttraining's binary_logloss: 0.125337\tvalid_1's auc: 0.835185\tvalid_1's binary_logloss: 0.132311\n",
            "[46]\ttraining's auc: 0.881614\ttraining's binary_logloss: 0.125039\tvalid_1's auc: 0.835136\tvalid_1's binary_logloss: 0.132247\n",
            "[47]\ttraining's auc: 0.882038\ttraining's binary_logloss: 0.124794\tvalid_1's auc: 0.834944\tvalid_1's binary_logloss: 0.132184\n",
            "[48]\ttraining's auc: 0.882308\ttraining's binary_logloss: 0.124557\tvalid_1's auc: 0.834904\tvalid_1's binary_logloss: 0.13211\n",
            "[49]\ttraining's auc: 0.882857\ttraining's binary_logloss: 0.124283\tvalid_1's auc: 0.834819\tvalid_1's binary_logloss: 0.132058\n",
            "[50]\ttraining's auc: 0.883868\ttraining's binary_logloss: 0.124018\tvalid_1's auc: 0.834826\tvalid_1's binary_logloss: 0.132002\n",
            "[51]\ttraining's auc: 0.884708\ttraining's binary_logloss: 0.12375\tvalid_1's auc: 0.834809\tvalid_1's binary_logloss: 0.131939\n",
            "[52]\ttraining's auc: 0.885159\ttraining's binary_logloss: 0.123515\tvalid_1's auc: 0.834994\tvalid_1's binary_logloss: 0.131863\n",
            "[53]\ttraining's auc: 0.885527\ttraining's binary_logloss: 0.123264\tvalid_1's auc: 0.835056\tvalid_1's binary_logloss: 0.131792\n",
            "[54]\ttraining's auc: 0.886332\ttraining's binary_logloss: 0.122989\tvalid_1's auc: 0.835077\tvalid_1's binary_logloss: 0.131748\n",
            "[55]\ttraining's auc: 0.887272\ttraining's binary_logloss: 0.122705\tvalid_1's auc: 0.834905\tvalid_1's binary_logloss: 0.131694\n",
            "[56]\ttraining's auc: 0.88777\ttraining's binary_logloss: 0.122471\tvalid_1's auc: 0.835096\tvalid_1's binary_logloss: 0.131639\n",
            "[57]\ttraining's auc: 0.888415\ttraining's binary_logloss: 0.122247\tvalid_1's auc: 0.835066\tvalid_1's binary_logloss: 0.131607\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 46%|████▌     | 23/50 [11:13<12:41, 28.21s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.159393\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.165154\n",
            "[2]\ttraining's auc: 0.831275\ttraining's binary_logloss: 0.15632\tvalid_1's auc: 0.816139\tvalid_1's binary_logloss: 0.162371\n",
            "[3]\ttraining's auc: 0.832397\ttraining's binary_logloss: 0.153744\tvalid_1's auc: 0.814515\tvalid_1's binary_logloss: 0.160182\n",
            "[4]\ttraining's auc: 0.83505\ttraining's binary_logloss: 0.15147\tvalid_1's auc: 0.816066\tvalid_1's binary_logloss: 0.158181\n",
            "[5]\ttraining's auc: 0.838788\ttraining's binary_logloss: 0.149462\tvalid_1's auc: 0.818737\tvalid_1's binary_logloss: 0.156379\n",
            "[6]\ttraining's auc: 0.839997\ttraining's binary_logloss: 0.147703\tvalid_1's auc: 0.819175\tvalid_1's binary_logloss: 0.154829\n",
            "[7]\ttraining's auc: 0.841892\ttraining's binary_logloss: 0.146089\tvalid_1's auc: 0.819534\tvalid_1's binary_logloss: 0.153485\n",
            "[8]\ttraining's auc: 0.847008\ttraining's binary_logloss: 0.144528\tvalid_1's auc: 0.823571\tvalid_1's binary_logloss: 0.152227\n",
            "[9]\ttraining's auc: 0.848818\ttraining's binary_logloss: 0.143176\tvalid_1's auc: 0.825746\tvalid_1's binary_logloss: 0.151115\n",
            "[10]\ttraining's auc: 0.849583\ttraining's binary_logloss: 0.141967\tvalid_1's auc: 0.826281\tvalid_1's binary_logloss: 0.150082\n",
            "[11]\ttraining's auc: 0.850643\ttraining's binary_logloss: 0.140797\tvalid_1's auc: 0.826888\tvalid_1's binary_logloss: 0.14913\n",
            "[12]\ttraining's auc: 0.851535\ttraining's binary_logloss: 0.139727\tvalid_1's auc: 0.828284\tvalid_1's binary_logloss: 0.148205\n",
            "[13]\ttraining's auc: 0.852151\ttraining's binary_logloss: 0.138674\tvalid_1's auc: 0.82817\tvalid_1's binary_logloss: 0.147425\n",
            "[14]\ttraining's auc: 0.852682\ttraining's binary_logloss: 0.137713\tvalid_1's auc: 0.828133\tvalid_1's binary_logloss: 0.146729\n",
            "[15]\ttraining's auc: 0.854178\ttraining's binary_logloss: 0.136826\tvalid_1's auc: 0.829571\tvalid_1's binary_logloss: 0.146032\n",
            "[16]\ttraining's auc: 0.855211\ttraining's binary_logloss: 0.135998\tvalid_1's auc: 0.830143\tvalid_1's binary_logloss: 0.145376\n",
            "[17]\ttraining's auc: 0.856787\ttraining's binary_logloss: 0.135207\tvalid_1's auc: 0.830484\tvalid_1's binary_logloss: 0.144778\n",
            "[18]\ttraining's auc: 0.857147\ttraining's binary_logloss: 0.134478\tvalid_1's auc: 0.830287\tvalid_1's binary_logloss: 0.144264\n",
            "[19]\ttraining's auc: 0.858169\ttraining's binary_logloss: 0.133774\tvalid_1's auc: 0.830236\tvalid_1's binary_logloss: 0.143747\n",
            "[20]\ttraining's auc: 0.859228\ttraining's binary_logloss: 0.133122\tvalid_1's auc: 0.830434\tvalid_1's binary_logloss: 0.143259\n",
            "[21]\ttraining's auc: 0.859995\ttraining's binary_logloss: 0.132512\tvalid_1's auc: 0.83096\tvalid_1's binary_logloss: 0.142783\n",
            "[22]\ttraining's auc: 0.861363\ttraining's binary_logloss: 0.131894\tvalid_1's auc: 0.831496\tvalid_1's binary_logloss: 0.142345\n",
            "[23]\ttraining's auc: 0.863175\ttraining's binary_logloss: 0.13132\tvalid_1's auc: 0.831414\tvalid_1's binary_logloss: 0.141988\n",
            "[24]\ttraining's auc: 0.863565\ttraining's binary_logloss: 0.130808\tvalid_1's auc: 0.831236\tvalid_1's binary_logloss: 0.141678\n",
            "[25]\ttraining's auc: 0.864148\ttraining's binary_logloss: 0.130304\tvalid_1's auc: 0.83131\tvalid_1's binary_logloss: 0.141342\n",
            "[26]\ttraining's auc: 0.865773\ttraining's binary_logloss: 0.129817\tvalid_1's auc: 0.831528\tvalid_1's binary_logloss: 0.141031\n",
            "[27]\ttraining's auc: 0.867385\ttraining's binary_logloss: 0.129307\tvalid_1's auc: 0.831894\tvalid_1's binary_logloss: 0.140735\n",
            "[28]\ttraining's auc: 0.868558\ttraining's binary_logloss: 0.128838\tvalid_1's auc: 0.831653\tvalid_1's binary_logloss: 0.140504\n",
            "[29]\ttraining's auc: 0.86982\ttraining's binary_logloss: 0.128381\tvalid_1's auc: 0.831511\tvalid_1's binary_logloss: 0.140276\n",
            "[30]\ttraining's auc: 0.871459\ttraining's binary_logloss: 0.127929\tvalid_1's auc: 0.83186\tvalid_1's binary_logloss: 0.140033\n",
            "[31]\ttraining's auc: 0.872552\ttraining's binary_logloss: 0.127511\tvalid_1's auc: 0.833242\tvalid_1's binary_logloss: 0.13982\n",
            "[32]\ttraining's auc: 0.873192\ttraining's binary_logloss: 0.127106\tvalid_1's auc: 0.83319\tvalid_1's binary_logloss: 0.139641\n",
            "[33]\ttraining's auc: 0.874208\ttraining's binary_logloss: 0.126703\tvalid_1's auc: 0.833769\tvalid_1's binary_logloss: 0.139436\n",
            "[34]\ttraining's auc: 0.874962\ttraining's binary_logloss: 0.126338\tvalid_1's auc: 0.834105\tvalid_1's binary_logloss: 0.139265\n",
            "[35]\ttraining's auc: 0.875847\ttraining's binary_logloss: 0.125965\tvalid_1's auc: 0.834278\tvalid_1's binary_logloss: 0.139086\n",
            "[36]\ttraining's auc: 0.876577\ttraining's binary_logloss: 0.125582\tvalid_1's auc: 0.834436\tvalid_1's binary_logloss: 0.138908\n",
            "[37]\ttraining's auc: 0.877483\ttraining's binary_logloss: 0.125247\tvalid_1's auc: 0.834532\tvalid_1's binary_logloss: 0.138738\n",
            "[38]\ttraining's auc: 0.878317\ttraining's binary_logloss: 0.124908\tvalid_1's auc: 0.834437\tvalid_1's binary_logloss: 0.13862\n",
            "[39]\ttraining's auc: 0.879207\ttraining's binary_logloss: 0.124554\tvalid_1's auc: 0.834604\tvalid_1's binary_logloss: 0.13848\n",
            "[40]\ttraining's auc: 0.880374\ttraining's binary_logloss: 0.124209\tvalid_1's auc: 0.834547\tvalid_1's binary_logloss: 0.138367\n",
            "[41]\ttraining's auc: 0.881389\ttraining's binary_logloss: 0.123882\tvalid_1's auc: 0.834671\tvalid_1's binary_logloss: 0.138227\n",
            "[42]\ttraining's auc: 0.882089\ttraining's binary_logloss: 0.123588\tvalid_1's auc: 0.834897\tvalid_1's binary_logloss: 0.138104\n",
            "[43]\ttraining's auc: 0.88318\ttraining's binary_logloss: 0.123235\tvalid_1's auc: 0.83488\tvalid_1's binary_logloss: 0.138033\n",
            "[44]\ttraining's auc: 0.883518\ttraining's binary_logloss: 0.122976\tvalid_1's auc: 0.834597\tvalid_1's binary_logloss: 0.137977\n",
            "[45]\ttraining's auc: 0.884314\ttraining's binary_logloss: 0.122657\tvalid_1's auc: 0.834325\tvalid_1's binary_logloss: 0.137923\n",
            "[46]\ttraining's auc: 0.88481\ttraining's binary_logloss: 0.12238\tvalid_1's auc: 0.834299\tvalid_1's binary_logloss: 0.137853\n",
            "[47]\ttraining's auc: 0.885543\ttraining's binary_logloss: 0.1221\tvalid_1's auc: 0.834102\tvalid_1's binary_logloss: 0.137755\n",
            "[48]\ttraining's auc: 0.885947\ttraining's binary_logloss: 0.121846\tvalid_1's auc: 0.834459\tvalid_1's binary_logloss: 0.137671\n",
            "[49]\ttraining's auc: 0.886623\ttraining's binary_logloss: 0.121568\tvalid_1's auc: 0.83467\tvalid_1's binary_logloss: 0.137583\n",
            "[50]\ttraining's auc: 0.887489\ttraining's binary_logloss: 0.121314\tvalid_1's auc: 0.835125\tvalid_1's binary_logloss: 0.13748\n",
            "[51]\ttraining's auc: 0.888167\ttraining's binary_logloss: 0.12105\tvalid_1's auc: 0.835353\tvalid_1's binary_logloss: 0.137382\n",
            "[52]\ttraining's auc: 0.888704\ttraining's binary_logloss: 0.120807\tvalid_1's auc: 0.835198\tvalid_1's binary_logloss: 0.137349\n",
            "[53]\ttraining's auc: 0.889197\ttraining's binary_logloss: 0.120555\tvalid_1's auc: 0.835492\tvalid_1's binary_logloss: 0.137269\n",
            "[54]\ttraining's auc: 0.889643\ttraining's binary_logloss: 0.120314\tvalid_1's auc: 0.835659\tvalid_1's binary_logloss: 0.137187\n",
            "[55]\ttraining's auc: 0.890215\ttraining's binary_logloss: 0.120086\tvalid_1's auc: 0.835543\tvalid_1's binary_logloss: 0.137139\n",
            "[56]\ttraining's auc: 0.890668\ttraining's binary_logloss: 0.119874\tvalid_1's auc: 0.835311\tvalid_1's binary_logloss: 0.137116\n",
            "[57]\ttraining's auc: 0.891159\ttraining's binary_logloss: 0.119638\tvalid_1's auc: 0.835434\tvalid_1's binary_logloss: 0.137055\n",
            "[58]\ttraining's auc: 0.891529\ttraining's binary_logloss: 0.119448\tvalid_1's auc: 0.835508\tvalid_1's binary_logloss: 0.137007\n",
            "[59]\ttraining's auc: 0.892021\ttraining's binary_logloss: 0.119248\tvalid_1's auc: 0.835505\tvalid_1's binary_logloss: 0.136979\n",
            "[60]\ttraining's auc: 0.892444\ttraining's binary_logloss: 0.119058\tvalid_1's auc: 0.835244\tvalid_1's binary_logloss: 0.13697\n",
            "[61]\ttraining's auc: 0.893009\ttraining's binary_logloss: 0.11886\tvalid_1's auc: 0.835394\tvalid_1's binary_logloss: 0.136923\n",
            "[62]\ttraining's auc: 0.893525\ttraining's binary_logloss: 0.118666\tvalid_1's auc: 0.835317\tvalid_1's binary_logloss: 0.136915\n",
            "[63]\ttraining's auc: 0.894316\ttraining's binary_logloss: 0.118431\tvalid_1's auc: 0.835557\tvalid_1's binary_logloss: 0.13687\n",
            "[64]\ttraining's auc: 0.895318\ttraining's binary_logloss: 0.118164\tvalid_1's auc: 0.835587\tvalid_1's binary_logloss: 0.13682\n",
            "[65]\ttraining's auc: 0.895811\ttraining's binary_logloss: 0.117957\tvalid_1's auc: 0.835546\tvalid_1's binary_logloss: 0.136806\n",
            "[66]\ttraining's auc: 0.896036\ttraining's binary_logloss: 0.117797\tvalid_1's auc: 0.83561\tvalid_1's binary_logloss: 0.136792\n",
            "[67]\ttraining's auc: 0.896577\ttraining's binary_logloss: 0.117608\tvalid_1's auc: 0.835548\tvalid_1's binary_logloss: 0.136776\n",
            "[68]\ttraining's auc: 0.896792\ttraining's binary_logloss: 0.117443\tvalid_1's auc: 0.835566\tvalid_1's binary_logloss: 0.136754\n",
            "[69]\ttraining's auc: 0.897427\ttraining's binary_logloss: 0.117244\tvalid_1's auc: 0.835495\tvalid_1's binary_logloss: 0.136739\n",
            "[70]\ttraining's auc: 0.897844\ttraining's binary_logloss: 0.117086\tvalid_1's auc: 0.835599\tvalid_1's binary_logloss: 0.136698\n",
            "[71]\ttraining's auc: 0.898458\ttraining's binary_logloss: 0.116873\tvalid_1's auc: 0.835713\tvalid_1's binary_logloss: 0.136664\n",
            "[72]\ttraining's auc: 0.898811\ttraining's binary_logloss: 0.116696\tvalid_1's auc: 0.835575\tvalid_1's binary_logloss: 0.136644\n",
            "[73]\ttraining's auc: 0.899357\ttraining's binary_logloss: 0.116533\tvalid_1's auc: 0.835506\tvalid_1's binary_logloss: 0.136638\n",
            "[74]\ttraining's auc: 0.899761\ttraining's binary_logloss: 0.116366\tvalid_1's auc: 0.83542\tvalid_1's binary_logloss: 0.136641\n",
            "[75]\ttraining's auc: 0.900171\ttraining's binary_logloss: 0.116205\tvalid_1's auc: 0.835411\tvalid_1's binary_logloss: 0.136622\n",
            "[76]\ttraining's auc: 0.900643\ttraining's binary_logloss: 0.11601\tvalid_1's auc: 0.835541\tvalid_1's binary_logloss: 0.13658\n",
            "[77]\ttraining's auc: 0.901086\ttraining's binary_logloss: 0.115867\tvalid_1's auc: 0.835653\tvalid_1's binary_logloss: 0.136547\n",
            "[78]\ttraining's auc: 0.901426\ttraining's binary_logloss: 0.11568\tvalid_1's auc: 0.835744\tvalid_1's binary_logloss: 0.136512\n",
            "[79]\ttraining's auc: 0.901807\ttraining's binary_logloss: 0.115516\tvalid_1's auc: 0.835679\tvalid_1's binary_logloss: 0.136514\n",
            "[80]\ttraining's auc: 0.902212\ttraining's binary_logloss: 0.115377\tvalid_1's auc: 0.835733\tvalid_1's binary_logloss: 0.136509\n",
            "[81]\ttraining's auc: 0.902836\ttraining's binary_logloss: 0.115142\tvalid_1's auc: 0.835793\tvalid_1's binary_logloss: 0.136469\n",
            "[82]\ttraining's auc: 0.903267\ttraining's binary_logloss: 0.115002\tvalid_1's auc: 0.835881\tvalid_1's binary_logloss: 0.136446\n",
            "[83]\ttraining's auc: 0.90378\ttraining's binary_logloss: 0.114789\tvalid_1's auc: 0.835843\tvalid_1's binary_logloss: 0.136448\n",
            "[84]\ttraining's auc: 0.904043\ttraining's binary_logloss: 0.114672\tvalid_1's auc: 0.835845\tvalid_1's binary_logloss: 0.136413\n",
            "[85]\ttraining's auc: 0.904503\ttraining's binary_logloss: 0.114526\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.136407\n",
            "[86]\ttraining's auc: 0.904988\ttraining's binary_logloss: 0.114301\tvalid_1's auc: 0.835965\tvalid_1's binary_logloss: 0.136405\n",
            "[87]\ttraining's auc: 0.905327\ttraining's binary_logloss: 0.114168\tvalid_1's auc: 0.83605\tvalid_1's binary_logloss: 0.136398\n",
            "[88]\ttraining's auc: 0.905658\ttraining's binary_logloss: 0.113984\tvalid_1's auc: 0.836037\tvalid_1's binary_logloss: 0.136357\n",
            "[89]\ttraining's auc: 0.90606\ttraining's binary_logloss: 0.113805\tvalid_1's auc: 0.836059\tvalid_1's binary_logloss: 0.136374\n",
            "[90]\ttraining's auc: 0.906484\ttraining's binary_logloss: 0.113628\tvalid_1's auc: 0.835978\tvalid_1's binary_logloss: 0.136377\n",
            "[91]\ttraining's auc: 0.907014\ttraining's binary_logloss: 0.113475\tvalid_1's auc: 0.835928\tvalid_1's binary_logloss: 0.136384\n",
            "[92]\ttraining's auc: 0.907576\ttraining's binary_logloss: 0.113288\tvalid_1's auc: 0.835795\tvalid_1's binary_logloss: 0.136418\n",
            "[93]\ttraining's auc: 0.907759\ttraining's binary_logloss: 0.113162\tvalid_1's auc: 0.835907\tvalid_1's binary_logloss: 0.136405\n",
            "[94]\ttraining's auc: 0.908217\ttraining's binary_logloss: 0.112966\tvalid_1's auc: 0.836009\tvalid_1's binary_logloss: 0.136389\n",
            "[95]\ttraining's auc: 0.908552\ttraining's binary_logloss: 0.112815\tvalid_1's auc: 0.835857\tvalid_1's binary_logloss: 0.136425\n",
            "[96]\ttraining's auc: 0.90871\ttraining's binary_logloss: 0.112688\tvalid_1's auc: 0.835799\tvalid_1's binary_logloss: 0.136438\n",
            "[97]\ttraining's auc: 0.909196\ttraining's binary_logloss: 0.112521\tvalid_1's auc: 0.835821\tvalid_1's binary_logloss: 0.136442\n",
            "[98]\ttraining's auc: 0.909464\ttraining's binary_logloss: 0.112398\tvalid_1's auc: 0.835808\tvalid_1's binary_logloss: 0.136456\n",
            "[99]\ttraining's auc: 0.909779\ttraining's binary_logloss: 0.112237\tvalid_1's auc: 0.835758\tvalid_1's binary_logloss: 0.136462\n",
            "[100]\ttraining's auc: 0.91017\ttraining's binary_logloss: 0.112056\tvalid_1's auc: 0.83577\tvalid_1's binary_logloss: 0.13646\n",
            "[101]\ttraining's auc: 0.910468\ttraining's binary_logloss: 0.111908\tvalid_1's auc: 0.835789\tvalid_1's binary_logloss: 0.136481\n",
            "[102]\ttraining's auc: 0.91069\ttraining's binary_logloss: 0.111787\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.13647\n",
            "[103]\ttraining's auc: 0.911007\ttraining's binary_logloss: 0.11168\tvalid_1's auc: 0.835946\tvalid_1's binary_logloss: 0.136468\n",
            "[104]\ttraining's auc: 0.911221\ttraining's binary_logloss: 0.111571\tvalid_1's auc: 0.835962\tvalid_1's binary_logloss: 0.136468\n",
            "[105]\ttraining's auc: 0.911578\ttraining's binary_logloss: 0.111421\tvalid_1's auc: 0.835926\tvalid_1's binary_logloss: 0.136475\n",
            "[106]\ttraining's auc: 0.911765\ttraining's binary_logloss: 0.111307\tvalid_1's auc: 0.835922\tvalid_1's binary_logloss: 0.136494\n",
            "[107]\ttraining's auc: 0.912026\ttraining's binary_logloss: 0.111201\tvalid_1's auc: 0.835956\tvalid_1's binary_logloss: 0.136488\n",
            "[108]\ttraining's auc: 0.912338\ttraining's binary_logloss: 0.111066\tvalid_1's auc: 0.835994\tvalid_1's binary_logloss: 0.136497\n",
            "[109]\ttraining's auc: 0.912639\ttraining's binary_logloss: 0.110916\tvalid_1's auc: 0.836094\tvalid_1's binary_logloss: 0.136482\n",
            "[110]\ttraining's auc: 0.913034\ttraining's binary_logloss: 0.110774\tvalid_1's auc: 0.836096\tvalid_1's binary_logloss: 0.13647\n",
            "[111]\ttraining's auc: 0.913318\ttraining's binary_logloss: 0.11065\tvalid_1's auc: 0.836059\tvalid_1's binary_logloss: 0.136485\n",
            "[112]\ttraining's auc: 0.913684\ttraining's binary_logloss: 0.110546\tvalid_1's auc: 0.836123\tvalid_1's binary_logloss: 0.136481\n",
            "[113]\ttraining's auc: 0.913877\ttraining's binary_logloss: 0.110417\tvalid_1's auc: 0.83605\tvalid_1's binary_logloss: 0.136499\n",
            "[114]\ttraining's auc: 0.914098\ttraining's binary_logloss: 0.110303\tvalid_1's auc: 0.835986\tvalid_1's binary_logloss: 0.136527\n",
            "[115]\ttraining's auc: 0.914195\ttraining's binary_logloss: 0.110205\tvalid_1's auc: 0.835974\tvalid_1's binary_logloss: 0.136544\n",
            "[116]\ttraining's auc: 0.914439\ttraining's binary_logloss: 0.110068\tvalid_1's auc: 0.835959\tvalid_1's binary_logloss: 0.136547\n",
            "[117]\ttraining's auc: 0.91466\ttraining's binary_logloss: 0.109957\tvalid_1's auc: 0.835839\tvalid_1's binary_logloss: 0.136568\n",
            "[118]\ttraining's auc: 0.914865\ttraining's binary_logloss: 0.109825\tvalid_1's auc: 0.835834\tvalid_1's binary_logloss: 0.136573\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 48%|████▊     | 24/50 [11:24<12:48, 29.57s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.156708\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.158931\n",
            "[2]\ttraining's auc: 0.8331\ttraining's binary_logloss: 0.15158\tvalid_1's auc: 0.806262\tvalid_1's binary_logloss: 0.154926\n",
            "[3]\ttraining's auc: 0.838288\ttraining's binary_logloss: 0.147727\tvalid_1's auc: 0.809691\tvalid_1's binary_logloss: 0.152024\n",
            "[4]\ttraining's auc: 0.842812\ttraining's binary_logloss: 0.144622\tvalid_1's auc: 0.812295\tvalid_1's binary_logloss: 0.149733\n",
            "[5]\ttraining's auc: 0.847354\ttraining's binary_logloss: 0.141967\tvalid_1's auc: 0.816718\tvalid_1's binary_logloss: 0.14776\n",
            "[6]\ttraining's auc: 0.852102\ttraining's binary_logloss: 0.139791\tvalid_1's auc: 0.820087\tvalid_1's binary_logloss: 0.146168\n",
            "[7]\ttraining's auc: 0.853769\ttraining's binary_logloss: 0.137853\tvalid_1's auc: 0.820496\tvalid_1's binary_logloss: 0.144868\n",
            "[8]\ttraining's auc: 0.855208\ttraining's binary_logloss: 0.136156\tvalid_1's auc: 0.821175\tvalid_1's binary_logloss: 0.143665\n",
            "[9]\ttraining's auc: 0.857104\ttraining's binary_logloss: 0.134659\tvalid_1's auc: 0.822521\tvalid_1's binary_logloss: 0.142585\n",
            "[10]\ttraining's auc: 0.858679\ttraining's binary_logloss: 0.133319\tvalid_1's auc: 0.822831\tvalid_1's binary_logloss: 0.141776\n",
            "[11]\ttraining's auc: 0.862182\ttraining's binary_logloss: 0.132047\tvalid_1's auc: 0.823432\tvalid_1's binary_logloss: 0.141012\n",
            "[12]\ttraining's auc: 0.863954\ttraining's binary_logloss: 0.130995\tvalid_1's auc: 0.824109\tvalid_1's binary_logloss: 0.140371\n",
            "[13]\ttraining's auc: 0.866399\ttraining's binary_logloss: 0.130004\tvalid_1's auc: 0.826038\tvalid_1's binary_logloss: 0.139799\n",
            "[14]\ttraining's auc: 0.868188\ttraining's binary_logloss: 0.129005\tvalid_1's auc: 0.826881\tvalid_1's binary_logloss: 0.139199\n",
            "[15]\ttraining's auc: 0.869728\ttraining's binary_logloss: 0.128174\tvalid_1's auc: 0.827353\tvalid_1's binary_logloss: 0.138773\n",
            "[16]\ttraining's auc: 0.871476\ttraining's binary_logloss: 0.12731\tvalid_1's auc: 0.827162\tvalid_1's binary_logloss: 0.138407\n",
            "[17]\ttraining's auc: 0.873418\ttraining's binary_logloss: 0.126503\tvalid_1's auc: 0.827005\tvalid_1's binary_logloss: 0.138144\n",
            "[18]\ttraining's auc: 0.875408\ttraining's binary_logloss: 0.125821\tvalid_1's auc: 0.827262\tvalid_1's binary_logloss: 0.137903\n",
            "[19]\ttraining's auc: 0.876629\ttraining's binary_logloss: 0.125202\tvalid_1's auc: 0.827073\tvalid_1's binary_logloss: 0.137662\n",
            "[20]\ttraining's auc: 0.879431\ttraining's binary_logloss: 0.124472\tvalid_1's auc: 0.827322\tvalid_1's binary_logloss: 0.137416\n",
            "[21]\ttraining's auc: 0.880759\ttraining's binary_logloss: 0.123854\tvalid_1's auc: 0.828699\tvalid_1's binary_logloss: 0.137188\n",
            "[22]\ttraining's auc: 0.88209\ttraining's binary_logloss: 0.123261\tvalid_1's auc: 0.828783\tvalid_1's binary_logloss: 0.136991\n",
            "[23]\ttraining's auc: 0.882946\ttraining's binary_logloss: 0.122702\tvalid_1's auc: 0.828681\tvalid_1's binary_logloss: 0.136872\n",
            "[24]\ttraining's auc: 0.88476\ttraining's binary_logloss: 0.122128\tvalid_1's auc: 0.829003\tvalid_1's binary_logloss: 0.136724\n",
            "[25]\ttraining's auc: 0.885603\ttraining's binary_logloss: 0.121642\tvalid_1's auc: 0.829384\tvalid_1's binary_logloss: 0.136583\n",
            "[26]\ttraining's auc: 0.886872\ttraining's binary_logloss: 0.121158\tvalid_1's auc: 0.829971\tvalid_1's binary_logloss: 0.136435\n",
            "[27]\ttraining's auc: 0.888568\ttraining's binary_logloss: 0.120576\tvalid_1's auc: 0.829791\tvalid_1's binary_logloss: 0.136394\n",
            "[28]\ttraining's auc: 0.890791\ttraining's binary_logloss: 0.119984\tvalid_1's auc: 0.830295\tvalid_1's binary_logloss: 0.136186\n",
            "[29]\ttraining's auc: 0.891769\ttraining's binary_logloss: 0.119561\tvalid_1's auc: 0.830071\tvalid_1's binary_logloss: 0.136217\n",
            "[30]\ttraining's auc: 0.893128\ttraining's binary_logloss: 0.119124\tvalid_1's auc: 0.830178\tvalid_1's binary_logloss: 0.136123\n",
            "[31]\ttraining's auc: 0.894058\ttraining's binary_logloss: 0.118702\tvalid_1's auc: 0.830385\tvalid_1's binary_logloss: 0.136077\n",
            "[32]\ttraining's auc: 0.894706\ttraining's binary_logloss: 0.118331\tvalid_1's auc: 0.83038\tvalid_1's binary_logloss: 0.136048\n",
            "[33]\ttraining's auc: 0.895513\ttraining's binary_logloss: 0.117958\tvalid_1's auc: 0.830736\tvalid_1's binary_logloss: 0.13596\n",
            "[34]\ttraining's auc: 0.896737\ttraining's binary_logloss: 0.117569\tvalid_1's auc: 0.830758\tvalid_1's binary_logloss: 0.135928\n",
            "[35]\ttraining's auc: 0.897441\ttraining's binary_logloss: 0.117214\tvalid_1's auc: 0.830356\tvalid_1's binary_logloss: 0.135993\n",
            "[36]\ttraining's auc: 0.899284\ttraining's binary_logloss: 0.116779\tvalid_1's auc: 0.831197\tvalid_1's binary_logloss: 0.135865\n",
            "[37]\ttraining's auc: 0.900181\ttraining's binary_logloss: 0.116408\tvalid_1's auc: 0.831078\tvalid_1's binary_logloss: 0.135828\n",
            "[38]\ttraining's auc: 0.900857\ttraining's binary_logloss: 0.116109\tvalid_1's auc: 0.831327\tvalid_1's binary_logloss: 0.135792\n",
            "[39]\ttraining's auc: 0.901937\ttraining's binary_logloss: 0.115787\tvalid_1's auc: 0.831583\tvalid_1's binary_logloss: 0.135753\n",
            "[40]\ttraining's auc: 0.902702\ttraining's binary_logloss: 0.115476\tvalid_1's auc: 0.831418\tvalid_1's binary_logloss: 0.135775\n",
            "[41]\ttraining's auc: 0.903312\ttraining's binary_logloss: 0.115153\tvalid_1's auc: 0.831068\tvalid_1's binary_logloss: 0.135831\n",
            "[42]\ttraining's auc: 0.904011\ttraining's binary_logloss: 0.114853\tvalid_1's auc: 0.830999\tvalid_1's binary_logloss: 0.135886\n",
            "[43]\ttraining's auc: 0.905168\ttraining's binary_logloss: 0.114467\tvalid_1's auc: 0.830476\tvalid_1's binary_logloss: 0.135983\n",
            "[44]\ttraining's auc: 0.905842\ttraining's binary_logloss: 0.114128\tvalid_1's auc: 0.830471\tvalid_1's binary_logloss: 0.136015\n",
            "[45]\ttraining's auc: 0.906592\ttraining's binary_logloss: 0.113853\tvalid_1's auc: 0.830157\tvalid_1's binary_logloss: 0.13608\n",
            "[46]\ttraining's auc: 0.907303\ttraining's binary_logloss: 0.113528\tvalid_1's auc: 0.830082\tvalid_1's binary_logloss: 0.136083\n",
            "[47]\ttraining's auc: 0.907906\ttraining's binary_logloss: 0.113264\tvalid_1's auc: 0.829956\tvalid_1's binary_logloss: 0.136135\n",
            "[48]\ttraining's auc: 0.908621\ttraining's binary_logloss: 0.112953\tvalid_1's auc: 0.829966\tvalid_1's binary_logloss: 0.136149\n",
            "[49]\ttraining's auc: 0.909246\ttraining's binary_logloss: 0.112691\tvalid_1's auc: 0.829734\tvalid_1's binary_logloss: 0.136178\n",
            "[50]\ttraining's auc: 0.909998\ttraining's binary_logloss: 0.112412\tvalid_1's auc: 0.829663\tvalid_1's binary_logloss: 0.13618\n",
            "[51]\ttraining's auc: 0.91071\ttraining's binary_logloss: 0.112143\tvalid_1's auc: 0.82979\tvalid_1's binary_logloss: 0.136185\n",
            "[52]\ttraining's auc: 0.911103\ttraining's binary_logloss: 0.111919\tvalid_1's auc: 0.829387\tvalid_1's binary_logloss: 0.13626\n",
            "[53]\ttraining's auc: 0.911923\ttraining's binary_logloss: 0.111615\tvalid_1's auc: 0.828995\tvalid_1's binary_logloss: 0.136352\n",
            "[54]\ttraining's auc: 0.912165\ttraining's binary_logloss: 0.111423\tvalid_1's auc: 0.828931\tvalid_1's binary_logloss: 0.136357\n",
            "[55]\ttraining's auc: 0.913105\ttraining's binary_logloss: 0.111081\tvalid_1's auc: 0.828902\tvalid_1's binary_logloss: 0.13635\n",
            "[56]\ttraining's auc: 0.913588\ttraining's binary_logloss: 0.110865\tvalid_1's auc: 0.828899\tvalid_1's binary_logloss: 0.136347\n",
            "[57]\ttraining's auc: 0.914004\ttraining's binary_logloss: 0.11064\tvalid_1's auc: 0.828714\tvalid_1's binary_logloss: 0.136398\n",
            "[58]\ttraining's auc: 0.914336\ttraining's binary_logloss: 0.110461\tvalid_1's auc: 0.828517\tvalid_1's binary_logloss: 0.136428\n",
            "[59]\ttraining's auc: 0.914883\ttraining's binary_logloss: 0.110225\tvalid_1's auc: 0.828385\tvalid_1's binary_logloss: 0.136436\n",
            "[60]\ttraining's auc: 0.915367\ttraining's binary_logloss: 0.109961\tvalid_1's auc: 0.828071\tvalid_1's binary_logloss: 0.136533\n",
            "[61]\ttraining's auc: 0.916035\ttraining's binary_logloss: 0.109654\tvalid_1's auc: 0.828014\tvalid_1's binary_logloss: 0.136527\n",
            "[62]\ttraining's auc: 0.916276\ttraining's binary_logloss: 0.109474\tvalid_1's auc: 0.8278\tvalid_1's binary_logloss: 0.13657\n",
            "[63]\ttraining's auc: 0.916526\ttraining's binary_logloss: 0.109288\tvalid_1's auc: 0.827614\tvalid_1's binary_logloss: 0.136625\n",
            "[64]\ttraining's auc: 0.917893\ttraining's binary_logloss: 0.109002\tvalid_1's auc: 0.827304\tvalid_1's binary_logloss: 0.136671\n",
            "[65]\ttraining's auc: 0.918592\ttraining's binary_logloss: 0.108793\tvalid_1's auc: 0.827055\tvalid_1's binary_logloss: 0.136728\n",
            "[66]\ttraining's auc: 0.918828\ttraining's binary_logloss: 0.108633\tvalid_1's auc: 0.82679\tvalid_1's binary_logloss: 0.136791\n",
            "[67]\ttraining's auc: 0.919192\ttraining's binary_logloss: 0.10845\tvalid_1's auc: 0.826654\tvalid_1's binary_logloss: 0.13685\n",
            "[68]\ttraining's auc: 0.919548\ttraining's binary_logloss: 0.108235\tvalid_1's auc: 0.826315\tvalid_1's binary_logloss: 0.136914\n",
            "[69]\ttraining's auc: 0.919809\ttraining's binary_logloss: 0.108041\tvalid_1's auc: 0.826241\tvalid_1's binary_logloss: 0.136924\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 48%|████▊     | 24/50 [11:33<12:48, 29.57s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.15912\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.154756\n",
            "[2]\ttraining's auc: 0.828184\ttraining's binary_logloss: 0.154029\tvalid_1's auc: 0.817652\tvalid_1's binary_logloss: 0.150639\n",
            "[3]\ttraining's auc: 0.833327\ttraining's binary_logloss: 0.150011\tvalid_1's auc: 0.81857\tvalid_1's binary_logloss: 0.147613\n",
            "[4]\ttraining's auc: 0.839336\ttraining's binary_logloss: 0.146842\tvalid_1's auc: 0.8224\tvalid_1's binary_logloss: 0.145246\n",
            "[5]\ttraining's auc: 0.844805\ttraining's binary_logloss: 0.144209\tvalid_1's auc: 0.824712\tvalid_1's binary_logloss: 0.143355\n",
            "[6]\ttraining's auc: 0.8493\ttraining's binary_logloss: 0.141929\tvalid_1's auc: 0.827044\tvalid_1's binary_logloss: 0.141793\n",
            "[7]\ttraining's auc: 0.852102\ttraining's binary_logloss: 0.140037\tvalid_1's auc: 0.828307\tvalid_1's binary_logloss: 0.140405\n",
            "[8]\ttraining's auc: 0.855651\ttraining's binary_logloss: 0.138329\tvalid_1's auc: 0.830892\tvalid_1's binary_logloss: 0.139227\n",
            "[9]\ttraining's auc: 0.858306\ttraining's binary_logloss: 0.136759\tvalid_1's auc: 0.830764\tvalid_1's binary_logloss: 0.138271\n",
            "[10]\ttraining's auc: 0.859701\ttraining's binary_logloss: 0.135463\tvalid_1's auc: 0.830374\tvalid_1's binary_logloss: 0.137439\n",
            "[11]\ttraining's auc: 0.86087\ttraining's binary_logloss: 0.134233\tvalid_1's auc: 0.831071\tvalid_1's binary_logloss: 0.136694\n",
            "[12]\ttraining's auc: 0.865419\ttraining's binary_logloss: 0.133018\tvalid_1's auc: 0.831512\tvalid_1's binary_logloss: 0.136062\n",
            "[13]\ttraining's auc: 0.867122\ttraining's binary_logloss: 0.131934\tvalid_1's auc: 0.832059\tvalid_1's binary_logloss: 0.135513\n",
            "[14]\ttraining's auc: 0.869612\ttraining's binary_logloss: 0.130945\tvalid_1's auc: 0.831892\tvalid_1's binary_logloss: 0.13511\n",
            "[15]\ttraining's auc: 0.87056\ttraining's binary_logloss: 0.130085\tvalid_1's auc: 0.831843\tvalid_1's binary_logloss: 0.134687\n",
            "[16]\ttraining's auc: 0.871951\ttraining's binary_logloss: 0.129284\tvalid_1's auc: 0.83207\tvalid_1's binary_logloss: 0.134267\n",
            "[17]\ttraining's auc: 0.872889\ttraining's binary_logloss: 0.12856\tvalid_1's auc: 0.832416\tvalid_1's binary_logloss: 0.133956\n",
            "[18]\ttraining's auc: 0.874259\ttraining's binary_logloss: 0.127848\tvalid_1's auc: 0.832583\tvalid_1's binary_logloss: 0.13373\n",
            "[19]\ttraining's auc: 0.874882\ttraining's binary_logloss: 0.127214\tvalid_1's auc: 0.832746\tvalid_1's binary_logloss: 0.133486\n",
            "[20]\ttraining's auc: 0.876341\ttraining's binary_logloss: 0.126542\tvalid_1's auc: 0.832736\tvalid_1's binary_logloss: 0.133246\n",
            "[21]\ttraining's auc: 0.877581\ttraining's binary_logloss: 0.125916\tvalid_1's auc: 0.832357\tvalid_1's binary_logloss: 0.133061\n",
            "[22]\ttraining's auc: 0.878487\ttraining's binary_logloss: 0.125354\tvalid_1's auc: 0.832442\tvalid_1's binary_logloss: 0.132886\n",
            "[23]\ttraining's auc: 0.879651\ttraining's binary_logloss: 0.124781\tvalid_1's auc: 0.832417\tvalid_1's binary_logloss: 0.132741\n",
            "[24]\ttraining's auc: 0.881973\ttraining's binary_logloss: 0.124209\tvalid_1's auc: 0.83233\tvalid_1's binary_logloss: 0.132628\n",
            "[25]\ttraining's auc: 0.884105\ttraining's binary_logloss: 0.12364\tvalid_1's auc: 0.832673\tvalid_1's binary_logloss: 0.132459\n",
            "[26]\ttraining's auc: 0.885374\ttraining's binary_logloss: 0.123146\tvalid_1's auc: 0.83288\tvalid_1's binary_logloss: 0.13235\n",
            "[27]\ttraining's auc: 0.886669\ttraining's binary_logloss: 0.122663\tvalid_1's auc: 0.832848\tvalid_1's binary_logloss: 0.13226\n",
            "[28]\ttraining's auc: 0.887811\ttraining's binary_logloss: 0.12216\tvalid_1's auc: 0.833229\tvalid_1's binary_logloss: 0.132163\n",
            "[29]\ttraining's auc: 0.888664\ttraining's binary_logloss: 0.121757\tvalid_1's auc: 0.833144\tvalid_1's binary_logloss: 0.132105\n",
            "[30]\ttraining's auc: 0.889825\ttraining's binary_logloss: 0.121313\tvalid_1's auc: 0.833648\tvalid_1's binary_logloss: 0.132003\n",
            "[31]\ttraining's auc: 0.890863\ttraining's binary_logloss: 0.120901\tvalid_1's auc: 0.833313\tvalid_1's binary_logloss: 0.132003\n",
            "[32]\ttraining's auc: 0.891529\ttraining's binary_logloss: 0.1205\tvalid_1's auc: 0.833711\tvalid_1's binary_logloss: 0.131897\n",
            "[33]\ttraining's auc: 0.892356\ttraining's binary_logloss: 0.120117\tvalid_1's auc: 0.833699\tvalid_1's binary_logloss: 0.131852\n",
            "[34]\ttraining's auc: 0.893173\ttraining's binary_logloss: 0.119733\tvalid_1's auc: 0.834258\tvalid_1's binary_logloss: 0.131718\n",
            "[35]\ttraining's auc: 0.894212\ttraining's binary_logloss: 0.119369\tvalid_1's auc: 0.834278\tvalid_1's binary_logloss: 0.131689\n",
            "[36]\ttraining's auc: 0.894897\ttraining's binary_logloss: 0.119032\tvalid_1's auc: 0.834012\tvalid_1's binary_logloss: 0.131689\n",
            "[37]\ttraining's auc: 0.896012\ttraining's binary_logloss: 0.118685\tvalid_1's auc: 0.833824\tvalid_1's binary_logloss: 0.131711\n",
            "[38]\ttraining's auc: 0.898005\ttraining's binary_logloss: 0.11827\tvalid_1's auc: 0.833882\tvalid_1's binary_logloss: 0.131675\n",
            "[39]\ttraining's auc: 0.898702\ttraining's binary_logloss: 0.117973\tvalid_1's auc: 0.833842\tvalid_1's binary_logloss: 0.131625\n",
            "[40]\ttraining's auc: 0.899994\ttraining's binary_logloss: 0.117622\tvalid_1's auc: 0.834003\tvalid_1's binary_logloss: 0.131614\n",
            "[41]\ttraining's auc: 0.900858\ttraining's binary_logloss: 0.117253\tvalid_1's auc: 0.833908\tvalid_1's binary_logloss: 0.131591\n",
            "[42]\ttraining's auc: 0.901606\ttraining's binary_logloss: 0.116968\tvalid_1's auc: 0.834142\tvalid_1's binary_logloss: 0.131557\n",
            "[43]\ttraining's auc: 0.902764\ttraining's binary_logloss: 0.116656\tvalid_1's auc: 0.834375\tvalid_1's binary_logloss: 0.131493\n",
            "[44]\ttraining's auc: 0.903385\ttraining's binary_logloss: 0.116371\tvalid_1's auc: 0.834435\tvalid_1's binary_logloss: 0.131485\n",
            "[45]\ttraining's auc: 0.904491\ttraining's binary_logloss: 0.116031\tvalid_1's auc: 0.834291\tvalid_1's binary_logloss: 0.131511\n",
            "[46]\ttraining's auc: 0.905169\ttraining's binary_logloss: 0.115776\tvalid_1's auc: 0.834306\tvalid_1's binary_logloss: 0.131512\n",
            "[47]\ttraining's auc: 0.905999\ttraining's binary_logloss: 0.115428\tvalid_1's auc: 0.834462\tvalid_1's binary_logloss: 0.131508\n",
            "[48]\ttraining's auc: 0.906847\ttraining's binary_logloss: 0.115109\tvalid_1's auc: 0.834216\tvalid_1's binary_logloss: 0.131554\n",
            "[49]\ttraining's auc: 0.907849\ttraining's binary_logloss: 0.114762\tvalid_1's auc: 0.834071\tvalid_1's binary_logloss: 0.131557\n",
            "[50]\ttraining's auc: 0.908402\ttraining's binary_logloss: 0.114517\tvalid_1's auc: 0.833983\tvalid_1's binary_logloss: 0.131566\n",
            "[51]\ttraining's auc: 0.908981\ttraining's binary_logloss: 0.114227\tvalid_1's auc: 0.834146\tvalid_1's binary_logloss: 0.131552\n",
            "[52]\ttraining's auc: 0.909781\ttraining's binary_logloss: 0.113964\tvalid_1's auc: 0.834268\tvalid_1's binary_logloss: 0.131526\n",
            "[53]\ttraining's auc: 0.910493\ttraining's binary_logloss: 0.113707\tvalid_1's auc: 0.833997\tvalid_1's binary_logloss: 0.131553\n",
            "[54]\ttraining's auc: 0.911055\ttraining's binary_logloss: 0.11343\tvalid_1's auc: 0.834094\tvalid_1's binary_logloss: 0.131538\n",
            "[55]\ttraining's auc: 0.912084\ttraining's binary_logloss: 0.113149\tvalid_1's auc: 0.834493\tvalid_1's binary_logloss: 0.131467\n",
            "[56]\ttraining's auc: 0.912941\ttraining's binary_logloss: 0.112787\tvalid_1's auc: 0.834455\tvalid_1's binary_logloss: 0.131485\n",
            "[57]\ttraining's auc: 0.913247\ttraining's binary_logloss: 0.112614\tvalid_1's auc: 0.834693\tvalid_1's binary_logloss: 0.131455\n",
            "[58]\ttraining's auc: 0.913716\ttraining's binary_logloss: 0.11236\tvalid_1's auc: 0.834745\tvalid_1's binary_logloss: 0.13144\n",
            "[59]\ttraining's auc: 0.914187\ttraining's binary_logloss: 0.112114\tvalid_1's auc: 0.834862\tvalid_1's binary_logloss: 0.131382\n",
            "[60]\ttraining's auc: 0.914755\ttraining's binary_logloss: 0.111859\tvalid_1's auc: 0.834481\tvalid_1's binary_logloss: 0.131457\n",
            "[61]\ttraining's auc: 0.91538\ttraining's binary_logloss: 0.111562\tvalid_1's auc: 0.834471\tvalid_1's binary_logloss: 0.131438\n",
            "[62]\ttraining's auc: 0.915706\ttraining's binary_logloss: 0.111351\tvalid_1's auc: 0.834342\tvalid_1's binary_logloss: 0.131452\n",
            "[63]\ttraining's auc: 0.916155\ttraining's binary_logloss: 0.111093\tvalid_1's auc: 0.834205\tvalid_1's binary_logloss: 0.131476\n",
            "[64]\ttraining's auc: 0.916547\ttraining's binary_logloss: 0.110929\tvalid_1's auc: 0.833905\tvalid_1's binary_logloss: 0.131533\n",
            "[65]\ttraining's auc: 0.916959\ttraining's binary_logloss: 0.110706\tvalid_1's auc: 0.833759\tvalid_1's binary_logloss: 0.131558\n",
            "[66]\ttraining's auc: 0.917339\ttraining's binary_logloss: 0.110503\tvalid_1's auc: 0.833836\tvalid_1's binary_logloss: 0.131554\n",
            "[67]\ttraining's auc: 0.91783\ttraining's binary_logloss: 0.110243\tvalid_1's auc: 0.833988\tvalid_1's binary_logloss: 0.131542\n",
            "[68]\ttraining's auc: 0.918137\ttraining's binary_logloss: 0.110059\tvalid_1's auc: 0.83387\tvalid_1's binary_logloss: 0.131552\n",
            "[69]\ttraining's auc: 0.918638\ttraining's binary_logloss: 0.109813\tvalid_1's auc: 0.833607\tvalid_1's binary_logloss: 0.131572\n",
            "[70]\ttraining's auc: 0.919056\ttraining's binary_logloss: 0.109596\tvalid_1's auc: 0.833769\tvalid_1's binary_logloss: 0.131552\n",
            "[71]\ttraining's auc: 0.919432\ttraining's binary_logloss: 0.109401\tvalid_1's auc: 0.833692\tvalid_1's binary_logloss: 0.131575\n",
            "[72]\ttraining's auc: 0.919755\ttraining's binary_logloss: 0.109212\tvalid_1's auc: 0.83363\tvalid_1's binary_logloss: 0.131593\n",
            "[73]\ttraining's auc: 0.920111\ttraining's binary_logloss: 0.109007\tvalid_1's auc: 0.833434\tvalid_1's binary_logloss: 0.131631\n",
            "[74]\ttraining's auc: 0.920771\ttraining's binary_logloss: 0.10882\tvalid_1's auc: 0.833498\tvalid_1's binary_logloss: 0.13164\n",
            "[75]\ttraining's auc: 0.921213\ttraining's binary_logloss: 0.108603\tvalid_1's auc: 0.833297\tvalid_1's binary_logloss: 0.131685\n",
            "[76]\ttraining's auc: 0.921429\ttraining's binary_logloss: 0.10845\tvalid_1's auc: 0.833167\tvalid_1's binary_logloss: 0.131709\n",
            "[77]\ttraining's auc: 0.921665\ttraining's binary_logloss: 0.108292\tvalid_1's auc: 0.833217\tvalid_1's binary_logloss: 0.131691\n",
            "[78]\ttraining's auc: 0.922207\ttraining's binary_logloss: 0.108017\tvalid_1's auc: 0.833024\tvalid_1's binary_logloss: 0.13172\n",
            "[79]\ttraining's auc: 0.922496\ttraining's binary_logloss: 0.10783\tvalid_1's auc: 0.833075\tvalid_1's binary_logloss: 0.131759\n",
            "[80]\ttraining's auc: 0.922811\ttraining's binary_logloss: 0.107694\tvalid_1's auc: 0.833046\tvalid_1's binary_logloss: 0.131778\n",
            "[81]\ttraining's auc: 0.923281\ttraining's binary_logloss: 0.107459\tvalid_1's auc: 0.833033\tvalid_1's binary_logloss: 0.131759\n",
            "[82]\ttraining's auc: 0.92344\ttraining's binary_logloss: 0.107328\tvalid_1's auc: 0.83305\tvalid_1's binary_logloss: 0.131758\n",
            "[83]\ttraining's auc: 0.923823\ttraining's binary_logloss: 0.107118\tvalid_1's auc: 0.833256\tvalid_1's binary_logloss: 0.131739\n",
            "[84]\ttraining's auc: 0.924049\ttraining's binary_logloss: 0.106955\tvalid_1's auc: 0.833191\tvalid_1's binary_logloss: 0.131767\n",
            "[85]\ttraining's auc: 0.924521\ttraining's binary_logloss: 0.10675\tvalid_1's auc: 0.832992\tvalid_1's binary_logloss: 0.131813\n",
            "[86]\ttraining's auc: 0.924829\ttraining's binary_logloss: 0.106588\tvalid_1's auc: 0.832913\tvalid_1's binary_logloss: 0.131832\n",
            "[87]\ttraining's auc: 0.925149\ttraining's binary_logloss: 0.106405\tvalid_1's auc: 0.832825\tvalid_1's binary_logloss: 0.131856\n",
            "[88]\ttraining's auc: 0.925371\ttraining's binary_logloss: 0.106252\tvalid_1's auc: 0.832447\tvalid_1's binary_logloss: 0.131917\n",
            "[89]\ttraining's auc: 0.925553\ttraining's binary_logloss: 0.106136\tvalid_1's auc: 0.832309\tvalid_1's binary_logloss: 0.131945\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 48%|████▊     | 24/50 [11:41<12:48, 29.57s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.15574\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.161886\n",
            "[2]\ttraining's auc: 0.833051\ttraining's binary_logloss: 0.150637\tvalid_1's auc: 0.815832\tvalid_1's binary_logloss: 0.157214\n",
            "[3]\ttraining's auc: 0.838332\ttraining's binary_logloss: 0.146916\tvalid_1's auc: 0.817645\tvalid_1's binary_logloss: 0.154039\n",
            "[4]\ttraining's auc: 0.84567\ttraining's binary_logloss: 0.143621\tvalid_1's auc: 0.823086\tvalid_1's binary_logloss: 0.151494\n",
            "[5]\ttraining's auc: 0.848727\ttraining's binary_logloss: 0.14104\tvalid_1's auc: 0.824701\tvalid_1's binary_logloss: 0.14945\n",
            "[6]\ttraining's auc: 0.850926\ttraining's binary_logloss: 0.138854\tvalid_1's auc: 0.82601\tvalid_1's binary_logloss: 0.147616\n",
            "[7]\ttraining's auc: 0.853398\ttraining's binary_logloss: 0.136913\tvalid_1's auc: 0.82758\tvalid_1's binary_logloss: 0.146177\n",
            "[8]\ttraining's auc: 0.856144\ttraining's binary_logloss: 0.135267\tvalid_1's auc: 0.828492\tvalid_1's binary_logloss: 0.144959\n",
            "[9]\ttraining's auc: 0.858041\ttraining's binary_logloss: 0.133792\tvalid_1's auc: 0.829551\tvalid_1's binary_logloss: 0.143825\n",
            "[10]\ttraining's auc: 0.859981\ttraining's binary_logloss: 0.132519\tvalid_1's auc: 0.83006\tvalid_1's binary_logloss: 0.142926\n",
            "[11]\ttraining's auc: 0.861561\ttraining's binary_logloss: 0.131333\tvalid_1's auc: 0.829811\tvalid_1's binary_logloss: 0.142154\n",
            "[12]\ttraining's auc: 0.863071\ttraining's binary_logloss: 0.130227\tvalid_1's auc: 0.830425\tvalid_1's binary_logloss: 0.141474\n",
            "[13]\ttraining's auc: 0.866825\ttraining's binary_logloss: 0.12921\tvalid_1's auc: 0.830599\tvalid_1's binary_logloss: 0.140888\n",
            "[14]\ttraining's auc: 0.868735\ttraining's binary_logloss: 0.128283\tvalid_1's auc: 0.830778\tvalid_1's binary_logloss: 0.140404\n",
            "[15]\ttraining's auc: 0.870886\ttraining's binary_logloss: 0.127419\tvalid_1's auc: 0.832532\tvalid_1's binary_logloss: 0.140017\n",
            "[16]\ttraining's auc: 0.872594\ttraining's binary_logloss: 0.126592\tvalid_1's auc: 0.832917\tvalid_1's binary_logloss: 0.139616\n",
            "[17]\ttraining's auc: 0.875424\ttraining's binary_logloss: 0.125786\tvalid_1's auc: 0.833666\tvalid_1's binary_logloss: 0.139208\n",
            "[18]\ttraining's auc: 0.877439\ttraining's binary_logloss: 0.125047\tvalid_1's auc: 0.834006\tvalid_1's binary_logloss: 0.138885\n",
            "[19]\ttraining's auc: 0.879013\ttraining's binary_logloss: 0.124338\tvalid_1's auc: 0.833797\tvalid_1's binary_logloss: 0.138598\n",
            "[20]\ttraining's auc: 0.880215\ttraining's binary_logloss: 0.123721\tvalid_1's auc: 0.83409\tvalid_1's binary_logloss: 0.138296\n",
            "[21]\ttraining's auc: 0.88226\ttraining's binary_logloss: 0.123078\tvalid_1's auc: 0.834041\tvalid_1's binary_logloss: 0.138112\n",
            "[22]\ttraining's auc: 0.883524\ttraining's binary_logloss: 0.122515\tvalid_1's auc: 0.834368\tvalid_1's binary_logloss: 0.137853\n",
            "[23]\ttraining's auc: 0.884309\ttraining's binary_logloss: 0.121965\tvalid_1's auc: 0.834679\tvalid_1's binary_logloss: 0.137673\n",
            "[24]\ttraining's auc: 0.886096\ttraining's binary_logloss: 0.121325\tvalid_1's auc: 0.834386\tvalid_1's binary_logloss: 0.137623\n",
            "[25]\ttraining's auc: 0.887031\ttraining's binary_logloss: 0.12083\tvalid_1's auc: 0.834967\tvalid_1's binary_logloss: 0.137417\n",
            "[26]\ttraining's auc: 0.889012\ttraining's binary_logloss: 0.120296\tvalid_1's auc: 0.834813\tvalid_1's binary_logloss: 0.137307\n",
            "[27]\ttraining's auc: 0.890279\ttraining's binary_logloss: 0.119842\tvalid_1's auc: 0.834527\tvalid_1's binary_logloss: 0.137219\n",
            "[28]\ttraining's auc: 0.89117\ttraining's binary_logloss: 0.119403\tvalid_1's auc: 0.834461\tvalid_1's binary_logloss: 0.137125\n",
            "[29]\ttraining's auc: 0.892108\ttraining's binary_logloss: 0.119016\tvalid_1's auc: 0.834782\tvalid_1's binary_logloss: 0.137022\n",
            "[30]\ttraining's auc: 0.8936\ttraining's binary_logloss: 0.118516\tvalid_1's auc: 0.834557\tvalid_1's binary_logloss: 0.137\n",
            "[31]\ttraining's auc: 0.894758\ttraining's binary_logloss: 0.118039\tvalid_1's auc: 0.834547\tvalid_1's binary_logloss: 0.136958\n",
            "[32]\ttraining's auc: 0.895671\ttraining's binary_logloss: 0.117619\tvalid_1's auc: 0.835192\tvalid_1's binary_logloss: 0.13677\n",
            "[33]\ttraining's auc: 0.896824\ttraining's binary_logloss: 0.117224\tvalid_1's auc: 0.835064\tvalid_1's binary_logloss: 0.136727\n",
            "[34]\ttraining's auc: 0.897848\ttraining's binary_logloss: 0.116872\tvalid_1's auc: 0.83457\tvalid_1's binary_logloss: 0.13674\n",
            "[35]\ttraining's auc: 0.89848\ttraining's binary_logloss: 0.116557\tvalid_1's auc: 0.834527\tvalid_1's binary_logloss: 0.136702\n",
            "[36]\ttraining's auc: 0.899412\ttraining's binary_logloss: 0.116183\tvalid_1's auc: 0.834509\tvalid_1's binary_logloss: 0.136686\n",
            "[37]\ttraining's auc: 0.900317\ttraining's binary_logloss: 0.115826\tvalid_1's auc: 0.83445\tvalid_1's binary_logloss: 0.136658\n",
            "[38]\ttraining's auc: 0.900745\ttraining's binary_logloss: 0.115575\tvalid_1's auc: 0.834225\tvalid_1's binary_logloss: 0.136674\n",
            "[39]\ttraining's auc: 0.901712\ttraining's binary_logloss: 0.115271\tvalid_1's auc: 0.834065\tvalid_1's binary_logloss: 0.13671\n",
            "[40]\ttraining's auc: 0.902523\ttraining's binary_logloss: 0.114922\tvalid_1's auc: 0.833919\tvalid_1's binary_logloss: 0.136708\n",
            "[41]\ttraining's auc: 0.903303\ttraining's binary_logloss: 0.114551\tvalid_1's auc: 0.834015\tvalid_1's binary_logloss: 0.136655\n",
            "[42]\ttraining's auc: 0.903949\ttraining's binary_logloss: 0.114285\tvalid_1's auc: 0.833797\tvalid_1's binary_logloss: 0.136662\n",
            "[43]\ttraining's auc: 0.904884\ttraining's binary_logloss: 0.113945\tvalid_1's auc: 0.833889\tvalid_1's binary_logloss: 0.136699\n",
            "[44]\ttraining's auc: 0.905627\ttraining's binary_logloss: 0.113615\tvalid_1's auc: 0.833945\tvalid_1's binary_logloss: 0.136696\n",
            "[45]\ttraining's auc: 0.906325\ttraining's binary_logloss: 0.113315\tvalid_1's auc: 0.833818\tvalid_1's binary_logloss: 0.136721\n",
            "[46]\ttraining's auc: 0.906884\ttraining's binary_logloss: 0.113038\tvalid_1's auc: 0.833692\tvalid_1's binary_logloss: 0.136742\n",
            "[47]\ttraining's auc: 0.907846\ttraining's binary_logloss: 0.112623\tvalid_1's auc: 0.833822\tvalid_1's binary_logloss: 0.136745\n",
            "[48]\ttraining's auc: 0.9085\ttraining's binary_logloss: 0.112339\tvalid_1's auc: 0.833714\tvalid_1's binary_logloss: 0.136786\n",
            "[49]\ttraining's auc: 0.909079\ttraining's binary_logloss: 0.112019\tvalid_1's auc: 0.833824\tvalid_1's binary_logloss: 0.136777\n",
            "[50]\ttraining's auc: 0.909631\ttraining's binary_logloss: 0.111756\tvalid_1's auc: 0.833875\tvalid_1's binary_logloss: 0.136798\n",
            "[51]\ttraining's auc: 0.909967\ttraining's binary_logloss: 0.111543\tvalid_1's auc: 0.834032\tvalid_1's binary_logloss: 0.136784\n",
            "[52]\ttraining's auc: 0.910758\ttraining's binary_logloss: 0.111322\tvalid_1's auc: 0.834173\tvalid_1's binary_logloss: 0.136772\n",
            "[53]\ttraining's auc: 0.911341\ttraining's binary_logloss: 0.111072\tvalid_1's auc: 0.834024\tvalid_1's binary_logloss: 0.136809\n",
            "[54]\ttraining's auc: 0.912139\ttraining's binary_logloss: 0.110807\tvalid_1's auc: 0.834005\tvalid_1's binary_logloss: 0.136823\n",
            "[55]\ttraining's auc: 0.912712\ttraining's binary_logloss: 0.110541\tvalid_1's auc: 0.834302\tvalid_1's binary_logloss: 0.136767\n",
            "[56]\ttraining's auc: 0.913099\ttraining's binary_logloss: 0.110341\tvalid_1's auc: 0.83427\tvalid_1's binary_logloss: 0.136818\n",
            "[57]\ttraining's auc: 0.913481\ttraining's binary_logloss: 0.110101\tvalid_1's auc: 0.834465\tvalid_1's binary_logloss: 0.136776\n",
            "[58]\ttraining's auc: 0.913962\ttraining's binary_logloss: 0.109871\tvalid_1's auc: 0.834542\tvalid_1's binary_logloss: 0.136767\n",
            "[59]\ttraining's auc: 0.914345\ttraining's binary_logloss: 0.109655\tvalid_1's auc: 0.834431\tvalid_1's binary_logloss: 0.136799\n",
            "[60]\ttraining's auc: 0.914689\ttraining's binary_logloss: 0.109467\tvalid_1's auc: 0.834256\tvalid_1's binary_logloss: 0.136829\n",
            "[61]\ttraining's auc: 0.9151\ttraining's binary_logloss: 0.109215\tvalid_1's auc: 0.834324\tvalid_1's binary_logloss: 0.136862\n",
            "[62]\ttraining's auc: 0.915394\ttraining's binary_logloss: 0.109036\tvalid_1's auc: 0.834076\tvalid_1's binary_logloss: 0.136913\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 50%|█████     | 25/50 [11:49<11:43, 28.15s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.163542\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.164582\n",
            "[2]\ttraining's auc: 0.826351\ttraining's binary_logloss: 0.162574\tvalid_1's auc: 0.804883\tvalid_1's binary_logloss: 0.163768\n",
            "[3]\ttraining's auc: 0.827591\ttraining's binary_logloss: 0.16165\tvalid_1's auc: 0.805185\tvalid_1's binary_logloss: 0.16299\n",
            "[4]\ttraining's auc: 0.828227\ttraining's binary_logloss: 0.160767\tvalid_1's auc: 0.805857\tvalid_1's binary_logloss: 0.162281\n",
            "[5]\ttraining's auc: 0.832278\ttraining's binary_logloss: 0.159921\tvalid_1's auc: 0.807828\tvalid_1's binary_logloss: 0.161617\n",
            "[6]\ttraining's auc: 0.833476\ttraining's binary_logloss: 0.159115\tvalid_1's auc: 0.808111\tvalid_1's binary_logloss: 0.160986\n",
            "[7]\ttraining's auc: 0.834368\ttraining's binary_logloss: 0.158345\tvalid_1's auc: 0.80782\tvalid_1's binary_logloss: 0.160384\n",
            "[8]\ttraining's auc: 0.834294\ttraining's binary_logloss: 0.157611\tvalid_1's auc: 0.808163\tvalid_1's binary_logloss: 0.159784\n",
            "[9]\ttraining's auc: 0.835776\ttraining's binary_logloss: 0.156898\tvalid_1's auc: 0.808603\tvalid_1's binary_logloss: 0.159237\n",
            "[10]\ttraining's auc: 0.836092\ttraining's binary_logloss: 0.156214\tvalid_1's auc: 0.808388\tvalid_1's binary_logloss: 0.158718\n",
            "[11]\ttraining's auc: 0.836384\ttraining's binary_logloss: 0.155553\tvalid_1's auc: 0.808594\tvalid_1's binary_logloss: 0.158195\n",
            "[12]\ttraining's auc: 0.836415\ttraining's binary_logloss: 0.154923\tvalid_1's auc: 0.808647\tvalid_1's binary_logloss: 0.157704\n",
            "[13]\ttraining's auc: 0.837247\ttraining's binary_logloss: 0.154297\tvalid_1's auc: 0.809342\tvalid_1's binary_logloss: 0.157201\n",
            "[14]\ttraining's auc: 0.837364\ttraining's binary_logloss: 0.153709\tvalid_1's auc: 0.809169\tvalid_1's binary_logloss: 0.156753\n",
            "[15]\ttraining's auc: 0.837408\ttraining's binary_logloss: 0.153144\tvalid_1's auc: 0.809437\tvalid_1's binary_logloss: 0.156296\n",
            "[16]\ttraining's auc: 0.838353\ttraining's binary_logloss: 0.152599\tvalid_1's auc: 0.810215\tvalid_1's binary_logloss: 0.155861\n",
            "[17]\ttraining's auc: 0.838585\ttraining's binary_logloss: 0.152066\tvalid_1's auc: 0.810487\tvalid_1's binary_logloss: 0.155434\n",
            "[18]\ttraining's auc: 0.838841\ttraining's binary_logloss: 0.151546\tvalid_1's auc: 0.810599\tvalid_1's binary_logloss: 0.155031\n",
            "[19]\ttraining's auc: 0.841136\ttraining's binary_logloss: 0.151044\tvalid_1's auc: 0.812536\tvalid_1's binary_logloss: 0.154618\n",
            "[20]\ttraining's auc: 0.842317\ttraining's binary_logloss: 0.150548\tvalid_1's auc: 0.81371\tvalid_1's binary_logloss: 0.154228\n",
            "[21]\ttraining's auc: 0.843422\ttraining's binary_logloss: 0.15007\tvalid_1's auc: 0.814403\tvalid_1's binary_logloss: 0.153869\n",
            "[22]\ttraining's auc: 0.84443\ttraining's binary_logloss: 0.149603\tvalid_1's auc: 0.814734\tvalid_1's binary_logloss: 0.153513\n",
            "[23]\ttraining's auc: 0.844707\ttraining's binary_logloss: 0.149159\tvalid_1's auc: 0.814832\tvalid_1's binary_logloss: 0.153159\n",
            "[24]\ttraining's auc: 0.845189\ttraining's binary_logloss: 0.148722\tvalid_1's auc: 0.815005\tvalid_1's binary_logloss: 0.152815\n",
            "[25]\ttraining's auc: 0.845277\ttraining's binary_logloss: 0.148297\tvalid_1's auc: 0.815284\tvalid_1's binary_logloss: 0.152484\n",
            "[26]\ttraining's auc: 0.846059\ttraining's binary_logloss: 0.147884\tvalid_1's auc: 0.816188\tvalid_1's binary_logloss: 0.152154\n",
            "[27]\ttraining's auc: 0.847099\ttraining's binary_logloss: 0.14748\tvalid_1's auc: 0.816927\tvalid_1's binary_logloss: 0.151837\n",
            "[28]\ttraining's auc: 0.84753\ttraining's binary_logloss: 0.147077\tvalid_1's auc: 0.816995\tvalid_1's binary_logloss: 0.151535\n",
            "[29]\ttraining's auc: 0.847808\ttraining's binary_logloss: 0.14668\tvalid_1's auc: 0.817071\tvalid_1's binary_logloss: 0.151255\n",
            "[30]\ttraining's auc: 0.848423\ttraining's binary_logloss: 0.146291\tvalid_1's auc: 0.817722\tvalid_1's binary_logloss: 0.150955\n",
            "[31]\ttraining's auc: 0.848754\ttraining's binary_logloss: 0.145909\tvalid_1's auc: 0.818166\tvalid_1's binary_logloss: 0.150654\n",
            "[32]\ttraining's auc: 0.84903\ttraining's binary_logloss: 0.145538\tvalid_1's auc: 0.818312\tvalid_1's binary_logloss: 0.150359\n",
            "[33]\ttraining's auc: 0.849199\ttraining's binary_logloss: 0.145179\tvalid_1's auc: 0.818801\tvalid_1's binary_logloss: 0.150086\n",
            "[34]\ttraining's auc: 0.849895\ttraining's binary_logloss: 0.144814\tvalid_1's auc: 0.819359\tvalid_1's binary_logloss: 0.149804\n",
            "[35]\ttraining's auc: 0.850186\ttraining's binary_logloss: 0.144451\tvalid_1's auc: 0.819504\tvalid_1's binary_logloss: 0.149538\n",
            "[36]\ttraining's auc: 0.850334\ttraining's binary_logloss: 0.144105\tvalid_1's auc: 0.819579\tvalid_1's binary_logloss: 0.149281\n",
            "[37]\ttraining's auc: 0.850893\ttraining's binary_logloss: 0.14377\tvalid_1's auc: 0.820233\tvalid_1's binary_logloss: 0.149031\n",
            "[38]\ttraining's auc: 0.851003\ttraining's binary_logloss: 0.143439\tvalid_1's auc: 0.82049\tvalid_1's binary_logloss: 0.148789\n",
            "[39]\ttraining's auc: 0.851153\ttraining's binary_logloss: 0.14312\tvalid_1's auc: 0.820363\tvalid_1's binary_logloss: 0.148553\n",
            "[40]\ttraining's auc: 0.852127\ttraining's binary_logloss: 0.142812\tvalid_1's auc: 0.821142\tvalid_1's binary_logloss: 0.148332\n",
            "[41]\ttraining's auc: 0.85236\ttraining's binary_logloss: 0.142508\tvalid_1's auc: 0.821391\tvalid_1's binary_logloss: 0.148107\n",
            "[42]\ttraining's auc: 0.851978\ttraining's binary_logloss: 0.142213\tvalid_1's auc: 0.821439\tvalid_1's binary_logloss: 0.14789\n",
            "[43]\ttraining's auc: 0.852557\ttraining's binary_logloss: 0.141924\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.147679\n",
            "[44]\ttraining's auc: 0.852839\ttraining's binary_logloss: 0.141633\tvalid_1's auc: 0.821686\tvalid_1's binary_logloss: 0.147464\n",
            "[45]\ttraining's auc: 0.853162\ttraining's binary_logloss: 0.141348\tvalid_1's auc: 0.821833\tvalid_1's binary_logloss: 0.147253\n",
            "[46]\ttraining's auc: 0.853396\ttraining's binary_logloss: 0.141069\tvalid_1's auc: 0.822288\tvalid_1's binary_logloss: 0.147047\n",
            "[47]\ttraining's auc: 0.853667\ttraining's binary_logloss: 0.140798\tvalid_1's auc: 0.822395\tvalid_1's binary_logloss: 0.146858\n",
            "[48]\ttraining's auc: 0.85445\ttraining's binary_logloss: 0.14053\tvalid_1's auc: 0.82312\tvalid_1's binary_logloss: 0.146661\n",
            "[49]\ttraining's auc: 0.854545\ttraining's binary_logloss: 0.140272\tvalid_1's auc: 0.82315\tvalid_1's binary_logloss: 0.146476\n",
            "[50]\ttraining's auc: 0.854681\ttraining's binary_logloss: 0.14002\tvalid_1's auc: 0.823177\tvalid_1's binary_logloss: 0.146289\n",
            "[51]\ttraining's auc: 0.854766\ttraining's binary_logloss: 0.139764\tvalid_1's auc: 0.823066\tvalid_1's binary_logloss: 0.146119\n",
            "[52]\ttraining's auc: 0.854989\ttraining's binary_logloss: 0.13952\tvalid_1's auc: 0.823036\tvalid_1's binary_logloss: 0.145937\n",
            "[53]\ttraining's auc: 0.854995\ttraining's binary_logloss: 0.139276\tvalid_1's auc: 0.823053\tvalid_1's binary_logloss: 0.145767\n",
            "[54]\ttraining's auc: 0.855279\ttraining's binary_logloss: 0.139038\tvalid_1's auc: 0.823116\tvalid_1's binary_logloss: 0.145592\n",
            "[55]\ttraining's auc: 0.855393\ttraining's binary_logloss: 0.138798\tvalid_1's auc: 0.823108\tvalid_1's binary_logloss: 0.14543\n",
            "[56]\ttraining's auc: 0.857407\ttraining's binary_logloss: 0.13857\tvalid_1's auc: 0.823644\tvalid_1's binary_logloss: 0.145268\n",
            "[57]\ttraining's auc: 0.857498\ttraining's binary_logloss: 0.138344\tvalid_1's auc: 0.823706\tvalid_1's binary_logloss: 0.145099\n",
            "[58]\ttraining's auc: 0.85763\ttraining's binary_logloss: 0.138108\tvalid_1's auc: 0.823754\tvalid_1's binary_logloss: 0.144941\n",
            "[59]\ttraining's auc: 0.857789\ttraining's binary_logloss: 0.137882\tvalid_1's auc: 0.823686\tvalid_1's binary_logloss: 0.144788\n",
            "[60]\ttraining's auc: 0.858005\ttraining's binary_logloss: 0.13766\tvalid_1's auc: 0.82435\tvalid_1's binary_logloss: 0.144629\n",
            "[61]\ttraining's auc: 0.858109\ttraining's binary_logloss: 0.137439\tvalid_1's auc: 0.824255\tvalid_1's binary_logloss: 0.144487\n",
            "[62]\ttraining's auc: 0.858396\ttraining's binary_logloss: 0.137224\tvalid_1's auc: 0.824286\tvalid_1's binary_logloss: 0.144342\n",
            "[63]\ttraining's auc: 0.858627\ttraining's binary_logloss: 0.137011\tvalid_1's auc: 0.824423\tvalid_1's binary_logloss: 0.144199\n",
            "[64]\ttraining's auc: 0.858906\ttraining's binary_logloss: 0.136804\tvalid_1's auc: 0.824478\tvalid_1's binary_logloss: 0.144058\n",
            "[65]\ttraining's auc: 0.859065\ttraining's binary_logloss: 0.136598\tvalid_1's auc: 0.824631\tvalid_1's binary_logloss: 0.143916\n",
            "[66]\ttraining's auc: 0.859143\ttraining's binary_logloss: 0.136398\tvalid_1's auc: 0.824541\tvalid_1's binary_logloss: 0.143786\n",
            "[67]\ttraining's auc: 0.859321\ttraining's binary_logloss: 0.136193\tvalid_1's auc: 0.824549\tvalid_1's binary_logloss: 0.143662\n",
            "[68]\ttraining's auc: 0.859486\ttraining's binary_logloss: 0.135994\tvalid_1's auc: 0.824446\tvalid_1's binary_logloss: 0.143543\n",
            "[69]\ttraining's auc: 0.859658\ttraining's binary_logloss: 0.135802\tvalid_1's auc: 0.824484\tvalid_1's binary_logloss: 0.143412\n",
            "[70]\ttraining's auc: 0.859855\ttraining's binary_logloss: 0.135624\tvalid_1's auc: 0.824678\tvalid_1's binary_logloss: 0.14328\n",
            "[71]\ttraining's auc: 0.860405\ttraining's binary_logloss: 0.135418\tvalid_1's auc: 0.824847\tvalid_1's binary_logloss: 0.143152\n",
            "[72]\ttraining's auc: 0.860637\ttraining's binary_logloss: 0.135246\tvalid_1's auc: 0.825017\tvalid_1's binary_logloss: 0.143019\n",
            "[73]\ttraining's auc: 0.861021\ttraining's binary_logloss: 0.135051\tvalid_1's auc: 0.825027\tvalid_1's binary_logloss: 0.142892\n",
            "[74]\ttraining's auc: 0.861401\ttraining's binary_logloss: 0.134867\tvalid_1's auc: 0.82523\tvalid_1's binary_logloss: 0.14277\n",
            "[75]\ttraining's auc: 0.861815\ttraining's binary_logloss: 0.134683\tvalid_1's auc: 0.825185\tvalid_1's binary_logloss: 0.142652\n",
            "[76]\ttraining's auc: 0.862199\ttraining's binary_logloss: 0.134505\tvalid_1's auc: 0.825264\tvalid_1's binary_logloss: 0.142536\n",
            "[77]\ttraining's auc: 0.862423\ttraining's binary_logloss: 0.134332\tvalid_1's auc: 0.825322\tvalid_1's binary_logloss: 0.14243\n",
            "[78]\ttraining's auc: 0.862602\ttraining's binary_logloss: 0.134164\tvalid_1's auc: 0.825376\tvalid_1's binary_logloss: 0.142314\n",
            "[79]\ttraining's auc: 0.862676\ttraining's binary_logloss: 0.134\tvalid_1's auc: 0.825473\tvalid_1's binary_logloss: 0.142196\n",
            "[80]\ttraining's auc: 0.862914\ttraining's binary_logloss: 0.133836\tvalid_1's auc: 0.825346\tvalid_1's binary_logloss: 0.142094\n",
            "[81]\ttraining's auc: 0.863005\ttraining's binary_logloss: 0.133677\tvalid_1's auc: 0.825326\tvalid_1's binary_logloss: 0.141994\n",
            "[82]\ttraining's auc: 0.863299\ttraining's binary_logloss: 0.133512\tvalid_1's auc: 0.825569\tvalid_1's binary_logloss: 0.141893\n",
            "[83]\ttraining's auc: 0.86347\ttraining's binary_logloss: 0.133348\tvalid_1's auc: 0.825772\tvalid_1's binary_logloss: 0.141801\n",
            "[84]\ttraining's auc: 0.864039\ttraining's binary_logloss: 0.133189\tvalid_1's auc: 0.826208\tvalid_1's binary_logloss: 0.141685\n",
            "[85]\ttraining's auc: 0.864346\ttraining's binary_logloss: 0.133033\tvalid_1's auc: 0.826135\tvalid_1's binary_logloss: 0.141585\n",
            "[86]\ttraining's auc: 0.864837\ttraining's binary_logloss: 0.13288\tvalid_1's auc: 0.826573\tvalid_1's binary_logloss: 0.141476\n",
            "[87]\ttraining's auc: 0.86492\ttraining's binary_logloss: 0.132734\tvalid_1's auc: 0.826778\tvalid_1's binary_logloss: 0.141383\n",
            "[88]\ttraining's auc: 0.865215\ttraining's binary_logloss: 0.132584\tvalid_1's auc: 0.826689\tvalid_1's binary_logloss: 0.141293\n",
            "[89]\ttraining's auc: 0.865339\ttraining's binary_logloss: 0.132443\tvalid_1's auc: 0.82674\tvalid_1's binary_logloss: 0.141209\n",
            "[90]\ttraining's auc: 0.865417\ttraining's binary_logloss: 0.132295\tvalid_1's auc: 0.826802\tvalid_1's binary_logloss: 0.141128\n",
            "[91]\ttraining's auc: 0.865672\ttraining's binary_logloss: 0.132152\tvalid_1's auc: 0.826821\tvalid_1's binary_logloss: 0.141038\n",
            "[92]\ttraining's auc: 0.865843\ttraining's binary_logloss: 0.132015\tvalid_1's auc: 0.8269\tvalid_1's binary_logloss: 0.140951\n",
            "[93]\ttraining's auc: 0.866076\ttraining's binary_logloss: 0.131875\tvalid_1's auc: 0.826875\tvalid_1's binary_logloss: 0.140871\n",
            "[94]\ttraining's auc: 0.8663\ttraining's binary_logloss: 0.131734\tvalid_1's auc: 0.827049\tvalid_1's binary_logloss: 0.14079\n",
            "[95]\ttraining's auc: 0.866628\ttraining's binary_logloss: 0.131601\tvalid_1's auc: 0.827093\tvalid_1's binary_logloss: 0.140702\n",
            "[96]\ttraining's auc: 0.866811\ttraining's binary_logloss: 0.131471\tvalid_1's auc: 0.827218\tvalid_1's binary_logloss: 0.140621\n",
            "[97]\ttraining's auc: 0.866958\ttraining's binary_logloss: 0.131329\tvalid_1's auc: 0.827292\tvalid_1's binary_logloss: 0.140539\n",
            "[98]\ttraining's auc: 0.867251\ttraining's binary_logloss: 0.131195\tvalid_1's auc: 0.827266\tvalid_1's binary_logloss: 0.140468\n",
            "[99]\ttraining's auc: 0.867582\ttraining's binary_logloss: 0.131064\tvalid_1's auc: 0.82732\tvalid_1's binary_logloss: 0.140396\n",
            "[100]\ttraining's auc: 0.867776\ttraining's binary_logloss: 0.130928\tvalid_1's auc: 0.827383\tvalid_1's binary_logloss: 0.140317\n",
            "[101]\ttraining's auc: 0.86773\ttraining's binary_logloss: 0.130803\tvalid_1's auc: 0.827199\tvalid_1's binary_logloss: 0.140238\n",
            "[102]\ttraining's auc: 0.868146\ttraining's binary_logloss: 0.130678\tvalid_1's auc: 0.827645\tvalid_1's binary_logloss: 0.140159\n",
            "[103]\ttraining's auc: 0.868425\ttraining's binary_logloss: 0.130553\tvalid_1's auc: 0.827788\tvalid_1's binary_logloss: 0.140093\n",
            "[104]\ttraining's auc: 0.868598\ttraining's binary_logloss: 0.130433\tvalid_1's auc: 0.827853\tvalid_1's binary_logloss: 0.14002\n",
            "[105]\ttraining's auc: 0.868788\ttraining's binary_logloss: 0.130304\tvalid_1's auc: 0.827851\tvalid_1's binary_logloss: 0.13995\n",
            "[106]\ttraining's auc: 0.868957\ttraining's binary_logloss: 0.130178\tvalid_1's auc: 0.827842\tvalid_1's binary_logloss: 0.139889\n",
            "[107]\ttraining's auc: 0.869151\ttraining's binary_logloss: 0.130058\tvalid_1's auc: 0.82783\tvalid_1's binary_logloss: 0.139827\n",
            "[108]\ttraining's auc: 0.869339\ttraining's binary_logloss: 0.129932\tvalid_1's auc: 0.827836\tvalid_1's binary_logloss: 0.139763\n",
            "[109]\ttraining's auc: 0.869432\ttraining's binary_logloss: 0.129817\tvalid_1's auc: 0.827809\tvalid_1's binary_logloss: 0.139709\n",
            "[110]\ttraining's auc: 0.869594\ttraining's binary_logloss: 0.129702\tvalid_1's auc: 0.827767\tvalid_1's binary_logloss: 0.139653\n",
            "[111]\ttraining's auc: 0.86974\ttraining's binary_logloss: 0.129584\tvalid_1's auc: 0.827809\tvalid_1's binary_logloss: 0.139589\n",
            "[112]\ttraining's auc: 0.869979\ttraining's binary_logloss: 0.129468\tvalid_1's auc: 0.827904\tvalid_1's binary_logloss: 0.139537\n",
            "[113]\ttraining's auc: 0.870097\ttraining's binary_logloss: 0.129351\tvalid_1's auc: 0.827717\tvalid_1's binary_logloss: 0.139481\n",
            "[114]\ttraining's auc: 0.870295\ttraining's binary_logloss: 0.129241\tvalid_1's auc: 0.827761\tvalid_1's binary_logloss: 0.139433\n",
            "[115]\ttraining's auc: 0.870444\ttraining's binary_logloss: 0.12913\tvalid_1's auc: 0.827824\tvalid_1's binary_logloss: 0.139372\n",
            "[116]\ttraining's auc: 0.870642\ttraining's binary_logloss: 0.129021\tvalid_1's auc: 0.82774\tvalid_1's binary_logloss: 0.139314\n",
            "[117]\ttraining's auc: 0.870757\ttraining's binary_logloss: 0.128912\tvalid_1's auc: 0.827723\tvalid_1's binary_logloss: 0.139254\n",
            "[118]\ttraining's auc: 0.870941\ttraining's binary_logloss: 0.128807\tvalid_1's auc: 0.827724\tvalid_1's binary_logloss: 0.139201\n",
            "[119]\ttraining's auc: 0.871057\ttraining's binary_logloss: 0.128706\tvalid_1's auc: 0.827779\tvalid_1's binary_logloss: 0.139141\n",
            "[120]\ttraining's auc: 0.871259\ttraining's binary_logloss: 0.128596\tvalid_1's auc: 0.827803\tvalid_1's binary_logloss: 0.139086\n",
            "[121]\ttraining's auc: 0.87151\ttraining's binary_logloss: 0.128493\tvalid_1's auc: 0.827821\tvalid_1's binary_logloss: 0.139026\n",
            "[122]\ttraining's auc: 0.871689\ttraining's binary_logloss: 0.128393\tvalid_1's auc: 0.827904\tvalid_1's binary_logloss: 0.13898\n",
            "[123]\ttraining's auc: 0.871916\ttraining's binary_logloss: 0.128282\tvalid_1's auc: 0.828153\tvalid_1's binary_logloss: 0.138925\n",
            "[124]\ttraining's auc: 0.872027\ttraining's binary_logloss: 0.128189\tvalid_1's auc: 0.828203\tvalid_1's binary_logloss: 0.138869\n",
            "[125]\ttraining's auc: 0.872322\ttraining's binary_logloss: 0.128076\tvalid_1's auc: 0.828277\tvalid_1's binary_logloss: 0.138816\n",
            "[126]\ttraining's auc: 0.872569\ttraining's binary_logloss: 0.127974\tvalid_1's auc: 0.828233\tvalid_1's binary_logloss: 0.138778\n",
            "[127]\ttraining's auc: 0.87278\ttraining's binary_logloss: 0.127867\tvalid_1's auc: 0.828235\tvalid_1's binary_logloss: 0.138729\n",
            "[128]\ttraining's auc: 0.872968\ttraining's binary_logloss: 0.127762\tvalid_1's auc: 0.828339\tvalid_1's binary_logloss: 0.138675\n",
            "[129]\ttraining's auc: 0.87325\ttraining's binary_logloss: 0.127651\tvalid_1's auc: 0.82843\tvalid_1's binary_logloss: 0.138632\n",
            "[130]\ttraining's auc: 0.873355\ttraining's binary_logloss: 0.127549\tvalid_1's auc: 0.828483\tvalid_1's binary_logloss: 0.13859\n",
            "[131]\ttraining's auc: 0.873725\ttraining's binary_logloss: 0.127451\tvalid_1's auc: 0.828594\tvalid_1's binary_logloss: 0.138552\n",
            "[132]\ttraining's auc: 0.873932\ttraining's binary_logloss: 0.127349\tvalid_1's auc: 0.828541\tvalid_1's binary_logloss: 0.138512\n",
            "[133]\ttraining's auc: 0.874116\ttraining's binary_logloss: 0.127249\tvalid_1's auc: 0.82852\tvalid_1's binary_logloss: 0.138468\n",
            "[134]\ttraining's auc: 0.874418\ttraining's binary_logloss: 0.127148\tvalid_1's auc: 0.828547\tvalid_1's binary_logloss: 0.138433\n",
            "[135]\ttraining's auc: 0.874599\ttraining's binary_logloss: 0.127051\tvalid_1's auc: 0.828479\tvalid_1's binary_logloss: 0.138396\n",
            "[136]\ttraining's auc: 0.874775\ttraining's binary_logloss: 0.126953\tvalid_1's auc: 0.828452\tvalid_1's binary_logloss: 0.138358\n",
            "[137]\ttraining's auc: 0.874908\ttraining's binary_logloss: 0.126857\tvalid_1's auc: 0.828403\tvalid_1's binary_logloss: 0.138325\n",
            "[138]\ttraining's auc: 0.875102\ttraining's binary_logloss: 0.126765\tvalid_1's auc: 0.828399\tvalid_1's binary_logloss: 0.138291\n",
            "[139]\ttraining's auc: 0.875274\ttraining's binary_logloss: 0.126676\tvalid_1's auc: 0.828418\tvalid_1's binary_logloss: 0.138253\n",
            "[140]\ttraining's auc: 0.875475\ttraining's binary_logloss: 0.126583\tvalid_1's auc: 0.828326\tvalid_1's binary_logloss: 0.138221\n",
            "[141]\ttraining's auc: 0.875615\ttraining's binary_logloss: 0.126494\tvalid_1's auc: 0.828379\tvalid_1's binary_logloss: 0.138186\n",
            "[142]\ttraining's auc: 0.875723\ttraining's binary_logloss: 0.126409\tvalid_1's auc: 0.828362\tvalid_1's binary_logloss: 0.138153\n",
            "[143]\ttraining's auc: 0.875869\ttraining's binary_logloss: 0.126315\tvalid_1's auc: 0.828402\tvalid_1's binary_logloss: 0.138115\n",
            "[144]\ttraining's auc: 0.875955\ttraining's binary_logloss: 0.126233\tvalid_1's auc: 0.828341\tvalid_1's binary_logloss: 0.138081\n",
            "[145]\ttraining's auc: 0.876433\ttraining's binary_logloss: 0.126138\tvalid_1's auc: 0.828351\tvalid_1's binary_logloss: 0.138044\n",
            "[146]\ttraining's auc: 0.876538\ttraining's binary_logloss: 0.126056\tvalid_1's auc: 0.828334\tvalid_1's binary_logloss: 0.138011\n",
            "[147]\ttraining's auc: 0.876832\ttraining's binary_logloss: 0.125962\tvalid_1's auc: 0.828359\tvalid_1's binary_logloss: 0.137978\n",
            "[148]\ttraining's auc: 0.876962\ttraining's binary_logloss: 0.125881\tvalid_1's auc: 0.82836\tvalid_1's binary_logloss: 0.137947\n",
            "[149]\ttraining's auc: 0.877062\ttraining's binary_logloss: 0.125802\tvalid_1's auc: 0.828383\tvalid_1's binary_logloss: 0.137918\n",
            "[150]\ttraining's auc: 0.877185\ttraining's binary_logloss: 0.125716\tvalid_1's auc: 0.828377\tvalid_1's binary_logloss: 0.13789\n",
            "[151]\ttraining's auc: 0.87732\ttraining's binary_logloss: 0.125637\tvalid_1's auc: 0.828406\tvalid_1's binary_logloss: 0.137858\n",
            "[152]\ttraining's auc: 0.877611\ttraining's binary_logloss: 0.125547\tvalid_1's auc: 0.82848\tvalid_1's binary_logloss: 0.137829\n",
            "[153]\ttraining's auc: 0.877727\ttraining's binary_logloss: 0.125469\tvalid_1's auc: 0.828499\tvalid_1's binary_logloss: 0.137801\n",
            "[154]\ttraining's auc: 0.877824\ttraining's binary_logloss: 0.125394\tvalid_1's auc: 0.828448\tvalid_1's binary_logloss: 0.137777\n",
            "[155]\ttraining's auc: 0.878007\ttraining's binary_logloss: 0.12531\tvalid_1's auc: 0.828406\tvalid_1's binary_logloss: 0.137746\n",
            "[156]\ttraining's auc: 0.878403\ttraining's binary_logloss: 0.125219\tvalid_1's auc: 0.828372\tvalid_1's binary_logloss: 0.137719\n",
            "[157]\ttraining's auc: 0.878572\ttraining's binary_logloss: 0.125137\tvalid_1's auc: 0.828399\tvalid_1's binary_logloss: 0.137687\n",
            "[158]\ttraining's auc: 0.878614\ttraining's binary_logloss: 0.125062\tvalid_1's auc: 0.828363\tvalid_1's binary_logloss: 0.137657\n",
            "[159]\ttraining's auc: 0.878816\ttraining's binary_logloss: 0.124977\tvalid_1's auc: 0.828373\tvalid_1's binary_logloss: 0.137629\n",
            "[160]\ttraining's auc: 0.878938\ttraining's binary_logloss: 0.124895\tvalid_1's auc: 0.828381\tvalid_1's binary_logloss: 0.137607\n",
            "[161]\ttraining's auc: 0.879093\ttraining's binary_logloss: 0.124819\tvalid_1's auc: 0.82843\tvalid_1's binary_logloss: 0.137579\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 50%|█████     | 25/50 [12:05<11:43, 28.15s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.165913\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.159937\n",
            "[2]\ttraining's auc: 0.819182\ttraining's binary_logloss: 0.164951\tvalid_1's auc: 0.802753\tvalid_1's binary_logloss: 0.159166\n",
            "[3]\ttraining's auc: 0.821082\ttraining's binary_logloss: 0.164043\tvalid_1's auc: 0.805174\tvalid_1's binary_logloss: 0.158425\n",
            "[4]\ttraining's auc: 0.821731\ttraining's binary_logloss: 0.163182\tvalid_1's auc: 0.80527\tvalid_1's binary_logloss: 0.157737\n",
            "[5]\ttraining's auc: 0.823119\ttraining's binary_logloss: 0.162351\tvalid_1's auc: 0.805754\tvalid_1's binary_logloss: 0.157067\n",
            "[6]\ttraining's auc: 0.823493\ttraining's binary_logloss: 0.161556\tvalid_1's auc: 0.805624\tvalid_1's binary_logloss: 0.156422\n",
            "[7]\ttraining's auc: 0.829249\ttraining's binary_logloss: 0.16079\tvalid_1's auc: 0.816217\tvalid_1's binary_logloss: 0.155787\n",
            "[8]\ttraining's auc: 0.829813\ttraining's binary_logloss: 0.160045\tvalid_1's auc: 0.817676\tvalid_1's binary_logloss: 0.15517\n",
            "[9]\ttraining's auc: 0.830569\ttraining's binary_logloss: 0.159326\tvalid_1's auc: 0.817789\tvalid_1's binary_logloss: 0.154599\n",
            "[10]\ttraining's auc: 0.832341\ttraining's binary_logloss: 0.158642\tvalid_1's auc: 0.818285\tvalid_1's binary_logloss: 0.154051\n",
            "[11]\ttraining's auc: 0.833653\ttraining's binary_logloss: 0.157968\tvalid_1's auc: 0.819093\tvalid_1's binary_logloss: 0.15352\n",
            "[12]\ttraining's auc: 0.834189\ttraining's binary_logloss: 0.157324\tvalid_1's auc: 0.81918\tvalid_1's binary_logloss: 0.153011\n",
            "[13]\ttraining's auc: 0.834703\ttraining's binary_logloss: 0.156706\tvalid_1's auc: 0.819299\tvalid_1's binary_logloss: 0.152519\n",
            "[14]\ttraining's auc: 0.834859\ttraining's binary_logloss: 0.156116\tvalid_1's auc: 0.819729\tvalid_1's binary_logloss: 0.152045\n",
            "[15]\ttraining's auc: 0.834916\ttraining's binary_logloss: 0.155544\tvalid_1's auc: 0.820015\tvalid_1's binary_logloss: 0.151581\n",
            "[16]\ttraining's auc: 0.835137\ttraining's binary_logloss: 0.15499\tvalid_1's auc: 0.819926\tvalid_1's binary_logloss: 0.151148\n",
            "[17]\ttraining's auc: 0.835532\ttraining's binary_logloss: 0.154442\tvalid_1's auc: 0.820343\tvalid_1's binary_logloss: 0.150725\n",
            "[18]\ttraining's auc: 0.835558\ttraining's binary_logloss: 0.153921\tvalid_1's auc: 0.820372\tvalid_1's binary_logloss: 0.150306\n",
            "[19]\ttraining's auc: 0.83576\ttraining's binary_logloss: 0.153416\tvalid_1's auc: 0.820519\tvalid_1's binary_logloss: 0.149898\n",
            "[20]\ttraining's auc: 0.836832\ttraining's binary_logloss: 0.152906\tvalid_1's auc: 0.821124\tvalid_1's binary_logloss: 0.149507\n",
            "[21]\ttraining's auc: 0.837034\ttraining's binary_logloss: 0.152427\tvalid_1's auc: 0.820997\tvalid_1's binary_logloss: 0.149131\n",
            "[22]\ttraining's auc: 0.837382\ttraining's binary_logloss: 0.151956\tvalid_1's auc: 0.821435\tvalid_1's binary_logloss: 0.148759\n",
            "[23]\ttraining's auc: 0.837363\ttraining's binary_logloss: 0.151499\tvalid_1's auc: 0.82136\tvalid_1's binary_logloss: 0.148403\n",
            "[24]\ttraining's auc: 0.837602\ttraining's binary_logloss: 0.151057\tvalid_1's auc: 0.821412\tvalid_1's binary_logloss: 0.148068\n",
            "[25]\ttraining's auc: 0.840581\ttraining's binary_logloss: 0.150615\tvalid_1's auc: 0.823812\tvalid_1's binary_logloss: 0.147743\n",
            "[26]\ttraining's auc: 0.840728\ttraining's binary_logloss: 0.150185\tvalid_1's auc: 0.823671\tvalid_1's binary_logloss: 0.147423\n",
            "[27]\ttraining's auc: 0.841151\ttraining's binary_logloss: 0.149771\tvalid_1's auc: 0.823934\tvalid_1's binary_logloss: 0.147109\n",
            "[28]\ttraining's auc: 0.841409\ttraining's binary_logloss: 0.149362\tvalid_1's auc: 0.82413\tvalid_1's binary_logloss: 0.146808\n",
            "[29]\ttraining's auc: 0.841588\ttraining's binary_logloss: 0.148974\tvalid_1's auc: 0.823944\tvalid_1's binary_logloss: 0.146512\n",
            "[30]\ttraining's auc: 0.841731\ttraining's binary_logloss: 0.148589\tvalid_1's auc: 0.82386\tvalid_1's binary_logloss: 0.146223\n",
            "[31]\ttraining's auc: 0.843237\ttraining's binary_logloss: 0.148205\tvalid_1's auc: 0.824569\tvalid_1's binary_logloss: 0.145935\n",
            "[32]\ttraining's auc: 0.843684\ttraining's binary_logloss: 0.147834\tvalid_1's auc: 0.824455\tvalid_1's binary_logloss: 0.145653\n",
            "[33]\ttraining's auc: 0.843995\ttraining's binary_logloss: 0.147477\tvalid_1's auc: 0.824698\tvalid_1's binary_logloss: 0.145385\n",
            "[34]\ttraining's auc: 0.844254\ttraining's binary_logloss: 0.147131\tvalid_1's auc: 0.825141\tvalid_1's binary_logloss: 0.145111\n",
            "[35]\ttraining's auc: 0.846603\ttraining's binary_logloss: 0.146773\tvalid_1's auc: 0.82719\tvalid_1's binary_logloss: 0.144856\n",
            "[36]\ttraining's auc: 0.847831\ttraining's binary_logloss: 0.146428\tvalid_1's auc: 0.827564\tvalid_1's binary_logloss: 0.144601\n",
            "[37]\ttraining's auc: 0.848551\ttraining's binary_logloss: 0.146089\tvalid_1's auc: 0.828214\tvalid_1's binary_logloss: 0.144359\n",
            "[38]\ttraining's auc: 0.848943\ttraining's binary_logloss: 0.145756\tvalid_1's auc: 0.828155\tvalid_1's binary_logloss: 0.144118\n",
            "[39]\ttraining's auc: 0.849552\ttraining's binary_logloss: 0.145421\tvalid_1's auc: 0.82844\tvalid_1's binary_logloss: 0.143883\n",
            "[40]\ttraining's auc: 0.84978\ttraining's binary_logloss: 0.145105\tvalid_1's auc: 0.828718\tvalid_1's binary_logloss: 0.143655\n",
            "[41]\ttraining's auc: 0.850115\ttraining's binary_logloss: 0.144798\tvalid_1's auc: 0.82882\tvalid_1's binary_logloss: 0.143428\n",
            "[42]\ttraining's auc: 0.850388\ttraining's binary_logloss: 0.144495\tvalid_1's auc: 0.82901\tvalid_1's binary_logloss: 0.143203\n",
            "[43]\ttraining's auc: 0.850935\ttraining's binary_logloss: 0.144187\tvalid_1's auc: 0.828951\tvalid_1's binary_logloss: 0.142995\n",
            "[44]\ttraining's auc: 0.851206\ttraining's binary_logloss: 0.143898\tvalid_1's auc: 0.829056\tvalid_1's binary_logloss: 0.142786\n",
            "[45]\ttraining's auc: 0.851415\ttraining's binary_logloss: 0.143617\tvalid_1's auc: 0.829265\tvalid_1's binary_logloss: 0.142582\n",
            "[46]\ttraining's auc: 0.85168\ttraining's binary_logloss: 0.143339\tvalid_1's auc: 0.829681\tvalid_1's binary_logloss: 0.142373\n",
            "[47]\ttraining's auc: 0.851954\ttraining's binary_logloss: 0.143065\tvalid_1's auc: 0.829722\tvalid_1's binary_logloss: 0.142172\n",
            "[48]\ttraining's auc: 0.852197\ttraining's binary_logloss: 0.14279\tvalid_1's auc: 0.829926\tvalid_1's binary_logloss: 0.141964\n",
            "[49]\ttraining's auc: 0.852431\ttraining's binary_logloss: 0.142521\tvalid_1's auc: 0.829911\tvalid_1's binary_logloss: 0.141764\n",
            "[50]\ttraining's auc: 0.85259\ttraining's binary_logloss: 0.142265\tvalid_1's auc: 0.829994\tvalid_1's binary_logloss: 0.141573\n",
            "[51]\ttraining's auc: 0.853539\ttraining's binary_logloss: 0.141999\tvalid_1's auc: 0.829942\tvalid_1's binary_logloss: 0.141376\n",
            "[52]\ttraining's auc: 0.853816\ttraining's binary_logloss: 0.141747\tvalid_1's auc: 0.829922\tvalid_1's binary_logloss: 0.141185\n",
            "[53]\ttraining's auc: 0.854125\ttraining's binary_logloss: 0.1415\tvalid_1's auc: 0.82991\tvalid_1's binary_logloss: 0.140994\n",
            "[54]\ttraining's auc: 0.854373\ttraining's binary_logloss: 0.141265\tvalid_1's auc: 0.83017\tvalid_1's binary_logloss: 0.140813\n",
            "[55]\ttraining's auc: 0.855023\ttraining's binary_logloss: 0.141027\tvalid_1's auc: 0.830435\tvalid_1's binary_logloss: 0.140636\n",
            "[56]\ttraining's auc: 0.855447\ttraining's binary_logloss: 0.140791\tvalid_1's auc: 0.830818\tvalid_1's binary_logloss: 0.140458\n",
            "[57]\ttraining's auc: 0.855981\ttraining's binary_logloss: 0.140559\tvalid_1's auc: 0.831156\tvalid_1's binary_logloss: 0.140289\n",
            "[58]\ttraining's auc: 0.856694\ttraining's binary_logloss: 0.140331\tvalid_1's auc: 0.832932\tvalid_1's binary_logloss: 0.140099\n",
            "[59]\ttraining's auc: 0.857054\ttraining's binary_logloss: 0.140108\tvalid_1's auc: 0.83313\tvalid_1's binary_logloss: 0.139919\n",
            "[60]\ttraining's auc: 0.857389\ttraining's binary_logloss: 0.13988\tvalid_1's auc: 0.83317\tvalid_1's binary_logloss: 0.139751\n",
            "[61]\ttraining's auc: 0.857489\ttraining's binary_logloss: 0.139665\tvalid_1's auc: 0.833178\tvalid_1's binary_logloss: 0.139606\n",
            "[62]\ttraining's auc: 0.857613\ttraining's binary_logloss: 0.139454\tvalid_1's auc: 0.833138\tvalid_1's binary_logloss: 0.13945\n",
            "[63]\ttraining's auc: 0.857952\ttraining's binary_logloss: 0.139239\tvalid_1's auc: 0.833117\tvalid_1's binary_logloss: 0.139294\n",
            "[64]\ttraining's auc: 0.858233\ttraining's binary_logloss: 0.139029\tvalid_1's auc: 0.833107\tvalid_1's binary_logloss: 0.139142\n",
            "[65]\ttraining's auc: 0.858628\ttraining's binary_logloss: 0.138821\tvalid_1's auc: 0.833155\tvalid_1's binary_logloss: 0.138999\n",
            "[66]\ttraining's auc: 0.858963\ttraining's binary_logloss: 0.138613\tvalid_1's auc: 0.833274\tvalid_1's binary_logloss: 0.138852\n",
            "[67]\ttraining's auc: 0.859112\ttraining's binary_logloss: 0.138404\tvalid_1's auc: 0.833372\tvalid_1's binary_logloss: 0.138723\n",
            "[68]\ttraining's auc: 0.859405\ttraining's binary_logloss: 0.1382\tvalid_1's auc: 0.833358\tvalid_1's binary_logloss: 0.138589\n",
            "[69]\ttraining's auc: 0.859649\ttraining's binary_logloss: 0.138002\tvalid_1's auc: 0.833396\tvalid_1's binary_logloss: 0.138457\n",
            "[70]\ttraining's auc: 0.85976\ttraining's binary_logloss: 0.13781\tvalid_1's auc: 0.833346\tvalid_1's binary_logloss: 0.13833\n",
            "[71]\ttraining's auc: 0.85991\ttraining's binary_logloss: 0.13762\tvalid_1's auc: 0.833327\tvalid_1's binary_logloss: 0.138205\n",
            "[72]\ttraining's auc: 0.860092\ttraining's binary_logloss: 0.137436\tvalid_1's auc: 0.833338\tvalid_1's binary_logloss: 0.138081\n",
            "[73]\ttraining's auc: 0.86011\ttraining's binary_logloss: 0.137254\tvalid_1's auc: 0.833281\tvalid_1's binary_logloss: 0.137957\n",
            "[74]\ttraining's auc: 0.861268\ttraining's binary_logloss: 0.137075\tvalid_1's auc: 0.834006\tvalid_1's binary_logloss: 0.13784\n",
            "[75]\ttraining's auc: 0.86152\ttraining's binary_logloss: 0.136893\tvalid_1's auc: 0.834035\tvalid_1's binary_logloss: 0.137715\n",
            "[76]\ttraining's auc: 0.861557\ttraining's binary_logloss: 0.136719\tvalid_1's auc: 0.834067\tvalid_1's binary_logloss: 0.137592\n",
            "[77]\ttraining's auc: 0.861699\ttraining's binary_logloss: 0.136546\tvalid_1's auc: 0.833994\tvalid_1's binary_logloss: 0.137472\n",
            "[78]\ttraining's auc: 0.861874\ttraining's binary_logloss: 0.136373\tvalid_1's auc: 0.834071\tvalid_1's binary_logloss: 0.137355\n",
            "[79]\ttraining's auc: 0.862186\ttraining's binary_logloss: 0.136206\tvalid_1's auc: 0.834183\tvalid_1's binary_logloss: 0.137252\n",
            "[80]\ttraining's auc: 0.862463\ttraining's binary_logloss: 0.13604\tvalid_1's auc: 0.834148\tvalid_1's binary_logloss: 0.137147\n",
            "[81]\ttraining's auc: 0.862599\ttraining's binary_logloss: 0.135873\tvalid_1's auc: 0.834256\tvalid_1's binary_logloss: 0.13703\n",
            "[82]\ttraining's auc: 0.862703\ttraining's binary_logloss: 0.135719\tvalid_1's auc: 0.834304\tvalid_1's binary_logloss: 0.136922\n",
            "[83]\ttraining's auc: 0.862793\ttraining's binary_logloss: 0.135559\tvalid_1's auc: 0.834177\tvalid_1's binary_logloss: 0.136823\n",
            "[84]\ttraining's auc: 0.862995\ttraining's binary_logloss: 0.135403\tvalid_1's auc: 0.834218\tvalid_1's binary_logloss: 0.136722\n",
            "[85]\ttraining's auc: 0.863169\ttraining's binary_logloss: 0.135242\tvalid_1's auc: 0.834165\tvalid_1's binary_logloss: 0.136629\n",
            "[86]\ttraining's auc: 0.863323\ttraining's binary_logloss: 0.135086\tvalid_1's auc: 0.834103\tvalid_1's binary_logloss: 0.136534\n",
            "[87]\ttraining's auc: 0.86338\ttraining's binary_logloss: 0.13493\tvalid_1's auc: 0.834144\tvalid_1's binary_logloss: 0.136446\n",
            "[88]\ttraining's auc: 0.863707\ttraining's binary_logloss: 0.13478\tvalid_1's auc: 0.834221\tvalid_1's binary_logloss: 0.136346\n",
            "[89]\ttraining's auc: 0.864446\ttraining's binary_logloss: 0.13462\tvalid_1's auc: 0.834472\tvalid_1's binary_logloss: 0.136254\n",
            "[90]\ttraining's auc: 0.864936\ttraining's binary_logloss: 0.134459\tvalid_1's auc: 0.834421\tvalid_1's binary_logloss: 0.136162\n",
            "[91]\ttraining's auc: 0.865458\ttraining's binary_logloss: 0.134304\tvalid_1's auc: 0.834582\tvalid_1's binary_logloss: 0.136074\n",
            "[92]\ttraining's auc: 0.865887\ttraining's binary_logloss: 0.134156\tvalid_1's auc: 0.834623\tvalid_1's binary_logloss: 0.135996\n",
            "[93]\ttraining's auc: 0.866414\ttraining's binary_logloss: 0.134007\tvalid_1's auc: 0.83472\tvalid_1's binary_logloss: 0.135908\n",
            "[94]\ttraining's auc: 0.866871\ttraining's binary_logloss: 0.133865\tvalid_1's auc: 0.835099\tvalid_1's binary_logloss: 0.135818\n",
            "[95]\ttraining's auc: 0.867145\ttraining's binary_logloss: 0.133721\tvalid_1's auc: 0.835189\tvalid_1's binary_logloss: 0.135731\n",
            "[96]\ttraining's auc: 0.867585\ttraining's binary_logloss: 0.133576\tvalid_1's auc: 0.835295\tvalid_1's binary_logloss: 0.135641\n",
            "[97]\ttraining's auc: 0.867729\ttraining's binary_logloss: 0.133437\tvalid_1's auc: 0.835294\tvalid_1's binary_logloss: 0.135562\n",
            "[98]\ttraining's auc: 0.86806\ttraining's binary_logloss: 0.133294\tvalid_1's auc: 0.835302\tvalid_1's binary_logloss: 0.135483\n",
            "[99]\ttraining's auc: 0.868337\ttraining's binary_logloss: 0.133156\tvalid_1's auc: 0.835283\tvalid_1's binary_logloss: 0.135411\n",
            "[100]\ttraining's auc: 0.868568\ttraining's binary_logloss: 0.133021\tvalid_1's auc: 0.835735\tvalid_1's binary_logloss: 0.135352\n",
            "[101]\ttraining's auc: 0.868861\ttraining's binary_logloss: 0.132886\tvalid_1's auc: 0.835898\tvalid_1's binary_logloss: 0.135271\n",
            "[102]\ttraining's auc: 0.869156\ttraining's binary_logloss: 0.132755\tvalid_1's auc: 0.835879\tvalid_1's binary_logloss: 0.135191\n",
            "[103]\ttraining's auc: 0.869519\ttraining's binary_logloss: 0.132623\tvalid_1's auc: 0.835649\tvalid_1's binary_logloss: 0.135126\n",
            "[104]\ttraining's auc: 0.869723\ttraining's binary_logloss: 0.132496\tvalid_1's auc: 0.835744\tvalid_1's binary_logloss: 0.135045\n",
            "[105]\ttraining's auc: 0.869858\ttraining's binary_logloss: 0.132371\tvalid_1's auc: 0.83572\tvalid_1's binary_logloss: 0.134987\n",
            "[106]\ttraining's auc: 0.870127\ttraining's binary_logloss: 0.132245\tvalid_1's auc: 0.835662\tvalid_1's binary_logloss: 0.134921\n",
            "[107]\ttraining's auc: 0.870463\ttraining's binary_logloss: 0.132115\tvalid_1's auc: 0.835587\tvalid_1's binary_logloss: 0.134857\n",
            "[108]\ttraining's auc: 0.870643\ttraining's binary_logloss: 0.131995\tvalid_1's auc: 0.835633\tvalid_1's binary_logloss: 0.134789\n",
            "[109]\ttraining's auc: 0.87087\ttraining's binary_logloss: 0.131873\tvalid_1's auc: 0.83557\tvalid_1's binary_logloss: 0.134727\n",
            "[110]\ttraining's auc: 0.871057\ttraining's binary_logloss: 0.131749\tvalid_1's auc: 0.835675\tvalid_1's binary_logloss: 0.134665\n",
            "[111]\ttraining's auc: 0.871277\ttraining's binary_logloss: 0.131631\tvalid_1's auc: 0.835646\tvalid_1's binary_logloss: 0.134604\n",
            "[112]\ttraining's auc: 0.871402\ttraining's binary_logloss: 0.131512\tvalid_1's auc: 0.835712\tvalid_1's binary_logloss: 0.134548\n",
            "[113]\ttraining's auc: 0.871497\ttraining's binary_logloss: 0.131397\tvalid_1's auc: 0.835674\tvalid_1's binary_logloss: 0.134493\n",
            "[114]\ttraining's auc: 0.871756\ttraining's binary_logloss: 0.131279\tvalid_1's auc: 0.835591\tvalid_1's binary_logloss: 0.134433\n",
            "[115]\ttraining's auc: 0.871874\ttraining's binary_logloss: 0.131165\tvalid_1's auc: 0.835538\tvalid_1's binary_logloss: 0.134377\n",
            "[116]\ttraining's auc: 0.872012\ttraining's binary_logloss: 0.131052\tvalid_1's auc: 0.835494\tvalid_1's binary_logloss: 0.134319\n",
            "[117]\ttraining's auc: 0.872229\ttraining's binary_logloss: 0.130937\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.134257\n",
            "[118]\ttraining's auc: 0.872366\ttraining's binary_logloss: 0.130828\tvalid_1's auc: 0.835516\tvalid_1's binary_logloss: 0.134198\n",
            "[119]\ttraining's auc: 0.872603\ttraining's binary_logloss: 0.130709\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.134143\n",
            "[120]\ttraining's auc: 0.872688\ttraining's binary_logloss: 0.130602\tvalid_1's auc: 0.835534\tvalid_1's binary_logloss: 0.134098\n",
            "[121]\ttraining's auc: 0.872855\ttraining's binary_logloss: 0.130486\tvalid_1's auc: 0.835396\tvalid_1's binary_logloss: 0.134051\n",
            "[122]\ttraining's auc: 0.873009\ttraining's binary_logloss: 0.130377\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.133995\n",
            "[123]\ttraining's auc: 0.873154\ttraining's binary_logloss: 0.130272\tvalid_1's auc: 0.835328\tvalid_1's binary_logloss: 0.133953\n",
            "[124]\ttraining's auc: 0.87324\ttraining's binary_logloss: 0.130165\tvalid_1's auc: 0.835248\tvalid_1's binary_logloss: 0.133909\n",
            "[125]\ttraining's auc: 0.873441\ttraining's binary_logloss: 0.130056\tvalid_1's auc: 0.835259\tvalid_1's binary_logloss: 0.133865\n",
            "[126]\ttraining's auc: 0.873505\ttraining's binary_logloss: 0.129958\tvalid_1's auc: 0.835155\tvalid_1's binary_logloss: 0.133828\n",
            "[127]\ttraining's auc: 0.873577\ttraining's binary_logloss: 0.129854\tvalid_1's auc: 0.835088\tvalid_1's binary_logloss: 0.133786\n",
            "[128]\ttraining's auc: 0.873703\ttraining's binary_logloss: 0.129756\tvalid_1's auc: 0.83505\tvalid_1's binary_logloss: 0.133745\n",
            "[129]\ttraining's auc: 0.87387\ttraining's binary_logloss: 0.129657\tvalid_1's auc: 0.834997\tvalid_1's binary_logloss: 0.133711\n",
            "[130]\ttraining's auc: 0.874011\ttraining's binary_logloss: 0.12956\tvalid_1's auc: 0.834996\tvalid_1's binary_logloss: 0.133666\n",
            "[131]\ttraining's auc: 0.874121\ttraining's binary_logloss: 0.129463\tvalid_1's auc: 0.835127\tvalid_1's binary_logloss: 0.133613\n",
            " 50%|█████     | 25/50 [12:18<11:43, 28.15s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.162109\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.1676\n",
            "[2]\ttraining's auc: 0.827183\ttraining's binary_logloss: 0.161193\tvalid_1's auc: 0.810898\tvalid_1's binary_logloss: 0.166757\n",
            "[3]\ttraining's auc: 0.827269\ttraining's binary_logloss: 0.16033\tvalid_1's auc: 0.81196\tvalid_1's binary_logloss: 0.165936\n",
            "[4]\ttraining's auc: 0.829919\ttraining's binary_logloss: 0.159497\tvalid_1's auc: 0.814913\tvalid_1's binary_logloss: 0.165165\n",
            "[5]\ttraining's auc: 0.830176\ttraining's binary_logloss: 0.158709\tvalid_1's auc: 0.815248\tvalid_1's binary_logloss: 0.164449\n",
            "[6]\ttraining's auc: 0.831272\ttraining's binary_logloss: 0.157956\tvalid_1's auc: 0.815846\tvalid_1's binary_logloss: 0.163772\n",
            "[7]\ttraining's auc: 0.831632\ttraining's binary_logloss: 0.157226\tvalid_1's auc: 0.815776\tvalid_1's binary_logloss: 0.163099\n",
            "[8]\ttraining's auc: 0.833324\ttraining's binary_logloss: 0.156515\tvalid_1's auc: 0.8165\tvalid_1's binary_logloss: 0.162461\n",
            "[9]\ttraining's auc: 0.833514\ttraining's binary_logloss: 0.155852\tvalid_1's auc: 0.816286\tvalid_1's binary_logloss: 0.161856\n",
            "[10]\ttraining's auc: 0.833886\ttraining's binary_logloss: 0.155205\tvalid_1's auc: 0.816091\tvalid_1's binary_logloss: 0.161292\n",
            "[11]\ttraining's auc: 0.834383\ttraining's binary_logloss: 0.154563\tvalid_1's auc: 0.816002\tvalid_1's binary_logloss: 0.160717\n",
            "[12]\ttraining's auc: 0.83514\ttraining's binary_logloss: 0.153947\tvalid_1's auc: 0.816765\tvalid_1's binary_logloss: 0.160152\n",
            "[13]\ttraining's auc: 0.835159\ttraining's binary_logloss: 0.153364\tvalid_1's auc: 0.816625\tvalid_1's binary_logloss: 0.159637\n",
            "[14]\ttraining's auc: 0.835814\ttraining's binary_logloss: 0.152783\tvalid_1's auc: 0.816569\tvalid_1's binary_logloss: 0.159136\n",
            "[15]\ttraining's auc: 0.837562\ttraining's binary_logloss: 0.152231\tvalid_1's auc: 0.818087\tvalid_1's binary_logloss: 0.158655\n",
            "[16]\ttraining's auc: 0.837966\ttraining's binary_logloss: 0.151697\tvalid_1's auc: 0.818265\tvalid_1's binary_logloss: 0.15819\n",
            "[17]\ttraining's auc: 0.83831\ttraining's binary_logloss: 0.151177\tvalid_1's auc: 0.818381\tvalid_1's binary_logloss: 0.157724\n",
            "[18]\ttraining's auc: 0.838555\ttraining's binary_logloss: 0.150677\tvalid_1's auc: 0.818324\tvalid_1's binary_logloss: 0.15729\n",
            "[19]\ttraining's auc: 0.839065\ttraining's binary_logloss: 0.150189\tvalid_1's auc: 0.818986\tvalid_1's binary_logloss: 0.156838\n",
            "[20]\ttraining's auc: 0.839153\ttraining's binary_logloss: 0.149698\tvalid_1's auc: 0.819209\tvalid_1's binary_logloss: 0.1564\n",
            "[21]\ttraining's auc: 0.839972\ttraining's binary_logloss: 0.14923\tvalid_1's auc: 0.81955\tvalid_1's binary_logloss: 0.15598\n",
            "[22]\ttraining's auc: 0.84129\ttraining's binary_logloss: 0.148784\tvalid_1's auc: 0.820472\tvalid_1's binary_logloss: 0.155567\n",
            "[23]\ttraining's auc: 0.841972\ttraining's binary_logloss: 0.148348\tvalid_1's auc: 0.820376\tvalid_1's binary_logloss: 0.155197\n",
            "[24]\ttraining's auc: 0.843684\ttraining's binary_logloss: 0.147918\tvalid_1's auc: 0.822324\tvalid_1's binary_logloss: 0.154802\n",
            "[25]\ttraining's auc: 0.844089\ttraining's binary_logloss: 0.147491\tvalid_1's auc: 0.822266\tvalid_1's binary_logloss: 0.154449\n",
            "[26]\ttraining's auc: 0.844403\ttraining's binary_logloss: 0.147083\tvalid_1's auc: 0.82215\tvalid_1's binary_logloss: 0.154094\n",
            "[27]\ttraining's auc: 0.846619\ttraining's binary_logloss: 0.146669\tvalid_1's auc: 0.82468\tvalid_1's binary_logloss: 0.153741\n",
            "[28]\ttraining's auc: 0.847297\ttraining's binary_logloss: 0.146256\tvalid_1's auc: 0.825177\tvalid_1's binary_logloss: 0.153398\n",
            "[29]\ttraining's auc: 0.848206\ttraining's binary_logloss: 0.145861\tvalid_1's auc: 0.825769\tvalid_1's binary_logloss: 0.153047\n",
            "[30]\ttraining's auc: 0.848789\ttraining's binary_logloss: 0.145474\tvalid_1's auc: 0.826238\tvalid_1's binary_logloss: 0.152722\n",
            "[31]\ttraining's auc: 0.849042\ttraining's binary_logloss: 0.145098\tvalid_1's auc: 0.826388\tvalid_1's binary_logloss: 0.152394\n",
            "[32]\ttraining's auc: 0.849348\ttraining's binary_logloss: 0.144729\tvalid_1's auc: 0.826874\tvalid_1's binary_logloss: 0.152092\n",
            "[33]\ttraining's auc: 0.84988\ttraining's binary_logloss: 0.144378\tvalid_1's auc: 0.827154\tvalid_1's binary_logloss: 0.151782\n",
            "[34]\ttraining's auc: 0.850261\ttraining's binary_logloss: 0.144037\tvalid_1's auc: 0.82737\tvalid_1's binary_logloss: 0.151473\n",
            "[35]\ttraining's auc: 0.850715\ttraining's binary_logloss: 0.143696\tvalid_1's auc: 0.82772\tvalid_1's binary_logloss: 0.15119\n",
            "[36]\ttraining's auc: 0.850979\ttraining's binary_logloss: 0.143369\tvalid_1's auc: 0.82784\tvalid_1's binary_logloss: 0.150908\n",
            "[37]\ttraining's auc: 0.851045\ttraining's binary_logloss: 0.143049\tvalid_1's auc: 0.82773\tvalid_1's binary_logloss: 0.150649\n",
            "[38]\ttraining's auc: 0.85118\ttraining's binary_logloss: 0.142735\tvalid_1's auc: 0.827901\tvalid_1's binary_logloss: 0.150379\n",
            "[39]\ttraining's auc: 0.851335\ttraining's binary_logloss: 0.142426\tvalid_1's auc: 0.827929\tvalid_1's binary_logloss: 0.15013\n",
            "[40]\ttraining's auc: 0.851593\ttraining's binary_logloss: 0.142128\tvalid_1's auc: 0.828193\tvalid_1's binary_logloss: 0.149866\n",
            "[41]\ttraining's auc: 0.85183\ttraining's binary_logloss: 0.141821\tvalid_1's auc: 0.828412\tvalid_1's binary_logloss: 0.149618\n",
            "[42]\ttraining's auc: 0.851386\ttraining's binary_logloss: 0.141526\tvalid_1's auc: 0.828618\tvalid_1's binary_logloss: 0.149369\n",
            "[43]\ttraining's auc: 0.851586\ttraining's binary_logloss: 0.141239\tvalid_1's auc: 0.828844\tvalid_1's binary_logloss: 0.149127\n",
            "[44]\ttraining's auc: 0.851956\ttraining's binary_logloss: 0.140954\tvalid_1's auc: 0.828833\tvalid_1's binary_logloss: 0.1489\n",
            "[45]\ttraining's auc: 0.852365\ttraining's binary_logloss: 0.140678\tvalid_1's auc: 0.828927\tvalid_1's binary_logloss: 0.148668\n",
            "[46]\ttraining's auc: 0.852606\ttraining's binary_logloss: 0.140406\tvalid_1's auc: 0.82876\tvalid_1's binary_logloss: 0.148454\n",
            "[47]\ttraining's auc: 0.852936\ttraining's binary_logloss: 0.140122\tvalid_1's auc: 0.828794\tvalid_1's binary_logloss: 0.148237\n",
            "[48]\ttraining's auc: 0.852988\ttraining's binary_logloss: 0.139863\tvalid_1's auc: 0.828944\tvalid_1's binary_logloss: 0.148018\n",
            "[49]\ttraining's auc: 0.852981\ttraining's binary_logloss: 0.139592\tvalid_1's auc: 0.82901\tvalid_1's binary_logloss: 0.147806\n",
            "[50]\ttraining's auc: 0.853196\ttraining's binary_logloss: 0.139336\tvalid_1's auc: 0.829045\tvalid_1's binary_logloss: 0.147594\n",
            "[51]\ttraining's auc: 0.853455\ttraining's binary_logloss: 0.139073\tvalid_1's auc: 0.829092\tvalid_1's binary_logloss: 0.147404\n",
            "[52]\ttraining's auc: 0.853506\ttraining's binary_logloss: 0.138818\tvalid_1's auc: 0.829007\tvalid_1's binary_logloss: 0.14721\n",
            "[53]\ttraining's auc: 0.853792\ttraining's binary_logloss: 0.13858\tvalid_1's auc: 0.829103\tvalid_1's binary_logloss: 0.147012\n",
            "[54]\ttraining's auc: 0.85407\ttraining's binary_logloss: 0.138337\tvalid_1's auc: 0.829747\tvalid_1's binary_logloss: 0.146831\n",
            "[55]\ttraining's auc: 0.854133\ttraining's binary_logloss: 0.138099\tvalid_1's auc: 0.829732\tvalid_1's binary_logloss: 0.146651\n",
            "[56]\ttraining's auc: 0.855006\ttraining's binary_logloss: 0.137858\tvalid_1's auc: 0.830012\tvalid_1's binary_logloss: 0.146469\n",
            "[57]\ttraining's auc: 0.855392\ttraining's binary_logloss: 0.137625\tvalid_1's auc: 0.830102\tvalid_1's binary_logloss: 0.146291\n",
            "[58]\ttraining's auc: 0.855652\ttraining's binary_logloss: 0.1374\tvalid_1's auc: 0.830242\tvalid_1's binary_logloss: 0.146113\n",
            "[59]\ttraining's auc: 0.855728\ttraining's binary_logloss: 0.137169\tvalid_1's auc: 0.830289\tvalid_1's binary_logloss: 0.145949\n",
            "[60]\ttraining's auc: 0.85623\ttraining's binary_logloss: 0.136947\tvalid_1's auc: 0.830462\tvalid_1's binary_logloss: 0.145784\n",
            "[61]\ttraining's auc: 0.856315\ttraining's binary_logloss: 0.136728\tvalid_1's auc: 0.830446\tvalid_1's binary_logloss: 0.145623\n",
            "[62]\ttraining's auc: 0.85644\ttraining's binary_logloss: 0.13652\tvalid_1's auc: 0.830473\tvalid_1's binary_logloss: 0.145459\n",
            "[63]\ttraining's auc: 0.856529\ttraining's binary_logloss: 0.136312\tvalid_1's auc: 0.830597\tvalid_1's binary_logloss: 0.145308\n",
            "[64]\ttraining's auc: 0.856872\ttraining's binary_logloss: 0.136106\tvalid_1's auc: 0.830703\tvalid_1's binary_logloss: 0.145151\n",
            "[65]\ttraining's auc: 0.85694\ttraining's binary_logloss: 0.135906\tvalid_1's auc: 0.830922\tvalid_1's binary_logloss: 0.144994\n",
            "[66]\ttraining's auc: 0.857244\ttraining's binary_logloss: 0.135711\tvalid_1's auc: 0.831053\tvalid_1's binary_logloss: 0.144836\n",
            "[67]\ttraining's auc: 0.857546\ttraining's binary_logloss: 0.135512\tvalid_1's auc: 0.831083\tvalid_1's binary_logloss: 0.144685\n",
            "[68]\ttraining's auc: 0.857639\ttraining's binary_logloss: 0.135319\tvalid_1's auc: 0.831294\tvalid_1's binary_logloss: 0.144534\n",
            "[69]\ttraining's auc: 0.857837\ttraining's binary_logloss: 0.135122\tvalid_1's auc: 0.831335\tvalid_1's binary_logloss: 0.144388\n",
            "[70]\ttraining's auc: 0.857984\ttraining's binary_logloss: 0.134933\tvalid_1's auc: 0.831357\tvalid_1's binary_logloss: 0.144244\n",
            "[71]\ttraining's auc: 0.85818\ttraining's binary_logloss: 0.13475\tvalid_1's auc: 0.83144\tvalid_1's binary_logloss: 0.144109\n",
            "[72]\ttraining's auc: 0.858451\ttraining's binary_logloss: 0.134566\tvalid_1's auc: 0.831507\tvalid_1's binary_logloss: 0.143973\n",
            "[73]\ttraining's auc: 0.858701\ttraining's binary_logloss: 0.134385\tvalid_1's auc: 0.831537\tvalid_1's binary_logloss: 0.14384\n",
            "[74]\ttraining's auc: 0.859174\ttraining's binary_logloss: 0.134211\tvalid_1's auc: 0.831284\tvalid_1's binary_logloss: 0.143721\n",
            "[75]\ttraining's auc: 0.859296\ttraining's binary_logloss: 0.134042\tvalid_1's auc: 0.831421\tvalid_1's binary_logloss: 0.143597\n",
            "[76]\ttraining's auc: 0.859414\ttraining's binary_logloss: 0.133872\tvalid_1's auc: 0.831533\tvalid_1's binary_logloss: 0.143469\n",
            "[77]\ttraining's auc: 0.859503\ttraining's binary_logloss: 0.133702\tvalid_1's auc: 0.831687\tvalid_1's binary_logloss: 0.143345\n",
            "[78]\ttraining's auc: 0.85966\ttraining's binary_logloss: 0.133537\tvalid_1's auc: 0.831722\tvalid_1's binary_logloss: 0.14323\n",
            "[79]\ttraining's auc: 0.860191\ttraining's binary_logloss: 0.13337\tvalid_1's auc: 0.831903\tvalid_1's binary_logloss: 0.143111\n",
            "[80]\ttraining's auc: 0.860468\ttraining's binary_logloss: 0.133207\tvalid_1's auc: 0.831974\tvalid_1's binary_logloss: 0.14299\n",
            "[81]\ttraining's auc: 0.860787\ttraining's binary_logloss: 0.133046\tvalid_1's auc: 0.832163\tvalid_1's binary_logloss: 0.14287\n",
            "[82]\ttraining's auc: 0.861195\ttraining's binary_logloss: 0.132889\tvalid_1's auc: 0.832118\tvalid_1's binary_logloss: 0.142758\n",
            "[83]\ttraining's auc: 0.861596\ttraining's binary_logloss: 0.132731\tvalid_1's auc: 0.832117\tvalid_1's binary_logloss: 0.142645\n",
            "[84]\ttraining's auc: 0.861658\ttraining's binary_logloss: 0.132573\tvalid_1's auc: 0.83219\tvalid_1's binary_logloss: 0.14255\n",
            "[85]\ttraining's auc: 0.862069\ttraining's binary_logloss: 0.132418\tvalid_1's auc: 0.832286\tvalid_1's binary_logloss: 0.142444\n",
            "[86]\ttraining's auc: 0.862366\ttraining's binary_logloss: 0.132263\tvalid_1's auc: 0.832099\tvalid_1's binary_logloss: 0.142353\n",
            "[87]\ttraining's auc: 0.86266\ttraining's binary_logloss: 0.132117\tvalid_1's auc: 0.832088\tvalid_1's binary_logloss: 0.142256\n",
            "[88]\ttraining's auc: 0.862922\ttraining's binary_logloss: 0.13197\tvalid_1's auc: 0.832076\tvalid_1's binary_logloss: 0.142154\n",
            "[89]\ttraining's auc: 0.863252\ttraining's binary_logloss: 0.131824\tvalid_1's auc: 0.832016\tvalid_1's binary_logloss: 0.142066\n",
            "[90]\ttraining's auc: 0.863968\ttraining's binary_logloss: 0.131676\tvalid_1's auc: 0.832223\tvalid_1's binary_logloss: 0.141974\n",
            "[91]\ttraining's auc: 0.864079\ttraining's binary_logloss: 0.131537\tvalid_1's auc: 0.832219\tvalid_1's binary_logloss: 0.141881\n",
            "[92]\ttraining's auc: 0.864621\ttraining's binary_logloss: 0.131396\tvalid_1's auc: 0.832319\tvalid_1's binary_logloss: 0.141784\n",
            "[93]\ttraining's auc: 0.864814\ttraining's binary_logloss: 0.131258\tvalid_1's auc: 0.832393\tvalid_1's binary_logloss: 0.141701\n",
            "[94]\ttraining's auc: 0.864947\ttraining's binary_logloss: 0.131126\tvalid_1's auc: 0.832401\tvalid_1's binary_logloss: 0.141612\n",
            "[95]\ttraining's auc: 0.86507\ttraining's binary_logloss: 0.130995\tvalid_1's auc: 0.832381\tvalid_1's binary_logloss: 0.141528\n",
            "[96]\ttraining's auc: 0.865191\ttraining's binary_logloss: 0.130864\tvalid_1's auc: 0.83233\tvalid_1's binary_logloss: 0.141448\n",
            "[97]\ttraining's auc: 0.865327\ttraining's binary_logloss: 0.130736\tvalid_1's auc: 0.83225\tvalid_1's binary_logloss: 0.141377\n",
            "[98]\ttraining's auc: 0.865718\ttraining's binary_logloss: 0.1306\tvalid_1's auc: 0.832268\tvalid_1's binary_logloss: 0.141295\n",
            "[99]\ttraining's auc: 0.866357\ttraining's binary_logloss: 0.130462\tvalid_1's auc: 0.832406\tvalid_1's binary_logloss: 0.141214\n",
            "[100]\ttraining's auc: 0.866589\ttraining's binary_logloss: 0.130335\tvalid_1's auc: 0.83237\tvalid_1's binary_logloss: 0.141135\n",
            "[101]\ttraining's auc: 0.866856\ttraining's binary_logloss: 0.130199\tvalid_1's auc: 0.83244\tvalid_1's binary_logloss: 0.14105\n",
            "[102]\ttraining's auc: 0.866979\ttraining's binary_logloss: 0.130069\tvalid_1's auc: 0.832371\tvalid_1's binary_logloss: 0.140965\n",
            "[103]\ttraining's auc: 0.867497\ttraining's binary_logloss: 0.129942\tvalid_1's auc: 0.832373\tvalid_1's binary_logloss: 0.140896\n",
            "[104]\ttraining's auc: 0.867617\ttraining's binary_logloss: 0.129817\tvalid_1's auc: 0.832453\tvalid_1's binary_logloss: 0.140816\n",
            "[105]\ttraining's auc: 0.867814\ttraining's binary_logloss: 0.129691\tvalid_1's auc: 0.832465\tvalid_1's binary_logloss: 0.140748\n",
            "[106]\ttraining's auc: 0.867976\ttraining's binary_logloss: 0.129572\tvalid_1's auc: 0.832501\tvalid_1's binary_logloss: 0.140683\n",
            "[107]\ttraining's auc: 0.868242\ttraining's binary_logloss: 0.129451\tvalid_1's auc: 0.832538\tvalid_1's binary_logloss: 0.140609\n",
            "[108]\ttraining's auc: 0.868414\ttraining's binary_logloss: 0.129333\tvalid_1's auc: 0.832561\tvalid_1's binary_logloss: 0.140543\n",
            "[109]\ttraining's auc: 0.868796\ttraining's binary_logloss: 0.129204\tvalid_1's auc: 0.832481\tvalid_1's binary_logloss: 0.140483\n",
            "[110]\ttraining's auc: 0.868947\ttraining's binary_logloss: 0.129084\tvalid_1's auc: 0.832447\tvalid_1's binary_logloss: 0.140421\n",
            "[111]\ttraining's auc: 0.869081\ttraining's binary_logloss: 0.128972\tvalid_1's auc: 0.832363\tvalid_1's binary_logloss: 0.140355\n",
            "[112]\ttraining's auc: 0.86959\ttraining's binary_logloss: 0.128853\tvalid_1's auc: 0.832594\tvalid_1's binary_logloss: 0.14029\n",
            "[113]\ttraining's auc: 0.869973\ttraining's binary_logloss: 0.128732\tvalid_1's auc: 0.832508\tvalid_1's binary_logloss: 0.140228\n",
            "[114]\ttraining's auc: 0.870686\ttraining's binary_logloss: 0.128618\tvalid_1's auc: 0.833902\tvalid_1's binary_logloss: 0.140162\n",
            "[115]\ttraining's auc: 0.87086\ttraining's binary_logloss: 0.128507\tvalid_1's auc: 0.833872\tvalid_1's binary_logloss: 0.140099\n",
            "[116]\ttraining's auc: 0.870959\ttraining's binary_logloss: 0.128398\tvalid_1's auc: 0.833936\tvalid_1's binary_logloss: 0.140035\n",
            "[117]\ttraining's auc: 0.871144\ttraining's binary_logloss: 0.128284\tvalid_1's auc: 0.834008\tvalid_1's binary_logloss: 0.13997\n",
            "[118]\ttraining's auc: 0.871692\ttraining's binary_logloss: 0.128174\tvalid_1's auc: 0.834619\tvalid_1's binary_logloss: 0.1399\n",
            "[119]\ttraining's auc: 0.87196\ttraining's binary_logloss: 0.128064\tvalid_1's auc: 0.83448\tvalid_1's binary_logloss: 0.139845\n",
            "[120]\ttraining's auc: 0.872096\ttraining's binary_logloss: 0.127957\tvalid_1's auc: 0.834615\tvalid_1's binary_logloss: 0.139778\n",
            "[121]\ttraining's auc: 0.872246\ttraining's binary_logloss: 0.127851\tvalid_1's auc: 0.834671\tvalid_1's binary_logloss: 0.139713\n",
            "[122]\ttraining's auc: 0.87264\ttraining's binary_logloss: 0.127737\tvalid_1's auc: 0.834819\tvalid_1's binary_logloss: 0.139648\n",
            "[123]\ttraining's auc: 0.872955\ttraining's binary_logloss: 0.127627\tvalid_1's auc: 0.834761\tvalid_1's binary_logloss: 0.139593\n",
            "[124]\ttraining's auc: 0.87319\ttraining's binary_logloss: 0.127517\tvalid_1's auc: 0.834788\tvalid_1's binary_logloss: 0.139539\n",
            "[125]\ttraining's auc: 0.873348\ttraining's binary_logloss: 0.127418\tvalid_1's auc: 0.834891\tvalid_1's binary_logloss: 0.139478\n",
            "[126]\ttraining's auc: 0.873508\ttraining's binary_logloss: 0.127318\tvalid_1's auc: 0.834801\tvalid_1's binary_logloss: 0.139428\n",
            "[127]\ttraining's auc: 0.873616\ttraining's binary_logloss: 0.12722\tvalid_1's auc: 0.834747\tvalid_1's binary_logloss: 0.139381\n",
            "[128]\ttraining's auc: 0.873919\ttraining's binary_logloss: 0.127116\tvalid_1's auc: 0.834766\tvalid_1's binary_logloss: 0.139328\n",
            "[129]\ttraining's auc: 0.874082\ttraining's binary_logloss: 0.127021\tvalid_1's auc: 0.834769\tvalid_1's binary_logloss: 0.139278\n",
            "[130]\ttraining's auc: 0.874254\ttraining's binary_logloss: 0.126923\tvalid_1's auc: 0.834811\tvalid_1's binary_logloss: 0.139232\n",
            "[131]\ttraining's auc: 0.87436\ttraining's binary_logloss: 0.126822\tvalid_1's auc: 0.834785\tvalid_1's binary_logloss: 0.139179\n",
            "[132]\ttraining's auc: 0.874554\ttraining's binary_logloss: 0.126724\tvalid_1's auc: 0.834839\tvalid_1's binary_logloss: 0.139128\n",
            "[133]\ttraining's auc: 0.874788\ttraining's binary_logloss: 0.126631\tvalid_1's auc: 0.835079\tvalid_1's binary_logloss: 0.139086\n",
            "[134]\ttraining's auc: 0.87493\ttraining's binary_logloss: 0.126534\tvalid_1's auc: 0.835105\tvalid_1's binary_logloss: 0.139043\n",
            "[135]\ttraining's auc: 0.875211\ttraining's binary_logloss: 0.126436\tvalid_1's auc: 0.835314\tvalid_1's binary_logloss: 0.138991\n",
            "[136]\ttraining's auc: 0.875399\ttraining's binary_logloss: 0.126344\tvalid_1's auc: 0.835343\tvalid_1's binary_logloss: 0.138944\n",
            "[137]\ttraining's auc: 0.875603\ttraining's binary_logloss: 0.126254\tvalid_1's auc: 0.835339\tvalid_1's binary_logloss: 0.138901\n",
            "[138]\ttraining's auc: 0.875697\ttraining's binary_logloss: 0.126158\tvalid_1's auc: 0.835302\tvalid_1's binary_logloss: 0.138864\n",
            "[139]\ttraining's auc: 0.87575\ttraining's binary_logloss: 0.126066\tvalid_1's auc: 0.835369\tvalid_1's binary_logloss: 0.138816\n",
            "[140]\ttraining's auc: 0.876078\ttraining's binary_logloss: 0.12596\tvalid_1's auc: 0.835486\tvalid_1's binary_logloss: 0.138771\n",
            "[141]\ttraining's auc: 0.876144\ttraining's binary_logloss: 0.125871\tvalid_1's auc: 0.835424\tvalid_1's binary_logloss: 0.138735\n",
            "[142]\ttraining's auc: 0.876322\ttraining's binary_logloss: 0.12578\tvalid_1's auc: 0.835449\tvalid_1's binary_logloss: 0.138697\n",
            "[143]\ttraining's auc: 0.876474\ttraining's binary_logloss: 0.125687\tvalid_1's auc: 0.835611\tvalid_1's binary_logloss: 0.138644\n",
            "[144]\ttraining's auc: 0.876734\ttraining's binary_logloss: 0.125599\tvalid_1's auc: 0.835747\tvalid_1's binary_logloss: 0.138603\n",
            "[145]\ttraining's auc: 0.877025\ttraining's binary_logloss: 0.125503\tvalid_1's auc: 0.835728\tvalid_1's binary_logloss: 0.138565\n",
            "[146]\ttraining's auc: 0.87724\ttraining's binary_logloss: 0.125412\tvalid_1's auc: 0.835718\tvalid_1's binary_logloss: 0.138525\n",
            "[147]\ttraining's auc: 0.87744\ttraining's binary_logloss: 0.125316\tvalid_1's auc: 0.835823\tvalid_1's binary_logloss: 0.138485\n",
            "[148]\ttraining's auc: 0.877638\ttraining's binary_logloss: 0.125229\tvalid_1's auc: 0.835786\tvalid_1's binary_logloss: 0.138444\n",
            "[149]\ttraining's auc: 0.87796\ttraining's binary_logloss: 0.125135\tvalid_1's auc: 0.835829\tvalid_1's binary_logloss: 0.138396\n",
            "[150]\ttraining's auc: 0.878338\ttraining's binary_logloss: 0.125046\tvalid_1's auc: 0.83586\tvalid_1's binary_logloss: 0.138357\n",
            "[151]\ttraining's auc: 0.878553\ttraining's binary_logloss: 0.124959\tvalid_1's auc: 0.835926\tvalid_1's binary_logloss: 0.138311\n",
            "[152]\ttraining's auc: 0.878706\ttraining's binary_logloss: 0.124874\tvalid_1's auc: 0.835921\tvalid_1's binary_logloss: 0.138275\n",
            "[153]\ttraining's auc: 0.878963\ttraining's binary_logloss: 0.124783\tvalid_1's auc: 0.836297\tvalid_1's binary_logloss: 0.138239\n",
            "[154]\ttraining's auc: 0.879187\ttraining's binary_logloss: 0.124696\tvalid_1's auc: 0.836267\tvalid_1's binary_logloss: 0.138199\n",
            "[155]\ttraining's auc: 0.879357\ttraining's binary_logloss: 0.124611\tvalid_1's auc: 0.836277\tvalid_1's binary_logloss: 0.13816\n",
            "[156]\ttraining's auc: 0.879525\ttraining's binary_logloss: 0.124534\tvalid_1's auc: 0.836232\tvalid_1's binary_logloss: 0.138127\n",
            "[157]\ttraining's auc: 0.879785\ttraining's binary_logloss: 0.124447\tvalid_1's auc: 0.83643\tvalid_1's binary_logloss: 0.138091\n",
            "[158]\ttraining's auc: 0.880021\ttraining's binary_logloss: 0.124372\tvalid_1's auc: 0.83652\tvalid_1's binary_logloss: 0.138057\n",
            "[159]\ttraining's auc: 0.880314\ttraining's binary_logloss: 0.124288\tvalid_1's auc: 0.836603\tvalid_1's binary_logloss: 0.138021\n",
            "[160]\ttraining's auc: 0.880587\ttraining's binary_logloss: 0.124204\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.137991\n",
            "[161]\ttraining's auc: 0.880739\ttraining's binary_logloss: 0.124122\tvalid_1's auc: 0.836555\tvalid_1's binary_logloss: 0.137965\n",
            "[162]\ttraining's auc: 0.88106\ttraining's binary_logloss: 0.124032\tvalid_1's auc: 0.836617\tvalid_1's binary_logloss: 0.137935\n",
            "[163]\ttraining's auc: 0.881215\ttraining's binary_logloss: 0.123951\tvalid_1's auc: 0.836584\tvalid_1's binary_logloss: 0.137907\n",
            "[164]\ttraining's auc: 0.881344\ttraining's binary_logloss: 0.123873\tvalid_1's auc: 0.836508\tvalid_1's binary_logloss: 0.137879\n",
            "[165]\ttraining's auc: 0.881426\ttraining's binary_logloss: 0.1238\tvalid_1's auc: 0.836482\tvalid_1's binary_logloss: 0.137849\n",
            "[166]\ttraining's auc: 0.881667\ttraining's binary_logloss: 0.123713\tvalid_1's auc: 0.836537\tvalid_1's binary_logloss: 0.137821\n",
            "[167]\ttraining's auc: 0.881704\ttraining's binary_logloss: 0.12364\tvalid_1's auc: 0.836493\tvalid_1's binary_logloss: 0.137795\n",
            "[168]\ttraining's auc: 0.88197\ttraining's binary_logloss: 0.123562\tvalid_1's auc: 0.836493\tvalid_1's binary_logloss: 0.13778\n",
            "[169]\ttraining's auc: 0.882136\ttraining's binary_logloss: 0.123489\tvalid_1's auc: 0.836507\tvalid_1's binary_logloss: 0.137749\n",
            "[170]\ttraining's auc: 0.882208\ttraining's binary_logloss: 0.123415\tvalid_1's auc: 0.836461\tvalid_1's binary_logloss: 0.13772\n",
            "[171]\ttraining's auc: 0.882373\ttraining's binary_logloss: 0.123338\tvalid_1's auc: 0.836408\tvalid_1's binary_logloss: 0.137692\n",
            "[172]\ttraining's auc: 0.88258\ttraining's binary_logloss: 0.123256\tvalid_1's auc: 0.836358\tvalid_1's binary_logloss: 0.137669\n",
            "[173]\ttraining's auc: 0.882859\ttraining's binary_logloss: 0.123178\tvalid_1's auc: 0.836406\tvalid_1's binary_logloss: 0.137642\n",
            "[174]\ttraining's auc: 0.882986\ttraining's binary_logloss: 0.123107\tvalid_1's auc: 0.836435\tvalid_1's binary_logloss: 0.137618\n",
            "[175]\ttraining's auc: 0.883126\ttraining's binary_logloss: 0.123036\tvalid_1's auc: 0.836382\tvalid_1's binary_logloss: 0.137591\n",
            "[176]\ttraining's auc: 0.883289\ttraining's binary_logloss: 0.122968\tvalid_1's auc: 0.836361\tvalid_1's binary_logloss: 0.137559\n",
            "[177]\ttraining's auc: 0.883461\ttraining's binary_logloss: 0.122897\tvalid_1's auc: 0.836429\tvalid_1's binary_logloss: 0.137532\n",
            "[178]\ttraining's auc: 0.883696\ttraining's binary_logloss: 0.122819\tvalid_1's auc: 0.83657\tvalid_1's binary_logloss: 0.137504\n",
            "[179]\ttraining's auc: 0.883936\ttraining's binary_logloss: 0.122748\tvalid_1's auc: 0.836408\tvalid_1's binary_logloss: 0.137477\n",
            "[180]\ttraining's auc: 0.884222\ttraining's binary_logloss: 0.122676\tvalid_1's auc: 0.836254\tvalid_1's binary_logloss: 0.137454\n",
            "[181]\ttraining's auc: 0.884447\ttraining's binary_logloss: 0.122601\tvalid_1's auc: 0.836259\tvalid_1's binary_logloss: 0.137438\n",
            "[182]\ttraining's auc: 0.884581\ttraining's binary_logloss: 0.122527\tvalid_1's auc: 0.836272\tvalid_1's binary_logloss: 0.137404\n",
            "[183]\ttraining's auc: 0.88477\ttraining's binary_logloss: 0.122451\tvalid_1's auc: 0.836364\tvalid_1's binary_logloss: 0.137377\n",
            "[184]\ttraining's auc: 0.885008\ttraining's binary_logloss: 0.122383\tvalid_1's auc: 0.836407\tvalid_1's binary_logloss: 0.137349\n",
            "[185]\ttraining's auc: 0.885277\ttraining's binary_logloss: 0.122313\tvalid_1's auc: 0.836534\tvalid_1's binary_logloss: 0.137323\n",
            "[186]\ttraining's auc: 0.885486\ttraining's binary_logloss: 0.122246\tvalid_1's auc: 0.836497\tvalid_1's binary_logloss: 0.137298\n",
            "[187]\ttraining's auc: 0.885667\ttraining's binary_logloss: 0.122176\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.137275\n",
            "[188]\ttraining's auc: 0.885836\ttraining's binary_logloss: 0.122104\tvalid_1's auc: 0.836564\tvalid_1's binary_logloss: 0.137253\n",
            "[189]\ttraining's auc: 0.885951\ttraining's binary_logloss: 0.122034\tvalid_1's auc: 0.836539\tvalid_1's binary_logloss: 0.137223\n",
            "[190]\ttraining's auc: 0.886124\ttraining's binary_logloss: 0.121963\tvalid_1's auc: 0.836586\tvalid_1's binary_logloss: 0.137205\n",
            "[191]\ttraining's auc: 0.886292\ttraining's binary_logloss: 0.121894\tvalid_1's auc: 0.836607\tvalid_1's binary_logloss: 0.137181\n",
            "[192]\ttraining's auc: 0.886575\ttraining's binary_logloss: 0.12182\tvalid_1's auc: 0.836665\tvalid_1's binary_logloss: 0.137161\n",
            "[193]\ttraining's auc: 0.886769\ttraining's binary_logloss: 0.121751\tvalid_1's auc: 0.83666\tvalid_1's binary_logloss: 0.137136\n",
            "[194]\ttraining's auc: 0.886944\ttraining's binary_logloss: 0.121682\tvalid_1's auc: 0.836606\tvalid_1's binary_logloss: 0.137118\n",
            "[195]\ttraining's auc: 0.887132\ttraining's binary_logloss: 0.121616\tvalid_1's auc: 0.83659\tvalid_1's binary_logloss: 0.137101\n",
            "[196]\ttraining's auc: 0.887268\ttraining's binary_logloss: 0.121548\tvalid_1's auc: 0.836544\tvalid_1's binary_logloss: 0.137078\n",
            "[197]\ttraining's auc: 0.887392\ttraining's binary_logloss: 0.121481\tvalid_1's auc: 0.836636\tvalid_1's binary_logloss: 0.137049\n",
            "[198]\ttraining's auc: 0.887579\ttraining's binary_logloss: 0.121416\tvalid_1's auc: 0.8366\tvalid_1's binary_logloss: 0.137031\n",
            "[199]\ttraining's auc: 0.887737\ttraining's binary_logloss: 0.121354\tvalid_1's auc: 0.836639\tvalid_1's binary_logloss: 0.137015\n",
            "[200]\ttraining's auc: 0.8878\ttraining's binary_logloss: 0.121294\tvalid_1's auc: 0.836749\tvalid_1's binary_logloss: 0.136982\n",
            "[201]\ttraining's auc: 0.887933\ttraining's binary_logloss: 0.121226\tvalid_1's auc: 0.836794\tvalid_1's binary_logloss: 0.136965\n",
            "[202]\ttraining's auc: 0.888052\ttraining's binary_logloss: 0.121168\tvalid_1's auc: 0.836804\tvalid_1's binary_logloss: 0.136942\n",
            "[203]\ttraining's auc: 0.888222\ttraining's binary_logloss: 0.121098\tvalid_1's auc: 0.836782\tvalid_1's binary_logloss: 0.136924\n",
            "[204]\ttraining's auc: 0.888431\ttraining's binary_logloss: 0.121037\tvalid_1's auc: 0.836799\tvalid_1's binary_logloss: 0.13691\n",
            "[205]\ttraining's auc: 0.888583\ttraining's binary_logloss: 0.120976\tvalid_1's auc: 0.83673\tvalid_1's binary_logloss: 0.136899\n",
            "[206]\ttraining's auc: 0.888744\ttraining's binary_logloss: 0.120911\tvalid_1's auc: 0.836669\tvalid_1's binary_logloss: 0.136886\n",
            "[207]\ttraining's auc: 0.88889\ttraining's binary_logloss: 0.120854\tvalid_1's auc: 0.836576\tvalid_1's binary_logloss: 0.136878\n",
            "[208]\ttraining's auc: 0.889\ttraining's binary_logloss: 0.120795\tvalid_1's auc: 0.836565\tvalid_1's binary_logloss: 0.136864\n",
            "[209]\ttraining's auc: 0.889177\ttraining's binary_logloss: 0.120734\tvalid_1's auc: 0.83652\tvalid_1's binary_logloss: 0.136853\n",
            "[210]\ttraining's auc: 0.88926\ttraining's binary_logloss: 0.120675\tvalid_1's auc: 0.836503\tvalid_1's binary_logloss: 0.136842\n",
            "[211]\ttraining's auc: 0.889402\ttraining's binary_logloss: 0.120613\tvalid_1's auc: 0.836508\tvalid_1's binary_logloss: 0.136835\n",
            "[212]\ttraining's auc: 0.889564\ttraining's binary_logloss: 0.120549\tvalid_1's auc: 0.836544\tvalid_1's binary_logloss: 0.136822\n",
            "[213]\ttraining's auc: 0.889682\ttraining's binary_logloss: 0.120494\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.136805\n",
            "[214]\ttraining's auc: 0.889799\ttraining's binary_logloss: 0.120439\tvalid_1's auc: 0.836506\tvalid_1's binary_logloss: 0.136797\n",
            "[215]\ttraining's auc: 0.88995\ttraining's binary_logloss: 0.120382\tvalid_1's auc: 0.836465\tvalid_1's binary_logloss: 0.136786\n",
            "[216]\ttraining's auc: 0.890071\ttraining's binary_logloss: 0.120323\tvalid_1's auc: 0.836445\tvalid_1's binary_logloss: 0.136774\n",
            "[217]\ttraining's auc: 0.890188\ttraining's binary_logloss: 0.120265\tvalid_1's auc: 0.836416\tvalid_1's binary_logloss: 0.136753\n",
            "[218]\ttraining's auc: 0.890381\ttraining's binary_logloss: 0.120206\tvalid_1's auc: 0.836509\tvalid_1's binary_logloss: 0.136735\n",
            "[219]\ttraining's auc: 0.890513\ttraining's binary_logloss: 0.120149\tvalid_1's auc: 0.836502\tvalid_1's binary_logloss: 0.136728\n",
            "[220]\ttraining's auc: 0.890659\ttraining's binary_logloss: 0.120093\tvalid_1's auc: 0.83653\tvalid_1's binary_logloss: 0.136712\n",
            "[221]\ttraining's auc: 0.890818\ttraining's binary_logloss: 0.120038\tvalid_1's auc: 0.836526\tvalid_1's binary_logloss: 0.136704\n",
            "[222]\ttraining's auc: 0.890981\ttraining's binary_logloss: 0.119981\tvalid_1's auc: 0.836471\tvalid_1's binary_logloss: 0.136699\n",
            "[223]\ttraining's auc: 0.891186\ttraining's binary_logloss: 0.119919\tvalid_1's auc: 0.836519\tvalid_1's binary_logloss: 0.136683\n",
            "[224]\ttraining's auc: 0.891309\ttraining's binary_logloss: 0.119865\tvalid_1's auc: 0.836541\tvalid_1's binary_logloss: 0.136671\n",
            "[225]\ttraining's auc: 0.891398\ttraining's binary_logloss: 0.119811\tvalid_1's auc: 0.836568\tvalid_1's binary_logloss: 0.136657\n",
            "[226]\ttraining's auc: 0.891515\ttraining's binary_logloss: 0.119758\tvalid_1's auc: 0.836533\tvalid_1's binary_logloss: 0.136652\n",
            "[227]\ttraining's auc: 0.891687\ttraining's binary_logloss: 0.1197\tvalid_1's auc: 0.83653\tvalid_1's binary_logloss: 0.136638\n",
            "[228]\ttraining's auc: 0.891853\ttraining's binary_logloss: 0.119637\tvalid_1's auc: 0.836519\tvalid_1's binary_logloss: 0.136631\n",
            "[229]\ttraining's auc: 0.891969\ttraining's binary_logloss: 0.119578\tvalid_1's auc: 0.83652\tvalid_1's binary_logloss: 0.136622\n",
            "[230]\ttraining's auc: 0.892065\ttraining's binary_logloss: 0.11952\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.136611\n",
            "[231]\ttraining's auc: 0.892268\ttraining's binary_logloss: 0.119458\tvalid_1's auc: 0.836484\tvalid_1's binary_logloss: 0.136605\n",
            "[232]\ttraining's auc: 0.892397\ttraining's binary_logloss: 0.119407\tvalid_1's auc: 0.83651\tvalid_1's binary_logloss: 0.136595\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 52%|█████▏    | 26/50 [12:42<14:13, 35.54s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.15668\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.158908\n",
            "[2]\ttraining's auc: 0.8331\ttraining's binary_logloss: 0.151542\tvalid_1's auc: 0.806262\tvalid_1's binary_logloss: 0.154895\n",
            "[3]\ttraining's auc: 0.838289\ttraining's binary_logloss: 0.147684\tvalid_1's auc: 0.809689\tvalid_1's binary_logloss: 0.151991\n",
            "[4]\ttraining's auc: 0.842812\ttraining's binary_logloss: 0.144577\tvalid_1's auc: 0.81229\tvalid_1's binary_logloss: 0.149699\n",
            "[5]\ttraining's auc: 0.847352\ttraining's binary_logloss: 0.14192\tvalid_1's auc: 0.81671\tvalid_1's binary_logloss: 0.147725\n",
            "[6]\ttraining's auc: 0.851892\ttraining's binary_logloss: 0.139735\tvalid_1's auc: 0.819876\tvalid_1's binary_logloss: 0.146087\n",
            "[7]\ttraining's auc: 0.853494\ttraining's binary_logloss: 0.1378\tvalid_1's auc: 0.82094\tvalid_1's binary_logloss: 0.144757\n",
            "[8]\ttraining's auc: 0.855523\ttraining's binary_logloss: 0.136076\tvalid_1's auc: 0.820976\tvalid_1's binary_logloss: 0.143635\n",
            "[9]\ttraining's auc: 0.857426\ttraining's binary_logloss: 0.134583\tvalid_1's auc: 0.822304\tvalid_1's binary_logloss: 0.142557\n",
            "[10]\ttraining's auc: 0.85867\ttraining's binary_logloss: 0.133263\tvalid_1's auc: 0.822811\tvalid_1's binary_logloss: 0.141771\n",
            "[11]\ttraining's auc: 0.862129\ttraining's binary_logloss: 0.131951\tvalid_1's auc: 0.823261\tvalid_1's binary_logloss: 0.141067\n",
            "[12]\ttraining's auc: 0.864387\ttraining's binary_logloss: 0.130844\tvalid_1's auc: 0.824198\tvalid_1's binary_logloss: 0.140422\n",
            "[13]\ttraining's auc: 0.866373\ttraining's binary_logloss: 0.129777\tvalid_1's auc: 0.825793\tvalid_1's binary_logloss: 0.13978\n",
            "[14]\ttraining's auc: 0.867867\ttraining's binary_logloss: 0.128873\tvalid_1's auc: 0.8264\tvalid_1's binary_logloss: 0.139328\n",
            "[15]\ttraining's auc: 0.870066\ttraining's binary_logloss: 0.127995\tvalid_1's auc: 0.827106\tvalid_1's binary_logloss: 0.138885\n",
            "[16]\ttraining's auc: 0.871235\ttraining's binary_logloss: 0.127247\tvalid_1's auc: 0.827758\tvalid_1's binary_logloss: 0.138478\n",
            "[17]\ttraining's auc: 0.872762\ttraining's binary_logloss: 0.126472\tvalid_1's auc: 0.82804\tvalid_1's binary_logloss: 0.138121\n",
            "[18]\ttraining's auc: 0.874772\ttraining's binary_logloss: 0.125802\tvalid_1's auc: 0.828154\tvalid_1's binary_logloss: 0.137847\n",
            "[19]\ttraining's auc: 0.876444\ttraining's binary_logloss: 0.125103\tvalid_1's auc: 0.827723\tvalid_1's binary_logloss: 0.137629\n",
            "[20]\ttraining's auc: 0.878579\ttraining's binary_logloss: 0.124419\tvalid_1's auc: 0.827383\tvalid_1's binary_logloss: 0.13742\n",
            "[21]\ttraining's auc: 0.879707\ttraining's binary_logloss: 0.123825\tvalid_1's auc: 0.827228\tvalid_1's binary_logloss: 0.13732\n",
            "[22]\ttraining's auc: 0.880852\ttraining's binary_logloss: 0.123229\tvalid_1's auc: 0.828157\tvalid_1's binary_logloss: 0.137084\n",
            "[23]\ttraining's auc: 0.881834\ttraining's binary_logloss: 0.122692\tvalid_1's auc: 0.828301\tvalid_1's binary_logloss: 0.13693\n",
            "[24]\ttraining's auc: 0.884277\ttraining's binary_logloss: 0.122049\tvalid_1's auc: 0.828468\tvalid_1's binary_logloss: 0.136846\n",
            "[25]\ttraining's auc: 0.886064\ttraining's binary_logloss: 0.121473\tvalid_1's auc: 0.828274\tvalid_1's binary_logloss: 0.136775\n",
            "[26]\ttraining's auc: 0.886751\ttraining's binary_logloss: 0.121024\tvalid_1's auc: 0.828326\tvalid_1's binary_logloss: 0.136681\n",
            "[27]\ttraining's auc: 0.887825\ttraining's binary_logloss: 0.120532\tvalid_1's auc: 0.82865\tvalid_1's binary_logloss: 0.13662\n",
            "[28]\ttraining's auc: 0.889291\ttraining's binary_logloss: 0.120071\tvalid_1's auc: 0.829591\tvalid_1's binary_logloss: 0.136436\n",
            "[29]\ttraining's auc: 0.89011\ttraining's binary_logloss: 0.119654\tvalid_1's auc: 0.829338\tvalid_1's binary_logloss: 0.136398\n",
            "[30]\ttraining's auc: 0.891141\ttraining's binary_logloss: 0.119235\tvalid_1's auc: 0.829274\tvalid_1's binary_logloss: 0.136371\n",
            "[31]\ttraining's auc: 0.892035\ttraining's binary_logloss: 0.118878\tvalid_1's auc: 0.829299\tvalid_1's binary_logloss: 0.136353\n",
            "[32]\ttraining's auc: 0.893076\ttraining's binary_logloss: 0.118491\tvalid_1's auc: 0.829421\tvalid_1's binary_logloss: 0.136305\n",
            "[33]\ttraining's auc: 0.895793\ttraining's binary_logloss: 0.117896\tvalid_1's auc: 0.830239\tvalid_1's binary_logloss: 0.136094\n",
            "[34]\ttraining's auc: 0.896607\ttraining's binary_logloss: 0.11753\tvalid_1's auc: 0.830485\tvalid_1's binary_logloss: 0.136021\n",
            "[35]\ttraining's auc: 0.89842\ttraining's binary_logloss: 0.117092\tvalid_1's auc: 0.831305\tvalid_1's binary_logloss: 0.135883\n",
            "[36]\ttraining's auc: 0.90032\ttraining's binary_logloss: 0.116622\tvalid_1's auc: 0.831313\tvalid_1's binary_logloss: 0.135865\n",
            "[37]\ttraining's auc: 0.901304\ttraining's binary_logloss: 0.116254\tvalid_1's auc: 0.831309\tvalid_1's binary_logloss: 0.135834\n",
            "[38]\ttraining's auc: 0.901992\ttraining's binary_logloss: 0.115947\tvalid_1's auc: 0.831175\tvalid_1's binary_logloss: 0.135846\n",
            "[39]\ttraining's auc: 0.902982\ttraining's binary_logloss: 0.115622\tvalid_1's auc: 0.831602\tvalid_1's binary_logloss: 0.135767\n",
            "[40]\ttraining's auc: 0.903753\ttraining's binary_logloss: 0.115343\tvalid_1's auc: 0.831488\tvalid_1's binary_logloss: 0.135768\n",
            "[41]\ttraining's auc: 0.904361\ttraining's binary_logloss: 0.115032\tvalid_1's auc: 0.831364\tvalid_1's binary_logloss: 0.135772\n",
            "[42]\ttraining's auc: 0.904861\ttraining's binary_logloss: 0.114756\tvalid_1's auc: 0.831229\tvalid_1's binary_logloss: 0.135797\n",
            "[43]\ttraining's auc: 0.906582\ttraining's binary_logloss: 0.114259\tvalid_1's auc: 0.830887\tvalid_1's binary_logloss: 0.135866\n",
            "[44]\ttraining's auc: 0.907408\ttraining's binary_logloss: 0.113926\tvalid_1's auc: 0.831337\tvalid_1's binary_logloss: 0.135752\n",
            "[45]\ttraining's auc: 0.907809\ttraining's binary_logloss: 0.113676\tvalid_1's auc: 0.831371\tvalid_1's binary_logloss: 0.135744\n",
            "[46]\ttraining's auc: 0.908245\ttraining's binary_logloss: 0.113409\tvalid_1's auc: 0.831523\tvalid_1's binary_logloss: 0.135732\n",
            "[47]\ttraining's auc: 0.909281\ttraining's binary_logloss: 0.113095\tvalid_1's auc: 0.831277\tvalid_1's binary_logloss: 0.135775\n",
            "[48]\ttraining's auc: 0.909793\ttraining's binary_logloss: 0.112827\tvalid_1's auc: 0.831445\tvalid_1's binary_logloss: 0.135741\n",
            "[49]\ttraining's auc: 0.910158\ttraining's binary_logloss: 0.112606\tvalid_1's auc: 0.831387\tvalid_1's binary_logloss: 0.135762\n",
            "[50]\ttraining's auc: 0.910911\ttraining's binary_logloss: 0.112275\tvalid_1's auc: 0.831305\tvalid_1's binary_logloss: 0.13578\n",
            "[51]\ttraining's auc: 0.911276\ttraining's binary_logloss: 0.112055\tvalid_1's auc: 0.830921\tvalid_1's binary_logloss: 0.135848\n",
            "[52]\ttraining's auc: 0.912097\ttraining's binary_logloss: 0.111826\tvalid_1's auc: 0.831069\tvalid_1's binary_logloss: 0.135813\n",
            "[53]\ttraining's auc: 0.912542\ttraining's binary_logloss: 0.111581\tvalid_1's auc: 0.830871\tvalid_1's binary_logloss: 0.135835\n",
            "[54]\ttraining's auc: 0.913141\ttraining's binary_logloss: 0.111324\tvalid_1's auc: 0.831082\tvalid_1's binary_logloss: 0.135824\n",
            "[55]\ttraining's auc: 0.913819\ttraining's binary_logloss: 0.111083\tvalid_1's auc: 0.830775\tvalid_1's binary_logloss: 0.135894\n",
            "[56]\ttraining's auc: 0.914502\ttraining's binary_logloss: 0.1108\tvalid_1's auc: 0.830781\tvalid_1's binary_logloss: 0.135903\n",
            "[57]\ttraining's auc: 0.915417\ttraining's binary_logloss: 0.110513\tvalid_1's auc: 0.830638\tvalid_1's binary_logloss: 0.135953\n",
            "[58]\ttraining's auc: 0.916137\ttraining's binary_logloss: 0.110251\tvalid_1's auc: 0.830485\tvalid_1's binary_logloss: 0.135972\n",
            "[59]\ttraining's auc: 0.916594\ttraining's binary_logloss: 0.11005\tvalid_1's auc: 0.830159\tvalid_1's binary_logloss: 0.136046\n",
            "[60]\ttraining's auc: 0.91788\ttraining's binary_logloss: 0.109774\tvalid_1's auc: 0.829894\tvalid_1's binary_logloss: 0.136093\n",
            "[61]\ttraining's auc: 0.918184\ttraining's binary_logloss: 0.109617\tvalid_1's auc: 0.829849\tvalid_1's binary_logloss: 0.136113\n",
            "[62]\ttraining's auc: 0.918894\ttraining's binary_logloss: 0.109423\tvalid_1's auc: 0.82982\tvalid_1's binary_logloss: 0.136117\n",
            "[63]\ttraining's auc: 0.919451\ttraining's binary_logloss: 0.109157\tvalid_1's auc: 0.829919\tvalid_1's binary_logloss: 0.136131\n",
            "[64]\ttraining's auc: 0.91997\ttraining's binary_logloss: 0.1089\tvalid_1's auc: 0.830046\tvalid_1's binary_logloss: 0.136107\n",
            "[65]\ttraining's auc: 0.920502\ttraining's binary_logloss: 0.108637\tvalid_1's auc: 0.829789\tvalid_1's binary_logloss: 0.136202\n",
            "[66]\ttraining's auc: 0.92074\ttraining's binary_logloss: 0.108457\tvalid_1's auc: 0.829467\tvalid_1's binary_logloss: 0.136295\n",
            "[67]\ttraining's auc: 0.921154\ttraining's binary_logloss: 0.108254\tvalid_1's auc: 0.829201\tvalid_1's binary_logloss: 0.136351\n",
            "[68]\ttraining's auc: 0.921784\ttraining's binary_logloss: 0.108032\tvalid_1's auc: 0.828952\tvalid_1's binary_logloss: 0.136416\n",
            "[69]\ttraining's auc: 0.92196\ttraining's binary_logloss: 0.107895\tvalid_1's auc: 0.828756\tvalid_1's binary_logloss: 0.136464\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 52%|█████▏    | 26/50 [12:51<14:13, 35.54s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.159093\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.154735\n",
            "[2]\ttraining's auc: 0.828181\ttraining's binary_logloss: 0.153991\tvalid_1's auc: 0.817645\tvalid_1's binary_logloss: 0.15061\n",
            "[3]\ttraining's auc: 0.833327\ttraining's binary_logloss: 0.149968\tvalid_1's auc: 0.818571\tvalid_1's binary_logloss: 0.14758\n",
            "[4]\ttraining's auc: 0.839336\ttraining's binary_logloss: 0.146796\tvalid_1's auc: 0.8224\tvalid_1's binary_logloss: 0.145212\n",
            "[5]\ttraining's auc: 0.844808\ttraining's binary_logloss: 0.144162\tvalid_1's auc: 0.824705\tvalid_1's binary_logloss: 0.143321\n",
            "[6]\ttraining's auc: 0.849318\ttraining's binary_logloss: 0.14188\tvalid_1's auc: 0.827086\tvalid_1's binary_logloss: 0.14176\n",
            "[7]\ttraining's auc: 0.852096\ttraining's binary_logloss: 0.139989\tvalid_1's auc: 0.828267\tvalid_1's binary_logloss: 0.140372\n",
            "[8]\ttraining's auc: 0.855666\ttraining's binary_logloss: 0.138281\tvalid_1's auc: 0.830879\tvalid_1's binary_logloss: 0.139195\n",
            "[9]\ttraining's auc: 0.857697\ttraining's binary_logloss: 0.136714\tvalid_1's auc: 0.831229\tvalid_1's binary_logloss: 0.138182\n",
            "[10]\ttraining's auc: 0.859978\ttraining's binary_logloss: 0.13536\tvalid_1's auc: 0.831714\tvalid_1's binary_logloss: 0.137369\n",
            "[11]\ttraining's auc: 0.861548\ttraining's binary_logloss: 0.134137\tvalid_1's auc: 0.831971\tvalid_1's binary_logloss: 0.136607\n",
            "[12]\ttraining's auc: 0.866416\ttraining's binary_logloss: 0.132922\tvalid_1's auc: 0.832812\tvalid_1's binary_logloss: 0.135968\n",
            "[13]\ttraining's auc: 0.868681\ttraining's binary_logloss: 0.131835\tvalid_1's auc: 0.833492\tvalid_1's binary_logloss: 0.135415\n",
            "[14]\ttraining's auc: 0.870444\ttraining's binary_logloss: 0.130878\tvalid_1's auc: 0.833256\tvalid_1's binary_logloss: 0.134917\n",
            "[15]\ttraining's auc: 0.871556\ttraining's binary_logloss: 0.130007\tvalid_1's auc: 0.833687\tvalid_1's binary_logloss: 0.13448\n",
            "[16]\ttraining's auc: 0.872556\ttraining's binary_logloss: 0.129173\tvalid_1's auc: 0.833492\tvalid_1's binary_logloss: 0.134103\n",
            "[17]\ttraining's auc: 0.873652\ttraining's binary_logloss: 0.128362\tvalid_1's auc: 0.833376\tvalid_1's binary_logloss: 0.133797\n",
            "[18]\ttraining's auc: 0.874607\ttraining's binary_logloss: 0.127662\tvalid_1's auc: 0.833136\tvalid_1's binary_logloss: 0.133569\n",
            "[19]\ttraining's auc: 0.875617\ttraining's binary_logloss: 0.126988\tvalid_1's auc: 0.833149\tvalid_1's binary_logloss: 0.133312\n",
            "[20]\ttraining's auc: 0.877222\ttraining's binary_logloss: 0.126303\tvalid_1's auc: 0.833018\tvalid_1's binary_logloss: 0.1331\n",
            "[21]\ttraining's auc: 0.878792\ttraining's binary_logloss: 0.125697\tvalid_1's auc: 0.83294\tvalid_1's binary_logloss: 0.132903\n",
            "[22]\ttraining's auc: 0.879983\ttraining's binary_logloss: 0.125077\tvalid_1's auc: 0.832916\tvalid_1's binary_logloss: 0.132704\n",
            "[23]\ttraining's auc: 0.881049\ttraining's binary_logloss: 0.124514\tvalid_1's auc: 0.832848\tvalid_1's binary_logloss: 0.132568\n",
            "[24]\ttraining's auc: 0.882622\ttraining's binary_logloss: 0.12394\tvalid_1's auc: 0.832506\tvalid_1's binary_logloss: 0.132457\n",
            "[25]\ttraining's auc: 0.884329\ttraining's binary_logloss: 0.123418\tvalid_1's auc: 0.83254\tvalid_1's binary_logloss: 0.132348\n",
            "[26]\ttraining's auc: 0.88594\ttraining's binary_logloss: 0.122877\tvalid_1's auc: 0.832725\tvalid_1's binary_logloss: 0.132197\n",
            "[27]\ttraining's auc: 0.886669\ttraining's binary_logloss: 0.122421\tvalid_1's auc: 0.833235\tvalid_1's binary_logloss: 0.132092\n",
            "[28]\ttraining's auc: 0.889228\ttraining's binary_logloss: 0.121856\tvalid_1's auc: 0.833542\tvalid_1's binary_logloss: 0.132026\n",
            "[29]\ttraining's auc: 0.890254\ttraining's binary_logloss: 0.12143\tvalid_1's auc: 0.833181\tvalid_1's binary_logloss: 0.131983\n",
            "[30]\ttraining's auc: 0.891346\ttraining's binary_logloss: 0.12102\tvalid_1's auc: 0.833011\tvalid_1's binary_logloss: 0.131941\n",
            "[31]\ttraining's auc: 0.892326\ttraining's binary_logloss: 0.120617\tvalid_1's auc: 0.833461\tvalid_1's binary_logloss: 0.131875\n",
            "[32]\ttraining's auc: 0.893344\ttraining's binary_logloss: 0.120226\tvalid_1's auc: 0.833473\tvalid_1's binary_logloss: 0.131811\n",
            "[33]\ttraining's auc: 0.893809\ttraining's binary_logloss: 0.119846\tvalid_1's auc: 0.83376\tvalid_1's binary_logloss: 0.131711\n",
            "[34]\ttraining's auc: 0.894677\ttraining's binary_logloss: 0.119422\tvalid_1's auc: 0.833891\tvalid_1's binary_logloss: 0.131684\n",
            "[35]\ttraining's auc: 0.895077\ttraining's binary_logloss: 0.119124\tvalid_1's auc: 0.833935\tvalid_1's binary_logloss: 0.131658\n",
            "[36]\ttraining's auc: 0.896144\ttraining's binary_logloss: 0.118775\tvalid_1's auc: 0.833935\tvalid_1's binary_logloss: 0.131629\n",
            "[37]\ttraining's auc: 0.896564\ttraining's binary_logloss: 0.118479\tvalid_1's auc: 0.833903\tvalid_1's binary_logloss: 0.131602\n",
            "[38]\ttraining's auc: 0.897611\ttraining's binary_logloss: 0.118172\tvalid_1's auc: 0.833659\tvalid_1's binary_logloss: 0.131605\n",
            "[39]\ttraining's auc: 0.899205\ttraining's binary_logloss: 0.117803\tvalid_1's auc: 0.833696\tvalid_1's binary_logloss: 0.131576\n",
            "[40]\ttraining's auc: 0.900598\ttraining's binary_logloss: 0.117427\tvalid_1's auc: 0.833815\tvalid_1's binary_logloss: 0.131552\n",
            "[41]\ttraining's auc: 0.902055\ttraining's binary_logloss: 0.117025\tvalid_1's auc: 0.834082\tvalid_1's binary_logloss: 0.131509\n",
            "[42]\ttraining's auc: 0.902752\ttraining's binary_logloss: 0.116693\tvalid_1's auc: 0.834014\tvalid_1's binary_logloss: 0.13151\n",
            "[43]\ttraining's auc: 0.903707\ttraining's binary_logloss: 0.116384\tvalid_1's auc: 0.834106\tvalid_1's binary_logloss: 0.131497\n",
            "[44]\ttraining's auc: 0.904629\ttraining's binary_logloss: 0.116068\tvalid_1's auc: 0.834178\tvalid_1's binary_logloss: 0.131427\n",
            "[45]\ttraining's auc: 0.905243\ttraining's binary_logloss: 0.115798\tvalid_1's auc: 0.83421\tvalid_1's binary_logloss: 0.13139\n",
            "[46]\ttraining's auc: 0.905751\ttraining's binary_logloss: 0.115548\tvalid_1's auc: 0.834355\tvalid_1's binary_logloss: 0.131363\n",
            "[47]\ttraining's auc: 0.906488\ttraining's binary_logloss: 0.115206\tvalid_1's auc: 0.83428\tvalid_1's binary_logloss: 0.131373\n",
            "[48]\ttraining's auc: 0.906928\ttraining's binary_logloss: 0.114938\tvalid_1's auc: 0.83413\tvalid_1's binary_logloss: 0.131423\n",
            "[49]\ttraining's auc: 0.907723\ttraining's binary_logloss: 0.114586\tvalid_1's auc: 0.834114\tvalid_1's binary_logloss: 0.131436\n",
            "[50]\ttraining's auc: 0.90816\ttraining's binary_logloss: 0.11436\tvalid_1's auc: 0.834119\tvalid_1's binary_logloss: 0.131412\n",
            "[51]\ttraining's auc: 0.908855\ttraining's binary_logloss: 0.114041\tvalid_1's auc: 0.83396\tvalid_1's binary_logloss: 0.13144\n",
            "[52]\ttraining's auc: 0.909657\ttraining's binary_logloss: 0.113719\tvalid_1's auc: 0.833857\tvalid_1's binary_logloss: 0.131479\n",
            "[53]\ttraining's auc: 0.910006\ttraining's binary_logloss: 0.113518\tvalid_1's auc: 0.833895\tvalid_1's binary_logloss: 0.131483\n",
            "[54]\ttraining's auc: 0.910778\ttraining's binary_logloss: 0.113243\tvalid_1's auc: 0.83379\tvalid_1's binary_logloss: 0.131503\n",
            "[55]\ttraining's auc: 0.911442\ttraining's binary_logloss: 0.112949\tvalid_1's auc: 0.833636\tvalid_1's binary_logloss: 0.131519\n",
            "[56]\ttraining's auc: 0.911926\ttraining's binary_logloss: 0.112715\tvalid_1's auc: 0.833547\tvalid_1's binary_logloss: 0.131513\n",
            "[57]\ttraining's auc: 0.912589\ttraining's binary_logloss: 0.112462\tvalid_1's auc: 0.833548\tvalid_1's binary_logloss: 0.131505\n",
            "[58]\ttraining's auc: 0.913014\ttraining's binary_logloss: 0.112224\tvalid_1's auc: 0.833345\tvalid_1's binary_logloss: 0.131536\n",
            "[59]\ttraining's auc: 0.913487\ttraining's binary_logloss: 0.111975\tvalid_1's auc: 0.833354\tvalid_1's binary_logloss: 0.131516\n",
            "[60]\ttraining's auc: 0.914109\ttraining's binary_logloss: 0.111688\tvalid_1's auc: 0.833215\tvalid_1's binary_logloss: 0.131551\n",
            "[61]\ttraining's auc: 0.914565\ttraining's binary_logloss: 0.111453\tvalid_1's auc: 0.832892\tvalid_1's binary_logloss: 0.13159\n",
            "[62]\ttraining's auc: 0.914875\ttraining's binary_logloss: 0.111237\tvalid_1's auc: 0.832975\tvalid_1's binary_logloss: 0.131597\n",
            "[63]\ttraining's auc: 0.915172\ttraining's binary_logloss: 0.111048\tvalid_1's auc: 0.833025\tvalid_1's binary_logloss: 0.13158\n",
            "[64]\ttraining's auc: 0.915369\ttraining's binary_logloss: 0.110884\tvalid_1's auc: 0.832961\tvalid_1's binary_logloss: 0.131581\n",
            "[65]\ttraining's auc: 0.916128\ttraining's binary_logloss: 0.110572\tvalid_1's auc: 0.832869\tvalid_1's binary_logloss: 0.131605\n",
            "[66]\ttraining's auc: 0.916797\ttraining's binary_logloss: 0.110278\tvalid_1's auc: 0.832665\tvalid_1's binary_logloss: 0.131675\n",
            "[67]\ttraining's auc: 0.917047\ttraining's binary_logloss: 0.110119\tvalid_1's auc: 0.832481\tvalid_1's binary_logloss: 0.131709\n",
            "[68]\ttraining's auc: 0.917577\ttraining's binary_logloss: 0.109908\tvalid_1's auc: 0.832287\tvalid_1's binary_logloss: 0.131747\n",
            "[69]\ttraining's auc: 0.917792\ttraining's binary_logloss: 0.109748\tvalid_1's auc: 0.832098\tvalid_1's binary_logloss: 0.131776\n",
            "[70]\ttraining's auc: 0.918083\ttraining's binary_logloss: 0.109593\tvalid_1's auc: 0.832092\tvalid_1's binary_logloss: 0.131785\n",
            "[71]\ttraining's auc: 0.918345\ttraining's binary_logloss: 0.109404\tvalid_1's auc: 0.832097\tvalid_1's binary_logloss: 0.131786\n",
            "[72]\ttraining's auc: 0.918683\ttraining's binary_logloss: 0.109228\tvalid_1's auc: 0.832069\tvalid_1's binary_logloss: 0.131797\n",
            "[73]\ttraining's auc: 0.919136\ttraining's binary_logloss: 0.109016\tvalid_1's auc: 0.832035\tvalid_1's binary_logloss: 0.131789\n",
            "[74]\ttraining's auc: 0.919646\ttraining's binary_logloss: 0.108794\tvalid_1's auc: 0.83179\tvalid_1's binary_logloss: 0.131864\n",
            "[75]\ttraining's auc: 0.919872\ttraining's binary_logloss: 0.108659\tvalid_1's auc: 0.831734\tvalid_1's binary_logloss: 0.131878\n",
            "[76]\ttraining's auc: 0.920255\ttraining's binary_logloss: 0.108458\tvalid_1's auc: 0.8317\tvalid_1's binary_logloss: 0.131906\n",
            " 52%|█████▏    | 26/50 [12:58<14:13, 35.54s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.155714\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.161863\n",
            "[2]\ttraining's auc: 0.83305\ttraining's binary_logloss: 0.1506\tvalid_1's auc: 0.815825\tvalid_1's binary_logloss: 0.157182\n",
            "[3]\ttraining's auc: 0.838375\ttraining's binary_logloss: 0.146868\tvalid_1's auc: 0.818315\tvalid_1's binary_logloss: 0.153938\n",
            "[4]\ttraining's auc: 0.846102\ttraining's binary_logloss: 0.143537\tvalid_1's auc: 0.823337\tvalid_1's binary_logloss: 0.151441\n",
            "[5]\ttraining's auc: 0.848841\ttraining's binary_logloss: 0.140992\tvalid_1's auc: 0.82475\tvalid_1's binary_logloss: 0.149421\n",
            "[6]\ttraining's auc: 0.851203\ttraining's binary_logloss: 0.13875\tvalid_1's auc: 0.826377\tvalid_1's binary_logloss: 0.147578\n",
            "[7]\ttraining's auc: 0.85319\ttraining's binary_logloss: 0.136844\tvalid_1's auc: 0.827824\tvalid_1's binary_logloss: 0.146138\n",
            "[8]\ttraining's auc: 0.855647\ttraining's binary_logloss: 0.135196\tvalid_1's auc: 0.829009\tvalid_1's binary_logloss: 0.144794\n",
            "[9]\ttraining's auc: 0.857311\ttraining's binary_logloss: 0.133704\tvalid_1's auc: 0.829853\tvalid_1's binary_logloss: 0.143723\n",
            "[10]\ttraining's auc: 0.860027\ttraining's binary_logloss: 0.13238\tvalid_1's auc: 0.830475\tvalid_1's binary_logloss: 0.142822\n",
            "[11]\ttraining's auc: 0.863428\ttraining's binary_logloss: 0.131199\tvalid_1's auc: 0.830952\tvalid_1's binary_logloss: 0.141997\n",
            "[12]\ttraining's auc: 0.8653\ttraining's binary_logloss: 0.130034\tvalid_1's auc: 0.831094\tvalid_1's binary_logloss: 0.141391\n",
            "[13]\ttraining's auc: 0.866788\ttraining's binary_logloss: 0.129076\tvalid_1's auc: 0.831326\tvalid_1's binary_logloss: 0.140807\n",
            "[14]\ttraining's auc: 0.869377\ttraining's binary_logloss: 0.128094\tvalid_1's auc: 0.831436\tvalid_1's binary_logloss: 0.140271\n",
            "[15]\ttraining's auc: 0.871587\ttraining's binary_logloss: 0.127219\tvalid_1's auc: 0.833525\tvalid_1's binary_logloss: 0.139799\n",
            "[16]\ttraining's auc: 0.872674\ttraining's binary_logloss: 0.126394\tvalid_1's auc: 0.833606\tvalid_1's binary_logloss: 0.1394\n",
            "[17]\ttraining's auc: 0.873676\ttraining's binary_logloss: 0.12566\tvalid_1's auc: 0.834796\tvalid_1's binary_logloss: 0.138976\n",
            "[18]\ttraining's auc: 0.875926\ttraining's binary_logloss: 0.124904\tvalid_1's auc: 0.834689\tvalid_1's binary_logloss: 0.138697\n",
            "[19]\ttraining's auc: 0.87844\ttraining's binary_logloss: 0.124157\tvalid_1's auc: 0.834773\tvalid_1's binary_logloss: 0.138406\n",
            "[20]\ttraining's auc: 0.880226\ttraining's binary_logloss: 0.123498\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.138081\n",
            "[21]\ttraining's auc: 0.881941\ttraining's binary_logloss: 0.12289\tvalid_1's auc: 0.835681\tvalid_1's binary_logloss: 0.137844\n",
            "[22]\ttraining's auc: 0.883444\ttraining's binary_logloss: 0.122324\tvalid_1's auc: 0.835433\tvalid_1's binary_logloss: 0.137662\n",
            "[23]\ttraining's auc: 0.884775\ttraining's binary_logloss: 0.121728\tvalid_1's auc: 0.835912\tvalid_1's binary_logloss: 0.137469\n",
            "[24]\ttraining's auc: 0.886051\ttraining's binary_logloss: 0.121166\tvalid_1's auc: 0.835336\tvalid_1's binary_logloss: 0.137427\n",
            "[25]\ttraining's auc: 0.88797\ttraining's binary_logloss: 0.120597\tvalid_1's auc: 0.835572\tvalid_1's binary_logloss: 0.137262\n",
            "[26]\ttraining's auc: 0.889025\ttraining's binary_logloss: 0.120087\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.137088\n",
            "[27]\ttraining's auc: 0.890284\ttraining's binary_logloss: 0.119614\tvalid_1's auc: 0.836452\tvalid_1's binary_logloss: 0.136987\n",
            "[28]\ttraining's auc: 0.891283\ttraining's binary_logloss: 0.119178\tvalid_1's auc: 0.836074\tvalid_1's binary_logloss: 0.136941\n",
            "[29]\ttraining's auc: 0.892625\ttraining's binary_logloss: 0.118725\tvalid_1's auc: 0.836207\tvalid_1's binary_logloss: 0.136876\n",
            "[30]\ttraining's auc: 0.893657\ttraining's binary_logloss: 0.118306\tvalid_1's auc: 0.83583\tvalid_1's binary_logloss: 0.136879\n",
            "[31]\ttraining's auc: 0.895525\ttraining's binary_logloss: 0.117762\tvalid_1's auc: 0.835808\tvalid_1's binary_logloss: 0.136794\n",
            "[32]\ttraining's auc: 0.897009\ttraining's binary_logloss: 0.117307\tvalid_1's auc: 0.835875\tvalid_1's binary_logloss: 0.13675\n",
            "[33]\ttraining's auc: 0.897659\ttraining's binary_logloss: 0.116956\tvalid_1's auc: 0.836028\tvalid_1's binary_logloss: 0.136703\n",
            "[34]\ttraining's auc: 0.898451\ttraining's binary_logloss: 0.11663\tvalid_1's auc: 0.836221\tvalid_1's binary_logloss: 0.136619\n",
            "[35]\ttraining's auc: 0.899351\ttraining's binary_logloss: 0.116269\tvalid_1's auc: 0.836576\tvalid_1's binary_logloss: 0.136515\n",
            "[36]\ttraining's auc: 0.900238\ttraining's binary_logloss: 0.115876\tvalid_1's auc: 0.836104\tvalid_1's binary_logloss: 0.136525\n",
            "[37]\ttraining's auc: 0.901156\ttraining's binary_logloss: 0.115525\tvalid_1's auc: 0.835928\tvalid_1's binary_logloss: 0.136519\n",
            "[38]\ttraining's auc: 0.901877\ttraining's binary_logloss: 0.115251\tvalid_1's auc: 0.835873\tvalid_1's binary_logloss: 0.13652\n",
            "[39]\ttraining's auc: 0.902825\ttraining's binary_logloss: 0.114932\tvalid_1's auc: 0.83567\tvalid_1's binary_logloss: 0.136523\n",
            "[40]\ttraining's auc: 0.903663\ttraining's binary_logloss: 0.114615\tvalid_1's auc: 0.835582\tvalid_1's binary_logloss: 0.136489\n",
            "[41]\ttraining's auc: 0.904477\ttraining's binary_logloss: 0.114323\tvalid_1's auc: 0.835728\tvalid_1's binary_logloss: 0.136456\n",
            "[42]\ttraining's auc: 0.905112\ttraining's binary_logloss: 0.11405\tvalid_1's auc: 0.835712\tvalid_1's binary_logloss: 0.136447\n",
            "[43]\ttraining's auc: 0.906094\ttraining's binary_logloss: 0.113639\tvalid_1's auc: 0.835878\tvalid_1's binary_logloss: 0.136419\n",
            "[44]\ttraining's auc: 0.90677\ttraining's binary_logloss: 0.113288\tvalid_1's auc: 0.835842\tvalid_1's binary_logloss: 0.136462\n",
            "[45]\ttraining's auc: 0.907674\ttraining's binary_logloss: 0.112967\tvalid_1's auc: 0.835901\tvalid_1's binary_logloss: 0.136494\n",
            "[46]\ttraining's auc: 0.908227\ttraining's binary_logloss: 0.112726\tvalid_1's auc: 0.835749\tvalid_1's binary_logloss: 0.13649\n",
            "[47]\ttraining's auc: 0.909096\ttraining's binary_logloss: 0.112347\tvalid_1's auc: 0.835989\tvalid_1's binary_logloss: 0.136447\n",
            "[48]\ttraining's auc: 0.909642\ttraining's binary_logloss: 0.1121\tvalid_1's auc: 0.835546\tvalid_1's binary_logloss: 0.136531\n",
            "[49]\ttraining's auc: 0.910168\ttraining's binary_logloss: 0.111838\tvalid_1's auc: 0.835684\tvalid_1's binary_logloss: 0.1365\n",
            "[50]\ttraining's auc: 0.910784\ttraining's binary_logloss: 0.111558\tvalid_1's auc: 0.835552\tvalid_1's binary_logloss: 0.136542\n",
            "[51]\ttraining's auc: 0.911342\ttraining's binary_logloss: 0.111247\tvalid_1's auc: 0.835679\tvalid_1's binary_logloss: 0.136538\n",
            "[52]\ttraining's auc: 0.911964\ttraining's binary_logloss: 0.110947\tvalid_1's auc: 0.835544\tvalid_1's binary_logloss: 0.136593\n",
            "[53]\ttraining's auc: 0.91253\ttraining's binary_logloss: 0.110683\tvalid_1's auc: 0.835188\tvalid_1's binary_logloss: 0.136677\n",
            "[54]\ttraining's auc: 0.912854\ttraining's binary_logloss: 0.110484\tvalid_1's auc: 0.835043\tvalid_1's binary_logloss: 0.136712\n",
            "[55]\ttraining's auc: 0.913175\ttraining's binary_logloss: 0.110296\tvalid_1's auc: 0.834963\tvalid_1's binary_logloss: 0.136736\n",
            "[56]\ttraining's auc: 0.913676\ttraining's binary_logloss: 0.110047\tvalid_1's auc: 0.834938\tvalid_1's binary_logloss: 0.136753\n",
            "[57]\ttraining's auc: 0.914237\ttraining's binary_logloss: 0.109805\tvalid_1's auc: 0.83487\tvalid_1's binary_logloss: 0.136788\n",
            "[58]\ttraining's auc: 0.914895\ttraining's binary_logloss: 0.109573\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.136778\n",
            "[59]\ttraining's auc: 0.915372\ttraining's binary_logloss: 0.109326\tvalid_1's auc: 0.835189\tvalid_1's binary_logloss: 0.136751\n",
            "[60]\ttraining's auc: 0.915771\ttraining's binary_logloss: 0.109099\tvalid_1's auc: 0.835056\tvalid_1's binary_logloss: 0.13675\n",
            "[61]\ttraining's auc: 0.916786\ttraining's binary_logloss: 0.108744\tvalid_1's auc: 0.834989\tvalid_1's binary_logloss: 0.136743\n",
            "[62]\ttraining's auc: 0.917338\ttraining's binary_logloss: 0.108481\tvalid_1's auc: 0.834946\tvalid_1's binary_logloss: 0.136768\n",
            "[63]\ttraining's auc: 0.917694\ttraining's binary_logloss: 0.108285\tvalid_1's auc: 0.834789\tvalid_1's binary_logloss: 0.136796\n",
            "[64]\ttraining's auc: 0.918237\ttraining's binary_logloss: 0.108089\tvalid_1's auc: 0.83489\tvalid_1's binary_logloss: 0.136796\n",
            "[65]\ttraining's auc: 0.918638\ttraining's binary_logloss: 0.107856\tvalid_1's auc: 0.834679\tvalid_1's binary_logloss: 0.136843\n",
            " 54%|█████▍    | 27/50 [13:06<12:20, 32.19s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.160432\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.161995\n",
            "[2]\ttraining's auc: 0.831825\ttraining's binary_logloss: 0.1571\tvalid_1's auc: 0.806546\tvalid_1's binary_logloss: 0.159418\n",
            "[3]\ttraining's auc: 0.833647\ttraining's binary_logloss: 0.154319\tvalid_1's auc: 0.807898\tvalid_1's binary_logloss: 0.157209\n",
            "[4]\ttraining's auc: 0.83597\ttraining's binary_logloss: 0.151957\tvalid_1's auc: 0.808721\tvalid_1's binary_logloss: 0.155317\n",
            "[5]\ttraining's auc: 0.839437\ttraining's binary_logloss: 0.149871\tvalid_1's auc: 0.810265\tvalid_1's binary_logloss: 0.153712\n",
            "[6]\ttraining's auc: 0.842982\ttraining's binary_logloss: 0.148011\tvalid_1's auc: 0.814314\tvalid_1's binary_logloss: 0.152296\n",
            "[7]\ttraining's auc: 0.845406\ttraining's binary_logloss: 0.146365\tvalid_1's auc: 0.815399\tvalid_1's binary_logloss: 0.151036\n",
            "[8]\ttraining's auc: 0.848718\ttraining's binary_logloss: 0.144816\tvalid_1's auc: 0.817159\tvalid_1's binary_logloss: 0.149934\n",
            "[9]\ttraining's auc: 0.850037\ttraining's binary_logloss: 0.143418\tvalid_1's auc: 0.818611\tvalid_1's binary_logloss: 0.148871\n",
            "[10]\ttraining's auc: 0.851139\ttraining's binary_logloss: 0.142125\tvalid_1's auc: 0.818998\tvalid_1's binary_logloss: 0.147938\n",
            "[11]\ttraining's auc: 0.853357\ttraining's binary_logloss: 0.14095\tvalid_1's auc: 0.820536\tvalid_1's binary_logloss: 0.147084\n",
            "[12]\ttraining's auc: 0.854474\ttraining's binary_logloss: 0.139836\tvalid_1's auc: 0.820977\tvalid_1's binary_logloss: 0.146343\n",
            "[13]\ttraining's auc: 0.855343\ttraining's binary_logloss: 0.138824\tvalid_1's auc: 0.821199\tvalid_1's binary_logloss: 0.145657\n",
            "[14]\ttraining's auc: 0.855931\ttraining's binary_logloss: 0.137872\tvalid_1's auc: 0.821932\tvalid_1's binary_logloss: 0.144993\n",
            "[15]\ttraining's auc: 0.856361\ttraining's binary_logloss: 0.136962\tvalid_1's auc: 0.82177\tvalid_1's binary_logloss: 0.144351\n",
            "[16]\ttraining's auc: 0.859236\ttraining's binary_logloss: 0.136125\tvalid_1's auc: 0.822523\tvalid_1's binary_logloss: 0.143787\n",
            "[17]\ttraining's auc: 0.859704\ttraining's binary_logloss: 0.135367\tvalid_1's auc: 0.823108\tvalid_1's binary_logloss: 0.143277\n",
            "[18]\ttraining's auc: 0.861707\ttraining's binary_logloss: 0.134581\tvalid_1's auc: 0.823261\tvalid_1's binary_logloss: 0.142803\n",
            "[19]\ttraining's auc: 0.862264\ttraining's binary_logloss: 0.133883\tvalid_1's auc: 0.823513\tvalid_1's binary_logloss: 0.14231\n",
            "[20]\ttraining's auc: 0.86263\ttraining's binary_logloss: 0.133218\tvalid_1's auc: 0.823559\tvalid_1's binary_logloss: 0.141874\n",
            "[21]\ttraining's auc: 0.864241\ttraining's binary_logloss: 0.132566\tvalid_1's auc: 0.824568\tvalid_1's binary_logloss: 0.141445\n",
            "[22]\ttraining's auc: 0.865432\ttraining's binary_logloss: 0.131969\tvalid_1's auc: 0.825182\tvalid_1's binary_logloss: 0.141038\n",
            "[23]\ttraining's auc: 0.86657\ttraining's binary_logloss: 0.131332\tvalid_1's auc: 0.825412\tvalid_1's binary_logloss: 0.140681\n",
            "[24]\ttraining's auc: 0.867102\ttraining's binary_logloss: 0.130768\tvalid_1's auc: 0.825452\tvalid_1's binary_logloss: 0.140437\n",
            "[25]\ttraining's auc: 0.868387\ttraining's binary_logloss: 0.130239\tvalid_1's auc: 0.826183\tvalid_1's binary_logloss: 0.140142\n",
            "[26]\ttraining's auc: 0.869105\ttraining's binary_logloss: 0.129742\tvalid_1's auc: 0.826487\tvalid_1's binary_logloss: 0.139872\n",
            "[27]\ttraining's auc: 0.870155\ttraining's binary_logloss: 0.129224\tvalid_1's auc: 0.826858\tvalid_1's binary_logloss: 0.139622\n",
            "[28]\ttraining's auc: 0.870854\ttraining's binary_logloss: 0.128768\tvalid_1's auc: 0.826944\tvalid_1's binary_logloss: 0.139419\n",
            "[29]\ttraining's auc: 0.871646\ttraining's binary_logloss: 0.128313\tvalid_1's auc: 0.827222\tvalid_1's binary_logloss: 0.13918\n",
            "[30]\ttraining's auc: 0.872357\ttraining's binary_logloss: 0.127905\tvalid_1's auc: 0.827166\tvalid_1's binary_logloss: 0.138977\n",
            "[31]\ttraining's auc: 0.873293\ttraining's binary_logloss: 0.127452\tvalid_1's auc: 0.827255\tvalid_1's binary_logloss: 0.138784\n",
            "[32]\ttraining's auc: 0.873699\ttraining's binary_logloss: 0.12707\tvalid_1's auc: 0.827285\tvalid_1's binary_logloss: 0.138625\n",
            "[33]\ttraining's auc: 0.87508\ttraining's binary_logloss: 0.126656\tvalid_1's auc: 0.827763\tvalid_1's binary_logloss: 0.138451\n",
            "[34]\ttraining's auc: 0.875763\ttraining's binary_logloss: 0.126263\tvalid_1's auc: 0.82788\tvalid_1's binary_logloss: 0.138296\n",
            "[35]\ttraining's auc: 0.876733\ttraining's binary_logloss: 0.125889\tvalid_1's auc: 0.827938\tvalid_1's binary_logloss: 0.13814\n",
            "[36]\ttraining's auc: 0.877655\ttraining's binary_logloss: 0.125534\tvalid_1's auc: 0.828112\tvalid_1's binary_logloss: 0.138016\n",
            "[37]\ttraining's auc: 0.879021\ttraining's binary_logloss: 0.125183\tvalid_1's auc: 0.82803\tvalid_1's binary_logloss: 0.13789\n",
            "[38]\ttraining's auc: 0.879288\ttraining's binary_logloss: 0.124855\tvalid_1's auc: 0.828266\tvalid_1's binary_logloss: 0.137739\n",
            "[39]\ttraining's auc: 0.879953\ttraining's binary_logloss: 0.124546\tvalid_1's auc: 0.828155\tvalid_1's binary_logloss: 0.137638\n",
            "[40]\ttraining's auc: 0.88037\ttraining's binary_logloss: 0.124242\tvalid_1's auc: 0.828347\tvalid_1's binary_logloss: 0.137554\n",
            "[41]\ttraining's auc: 0.88073\ttraining's binary_logloss: 0.123954\tvalid_1's auc: 0.828774\tvalid_1's binary_logloss: 0.13743\n",
            "[42]\ttraining's auc: 0.881605\ttraining's binary_logloss: 0.123637\tvalid_1's auc: 0.828858\tvalid_1's binary_logloss: 0.137343\n",
            "[43]\ttraining's auc: 0.882249\ttraining's binary_logloss: 0.123342\tvalid_1's auc: 0.828752\tvalid_1's binary_logloss: 0.137244\n",
            "[44]\ttraining's auc: 0.883025\ttraining's binary_logloss: 0.123048\tvalid_1's auc: 0.82847\tvalid_1's binary_logloss: 0.137204\n",
            "[45]\ttraining's auc: 0.883708\ttraining's binary_logloss: 0.122757\tvalid_1's auc: 0.828426\tvalid_1's binary_logloss: 0.137115\n",
            "[46]\ttraining's auc: 0.884615\ttraining's binary_logloss: 0.122461\tvalid_1's auc: 0.828662\tvalid_1's binary_logloss: 0.137023\n",
            "[47]\ttraining's auc: 0.885273\ttraining's binary_logloss: 0.122197\tvalid_1's auc: 0.828428\tvalid_1's binary_logloss: 0.136977\n",
            "[48]\ttraining's auc: 0.886274\ttraining's binary_logloss: 0.121887\tvalid_1's auc: 0.829103\tvalid_1's binary_logloss: 0.136859\n",
            "[49]\ttraining's auc: 0.88685\ttraining's binary_logloss: 0.121607\tvalid_1's auc: 0.829388\tvalid_1's binary_logloss: 0.136778\n",
            "[50]\ttraining's auc: 0.887692\ttraining's binary_logloss: 0.121314\tvalid_1's auc: 0.829337\tvalid_1's binary_logloss: 0.136724\n",
            "[51]\ttraining's auc: 0.887981\ttraining's binary_logloss: 0.121082\tvalid_1's auc: 0.829458\tvalid_1's binary_logloss: 0.136673\n",
            "[52]\ttraining's auc: 0.888899\ttraining's binary_logloss: 0.120823\tvalid_1's auc: 0.829582\tvalid_1's binary_logloss: 0.136608\n",
            "[53]\ttraining's auc: 0.889678\ttraining's binary_logloss: 0.120556\tvalid_1's auc: 0.82981\tvalid_1's binary_logloss: 0.136567\n",
            "[54]\ttraining's auc: 0.890388\ttraining's binary_logloss: 0.120276\tvalid_1's auc: 0.829764\tvalid_1's binary_logloss: 0.136556\n",
            "[55]\ttraining's auc: 0.890976\ttraining's binary_logloss: 0.120037\tvalid_1's auc: 0.829893\tvalid_1's binary_logloss: 0.136499\n",
            "[56]\ttraining's auc: 0.891428\ttraining's binary_logloss: 0.119845\tvalid_1's auc: 0.830012\tvalid_1's binary_logloss: 0.136443\n",
            "[57]\ttraining's auc: 0.891919\ttraining's binary_logloss: 0.119612\tvalid_1's auc: 0.83007\tvalid_1's binary_logloss: 0.136419\n",
            "[58]\ttraining's auc: 0.893019\ttraining's binary_logloss: 0.119345\tvalid_1's auc: 0.830325\tvalid_1's binary_logloss: 0.13634\n",
            "[59]\ttraining's auc: 0.893389\ttraining's binary_logloss: 0.119152\tvalid_1's auc: 0.83023\tvalid_1's binary_logloss: 0.136322\n",
            "[60]\ttraining's auc: 0.893932\ttraining's binary_logloss: 0.118937\tvalid_1's auc: 0.830352\tvalid_1's binary_logloss: 0.136306\n",
            "[61]\ttraining's auc: 0.89477\ttraining's binary_logloss: 0.118697\tvalid_1's auc: 0.830551\tvalid_1's binary_logloss: 0.136227\n",
            "[62]\ttraining's auc: 0.895173\ttraining's binary_logloss: 0.118521\tvalid_1's auc: 0.830574\tvalid_1's binary_logloss: 0.136203\n",
            "[63]\ttraining's auc: 0.89575\ttraining's binary_logloss: 0.118321\tvalid_1's auc: 0.830686\tvalid_1's binary_logloss: 0.136179\n",
            "[64]\ttraining's auc: 0.896196\ttraining's binary_logloss: 0.118116\tvalid_1's auc: 0.830663\tvalid_1's binary_logloss: 0.136153\n",
            "[65]\ttraining's auc: 0.896527\ttraining's binary_logloss: 0.117937\tvalid_1's auc: 0.830329\tvalid_1's binary_logloss: 0.136196\n",
            "[66]\ttraining's auc: 0.897117\ttraining's binary_logloss: 0.117745\tvalid_1's auc: 0.830361\tvalid_1's binary_logloss: 0.136199\n",
            "[67]\ttraining's auc: 0.897584\ttraining's binary_logloss: 0.117561\tvalid_1's auc: 0.830464\tvalid_1's binary_logloss: 0.136174\n",
            "[68]\ttraining's auc: 0.898219\ttraining's binary_logloss: 0.117344\tvalid_1's auc: 0.830316\tvalid_1's binary_logloss: 0.136195\n",
            "[69]\ttraining's auc: 0.898601\ttraining's binary_logloss: 0.117152\tvalid_1's auc: 0.830199\tvalid_1's binary_logloss: 0.136213\n",
            "[70]\ttraining's auc: 0.899548\ttraining's binary_logloss: 0.116932\tvalid_1's auc: 0.830742\tvalid_1's binary_logloss: 0.136131\n",
            "[71]\ttraining's auc: 0.8999\ttraining's binary_logloss: 0.116746\tvalid_1's auc: 0.830664\tvalid_1's binary_logloss: 0.136141\n",
            "[72]\ttraining's auc: 0.900536\ttraining's binary_logloss: 0.116535\tvalid_1's auc: 0.830807\tvalid_1's binary_logloss: 0.1361\n",
            "[73]\ttraining's auc: 0.901063\ttraining's binary_logloss: 0.116374\tvalid_1's auc: 0.831057\tvalid_1's binary_logloss: 0.136062\n",
            "[74]\ttraining's auc: 0.901809\ttraining's binary_logloss: 0.116182\tvalid_1's auc: 0.831392\tvalid_1's binary_logloss: 0.136005\n",
            "[75]\ttraining's auc: 0.902342\ttraining's binary_logloss: 0.115979\tvalid_1's auc: 0.831352\tvalid_1's binary_logloss: 0.136015\n",
            "[76]\ttraining's auc: 0.902848\ttraining's binary_logloss: 0.115816\tvalid_1's auc: 0.831401\tvalid_1's binary_logloss: 0.136007\n",
            "[77]\ttraining's auc: 0.903284\ttraining's binary_logloss: 0.115642\tvalid_1's auc: 0.831358\tvalid_1's binary_logloss: 0.136001\n",
            "[78]\ttraining's auc: 0.90359\ttraining's binary_logloss: 0.11546\tvalid_1's auc: 0.831429\tvalid_1's binary_logloss: 0.135979\n",
            "[79]\ttraining's auc: 0.903897\ttraining's binary_logloss: 0.115311\tvalid_1's auc: 0.831623\tvalid_1's binary_logloss: 0.135954\n",
            "[80]\ttraining's auc: 0.904198\ttraining's binary_logloss: 0.115151\tvalid_1's auc: 0.831469\tvalid_1's binary_logloss: 0.135956\n",
            "[81]\ttraining's auc: 0.904577\ttraining's binary_logloss: 0.114992\tvalid_1's auc: 0.831501\tvalid_1's binary_logloss: 0.135959\n",
            "[82]\ttraining's auc: 0.904967\ttraining's binary_logloss: 0.114849\tvalid_1's auc: 0.831448\tvalid_1's binary_logloss: 0.135959\n",
            "[83]\ttraining's auc: 0.905297\ttraining's binary_logloss: 0.114683\tvalid_1's auc: 0.831492\tvalid_1's binary_logloss: 0.135964\n",
            "[84]\ttraining's auc: 0.906013\ttraining's binary_logloss: 0.114455\tvalid_1's auc: 0.831319\tvalid_1's binary_logloss: 0.13598\n",
            "[85]\ttraining's auc: 0.906385\ttraining's binary_logloss: 0.114266\tvalid_1's auc: 0.831413\tvalid_1's binary_logloss: 0.135977\n",
            "[86]\ttraining's auc: 0.906695\ttraining's binary_logloss: 0.114103\tvalid_1's auc: 0.83139\tvalid_1's binary_logloss: 0.135989\n",
            "[87]\ttraining's auc: 0.907228\ttraining's binary_logloss: 0.113971\tvalid_1's auc: 0.831502\tvalid_1's binary_logloss: 0.135965\n",
            "[88]\ttraining's auc: 0.907609\ttraining's binary_logloss: 0.113817\tvalid_1's auc: 0.831469\tvalid_1's binary_logloss: 0.135976\n",
            "[89]\ttraining's auc: 0.907849\ttraining's binary_logloss: 0.113692\tvalid_1's auc: 0.831487\tvalid_1's binary_logloss: 0.135968\n",
            "[90]\ttraining's auc: 0.908548\ttraining's binary_logloss: 0.11351\tvalid_1's auc: 0.831483\tvalid_1's binary_logloss: 0.135968\n",
            "[91]\ttraining's auc: 0.908779\ttraining's binary_logloss: 0.113368\tvalid_1's auc: 0.831399\tvalid_1's binary_logloss: 0.135989\n",
            "[92]\ttraining's auc: 0.909086\ttraining's binary_logloss: 0.113216\tvalid_1's auc: 0.831269\tvalid_1's binary_logloss: 0.136006\n",
            "[93]\ttraining's auc: 0.909379\ttraining's binary_logloss: 0.113093\tvalid_1's auc: 0.831046\tvalid_1's binary_logloss: 0.136035\n",
            "[94]\ttraining's auc: 0.909813\ttraining's binary_logloss: 0.112915\tvalid_1's auc: 0.831051\tvalid_1's binary_logloss: 0.136036\n",
            "[95]\ttraining's auc: 0.910152\ttraining's binary_logloss: 0.11275\tvalid_1's auc: 0.830847\tvalid_1's binary_logloss: 0.136075\n",
            "[96]\ttraining's auc: 0.910465\ttraining's binary_logloss: 0.112631\tvalid_1's auc: 0.830792\tvalid_1's binary_logloss: 0.136081\n",
            "[97]\ttraining's auc: 0.910885\ttraining's binary_logloss: 0.112472\tvalid_1's auc: 0.830835\tvalid_1's binary_logloss: 0.136083\n",
            "[98]\ttraining's auc: 0.911198\ttraining's binary_logloss: 0.112331\tvalid_1's auc: 0.830695\tvalid_1's binary_logloss: 0.136109\n",
            "[99]\ttraining's auc: 0.911413\ttraining's binary_logloss: 0.112201\tvalid_1's auc: 0.830668\tvalid_1's binary_logloss: 0.136121\n",
            "[100]\ttraining's auc: 0.911708\ttraining's binary_logloss: 0.112058\tvalid_1's auc: 0.830581\tvalid_1's binary_logloss: 0.136134\n",
            "[101]\ttraining's auc: 0.91186\ttraining's binary_logloss: 0.111944\tvalid_1's auc: 0.830485\tvalid_1's binary_logloss: 0.136151\n",
            "[102]\ttraining's auc: 0.912058\ttraining's binary_logloss: 0.111822\tvalid_1's auc: 0.830529\tvalid_1's binary_logloss: 0.136146\n",
            "[103]\ttraining's auc: 0.912335\ttraining's binary_logloss: 0.111708\tvalid_1's auc: 0.830474\tvalid_1's binary_logloss: 0.136156\n",
            "[104]\ttraining's auc: 0.91261\ttraining's binary_logloss: 0.111572\tvalid_1's auc: 0.830411\tvalid_1's binary_logloss: 0.136164\n",
            "[105]\ttraining's auc: 0.912939\ttraining's binary_logloss: 0.111428\tvalid_1's auc: 0.830324\tvalid_1's binary_logloss: 0.136192\n",
            "[106]\ttraining's auc: 0.91396\ttraining's binary_logloss: 0.111244\tvalid_1's auc: 0.830238\tvalid_1's binary_logloss: 0.136206\n",
            "[107]\ttraining's auc: 0.914704\ttraining's binary_logloss: 0.111103\tvalid_1's auc: 0.830145\tvalid_1's binary_logloss: 0.136212\n",
            "[108]\ttraining's auc: 0.914951\ttraining's binary_logloss: 0.110973\tvalid_1's auc: 0.830006\tvalid_1's binary_logloss: 0.136242\n",
            "[109]\ttraining's auc: 0.915249\ttraining's binary_logloss: 0.110831\tvalid_1's auc: 0.829983\tvalid_1's binary_logloss: 0.136257\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 54%|█████▍    | 27/50 [13:19<12:20, 32.19s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.162822\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.157559\n",
            "[2]\ttraining's auc: 0.823247\ttraining's binary_logloss: 0.159566\tvalid_1's auc: 0.804348\tvalid_1's binary_logloss: 0.154922\n",
            "[3]\ttraining's auc: 0.829874\ttraining's binary_logloss: 0.156779\tvalid_1's auc: 0.816066\tvalid_1's binary_logloss: 0.152662\n",
            "[4]\ttraining's auc: 0.834231\ttraining's binary_logloss: 0.154358\tvalid_1's auc: 0.818962\tvalid_1's binary_logloss: 0.150763\n",
            "[5]\ttraining's auc: 0.835215\ttraining's binary_logloss: 0.152253\tvalid_1's auc: 0.819053\tvalid_1's binary_logloss: 0.149138\n",
            "[6]\ttraining's auc: 0.837268\ttraining's binary_logloss: 0.150358\tvalid_1's auc: 0.820084\tvalid_1's binary_logloss: 0.147676\n",
            "[7]\ttraining's auc: 0.840358\ttraining's binary_logloss: 0.148677\tvalid_1's auc: 0.822779\tvalid_1's binary_logloss: 0.146425\n",
            "[8]\ttraining's auc: 0.841883\ttraining's binary_logloss: 0.14717\tvalid_1's auc: 0.823426\tvalid_1's binary_logloss: 0.145274\n",
            "[9]\ttraining's auc: 0.844135\ttraining's binary_logloss: 0.145768\tvalid_1's auc: 0.824518\tvalid_1's binary_logloss: 0.144253\n",
            "[10]\ttraining's auc: 0.848267\ttraining's binary_logloss: 0.144442\tvalid_1's auc: 0.826929\tvalid_1's binary_logloss: 0.14333\n",
            "[11]\ttraining's auc: 0.849328\ttraining's binary_logloss: 0.143262\tvalid_1's auc: 0.827791\tvalid_1's binary_logloss: 0.142469\n",
            "[12]\ttraining's auc: 0.85067\ttraining's binary_logloss: 0.142154\tvalid_1's auc: 0.829008\tvalid_1's binary_logloss: 0.141606\n",
            "[13]\ttraining's auc: 0.852289\ttraining's binary_logloss: 0.141156\tvalid_1's auc: 0.82908\tvalid_1's binary_logloss: 0.14088\n",
            "[14]\ttraining's auc: 0.855235\ttraining's binary_logloss: 0.140161\tvalid_1's auc: 0.830269\tvalid_1's binary_logloss: 0.140191\n",
            "[15]\ttraining's auc: 0.856522\ttraining's binary_logloss: 0.139268\tvalid_1's auc: 0.832819\tvalid_1's binary_logloss: 0.139477\n",
            "[16]\ttraining's auc: 0.857218\ttraining's binary_logloss: 0.138392\tvalid_1's auc: 0.833017\tvalid_1's binary_logloss: 0.138898\n",
            "[17]\ttraining's auc: 0.857924\ttraining's binary_logloss: 0.137574\tvalid_1's auc: 0.832785\tvalid_1's binary_logloss: 0.138421\n",
            "[18]\ttraining's auc: 0.859009\ttraining's binary_logloss: 0.136821\tvalid_1's auc: 0.832676\tvalid_1's binary_logloss: 0.137933\n",
            "[19]\ttraining's auc: 0.860085\ttraining's binary_logloss: 0.136097\tvalid_1's auc: 0.832442\tvalid_1's binary_logloss: 0.137455\n",
            "[20]\ttraining's auc: 0.86059\ttraining's binary_logloss: 0.135432\tvalid_1's auc: 0.83229\tvalid_1's binary_logloss: 0.137053\n",
            "[21]\ttraining's auc: 0.862786\ttraining's binary_logloss: 0.134761\tvalid_1's auc: 0.832705\tvalid_1's binary_logloss: 0.136638\n",
            "[22]\ttraining's auc: 0.864735\ttraining's binary_logloss: 0.134098\tvalid_1's auc: 0.833048\tvalid_1's binary_logloss: 0.136272\n",
            "[23]\ttraining's auc: 0.866006\ttraining's binary_logloss: 0.133496\tvalid_1's auc: 0.833381\tvalid_1's binary_logloss: 0.135925\n",
            "[24]\ttraining's auc: 0.867459\ttraining's binary_logloss: 0.132896\tvalid_1's auc: 0.833482\tvalid_1's binary_logloss: 0.135601\n",
            "[25]\ttraining's auc: 0.868239\ttraining's binary_logloss: 0.132373\tvalid_1's auc: 0.833992\tvalid_1's binary_logloss: 0.135292\n",
            "[26]\ttraining's auc: 0.870099\ttraining's binary_logloss: 0.131841\tvalid_1's auc: 0.834432\tvalid_1's binary_logloss: 0.135006\n",
            "[27]\ttraining's auc: 0.871005\ttraining's binary_logloss: 0.131325\tvalid_1's auc: 0.834454\tvalid_1's binary_logloss: 0.134768\n",
            "[28]\ttraining's auc: 0.871603\ttraining's binary_logloss: 0.13087\tvalid_1's auc: 0.834155\tvalid_1's binary_logloss: 0.134525\n",
            "[29]\ttraining's auc: 0.872348\ttraining's binary_logloss: 0.130387\tvalid_1's auc: 0.833978\tvalid_1's binary_logloss: 0.134324\n",
            "[30]\ttraining's auc: 0.872838\ttraining's binary_logloss: 0.129967\tvalid_1's auc: 0.834001\tvalid_1's binary_logloss: 0.1341\n",
            "[31]\ttraining's auc: 0.873432\ttraining's binary_logloss: 0.129556\tvalid_1's auc: 0.833893\tvalid_1's binary_logloss: 0.133915\n",
            "[32]\ttraining's auc: 0.874108\ttraining's binary_logloss: 0.12915\tvalid_1's auc: 0.833659\tvalid_1's binary_logloss: 0.133736\n",
            "[33]\ttraining's auc: 0.874602\ttraining's binary_logloss: 0.12876\tvalid_1's auc: 0.833934\tvalid_1's binary_logloss: 0.133537\n",
            "[34]\ttraining's auc: 0.875123\ttraining's binary_logloss: 0.128354\tvalid_1's auc: 0.833932\tvalid_1's binary_logloss: 0.133386\n",
            "[35]\ttraining's auc: 0.876524\ttraining's binary_logloss: 0.128007\tvalid_1's auc: 0.834638\tvalid_1's binary_logloss: 0.133227\n",
            "[36]\ttraining's auc: 0.876804\ttraining's binary_logloss: 0.127665\tvalid_1's auc: 0.834511\tvalid_1's binary_logloss: 0.133077\n",
            "[37]\ttraining's auc: 0.877861\ttraining's binary_logloss: 0.127299\tvalid_1's auc: 0.834526\tvalid_1's binary_logloss: 0.132952\n",
            "[38]\ttraining's auc: 0.878488\ttraining's binary_logloss: 0.12694\tvalid_1's auc: 0.834457\tvalid_1's binary_logloss: 0.132833\n",
            "[39]\ttraining's auc: 0.878997\ttraining's binary_logloss: 0.126594\tvalid_1's auc: 0.834438\tvalid_1's binary_logloss: 0.132707\n",
            "[40]\ttraining's auc: 0.879292\ttraining's binary_logloss: 0.12628\tvalid_1's auc: 0.834268\tvalid_1's binary_logloss: 0.132611\n",
            "[41]\ttraining's auc: 0.879827\ttraining's binary_logloss: 0.125969\tvalid_1's auc: 0.834426\tvalid_1's binary_logloss: 0.132518\n",
            "[42]\ttraining's auc: 0.880231\ttraining's binary_logloss: 0.125645\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.132414\n",
            "[43]\ttraining's auc: 0.880734\ttraining's binary_logloss: 0.125361\tvalid_1's auc: 0.834247\tvalid_1's binary_logloss: 0.132338\n",
            "[44]\ttraining's auc: 0.881716\ttraining's binary_logloss: 0.125056\tvalid_1's auc: 0.834774\tvalid_1's binary_logloss: 0.13221\n",
            "[45]\ttraining's auc: 0.882475\ttraining's binary_logloss: 0.124786\tvalid_1's auc: 0.834908\tvalid_1's binary_logloss: 0.132121\n",
            "[46]\ttraining's auc: 0.882842\ttraining's binary_logloss: 0.124496\tvalid_1's auc: 0.834817\tvalid_1's binary_logloss: 0.132058\n",
            "[47]\ttraining's auc: 0.883931\ttraining's binary_logloss: 0.124189\tvalid_1's auc: 0.834878\tvalid_1's binary_logloss: 0.131994\n",
            "[48]\ttraining's auc: 0.884396\ttraining's binary_logloss: 0.123949\tvalid_1's auc: 0.835045\tvalid_1's binary_logloss: 0.131903\n",
            "[49]\ttraining's auc: 0.884881\ttraining's binary_logloss: 0.123684\tvalid_1's auc: 0.835332\tvalid_1's binary_logloss: 0.131812\n",
            "[50]\ttraining's auc: 0.885729\ttraining's binary_logloss: 0.123406\tvalid_1's auc: 0.835411\tvalid_1's binary_logloss: 0.131741\n",
            "[51]\ttraining's auc: 0.885984\ttraining's binary_logloss: 0.123186\tvalid_1's auc: 0.835643\tvalid_1's binary_logloss: 0.131645\n",
            "[52]\ttraining's auc: 0.886989\ttraining's binary_logloss: 0.122889\tvalid_1's auc: 0.835561\tvalid_1's binary_logloss: 0.131588\n",
            "[53]\ttraining's auc: 0.887302\ttraining's binary_logloss: 0.122664\tvalid_1's auc: 0.835603\tvalid_1's binary_logloss: 0.131545\n",
            "[54]\ttraining's auc: 0.887758\ttraining's binary_logloss: 0.122429\tvalid_1's auc: 0.835365\tvalid_1's binary_logloss: 0.131502\n",
            "[55]\ttraining's auc: 0.888655\ttraining's binary_logloss: 0.122155\tvalid_1's auc: 0.835529\tvalid_1's binary_logloss: 0.131451\n",
            "[56]\ttraining's auc: 0.889664\ttraining's binary_logloss: 0.121899\tvalid_1's auc: 0.835856\tvalid_1's binary_logloss: 0.131404\n",
            "[57]\ttraining's auc: 0.889952\ttraining's binary_logloss: 0.121665\tvalid_1's auc: 0.836026\tvalid_1's binary_logloss: 0.13135\n",
            "[58]\ttraining's auc: 0.890687\ttraining's binary_logloss: 0.121425\tvalid_1's auc: 0.836444\tvalid_1's binary_logloss: 0.131266\n",
            "[59]\ttraining's auc: 0.891233\ttraining's binary_logloss: 0.1212\tvalid_1's auc: 0.836526\tvalid_1's binary_logloss: 0.131213\n",
            "[60]\ttraining's auc: 0.891653\ttraining's binary_logloss: 0.120977\tvalid_1's auc: 0.836696\tvalid_1's binary_logloss: 0.131158\n",
            "[61]\ttraining's auc: 0.892034\ttraining's binary_logloss: 0.120771\tvalid_1's auc: 0.836869\tvalid_1's binary_logloss: 0.1311\n",
            "[62]\ttraining's auc: 0.892481\ttraining's binary_logloss: 0.120574\tvalid_1's auc: 0.837005\tvalid_1's binary_logloss: 0.131067\n",
            "[63]\ttraining's auc: 0.893241\ttraining's binary_logloss: 0.120364\tvalid_1's auc: 0.83713\tvalid_1's binary_logloss: 0.131017\n",
            "[64]\ttraining's auc: 0.893634\ttraining's binary_logloss: 0.120155\tvalid_1's auc: 0.837247\tvalid_1's binary_logloss: 0.130985\n",
            "[65]\ttraining's auc: 0.89409\ttraining's binary_logloss: 0.119949\tvalid_1's auc: 0.837207\tvalid_1's binary_logloss: 0.130948\n",
            "[66]\ttraining's auc: 0.894367\ttraining's binary_logloss: 0.119773\tvalid_1's auc: 0.83731\tvalid_1's binary_logloss: 0.130913\n",
            "[67]\ttraining's auc: 0.895062\ttraining's binary_logloss: 0.119576\tvalid_1's auc: 0.837187\tvalid_1's binary_logloss: 0.130905\n",
            "[68]\ttraining's auc: 0.895594\ttraining's binary_logloss: 0.119397\tvalid_1's auc: 0.837432\tvalid_1's binary_logloss: 0.130854\n",
            "[69]\ttraining's auc: 0.896105\ttraining's binary_logloss: 0.119193\tvalid_1's auc: 0.837263\tvalid_1's binary_logloss: 0.130836\n",
            "[70]\ttraining's auc: 0.896778\ttraining's binary_logloss: 0.119011\tvalid_1's auc: 0.837229\tvalid_1's binary_logloss: 0.130816\n",
            "[71]\ttraining's auc: 0.897309\ttraining's binary_logloss: 0.118832\tvalid_1's auc: 0.837149\tvalid_1's binary_logloss: 0.130817\n",
            "[72]\ttraining's auc: 0.897971\ttraining's binary_logloss: 0.11864\tvalid_1's auc: 0.837051\tvalid_1's binary_logloss: 0.130823\n",
            "[73]\ttraining's auc: 0.898813\ttraining's binary_logloss: 0.118453\tvalid_1's auc: 0.836886\tvalid_1's binary_logloss: 0.130821\n",
            "[74]\ttraining's auc: 0.89944\ttraining's binary_logloss: 0.118285\tvalid_1's auc: 0.836814\tvalid_1's binary_logloss: 0.130822\n",
            "[75]\ttraining's auc: 0.899716\ttraining's binary_logloss: 0.118131\tvalid_1's auc: 0.836891\tvalid_1's binary_logloss: 0.1308\n",
            "[76]\ttraining's auc: 0.900436\ttraining's binary_logloss: 0.117924\tvalid_1's auc: 0.837049\tvalid_1's binary_logloss: 0.130767\n",
            "[77]\ttraining's auc: 0.900901\ttraining's binary_logloss: 0.117757\tvalid_1's auc: 0.837042\tvalid_1's binary_logloss: 0.130766\n",
            "[78]\ttraining's auc: 0.901363\ttraining's binary_logloss: 0.117618\tvalid_1's auc: 0.836956\tvalid_1's binary_logloss: 0.130773\n",
            "[79]\ttraining's auc: 0.901863\ttraining's binary_logloss: 0.117455\tvalid_1's auc: 0.836963\tvalid_1's binary_logloss: 0.130755\n",
            "[80]\ttraining's auc: 0.902585\ttraining's binary_logloss: 0.117285\tvalid_1's auc: 0.836921\tvalid_1's binary_logloss: 0.130755\n",
            "[81]\ttraining's auc: 0.903275\ttraining's binary_logloss: 0.117092\tvalid_1's auc: 0.836747\tvalid_1's binary_logloss: 0.130763\n",
            "[82]\ttraining's auc: 0.9037\ttraining's binary_logloss: 0.116909\tvalid_1's auc: 0.836934\tvalid_1's binary_logloss: 0.130733\n",
            "[83]\ttraining's auc: 0.904175\ttraining's binary_logloss: 0.116726\tvalid_1's auc: 0.836938\tvalid_1's binary_logloss: 0.130724\n",
            "[84]\ttraining's auc: 0.90471\ttraining's binary_logloss: 0.116575\tvalid_1's auc: 0.83693\tvalid_1's binary_logloss: 0.130717\n",
            "[85]\ttraining's auc: 0.905136\ttraining's binary_logloss: 0.116406\tvalid_1's auc: 0.836967\tvalid_1's binary_logloss: 0.130705\n",
            "[86]\ttraining's auc: 0.905764\ttraining's binary_logloss: 0.11623\tvalid_1's auc: 0.837116\tvalid_1's binary_logloss: 0.130686\n",
            "[87]\ttraining's auc: 0.90603\ttraining's binary_logloss: 0.116115\tvalid_1's auc: 0.837104\tvalid_1's binary_logloss: 0.130689\n",
            "[88]\ttraining's auc: 0.906448\ttraining's binary_logloss: 0.115919\tvalid_1's auc: 0.837078\tvalid_1's binary_logloss: 0.130703\n",
            "[89]\ttraining's auc: 0.906814\ttraining's binary_logloss: 0.115756\tvalid_1's auc: 0.837034\tvalid_1's binary_logloss: 0.130696\n",
            "[90]\ttraining's auc: 0.907357\ttraining's binary_logloss: 0.115611\tvalid_1's auc: 0.837087\tvalid_1's binary_logloss: 0.130687\n",
            "[91]\ttraining's auc: 0.90772\ttraining's binary_logloss: 0.11545\tvalid_1's auc: 0.837164\tvalid_1's binary_logloss: 0.13067\n",
            "[92]\ttraining's auc: 0.908184\ttraining's binary_logloss: 0.115283\tvalid_1's auc: 0.837182\tvalid_1's binary_logloss: 0.130664\n",
            "[93]\ttraining's auc: 0.908464\ttraining's binary_logloss: 0.115122\tvalid_1's auc: 0.83724\tvalid_1's binary_logloss: 0.130655\n",
            "[94]\ttraining's auc: 0.908684\ttraining's binary_logloss: 0.115019\tvalid_1's auc: 0.837323\tvalid_1's binary_logloss: 0.130638\n",
            "[95]\ttraining's auc: 0.909033\ttraining's binary_logloss: 0.11485\tvalid_1's auc: 0.837352\tvalid_1's binary_logloss: 0.130637\n",
            "[96]\ttraining's auc: 0.909283\ttraining's binary_logloss: 0.114747\tvalid_1's auc: 0.837379\tvalid_1's binary_logloss: 0.130634\n",
            "[97]\ttraining's auc: 0.909787\ttraining's binary_logloss: 0.114562\tvalid_1's auc: 0.837233\tvalid_1's binary_logloss: 0.130657\n",
            "[98]\ttraining's auc: 0.910254\ttraining's binary_logloss: 0.114386\tvalid_1's auc: 0.837177\tvalid_1's binary_logloss: 0.130659\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 54%|█████▍    | 27/50 [13:32<12:20, 32.19s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.159213\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.164992\n",
            "[2]\ttraining's auc: 0.830827\ttraining's binary_logloss: 0.156057\tvalid_1's auc: 0.815227\tvalid_1's binary_logloss: 0.162106\n",
            "[3]\ttraining's auc: 0.832475\ttraining's binary_logloss: 0.153434\tvalid_1's auc: 0.814071\tvalid_1's binary_logloss: 0.159849\n",
            "[4]\ttraining's auc: 0.834783\ttraining's binary_logloss: 0.151099\tvalid_1's auc: 0.815564\tvalid_1's binary_logloss: 0.157753\n",
            "[5]\ttraining's auc: 0.838961\ttraining's binary_logloss: 0.149027\tvalid_1's auc: 0.818081\tvalid_1's binary_logloss: 0.155964\n",
            "[6]\ttraining's auc: 0.840184\ttraining's binary_logloss: 0.147178\tvalid_1's auc: 0.818791\tvalid_1's binary_logloss: 0.154353\n",
            "[7]\ttraining's auc: 0.844389\ttraining's binary_logloss: 0.145504\tvalid_1's auc: 0.822982\tvalid_1's binary_logloss: 0.152909\n",
            "[8]\ttraining's auc: 0.847972\ttraining's binary_logloss: 0.143981\tvalid_1's auc: 0.825681\tvalid_1's binary_logloss: 0.151646\n",
            "[9]\ttraining's auc: 0.849532\ttraining's binary_logloss: 0.14261\tvalid_1's auc: 0.826494\tvalid_1's binary_logloss: 0.150533\n",
            "[10]\ttraining's auc: 0.850126\ttraining's binary_logloss: 0.141365\tvalid_1's auc: 0.827393\tvalid_1's binary_logloss: 0.149479\n",
            "[11]\ttraining's auc: 0.85145\ttraining's binary_logloss: 0.140176\tvalid_1's auc: 0.827565\tvalid_1's binary_logloss: 0.148551\n",
            "[12]\ttraining's auc: 0.852252\ttraining's binary_logloss: 0.139054\tvalid_1's auc: 0.828425\tvalid_1's binary_logloss: 0.14765\n",
            "[13]\ttraining's auc: 0.85348\ttraining's binary_logloss: 0.138061\tvalid_1's auc: 0.828995\tvalid_1's binary_logloss: 0.14685\n",
            "[14]\ttraining's auc: 0.854056\ttraining's binary_logloss: 0.137084\tvalid_1's auc: 0.829159\tvalid_1's binary_logloss: 0.146162\n",
            "[15]\ttraining's auc: 0.855759\ttraining's binary_logloss: 0.136205\tvalid_1's auc: 0.829621\tvalid_1's binary_logloss: 0.14551\n",
            "[16]\ttraining's auc: 0.856737\ttraining's binary_logloss: 0.135371\tvalid_1's auc: 0.83021\tvalid_1's binary_logloss: 0.14487\n",
            "[17]\ttraining's auc: 0.857651\ttraining's binary_logloss: 0.134592\tvalid_1's auc: 0.830621\tvalid_1's binary_logloss: 0.144297\n",
            "[18]\ttraining's auc: 0.858559\ttraining's binary_logloss: 0.133846\tvalid_1's auc: 0.830532\tvalid_1's binary_logloss: 0.143751\n",
            "[19]\ttraining's auc: 0.859437\ttraining's binary_logloss: 0.133143\tvalid_1's auc: 0.830925\tvalid_1's binary_logloss: 0.143213\n",
            "[20]\ttraining's auc: 0.860941\ttraining's binary_logloss: 0.132498\tvalid_1's auc: 0.830817\tvalid_1's binary_logloss: 0.142747\n",
            "[21]\ttraining's auc: 0.862041\ttraining's binary_logloss: 0.131881\tvalid_1's auc: 0.831002\tvalid_1's binary_logloss: 0.142314\n",
            "[22]\ttraining's auc: 0.863203\ttraining's binary_logloss: 0.131271\tvalid_1's auc: 0.83176\tvalid_1's binary_logloss: 0.141916\n",
            "[23]\ttraining's auc: 0.86421\ttraining's binary_logloss: 0.13071\tvalid_1's auc: 0.831746\tvalid_1's binary_logloss: 0.14157\n",
            "[24]\ttraining's auc: 0.86505\ttraining's binary_logloss: 0.130162\tvalid_1's auc: 0.831999\tvalid_1's binary_logloss: 0.141203\n",
            "[25]\ttraining's auc: 0.86616\ttraining's binary_logloss: 0.129653\tvalid_1's auc: 0.832023\tvalid_1's binary_logloss: 0.140892\n",
            "[26]\ttraining's auc: 0.868022\ttraining's binary_logloss: 0.129102\tvalid_1's auc: 0.832091\tvalid_1's binary_logloss: 0.140599\n",
            "[27]\ttraining's auc: 0.869817\ttraining's binary_logloss: 0.128597\tvalid_1's auc: 0.83379\tvalid_1's binary_logloss: 0.140317\n",
            "[28]\ttraining's auc: 0.870549\ttraining's binary_logloss: 0.12813\tvalid_1's auc: 0.833972\tvalid_1's binary_logloss: 0.140038\n",
            "[29]\ttraining's auc: 0.871372\ttraining's binary_logloss: 0.12768\tvalid_1's auc: 0.834315\tvalid_1's binary_logloss: 0.139755\n",
            "[30]\ttraining's auc: 0.872743\ttraining's binary_logloss: 0.127242\tvalid_1's auc: 0.83484\tvalid_1's binary_logloss: 0.139514\n",
            "[31]\ttraining's auc: 0.873882\ttraining's binary_logloss: 0.12684\tvalid_1's auc: 0.835339\tvalid_1's binary_logloss: 0.139291\n",
            "[32]\ttraining's auc: 0.874707\ttraining's binary_logloss: 0.126437\tvalid_1's auc: 0.835395\tvalid_1's binary_logloss: 0.139096\n",
            "[33]\ttraining's auc: 0.875146\ttraining's binary_logloss: 0.126081\tvalid_1's auc: 0.835585\tvalid_1's binary_logloss: 0.138901\n",
            "[34]\ttraining's auc: 0.876195\ttraining's binary_logloss: 0.125679\tvalid_1's auc: 0.83553\tvalid_1's binary_logloss: 0.138738\n",
            "[35]\ttraining's auc: 0.877178\ttraining's binary_logloss: 0.12532\tvalid_1's auc: 0.835711\tvalid_1's binary_logloss: 0.138558\n",
            "[36]\ttraining's auc: 0.878583\ttraining's binary_logloss: 0.124911\tvalid_1's auc: 0.835491\tvalid_1's binary_logloss: 0.138423\n",
            "[37]\ttraining's auc: 0.87941\ttraining's binary_logloss: 0.124539\tvalid_1's auc: 0.835619\tvalid_1's binary_logloss: 0.138279\n",
            "[38]\ttraining's auc: 0.880517\ttraining's binary_logloss: 0.124165\tvalid_1's auc: 0.835903\tvalid_1's binary_logloss: 0.138074\n",
            "[39]\ttraining's auc: 0.881409\ttraining's binary_logloss: 0.123806\tvalid_1's auc: 0.835953\tvalid_1's binary_logloss: 0.137943\n",
            "[40]\ttraining's auc: 0.882215\ttraining's binary_logloss: 0.123475\tvalid_1's auc: 0.836293\tvalid_1's binary_logloss: 0.137816\n",
            "[41]\ttraining's auc: 0.882691\ttraining's binary_logloss: 0.123166\tvalid_1's auc: 0.83635\tvalid_1's binary_logloss: 0.137703\n",
            "[42]\ttraining's auc: 0.88307\ttraining's binary_logloss: 0.122866\tvalid_1's auc: 0.83644\tvalid_1's binary_logloss: 0.137611\n",
            "[43]\ttraining's auc: 0.884056\ttraining's binary_logloss: 0.122533\tvalid_1's auc: 0.836151\tvalid_1's binary_logloss: 0.137518\n",
            "[44]\ttraining's auc: 0.884999\ttraining's binary_logloss: 0.122237\tvalid_1's auc: 0.836026\tvalid_1's binary_logloss: 0.137433\n",
            "[45]\ttraining's auc: 0.885779\ttraining's binary_logloss: 0.121953\tvalid_1's auc: 0.836024\tvalid_1's binary_logloss: 0.137319\n",
            "[46]\ttraining's auc: 0.886742\ttraining's binary_logloss: 0.121645\tvalid_1's auc: 0.836039\tvalid_1's binary_logloss: 0.137224\n",
            "[47]\ttraining's auc: 0.88753\ttraining's binary_logloss: 0.121372\tvalid_1's auc: 0.836337\tvalid_1's binary_logloss: 0.137144\n",
            "[48]\ttraining's auc: 0.888162\ttraining's binary_logloss: 0.121105\tvalid_1's auc: 0.836316\tvalid_1's binary_logloss: 0.137063\n",
            "[49]\ttraining's auc: 0.88856\ttraining's binary_logloss: 0.120846\tvalid_1's auc: 0.836379\tvalid_1's binary_logloss: 0.13698\n",
            "[50]\ttraining's auc: 0.889036\ttraining's binary_logloss: 0.120605\tvalid_1's auc: 0.83636\tvalid_1's binary_logloss: 0.13693\n",
            "[51]\ttraining's auc: 0.889582\ttraining's binary_logloss: 0.120345\tvalid_1's auc: 0.836513\tvalid_1's binary_logloss: 0.13687\n",
            "[52]\ttraining's auc: 0.890124\ttraining's binary_logloss: 0.12012\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.136837\n",
            "[53]\ttraining's auc: 0.890428\ttraining's binary_logloss: 0.119889\tvalid_1's auc: 0.83643\tvalid_1's binary_logloss: 0.136773\n",
            "[54]\ttraining's auc: 0.891044\ttraining's binary_logloss: 0.119657\tvalid_1's auc: 0.836538\tvalid_1's binary_logloss: 0.136732\n",
            "[55]\ttraining's auc: 0.891528\ttraining's binary_logloss: 0.119435\tvalid_1's auc: 0.836674\tvalid_1's binary_logloss: 0.136655\n",
            "[56]\ttraining's auc: 0.892112\ttraining's binary_logloss: 0.119189\tvalid_1's auc: 0.836585\tvalid_1's binary_logloss: 0.136624\n",
            "[57]\ttraining's auc: 0.892551\ttraining's binary_logloss: 0.118991\tvalid_1's auc: 0.836789\tvalid_1's binary_logloss: 0.136557\n",
            "[58]\ttraining's auc: 0.893175\ttraining's binary_logloss: 0.118788\tvalid_1's auc: 0.836635\tvalid_1's binary_logloss: 0.136554\n",
            "[59]\ttraining's auc: 0.893613\ttraining's binary_logloss: 0.118581\tvalid_1's auc: 0.836642\tvalid_1's binary_logloss: 0.13651\n",
            "[60]\ttraining's auc: 0.894412\ttraining's binary_logloss: 0.118377\tvalid_1's auc: 0.836644\tvalid_1's binary_logloss: 0.136465\n",
            "[61]\ttraining's auc: 0.894877\ttraining's binary_logloss: 0.118178\tvalid_1's auc: 0.836467\tvalid_1's binary_logloss: 0.136467\n",
            "[62]\ttraining's auc: 0.895547\ttraining's binary_logloss: 0.117945\tvalid_1's auc: 0.83654\tvalid_1's binary_logloss: 0.136448\n",
            "[63]\ttraining's auc: 0.896183\ttraining's binary_logloss: 0.11774\tvalid_1's auc: 0.836343\tvalid_1's binary_logloss: 0.136432\n",
            "[64]\ttraining's auc: 0.896683\ttraining's binary_logloss: 0.117539\tvalid_1's auc: 0.836277\tvalid_1's binary_logloss: 0.136409\n",
            "[65]\ttraining's auc: 0.897256\ttraining's binary_logloss: 0.117314\tvalid_1's auc: 0.836324\tvalid_1's binary_logloss: 0.136386\n",
            "[66]\ttraining's auc: 0.897688\ttraining's binary_logloss: 0.117148\tvalid_1's auc: 0.836231\tvalid_1's binary_logloss: 0.136372\n",
            "[67]\ttraining's auc: 0.898165\ttraining's binary_logloss: 0.116958\tvalid_1's auc: 0.836089\tvalid_1's binary_logloss: 0.136376\n",
            "[68]\ttraining's auc: 0.898825\ttraining's binary_logloss: 0.116763\tvalid_1's auc: 0.836011\tvalid_1's binary_logloss: 0.136347\n",
            "[69]\ttraining's auc: 0.899136\ttraining's binary_logloss: 0.116606\tvalid_1's auc: 0.835816\tvalid_1's binary_logloss: 0.136333\n",
            "[70]\ttraining's auc: 0.89961\ttraining's binary_logloss: 0.116428\tvalid_1's auc: 0.836064\tvalid_1's binary_logloss: 0.136288\n",
            "[71]\ttraining's auc: 0.900369\ttraining's binary_logloss: 0.116212\tvalid_1's auc: 0.836002\tvalid_1's binary_logloss: 0.136287\n",
            "[72]\ttraining's auc: 0.900599\ttraining's binary_logloss: 0.116053\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.136285\n",
            "[73]\ttraining's auc: 0.901046\ttraining's binary_logloss: 0.115867\tvalid_1's auc: 0.836023\tvalid_1's binary_logloss: 0.13626\n",
            "[74]\ttraining's auc: 0.901598\ttraining's binary_logloss: 0.115703\tvalid_1's auc: 0.836016\tvalid_1's binary_logloss: 0.136259\n",
            "[75]\ttraining's auc: 0.902075\ttraining's binary_logloss: 0.115538\tvalid_1's auc: 0.835913\tvalid_1's binary_logloss: 0.136256\n",
            "[76]\ttraining's auc: 0.902493\ttraining's binary_logloss: 0.115398\tvalid_1's auc: 0.835756\tvalid_1's binary_logloss: 0.136245\n",
            "[77]\ttraining's auc: 0.902813\ttraining's binary_logloss: 0.115248\tvalid_1's auc: 0.835951\tvalid_1's binary_logloss: 0.136207\n",
            "[78]\ttraining's auc: 0.903568\ttraining's binary_logloss: 0.115015\tvalid_1's auc: 0.83601\tvalid_1's binary_logloss: 0.136221\n",
            "[79]\ttraining's auc: 0.903994\ttraining's binary_logloss: 0.114856\tvalid_1's auc: 0.83603\tvalid_1's binary_logloss: 0.136204\n",
            "[80]\ttraining's auc: 0.904392\ttraining's binary_logloss: 0.114724\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.136195\n",
            "[81]\ttraining's auc: 0.904962\ttraining's binary_logloss: 0.114483\tvalid_1's auc: 0.835869\tvalid_1's binary_logloss: 0.136233\n",
            "[82]\ttraining's auc: 0.905307\ttraining's binary_logloss: 0.114301\tvalid_1's auc: 0.835848\tvalid_1's binary_logloss: 0.136229\n",
            "[83]\ttraining's auc: 0.905654\ttraining's binary_logloss: 0.114123\tvalid_1's auc: 0.835701\tvalid_1's binary_logloss: 0.13627\n",
            "[84]\ttraining's auc: 0.906045\ttraining's binary_logloss: 0.113955\tvalid_1's auc: 0.835513\tvalid_1's binary_logloss: 0.13631\n",
            "[85]\ttraining's auc: 0.906513\ttraining's binary_logloss: 0.113769\tvalid_1's auc: 0.835372\tvalid_1's binary_logloss: 0.13633\n",
            "[86]\ttraining's auc: 0.907086\ttraining's binary_logloss: 0.113557\tvalid_1's auc: 0.835443\tvalid_1's binary_logloss: 0.13632\n",
            "[87]\ttraining's auc: 0.907555\ttraining's binary_logloss: 0.113365\tvalid_1's auc: 0.835486\tvalid_1's binary_logloss: 0.136322\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 56%|█████▌    | 28/50 [13:40<11:55, 32.51s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.161364\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.162768\n",
            "[2]\ttraining's auc: 0.832253\ttraining's binary_logloss: 0.158656\tvalid_1's auc: 0.807016\tvalid_1's binary_logloss: 0.160639\n",
            "[3]\ttraining's auc: 0.834363\ttraining's binary_logloss: 0.156298\tvalid_1's auc: 0.807763\tvalid_1's binary_logloss: 0.158706\n",
            "[4]\ttraining's auc: 0.836712\ttraining's binary_logloss: 0.154248\tvalid_1's auc: 0.808908\tvalid_1's binary_logloss: 0.157077\n",
            "[5]\ttraining's auc: 0.837003\ttraining's binary_logloss: 0.152429\tvalid_1's auc: 0.808453\tvalid_1's binary_logloss: 0.155688\n",
            "[6]\ttraining's auc: 0.838137\ttraining's binary_logloss: 0.150783\tvalid_1's auc: 0.810168\tvalid_1's binary_logloss: 0.154339\n",
            "[7]\ttraining's auc: 0.844256\ttraining's binary_logloss: 0.149261\tvalid_1's auc: 0.814873\tvalid_1's binary_logloss: 0.153194\n",
            "[8]\ttraining's auc: 0.844384\ttraining's binary_logloss: 0.147896\tvalid_1's auc: 0.815008\tvalid_1's binary_logloss: 0.152141\n",
            "[9]\ttraining's auc: 0.846689\ttraining's binary_logloss: 0.146631\tvalid_1's auc: 0.816858\tvalid_1's binary_logloss: 0.151133\n",
            "[10]\ttraining's auc: 0.848275\ttraining's binary_logloss: 0.145429\tvalid_1's auc: 0.818481\tvalid_1's binary_logloss: 0.150211\n",
            "[11]\ttraining's auc: 0.848771\ttraining's binary_logloss: 0.14432\tvalid_1's auc: 0.819165\tvalid_1's binary_logloss: 0.149357\n",
            "[12]\ttraining's auc: 0.849632\ttraining's binary_logloss: 0.143247\tvalid_1's auc: 0.819441\tvalid_1's binary_logloss: 0.148583\n",
            "[13]\ttraining's auc: 0.850877\ttraining's binary_logloss: 0.142264\tvalid_1's auc: 0.820648\tvalid_1's binary_logloss: 0.147887\n",
            "[14]\ttraining's auc: 0.851892\ttraining's binary_logloss: 0.141347\tvalid_1's auc: 0.820719\tvalid_1's binary_logloss: 0.14722\n",
            "[15]\ttraining's auc: 0.8523\ttraining's binary_logloss: 0.140476\tvalid_1's auc: 0.82079\tvalid_1's binary_logloss: 0.146607\n",
            "[16]\ttraining's auc: 0.852977\ttraining's binary_logloss: 0.13968\tvalid_1's auc: 0.82101\tvalid_1's binary_logloss: 0.146021\n",
            "[17]\ttraining's auc: 0.853522\ttraining's binary_logloss: 0.138919\tvalid_1's auc: 0.821305\tvalid_1's binary_logloss: 0.145503\n",
            "[18]\ttraining's auc: 0.855599\ttraining's binary_logloss: 0.138205\tvalid_1's auc: 0.822448\tvalid_1's binary_logloss: 0.144968\n",
            "[19]\ttraining's auc: 0.856239\ttraining's binary_logloss: 0.137482\tvalid_1's auc: 0.822915\tvalid_1's binary_logloss: 0.144479\n",
            "[20]\ttraining's auc: 0.856654\ttraining's binary_logloss: 0.136811\tvalid_1's auc: 0.823024\tvalid_1's binary_logloss: 0.144016\n",
            "[21]\ttraining's auc: 0.857955\ttraining's binary_logloss: 0.136178\tvalid_1's auc: 0.823232\tvalid_1's binary_logloss: 0.143587\n",
            "[22]\ttraining's auc: 0.858359\ttraining's binary_logloss: 0.135593\tvalid_1's auc: 0.823075\tvalid_1's binary_logloss: 0.143167\n",
            "[23]\ttraining's auc: 0.859471\ttraining's binary_logloss: 0.135052\tvalid_1's auc: 0.823739\tvalid_1's binary_logloss: 0.142758\n",
            "[24]\ttraining's auc: 0.860969\ttraining's binary_logloss: 0.134487\tvalid_1's auc: 0.824283\tvalid_1's binary_logloss: 0.142393\n",
            "[25]\ttraining's auc: 0.861263\ttraining's binary_logloss: 0.133968\tvalid_1's auc: 0.824174\tvalid_1's binary_logloss: 0.142047\n",
            "[26]\ttraining's auc: 0.861997\ttraining's binary_logloss: 0.133458\tvalid_1's auc: 0.824795\tvalid_1's binary_logloss: 0.141704\n",
            "[27]\ttraining's auc: 0.863198\ttraining's binary_logloss: 0.132977\tvalid_1's auc: 0.825026\tvalid_1's binary_logloss: 0.141391\n",
            "[28]\ttraining's auc: 0.864214\ttraining's binary_logloss: 0.132499\tvalid_1's auc: 0.825687\tvalid_1's binary_logloss: 0.141113\n",
            "[29]\ttraining's auc: 0.864708\ttraining's binary_logloss: 0.132031\tvalid_1's auc: 0.825969\tvalid_1's binary_logloss: 0.140886\n",
            "[30]\ttraining's auc: 0.865632\ttraining's binary_logloss: 0.131601\tvalid_1's auc: 0.826304\tvalid_1's binary_logloss: 0.140634\n",
            "[31]\ttraining's auc: 0.86652\ttraining's binary_logloss: 0.13119\tvalid_1's auc: 0.826477\tvalid_1's binary_logloss: 0.140381\n",
            "[32]\ttraining's auc: 0.866766\ttraining's binary_logloss: 0.130771\tvalid_1's auc: 0.826288\tvalid_1's binary_logloss: 0.140151\n",
            "[33]\ttraining's auc: 0.867661\ttraining's binary_logloss: 0.130381\tvalid_1's auc: 0.827177\tvalid_1's binary_logloss: 0.139918\n",
            "[34]\ttraining's auc: 0.868603\ttraining's binary_logloss: 0.129991\tvalid_1's auc: 0.827251\tvalid_1's binary_logloss: 0.13975\n",
            "[35]\ttraining's auc: 0.869008\ttraining's binary_logloss: 0.129633\tvalid_1's auc: 0.827373\tvalid_1's binary_logloss: 0.139567\n",
            "[36]\ttraining's auc: 0.869315\ttraining's binary_logloss: 0.129289\tvalid_1's auc: 0.827285\tvalid_1's binary_logloss: 0.139415\n",
            "[37]\ttraining's auc: 0.869906\ttraining's binary_logloss: 0.128938\tvalid_1's auc: 0.827439\tvalid_1's binary_logloss: 0.139239\n",
            "[38]\ttraining's auc: 0.870283\ttraining's binary_logloss: 0.128616\tvalid_1's auc: 0.827421\tvalid_1's binary_logloss: 0.139076\n",
            "[39]\ttraining's auc: 0.870919\ttraining's binary_logloss: 0.128285\tvalid_1's auc: 0.827665\tvalid_1's binary_logloss: 0.138899\n",
            "[40]\ttraining's auc: 0.871523\ttraining's binary_logloss: 0.127959\tvalid_1's auc: 0.827873\tvalid_1's binary_logloss: 0.138741\n",
            "[41]\ttraining's auc: 0.87213\ttraining's binary_logloss: 0.127634\tvalid_1's auc: 0.827623\tvalid_1's binary_logloss: 0.138627\n",
            "[42]\ttraining's auc: 0.873302\ttraining's binary_logloss: 0.12729\tvalid_1's auc: 0.827866\tvalid_1's binary_logloss: 0.138463\n",
            "[43]\ttraining's auc: 0.873913\ttraining's binary_logloss: 0.127007\tvalid_1's auc: 0.827796\tvalid_1's binary_logloss: 0.138346\n",
            "[44]\ttraining's auc: 0.874528\ttraining's binary_logloss: 0.12672\tvalid_1's auc: 0.827774\tvalid_1's binary_logloss: 0.138254\n",
            "[45]\ttraining's auc: 0.875204\ttraining's binary_logloss: 0.126409\tvalid_1's auc: 0.827821\tvalid_1's binary_logloss: 0.138115\n",
            "[46]\ttraining's auc: 0.875673\ttraining's binary_logloss: 0.126135\tvalid_1's auc: 0.828006\tvalid_1's binary_logloss: 0.137992\n",
            "[47]\ttraining's auc: 0.87642\ttraining's binary_logloss: 0.125848\tvalid_1's auc: 0.828136\tvalid_1's binary_logloss: 0.137875\n",
            "[48]\ttraining's auc: 0.877807\ttraining's binary_logloss: 0.125567\tvalid_1's auc: 0.828413\tvalid_1's binary_logloss: 0.137781\n",
            "[49]\ttraining's auc: 0.878385\ttraining's binary_logloss: 0.1253\tvalid_1's auc: 0.827998\tvalid_1's binary_logloss: 0.137725\n",
            "[50]\ttraining's auc: 0.879169\ttraining's binary_logloss: 0.125022\tvalid_1's auc: 0.828036\tvalid_1's binary_logloss: 0.137653\n",
            "[51]\ttraining's auc: 0.880732\ttraining's binary_logloss: 0.124714\tvalid_1's auc: 0.828061\tvalid_1's binary_logloss: 0.137559\n",
            "[52]\ttraining's auc: 0.880982\ttraining's binary_logloss: 0.124486\tvalid_1's auc: 0.828181\tvalid_1's binary_logloss: 0.137467\n",
            "[53]\ttraining's auc: 0.881478\ttraining's binary_logloss: 0.124238\tvalid_1's auc: 0.828129\tvalid_1's binary_logloss: 0.137394\n",
            "[54]\ttraining's auc: 0.881958\ttraining's binary_logloss: 0.124003\tvalid_1's auc: 0.828028\tvalid_1's binary_logloss: 0.137316\n",
            "[55]\ttraining's auc: 0.882572\ttraining's binary_logloss: 0.123759\tvalid_1's auc: 0.828009\tvalid_1's binary_logloss: 0.137231\n",
            "[56]\ttraining's auc: 0.883245\ttraining's binary_logloss: 0.123509\tvalid_1's auc: 0.827968\tvalid_1's binary_logloss: 0.137177\n",
            "[57]\ttraining's auc: 0.883968\ttraining's binary_logloss: 0.123264\tvalid_1's auc: 0.828698\tvalid_1's binary_logloss: 0.137077\n",
            "[58]\ttraining's auc: 0.88418\ttraining's binary_logloss: 0.123065\tvalid_1's auc: 0.828724\tvalid_1's binary_logloss: 0.137026\n",
            "[59]\ttraining's auc: 0.884743\ttraining's binary_logloss: 0.122846\tvalid_1's auc: 0.828841\tvalid_1's binary_logloss: 0.136949\n",
            "[60]\ttraining's auc: 0.885296\ttraining's binary_logloss: 0.122642\tvalid_1's auc: 0.828849\tvalid_1's binary_logloss: 0.136898\n",
            "[61]\ttraining's auc: 0.886033\ttraining's binary_logloss: 0.122396\tvalid_1's auc: 0.82897\tvalid_1's binary_logloss: 0.136844\n",
            "[62]\ttraining's auc: 0.886385\ttraining's binary_logloss: 0.122202\tvalid_1's auc: 0.828907\tvalid_1's binary_logloss: 0.136793\n",
            "[63]\ttraining's auc: 0.886899\ttraining's binary_logloss: 0.121982\tvalid_1's auc: 0.82885\tvalid_1's binary_logloss: 0.136751\n",
            "[64]\ttraining's auc: 0.887242\ttraining's binary_logloss: 0.121781\tvalid_1's auc: 0.828973\tvalid_1's binary_logloss: 0.1367\n",
            "[65]\ttraining's auc: 0.887647\ttraining's binary_logloss: 0.121589\tvalid_1's auc: 0.828771\tvalid_1's binary_logloss: 0.136678\n",
            "[66]\ttraining's auc: 0.888036\ttraining's binary_logloss: 0.121388\tvalid_1's auc: 0.828967\tvalid_1's binary_logloss: 0.136619\n",
            "[67]\ttraining's auc: 0.888671\ttraining's binary_logloss: 0.121168\tvalid_1's auc: 0.829064\tvalid_1's binary_logloss: 0.136599\n",
            "[68]\ttraining's auc: 0.889107\ttraining's binary_logloss: 0.120982\tvalid_1's auc: 0.828869\tvalid_1's binary_logloss: 0.136561\n",
            "[69]\ttraining's auc: 0.889417\ttraining's binary_logloss: 0.120812\tvalid_1's auc: 0.828971\tvalid_1's binary_logloss: 0.136527\n",
            "[70]\ttraining's auc: 0.889758\ttraining's binary_logloss: 0.120646\tvalid_1's auc: 0.828918\tvalid_1's binary_logloss: 0.136507\n",
            "[71]\ttraining's auc: 0.890727\ttraining's binary_logloss: 0.120417\tvalid_1's auc: 0.829318\tvalid_1's binary_logloss: 0.136406\n",
            "[72]\ttraining's auc: 0.891163\ttraining's binary_logloss: 0.120228\tvalid_1's auc: 0.829361\tvalid_1's binary_logloss: 0.136393\n",
            "[73]\ttraining's auc: 0.891377\ttraining's binary_logloss: 0.120058\tvalid_1's auc: 0.829345\tvalid_1's binary_logloss: 0.136381\n",
            "[74]\ttraining's auc: 0.892116\ttraining's binary_logloss: 0.119864\tvalid_1's auc: 0.829592\tvalid_1's binary_logloss: 0.13631\n",
            "[75]\ttraining's auc: 0.892455\ttraining's binary_logloss: 0.119691\tvalid_1's auc: 0.829746\tvalid_1's binary_logloss: 0.136249\n",
            "[76]\ttraining's auc: 0.89276\ttraining's binary_logloss: 0.119518\tvalid_1's auc: 0.829712\tvalid_1's binary_logloss: 0.136232\n",
            "[77]\ttraining's auc: 0.893301\ttraining's binary_logloss: 0.119329\tvalid_1's auc: 0.830043\tvalid_1's binary_logloss: 0.136183\n",
            "[78]\ttraining's auc: 0.893659\ttraining's binary_logloss: 0.119172\tvalid_1's auc: 0.830014\tvalid_1's binary_logloss: 0.136154\n",
            "[79]\ttraining's auc: 0.894086\ttraining's binary_logloss: 0.119005\tvalid_1's auc: 0.830082\tvalid_1's binary_logloss: 0.136147\n",
            "[80]\ttraining's auc: 0.894518\ttraining's binary_logloss: 0.11883\tvalid_1's auc: 0.830467\tvalid_1's binary_logloss: 0.136087\n",
            "[81]\ttraining's auc: 0.895034\ttraining's binary_logloss: 0.118676\tvalid_1's auc: 0.830392\tvalid_1's binary_logloss: 0.136068\n",
            "[82]\ttraining's auc: 0.895284\ttraining's binary_logloss: 0.118534\tvalid_1's auc: 0.830427\tvalid_1's binary_logloss: 0.13606\n",
            "[83]\ttraining's auc: 0.89563\ttraining's binary_logloss: 0.118381\tvalid_1's auc: 0.830562\tvalid_1's binary_logloss: 0.136018\n",
            "[84]\ttraining's auc: 0.896172\ttraining's binary_logloss: 0.118221\tvalid_1's auc: 0.830448\tvalid_1's binary_logloss: 0.136006\n",
            "[85]\ttraining's auc: 0.89642\ttraining's binary_logloss: 0.118058\tvalid_1's auc: 0.83045\tvalid_1's binary_logloss: 0.135995\n",
            "[86]\ttraining's auc: 0.896848\ttraining's binary_logloss: 0.117904\tvalid_1's auc: 0.830523\tvalid_1's binary_logloss: 0.135965\n",
            "[87]\ttraining's auc: 0.897035\ttraining's binary_logloss: 0.11777\tvalid_1's auc: 0.830634\tvalid_1's binary_logloss: 0.135963\n",
            "[88]\ttraining's auc: 0.897278\ttraining's binary_logloss: 0.117635\tvalid_1's auc: 0.830574\tvalid_1's binary_logloss: 0.135959\n",
            "[89]\ttraining's auc: 0.897614\ttraining's binary_logloss: 0.117479\tvalid_1's auc: 0.830575\tvalid_1's binary_logloss: 0.135957\n",
            "[90]\ttraining's auc: 0.897891\ttraining's binary_logloss: 0.117333\tvalid_1's auc: 0.830424\tvalid_1's binary_logloss: 0.135965\n",
            "[91]\ttraining's auc: 0.89837\ttraining's binary_logloss: 0.11719\tvalid_1's auc: 0.830319\tvalid_1's binary_logloss: 0.135972\n",
            "[92]\ttraining's auc: 0.898698\ttraining's binary_logloss: 0.117066\tvalid_1's auc: 0.83032\tvalid_1's binary_logloss: 0.135971\n",
            "[93]\ttraining's auc: 0.899129\ttraining's binary_logloss: 0.116921\tvalid_1's auc: 0.830298\tvalid_1's binary_logloss: 0.135971\n",
            "[94]\ttraining's auc: 0.899602\ttraining's binary_logloss: 0.116774\tvalid_1's auc: 0.830335\tvalid_1's binary_logloss: 0.135949\n",
            "[95]\ttraining's auc: 0.900006\ttraining's binary_logloss: 0.116646\tvalid_1's auc: 0.830362\tvalid_1's binary_logloss: 0.135928\n",
            "[96]\ttraining's auc: 0.900719\ttraining's binary_logloss: 0.116485\tvalid_1's auc: 0.83071\tvalid_1's binary_logloss: 0.135875\n",
            "[97]\ttraining's auc: 0.901181\ttraining's binary_logloss: 0.116336\tvalid_1's auc: 0.830797\tvalid_1's binary_logloss: 0.13585\n",
            "[98]\ttraining's auc: 0.901704\ttraining's binary_logloss: 0.116194\tvalid_1's auc: 0.830862\tvalid_1's binary_logloss: 0.135822\n",
            "[99]\ttraining's auc: 0.902124\ttraining's binary_logloss: 0.116073\tvalid_1's auc: 0.830911\tvalid_1's binary_logloss: 0.135825\n",
            "[100]\ttraining's auc: 0.902543\ttraining's binary_logloss: 0.115944\tvalid_1's auc: 0.830955\tvalid_1's binary_logloss: 0.135814\n",
            "[101]\ttraining's auc: 0.90318\ttraining's binary_logloss: 0.115806\tvalid_1's auc: 0.831033\tvalid_1's binary_logloss: 0.135796\n",
            "[102]\ttraining's auc: 0.903462\ttraining's binary_logloss: 0.115659\tvalid_1's auc: 0.831163\tvalid_1's binary_logloss: 0.135787\n",
            "[103]\ttraining's auc: 0.903859\ttraining's binary_logloss: 0.115549\tvalid_1's auc: 0.831076\tvalid_1's binary_logloss: 0.13579\n",
            "[104]\ttraining's auc: 0.90415\ttraining's binary_logloss: 0.1154\tvalid_1's auc: 0.830959\tvalid_1's binary_logloss: 0.13582\n",
            "[105]\ttraining's auc: 0.904413\ttraining's binary_logloss: 0.115268\tvalid_1's auc: 0.831018\tvalid_1's binary_logloss: 0.135822\n",
            "[106]\ttraining's auc: 0.90469\ttraining's binary_logloss: 0.115133\tvalid_1's auc: 0.830974\tvalid_1's binary_logloss: 0.135837\n",
            "[107]\ttraining's auc: 0.904914\ttraining's binary_logloss: 0.115019\tvalid_1's auc: 0.830933\tvalid_1's binary_logloss: 0.13586\n",
            "[108]\ttraining's auc: 0.9051\ttraining's binary_logloss: 0.114914\tvalid_1's auc: 0.830806\tvalid_1's binary_logloss: 0.135883\n",
            "[109]\ttraining's auc: 0.9053\ttraining's binary_logloss: 0.114813\tvalid_1's auc: 0.830865\tvalid_1's binary_logloss: 0.135882\n",
            "[110]\ttraining's auc: 0.905531\ttraining's binary_logloss: 0.114696\tvalid_1's auc: 0.830856\tvalid_1's binary_logloss: 0.135883\n",
            "[111]\ttraining's auc: 0.905727\ttraining's binary_logloss: 0.114572\tvalid_1's auc: 0.830792\tvalid_1's binary_logloss: 0.135895\n",
            "[112]\ttraining's auc: 0.905982\ttraining's binary_logloss: 0.11445\tvalid_1's auc: 0.830639\tvalid_1's binary_logloss: 0.135929\n",
            "[113]\ttraining's auc: 0.906268\ttraining's binary_logloss: 0.114341\tvalid_1's auc: 0.830521\tvalid_1's binary_logloss: 0.135948\n",
            "[114]\ttraining's auc: 0.906563\ttraining's binary_logloss: 0.114217\tvalid_1's auc: 0.830499\tvalid_1's binary_logloss: 0.135937\n",
            "[115]\ttraining's auc: 0.906711\ttraining's binary_logloss: 0.114117\tvalid_1's auc: 0.830531\tvalid_1's binary_logloss: 0.135935\n",
            "[116]\ttraining's auc: 0.906981\ttraining's binary_logloss: 0.113996\tvalid_1's auc: 0.830494\tvalid_1's binary_logloss: 0.135939\n",
            "[117]\ttraining's auc: 0.907293\ttraining's binary_logloss: 0.113851\tvalid_1's auc: 0.830539\tvalid_1's binary_logloss: 0.135931\n",
            "[118]\ttraining's auc: 0.907848\ttraining's binary_logloss: 0.113702\tvalid_1's auc: 0.830473\tvalid_1's binary_logloss: 0.135936\n",
            "[119]\ttraining's auc: 0.908112\ttraining's binary_logloss: 0.113574\tvalid_1's auc: 0.830463\tvalid_1's binary_logloss: 0.135932\n",
            "[120]\ttraining's auc: 0.908292\ttraining's binary_logloss: 0.11347\tvalid_1's auc: 0.830499\tvalid_1's binary_logloss: 0.135926\n",
            "[121]\ttraining's auc: 0.908514\ttraining's binary_logloss: 0.11335\tvalid_1's auc: 0.83041\tvalid_1's binary_logloss: 0.135956\n",
            "[122]\ttraining's auc: 0.908806\ttraining's binary_logloss: 0.113247\tvalid_1's auc: 0.830282\tvalid_1's binary_logloss: 0.135978\n",
            "[123]\ttraining's auc: 0.909043\ttraining's binary_logloss: 0.113143\tvalid_1's auc: 0.830187\tvalid_1's binary_logloss: 0.135985\n",
            "[124]\ttraining's auc: 0.909298\ttraining's binary_logloss: 0.113031\tvalid_1's auc: 0.830073\tvalid_1's binary_logloss: 0.136009\n",
            "[125]\ttraining's auc: 0.909533\ttraining's binary_logloss: 0.112926\tvalid_1's auc: 0.830001\tvalid_1's binary_logloss: 0.136027\n",
            "[126]\ttraining's auc: 0.909908\ttraining's binary_logloss: 0.112828\tvalid_1's auc: 0.829988\tvalid_1's binary_logloss: 0.136025\n",
            "[127]\ttraining's auc: 0.910138\ttraining's binary_logloss: 0.112739\tvalid_1's auc: 0.829884\tvalid_1's binary_logloss: 0.136046\n",
            "[128]\ttraining's auc: 0.910498\ttraining's binary_logloss: 0.112636\tvalid_1's auc: 0.829789\tvalid_1's binary_logloss: 0.136069\n",
            "[129]\ttraining's auc: 0.910672\ttraining's binary_logloss: 0.112541\tvalid_1's auc: 0.829833\tvalid_1's binary_logloss: 0.136068\n",
            "[130]\ttraining's auc: 0.910811\ttraining's binary_logloss: 0.112445\tvalid_1's auc: 0.829974\tvalid_1's binary_logloss: 0.13605\n",
            "[131]\ttraining's auc: 0.911406\ttraining's binary_logloss: 0.112293\tvalid_1's auc: 0.829874\tvalid_1's binary_logloss: 0.136073\n",
            "[132]\ttraining's auc: 0.911639\ttraining's binary_logloss: 0.112203\tvalid_1's auc: 0.829771\tvalid_1's binary_logloss: 0.136088\n",
            " 56%|█████▌    | 28/50 [14:00<11:55, 32.51s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.163748\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.158269\n",
            "[2]\ttraining's auc: 0.822332\ttraining's binary_logloss: 0.16108\tvalid_1's auc: 0.804484\tvalid_1's binary_logloss: 0.156064\n",
            "[3]\ttraining's auc: 0.828475\ttraining's binary_logloss: 0.158711\tvalid_1's auc: 0.816004\tvalid_1's binary_logloss: 0.154229\n",
            "[4]\ttraining's auc: 0.830862\ttraining's binary_logloss: 0.156637\tvalid_1's auc: 0.818082\tvalid_1's binary_logloss: 0.152559\n",
            "[5]\ttraining's auc: 0.833843\ttraining's binary_logloss: 0.154764\tvalid_1's auc: 0.819312\tvalid_1's binary_logloss: 0.151078\n",
            "[6]\ttraining's auc: 0.834755\ttraining's binary_logloss: 0.153074\tvalid_1's auc: 0.819231\tvalid_1's binary_logloss: 0.149808\n",
            "[7]\ttraining's auc: 0.836491\ttraining's binary_logloss: 0.151555\tvalid_1's auc: 0.820718\tvalid_1's binary_logloss: 0.148624\n",
            "[8]\ttraining's auc: 0.837126\ttraining's binary_logloss: 0.150161\tvalid_1's auc: 0.820149\tvalid_1's binary_logloss: 0.14755\n",
            "[9]\ttraining's auc: 0.840332\ttraining's binary_logloss: 0.148858\tvalid_1's auc: 0.823034\tvalid_1's binary_logloss: 0.146572\n",
            "[10]\ttraining's auc: 0.84286\ttraining's binary_logloss: 0.147652\tvalid_1's auc: 0.82427\tvalid_1's binary_logloss: 0.14567\n",
            "[11]\ttraining's auc: 0.844898\ttraining's binary_logloss: 0.146521\tvalid_1's auc: 0.825495\tvalid_1's binary_logloss: 0.144808\n",
            "[12]\ttraining's auc: 0.847838\ttraining's binary_logloss: 0.145459\tvalid_1's auc: 0.827504\tvalid_1's binary_logloss: 0.144031\n",
            "[13]\ttraining's auc: 0.849915\ttraining's binary_logloss: 0.144466\tvalid_1's auc: 0.828592\tvalid_1's binary_logloss: 0.143275\n",
            "[14]\ttraining's auc: 0.850532\ttraining's binary_logloss: 0.143538\tvalid_1's auc: 0.82912\tvalid_1's binary_logloss: 0.142605\n",
            "[15]\ttraining's auc: 0.851416\ttraining's binary_logloss: 0.142653\tvalid_1's auc: 0.829557\tvalid_1's binary_logloss: 0.141925\n",
            "[16]\ttraining's auc: 0.852233\ttraining's binary_logloss: 0.141841\tvalid_1's auc: 0.829944\tvalid_1's binary_logloss: 0.141333\n",
            "[17]\ttraining's auc: 0.853435\ttraining's binary_logloss: 0.141038\tvalid_1's auc: 0.830184\tvalid_1's binary_logloss: 0.140773\n",
            "[18]\ttraining's auc: 0.854417\ttraining's binary_logloss: 0.140294\tvalid_1's auc: 0.830284\tvalid_1's binary_logloss: 0.140229\n",
            "[19]\ttraining's auc: 0.855874\ttraining's binary_logloss: 0.139575\tvalid_1's auc: 0.831385\tvalid_1's binary_logloss: 0.139691\n",
            "[20]\ttraining's auc: 0.857393\ttraining's binary_logloss: 0.138898\tvalid_1's auc: 0.832976\tvalid_1's binary_logloss: 0.139242\n",
            "[21]\ttraining's auc: 0.858037\ttraining's binary_logloss: 0.138263\tvalid_1's auc: 0.833266\tvalid_1's binary_logloss: 0.138776\n",
            "[22]\ttraining's auc: 0.858593\ttraining's binary_logloss: 0.137644\tvalid_1's auc: 0.833264\tvalid_1's binary_logloss: 0.138377\n",
            "[23]\ttraining's auc: 0.85968\ttraining's binary_logloss: 0.137041\tvalid_1's auc: 0.83286\tvalid_1's binary_logloss: 0.137994\n",
            "[24]\ttraining's auc: 0.860214\ttraining's binary_logloss: 0.136447\tvalid_1's auc: 0.832719\tvalid_1's binary_logloss: 0.137641\n",
            "[25]\ttraining's auc: 0.860593\ttraining's binary_logloss: 0.135915\tvalid_1's auc: 0.832909\tvalid_1's binary_logloss: 0.137266\n",
            "[26]\ttraining's auc: 0.861683\ttraining's binary_logloss: 0.135371\tvalid_1's auc: 0.833114\tvalid_1's binary_logloss: 0.136936\n",
            "[27]\ttraining's auc: 0.862108\ttraining's binary_logloss: 0.134858\tvalid_1's auc: 0.833088\tvalid_1's binary_logloss: 0.136623\n",
            "[28]\ttraining's auc: 0.863488\ttraining's binary_logloss: 0.134375\tvalid_1's auc: 0.833712\tvalid_1's binary_logloss: 0.136336\n",
            "[29]\ttraining's auc: 0.865676\ttraining's binary_logloss: 0.133857\tvalid_1's auc: 0.833939\tvalid_1's binary_logloss: 0.136055\n",
            "[30]\ttraining's auc: 0.866604\ttraining's binary_logloss: 0.133398\tvalid_1's auc: 0.834519\tvalid_1's binary_logloss: 0.135788\n",
            "[31]\ttraining's auc: 0.868134\ttraining's binary_logloss: 0.132954\tvalid_1's auc: 0.834633\tvalid_1's binary_logloss: 0.135543\n",
            "[32]\ttraining's auc: 0.868592\ttraining's binary_logloss: 0.132538\tvalid_1's auc: 0.834368\tvalid_1's binary_logloss: 0.135324\n",
            "[33]\ttraining's auc: 0.86913\ttraining's binary_logloss: 0.132113\tvalid_1's auc: 0.835197\tvalid_1's binary_logloss: 0.135106\n",
            "[34]\ttraining's auc: 0.870044\ttraining's binary_logloss: 0.131721\tvalid_1's auc: 0.83494\tvalid_1's binary_logloss: 0.134907\n",
            "[35]\ttraining's auc: 0.870892\ttraining's binary_logloss: 0.131307\tvalid_1's auc: 0.834835\tvalid_1's binary_logloss: 0.134746\n",
            "[36]\ttraining's auc: 0.871796\ttraining's binary_logloss: 0.130922\tvalid_1's auc: 0.834703\tvalid_1's binary_logloss: 0.134576\n",
            "[37]\ttraining's auc: 0.872272\ttraining's binary_logloss: 0.130563\tvalid_1's auc: 0.834712\tvalid_1's binary_logloss: 0.134406\n",
            "[38]\ttraining's auc: 0.872721\ttraining's binary_logloss: 0.130216\tvalid_1's auc: 0.834594\tvalid_1's binary_logloss: 0.134252\n",
            "[39]\ttraining's auc: 0.873245\ttraining's binary_logloss: 0.129879\tvalid_1's auc: 0.834438\tvalid_1's binary_logloss: 0.134099\n",
            "[40]\ttraining's auc: 0.873596\ttraining's binary_logloss: 0.129549\tvalid_1's auc: 0.834606\tvalid_1's binary_logloss: 0.133931\n",
            "[41]\ttraining's auc: 0.874228\ttraining's binary_logloss: 0.129209\tvalid_1's auc: 0.834318\tvalid_1's binary_logloss: 0.133807\n",
            "[42]\ttraining's auc: 0.87488\ttraining's binary_logloss: 0.128883\tvalid_1's auc: 0.834237\tvalid_1's binary_logloss: 0.133683\n",
            "[43]\ttraining's auc: 0.875046\ttraining's binary_logloss: 0.128586\tvalid_1's auc: 0.834206\tvalid_1's binary_logloss: 0.133573\n",
            "[44]\ttraining's auc: 0.875431\ttraining's binary_logloss: 0.128291\tvalid_1's auc: 0.834034\tvalid_1's binary_logloss: 0.133458\n",
            "[45]\ttraining's auc: 0.875808\ttraining's binary_logloss: 0.128012\tvalid_1's auc: 0.833993\tvalid_1's binary_logloss: 0.133367\n",
            "[46]\ttraining's auc: 0.876073\ttraining's binary_logloss: 0.127749\tvalid_1's auc: 0.834107\tvalid_1's binary_logloss: 0.133241\n",
            "[47]\ttraining's auc: 0.876602\ttraining's binary_logloss: 0.127482\tvalid_1's auc: 0.834121\tvalid_1's binary_logloss: 0.133131\n",
            "[48]\ttraining's auc: 0.877242\ttraining's binary_logloss: 0.12721\tvalid_1's auc: 0.834147\tvalid_1's binary_logloss: 0.133009\n",
            "[49]\ttraining's auc: 0.877866\ttraining's binary_logloss: 0.126926\tvalid_1's auc: 0.834303\tvalid_1's binary_logloss: 0.132896\n",
            "[50]\ttraining's auc: 0.878499\ttraining's binary_logloss: 0.126654\tvalid_1's auc: 0.83423\tvalid_1's binary_logloss: 0.1328\n",
            "[51]\ttraining's auc: 0.878809\ttraining's binary_logloss: 0.126382\tvalid_1's auc: 0.834121\tvalid_1's binary_logloss: 0.132717\n",
            "[52]\ttraining's auc: 0.879365\ttraining's binary_logloss: 0.126125\tvalid_1's auc: 0.834245\tvalid_1's binary_logloss: 0.13264\n",
            "[53]\ttraining's auc: 0.879609\ttraining's binary_logloss: 0.125863\tvalid_1's auc: 0.834108\tvalid_1's binary_logloss: 0.132558\n",
            "[54]\ttraining's auc: 0.880459\ttraining's binary_logloss: 0.125613\tvalid_1's auc: 0.83424\tvalid_1's binary_logloss: 0.132462\n",
            "[55]\ttraining's auc: 0.880674\ttraining's binary_logloss: 0.125382\tvalid_1's auc: 0.83409\tvalid_1's binary_logloss: 0.132396\n",
            "[56]\ttraining's auc: 0.881629\ttraining's binary_logloss: 0.12511\tvalid_1's auc: 0.834931\tvalid_1's binary_logloss: 0.132273\n",
            "[57]\ttraining's auc: 0.881945\ttraining's binary_logloss: 0.124891\tvalid_1's auc: 0.834849\tvalid_1's binary_logloss: 0.132215\n",
            "[58]\ttraining's auc: 0.882297\ttraining's binary_logloss: 0.124668\tvalid_1's auc: 0.834717\tvalid_1's binary_logloss: 0.132163\n",
            "[59]\ttraining's auc: 0.882623\ttraining's binary_logloss: 0.124461\tvalid_1's auc: 0.834634\tvalid_1's binary_logloss: 0.132095\n",
            "[60]\ttraining's auc: 0.883789\ttraining's binary_logloss: 0.124219\tvalid_1's auc: 0.834683\tvalid_1's binary_logloss: 0.132031\n",
            "[61]\ttraining's auc: 0.884297\ttraining's binary_logloss: 0.124006\tvalid_1's auc: 0.834784\tvalid_1's binary_logloss: 0.131972\n",
            "[62]\ttraining's auc: 0.884741\ttraining's binary_logloss: 0.123799\tvalid_1's auc: 0.834884\tvalid_1's binary_logloss: 0.13192\n",
            "[63]\ttraining's auc: 0.885267\ttraining's binary_logloss: 0.123609\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.131863\n",
            " 56%|█████▌    | 28/50 [14:06<11:55, 32.51s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.160081\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.165773\n",
            "[2]\ttraining's auc: 0.830948\ttraining's binary_logloss: 0.157492\tvalid_1's auc: 0.81629\tvalid_1's binary_logloss: 0.163404\n",
            "[3]\ttraining's auc: 0.832195\ttraining's binary_logloss: 0.155286\tvalid_1's auc: 0.814219\tvalid_1's binary_logloss: 0.161504\n",
            "[4]\ttraining's auc: 0.833815\ttraining's binary_logloss: 0.153298\tvalid_1's auc: 0.816404\tvalid_1's binary_logloss: 0.159645\n",
            "[5]\ttraining's auc: 0.835524\ttraining's binary_logloss: 0.15152\tvalid_1's auc: 0.817173\tvalid_1's binary_logloss: 0.158101\n",
            "[6]\ttraining's auc: 0.839002\ttraining's binary_logloss: 0.149874\tvalid_1's auc: 0.819638\tvalid_1's binary_logloss: 0.156628\n",
            "[7]\ttraining's auc: 0.839459\ttraining's binary_logloss: 0.148411\tvalid_1's auc: 0.81905\tvalid_1's binary_logloss: 0.155396\n",
            "[8]\ttraining's auc: 0.843232\ttraining's binary_logloss: 0.147025\tvalid_1's auc: 0.822738\tvalid_1's binary_logloss: 0.154201\n",
            "[9]\ttraining's auc: 0.846699\ttraining's binary_logloss: 0.145734\tvalid_1's auc: 0.825712\tvalid_1's binary_logloss: 0.153112\n",
            "[10]\ttraining's auc: 0.848338\ttraining's binary_logloss: 0.144545\tvalid_1's auc: 0.827139\tvalid_1's binary_logloss: 0.152076\n",
            "[11]\ttraining's auc: 0.849973\ttraining's binary_logloss: 0.143465\tvalid_1's auc: 0.827737\tvalid_1's binary_logloss: 0.151156\n",
            "[12]\ttraining's auc: 0.85037\ttraining's binary_logloss: 0.142451\tvalid_1's auc: 0.828067\tvalid_1's binary_logloss: 0.150307\n",
            "[13]\ttraining's auc: 0.850232\ttraining's binary_logloss: 0.141521\tvalid_1's auc: 0.828529\tvalid_1's binary_logloss: 0.149535\n",
            "[14]\ttraining's auc: 0.851507\ttraining's binary_logloss: 0.140607\tvalid_1's auc: 0.828908\tvalid_1's binary_logloss: 0.148789\n",
            "[15]\ttraining's auc: 0.852509\ttraining's binary_logloss: 0.139706\tvalid_1's auc: 0.829381\tvalid_1's binary_logloss: 0.148088\n",
            "[16]\ttraining's auc: 0.853043\ttraining's binary_logloss: 0.13891\tvalid_1's auc: 0.829274\tvalid_1's binary_logloss: 0.14744\n",
            "[17]\ttraining's auc: 0.853693\ttraining's binary_logloss: 0.138134\tvalid_1's auc: 0.829796\tvalid_1's binary_logloss: 0.146835\n",
            "[18]\ttraining's auc: 0.854499\ttraining's binary_logloss: 0.137403\tvalid_1's auc: 0.830563\tvalid_1's binary_logloss: 0.146253\n",
            "[19]\ttraining's auc: 0.855264\ttraining's binary_logloss: 0.136699\tvalid_1's auc: 0.83058\tvalid_1's binary_logloss: 0.145745\n",
            "[20]\ttraining's auc: 0.856203\ttraining's binary_logloss: 0.13604\tvalid_1's auc: 0.830931\tvalid_1's binary_logloss: 0.145224\n",
            "[21]\ttraining's auc: 0.856814\ttraining's binary_logloss: 0.135391\tvalid_1's auc: 0.831053\tvalid_1's binary_logloss: 0.144726\n",
            "[22]\ttraining's auc: 0.857331\ttraining's binary_logloss: 0.134797\tvalid_1's auc: 0.83128\tvalid_1's binary_logloss: 0.14428\n",
            "[23]\ttraining's auc: 0.858489\ttraining's binary_logloss: 0.134221\tvalid_1's auc: 0.831667\tvalid_1's binary_logloss: 0.143848\n",
            "[24]\ttraining's auc: 0.859117\ttraining's binary_logloss: 0.133696\tvalid_1's auc: 0.83198\tvalid_1's binary_logloss: 0.14343\n",
            "[25]\ttraining's auc: 0.859826\ttraining's binary_logloss: 0.133159\tvalid_1's auc: 0.831939\tvalid_1's binary_logloss: 0.143073\n",
            "[26]\ttraining's auc: 0.860952\ttraining's binary_logloss: 0.132643\tvalid_1's auc: 0.832476\tvalid_1's binary_logloss: 0.142688\n",
            "[27]\ttraining's auc: 0.862392\ttraining's binary_logloss: 0.132165\tvalid_1's auc: 0.832749\tvalid_1's binary_logloss: 0.142355\n",
            "[28]\ttraining's auc: 0.862782\ttraining's binary_logloss: 0.131714\tvalid_1's auc: 0.832819\tvalid_1's binary_logloss: 0.142047\n",
            "[29]\ttraining's auc: 0.863416\ttraining's binary_logloss: 0.131258\tvalid_1's auc: 0.832777\tvalid_1's binary_logloss: 0.141767\n",
            "[30]\ttraining's auc: 0.863869\ttraining's binary_logloss: 0.130818\tvalid_1's auc: 0.832801\tvalid_1's binary_logloss: 0.141485\n",
            "[31]\ttraining's auc: 0.864501\ttraining's binary_logloss: 0.130412\tvalid_1's auc: 0.832674\tvalid_1's binary_logloss: 0.141236\n",
            "[32]\ttraining's auc: 0.864931\ttraining's binary_logloss: 0.129998\tvalid_1's auc: 0.832836\tvalid_1's binary_logloss: 0.140993\n",
            "[33]\ttraining's auc: 0.866444\ttraining's binary_logloss: 0.12958\tvalid_1's auc: 0.833086\tvalid_1's binary_logloss: 0.140736\n",
            "[34]\ttraining's auc: 0.867663\ttraining's binary_logloss: 0.129186\tvalid_1's auc: 0.833105\tvalid_1's binary_logloss: 0.140506\n",
            "[35]\ttraining's auc: 0.868501\ttraining's binary_logloss: 0.128804\tvalid_1's auc: 0.832985\tvalid_1's binary_logloss: 0.140317\n",
            "[36]\ttraining's auc: 0.869502\ttraining's binary_logloss: 0.128435\tvalid_1's auc: 0.833303\tvalid_1's binary_logloss: 0.140111\n",
            "[37]\ttraining's auc: 0.870747\ttraining's binary_logloss: 0.128088\tvalid_1's auc: 0.835013\tvalid_1's binary_logloss: 0.139926\n",
            "[38]\ttraining's auc: 0.871196\ttraining's binary_logloss: 0.127758\tvalid_1's auc: 0.834756\tvalid_1's binary_logloss: 0.139766\n",
            "[39]\ttraining's auc: 0.872219\ttraining's binary_logloss: 0.127422\tvalid_1's auc: 0.835075\tvalid_1's binary_logloss: 0.139581\n",
            "[40]\ttraining's auc: 0.872641\ttraining's binary_logloss: 0.127101\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.139423\n",
            "[41]\ttraining's auc: 0.873321\ttraining's binary_logloss: 0.126765\tvalid_1's auc: 0.835005\tvalid_1's binary_logloss: 0.139274\n",
            "[42]\ttraining's auc: 0.87396\ttraining's binary_logloss: 0.126473\tvalid_1's auc: 0.835416\tvalid_1's binary_logloss: 0.139131\n",
            "[43]\ttraining's auc: 0.874771\ttraining's binary_logloss: 0.126167\tvalid_1's auc: 0.835558\tvalid_1's binary_logloss: 0.139005\n",
            "[44]\ttraining's auc: 0.875204\ttraining's binary_logloss: 0.125885\tvalid_1's auc: 0.835729\tvalid_1's binary_logloss: 0.138887\n",
            "[45]\ttraining's auc: 0.876004\ttraining's binary_logloss: 0.125579\tvalid_1's auc: 0.835924\tvalid_1's binary_logloss: 0.138744\n",
            "[46]\ttraining's auc: 0.87642\ttraining's binary_logloss: 0.125317\tvalid_1's auc: 0.835836\tvalid_1's binary_logloss: 0.138619\n",
            "[47]\ttraining's auc: 0.877388\ttraining's binary_logloss: 0.125027\tvalid_1's auc: 0.835803\tvalid_1's binary_logloss: 0.138489\n",
            "[48]\ttraining's auc: 0.878225\ttraining's binary_logloss: 0.12476\tvalid_1's auc: 0.836193\tvalid_1's binary_logloss: 0.138339\n",
            "[49]\ttraining's auc: 0.878975\ttraining's binary_logloss: 0.124494\tvalid_1's auc: 0.836436\tvalid_1's binary_logloss: 0.138202\n",
            "[50]\ttraining's auc: 0.879631\ttraining's binary_logloss: 0.124217\tvalid_1's auc: 0.836879\tvalid_1's binary_logloss: 0.138074\n",
            "[51]\ttraining's auc: 0.880171\ttraining's binary_logloss: 0.123961\tvalid_1's auc: 0.836835\tvalid_1's binary_logloss: 0.13798\n",
            "[52]\ttraining's auc: 0.880738\ttraining's binary_logloss: 0.123723\tvalid_1's auc: 0.83691\tvalid_1's binary_logloss: 0.137898\n",
            "[53]\ttraining's auc: 0.881506\ttraining's binary_logloss: 0.123478\tvalid_1's auc: 0.836995\tvalid_1's binary_logloss: 0.137801\n",
            "[54]\ttraining's auc: 0.882713\ttraining's binary_logloss: 0.12323\tvalid_1's auc: 0.83682\tvalid_1's binary_logloss: 0.137711\n",
            "[55]\ttraining's auc: 0.883043\ttraining's binary_logloss: 0.123007\tvalid_1's auc: 0.836865\tvalid_1's binary_logloss: 0.137604\n",
            "[56]\ttraining's auc: 0.884026\ttraining's binary_logloss: 0.122746\tvalid_1's auc: 0.836803\tvalid_1's binary_logloss: 0.137542\n",
            "[57]\ttraining's auc: 0.884513\ttraining's binary_logloss: 0.122506\tvalid_1's auc: 0.836847\tvalid_1's binary_logloss: 0.137468\n",
            "[58]\ttraining's auc: 0.885104\ttraining's binary_logloss: 0.122293\tvalid_1's auc: 0.836846\tvalid_1's binary_logloss: 0.137391\n",
            "[59]\ttraining's auc: 0.8856\ttraining's binary_logloss: 0.122073\tvalid_1's auc: 0.836981\tvalid_1's binary_logloss: 0.13731\n",
            "[60]\ttraining's auc: 0.886288\ttraining's binary_logloss: 0.12184\tvalid_1's auc: 0.837094\tvalid_1's binary_logloss: 0.137243\n",
            "[61]\ttraining's auc: 0.886852\ttraining's binary_logloss: 0.12163\tvalid_1's auc: 0.837492\tvalid_1's binary_logloss: 0.13715\n",
            "[62]\ttraining's auc: 0.887249\ttraining's binary_logloss: 0.121426\tvalid_1's auc: 0.837913\tvalid_1's binary_logloss: 0.137038\n",
            "[63]\ttraining's auc: 0.887864\ttraining's binary_logloss: 0.121216\tvalid_1's auc: 0.837847\tvalid_1's binary_logloss: 0.136986\n",
            "[64]\ttraining's auc: 0.888352\ttraining's binary_logloss: 0.12102\tvalid_1's auc: 0.837812\tvalid_1's binary_logloss: 0.136942\n",
            "[65]\ttraining's auc: 0.888758\ttraining's binary_logloss: 0.120824\tvalid_1's auc: 0.837813\tvalid_1's binary_logloss: 0.136892\n",
            "[66]\ttraining's auc: 0.889065\ttraining's binary_logloss: 0.120649\tvalid_1's auc: 0.837849\tvalid_1's binary_logloss: 0.136844\n",
            "[67]\ttraining's auc: 0.88975\ttraining's binary_logloss: 0.120417\tvalid_1's auc: 0.837558\tvalid_1's binary_logloss: 0.136826\n",
            "[68]\ttraining's auc: 0.890228\ttraining's binary_logloss: 0.120229\tvalid_1's auc: 0.837425\tvalid_1's binary_logloss: 0.1368\n",
            "[69]\ttraining's auc: 0.890748\ttraining's binary_logloss: 0.120031\tvalid_1's auc: 0.837419\tvalid_1's binary_logloss: 0.136759\n",
            "[70]\ttraining's auc: 0.89106\ttraining's binary_logloss: 0.119852\tvalid_1's auc: 0.837298\tvalid_1's binary_logloss: 0.136726\n",
            "[71]\ttraining's auc: 0.891322\ttraining's binary_logloss: 0.11968\tvalid_1's auc: 0.837515\tvalid_1's binary_logloss: 0.136655\n",
            "[72]\ttraining's auc: 0.891772\ttraining's binary_logloss: 0.1195\tvalid_1's auc: 0.837416\tvalid_1's binary_logloss: 0.136643\n",
            "[73]\ttraining's auc: 0.892148\ttraining's binary_logloss: 0.119348\tvalid_1's auc: 0.837415\tvalid_1's binary_logloss: 0.136616\n",
            "[74]\ttraining's auc: 0.892623\ttraining's binary_logloss: 0.119169\tvalid_1's auc: 0.837296\tvalid_1's binary_logloss: 0.136598\n",
            "[75]\ttraining's auc: 0.893042\ttraining's binary_logloss: 0.118982\tvalid_1's auc: 0.837307\tvalid_1's binary_logloss: 0.136558\n",
            "[76]\ttraining's auc: 0.893306\ttraining's binary_logloss: 0.118838\tvalid_1's auc: 0.837346\tvalid_1's binary_logloss: 0.136533\n",
            "[77]\ttraining's auc: 0.893653\ttraining's binary_logloss: 0.118693\tvalid_1's auc: 0.837185\tvalid_1's binary_logloss: 0.136515\n",
            "[78]\ttraining's auc: 0.89397\ttraining's binary_logloss: 0.118527\tvalid_1's auc: 0.837451\tvalid_1's binary_logloss: 0.136464\n",
            "[79]\ttraining's auc: 0.894356\ttraining's binary_logloss: 0.118382\tvalid_1's auc: 0.837237\tvalid_1's binary_logloss: 0.136466\n",
            "[80]\ttraining's auc: 0.894779\ttraining's binary_logloss: 0.118237\tvalid_1's auc: 0.837297\tvalid_1's binary_logloss: 0.136443\n",
            "[81]\ttraining's auc: 0.895117\ttraining's binary_logloss: 0.118087\tvalid_1's auc: 0.837186\tvalid_1's binary_logloss: 0.136439\n",
            "[82]\ttraining's auc: 0.895527\ttraining's binary_logloss: 0.11791\tvalid_1's auc: 0.837244\tvalid_1's binary_logloss: 0.136418\n",
            "[83]\ttraining's auc: 0.895723\ttraining's binary_logloss: 0.117789\tvalid_1's auc: 0.8372\tvalid_1's binary_logloss: 0.136401\n",
            "[84]\ttraining's auc: 0.896299\ttraining's binary_logloss: 0.117616\tvalid_1's auc: 0.837027\tvalid_1's binary_logloss: 0.136394\n",
            "[85]\ttraining's auc: 0.896607\ttraining's binary_logloss: 0.117474\tvalid_1's auc: 0.836871\tvalid_1's binary_logloss: 0.136383\n",
            "[86]\ttraining's auc: 0.897182\ttraining's binary_logloss: 0.117301\tvalid_1's auc: 0.83685\tvalid_1's binary_logloss: 0.136373\n",
            "[87]\ttraining's auc: 0.897537\ttraining's binary_logloss: 0.117145\tvalid_1's auc: 0.836992\tvalid_1's binary_logloss: 0.136332\n",
            "[88]\ttraining's auc: 0.897827\ttraining's binary_logloss: 0.117017\tvalid_1's auc: 0.83695\tvalid_1's binary_logloss: 0.136324\n",
            "[89]\ttraining's auc: 0.898405\ttraining's binary_logloss: 0.116862\tvalid_1's auc: 0.836915\tvalid_1's binary_logloss: 0.136316\n",
            "[90]\ttraining's auc: 0.898802\ttraining's binary_logloss: 0.116731\tvalid_1's auc: 0.836769\tvalid_1's binary_logloss: 0.136318\n",
            "[91]\ttraining's auc: 0.899175\ttraining's binary_logloss: 0.116589\tvalid_1's auc: 0.83668\tvalid_1's binary_logloss: 0.136295\n",
            "[92]\ttraining's auc: 0.899498\ttraining's binary_logloss: 0.116445\tvalid_1's auc: 0.836611\tvalid_1's binary_logloss: 0.136279\n",
            " 58%|█████▊    | 29/50 [14:18<12:04, 34.49s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.16316\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.164263\n",
            "[2]\ttraining's auc: 0.827212\ttraining's binary_logloss: 0.161848\tvalid_1's auc: 0.805077\tvalid_1's binary_logloss: 0.163166\n",
            "[3]\ttraining's auc: 0.827721\ttraining's binary_logloss: 0.160631\tvalid_1's auc: 0.804913\tvalid_1's binary_logloss: 0.162186\n",
            "[4]\ttraining's auc: 0.832844\ttraining's binary_logloss: 0.159484\tvalid_1's auc: 0.808184\tvalid_1's binary_logloss: 0.161273\n",
            "[5]\ttraining's auc: 0.833679\ttraining's binary_logloss: 0.158402\tvalid_1's auc: 0.808051\tvalid_1's binary_logloss: 0.160437\n",
            "[6]\ttraining's auc: 0.834402\ttraining's binary_logloss: 0.157388\tvalid_1's auc: 0.807428\tvalid_1's binary_logloss: 0.159655\n",
            "[7]\ttraining's auc: 0.835337\ttraining's binary_logloss: 0.15643\tvalid_1's auc: 0.808257\tvalid_1's binary_logloss: 0.158878\n",
            "[8]\ttraining's auc: 0.83609\ttraining's binary_logloss: 0.155527\tvalid_1's auc: 0.808315\tvalid_1's binary_logloss: 0.158161\n",
            "[9]\ttraining's auc: 0.836245\ttraining's binary_logloss: 0.154666\tvalid_1's auc: 0.808183\tvalid_1's binary_logloss: 0.157484\n",
            "[10]\ttraining's auc: 0.836802\ttraining's binary_logloss: 0.153846\tvalid_1's auc: 0.808545\tvalid_1's binary_logloss: 0.156827\n",
            "[11]\ttraining's auc: 0.836833\ttraining's binary_logloss: 0.153064\tvalid_1's auc: 0.808617\tvalid_1's binary_logloss: 0.156226\n",
            "[12]\ttraining's auc: 0.838343\ttraining's binary_logloss: 0.152317\tvalid_1's auc: 0.809843\tvalid_1's binary_logloss: 0.155636\n",
            "[13]\ttraining's auc: 0.838581\ttraining's binary_logloss: 0.151597\tvalid_1's auc: 0.810062\tvalid_1's binary_logloss: 0.155074\n",
            "[14]\ttraining's auc: 0.841245\ttraining's binary_logloss: 0.150899\tvalid_1's auc: 0.812034\tvalid_1's binary_logloss: 0.154539\n",
            "[15]\ttraining's auc: 0.842716\ttraining's binary_logloss: 0.150231\tvalid_1's auc: 0.813996\tvalid_1's binary_logloss: 0.153994\n",
            "[16]\ttraining's auc: 0.84408\ttraining's binary_logloss: 0.14959\tvalid_1's auc: 0.814974\tvalid_1's binary_logloss: 0.153508\n",
            "[17]\ttraining's auc: 0.845237\ttraining's binary_logloss: 0.148967\tvalid_1's auc: 0.815118\tvalid_1's binary_logloss: 0.153037\n",
            "[18]\ttraining's auc: 0.84556\ttraining's binary_logloss: 0.148381\tvalid_1's auc: 0.815041\tvalid_1's binary_logloss: 0.152569\n",
            "[19]\ttraining's auc: 0.84578\ttraining's binary_logloss: 0.147811\tvalid_1's auc: 0.815421\tvalid_1's binary_logloss: 0.152122\n",
            "[20]\ttraining's auc: 0.846947\ttraining's binary_logloss: 0.14726\tvalid_1's auc: 0.816562\tvalid_1's binary_logloss: 0.151694\n",
            "[21]\ttraining's auc: 0.847441\ttraining's binary_logloss: 0.146718\tvalid_1's auc: 0.816848\tvalid_1's binary_logloss: 0.151302\n",
            "[22]\ttraining's auc: 0.848345\ttraining's binary_logloss: 0.146183\tvalid_1's auc: 0.817446\tvalid_1's binary_logloss: 0.150882\n",
            "[23]\ttraining's auc: 0.84895\ttraining's binary_logloss: 0.145654\tvalid_1's auc: 0.817968\tvalid_1's binary_logloss: 0.150493\n",
            "[24]\ttraining's auc: 0.849596\ttraining's binary_logloss: 0.145156\tvalid_1's auc: 0.818489\tvalid_1's binary_logloss: 0.150122\n",
            "[25]\ttraining's auc: 0.850036\ttraining's binary_logloss: 0.144676\tvalid_1's auc: 0.819374\tvalid_1's binary_logloss: 0.149748\n",
            "[26]\ttraining's auc: 0.850344\ttraining's binary_logloss: 0.144188\tvalid_1's auc: 0.819546\tvalid_1's binary_logloss: 0.149379\n",
            "[27]\ttraining's auc: 0.850563\ttraining's binary_logloss: 0.143731\tvalid_1's auc: 0.819576\tvalid_1's binary_logloss: 0.149052\n",
            "[28]\ttraining's auc: 0.851179\ttraining's binary_logloss: 0.143275\tvalid_1's auc: 0.820036\tvalid_1's binary_logloss: 0.148715\n",
            "[29]\ttraining's auc: 0.85144\ttraining's binary_logloss: 0.142837\tvalid_1's auc: 0.820247\tvalid_1's binary_logloss: 0.148398\n",
            "[30]\ttraining's auc: 0.851831\ttraining's binary_logloss: 0.142418\tvalid_1's auc: 0.820613\tvalid_1's binary_logloss: 0.148077\n",
            "[31]\ttraining's auc: 0.852169\ttraining's binary_logloss: 0.142008\tvalid_1's auc: 0.820732\tvalid_1's binary_logloss: 0.147773\n",
            "[32]\ttraining's auc: 0.852585\ttraining's binary_logloss: 0.141613\tvalid_1's auc: 0.821083\tvalid_1's binary_logloss: 0.147473\n",
            "[33]\ttraining's auc: 0.853332\ttraining's binary_logloss: 0.141228\tvalid_1's auc: 0.821716\tvalid_1's binary_logloss: 0.147184\n",
            "[34]\ttraining's auc: 0.853399\ttraining's binary_logloss: 0.140847\tvalid_1's auc: 0.821692\tvalid_1's binary_logloss: 0.146898\n",
            "[35]\ttraining's auc: 0.853757\ttraining's binary_logloss: 0.140481\tvalid_1's auc: 0.822173\tvalid_1's binary_logloss: 0.146634\n",
            "[36]\ttraining's auc: 0.854307\ttraining's binary_logloss: 0.140112\tvalid_1's auc: 0.822014\tvalid_1's binary_logloss: 0.146372\n",
            "[37]\ttraining's auc: 0.854407\ttraining's binary_logloss: 0.13977\tvalid_1's auc: 0.821989\tvalid_1's binary_logloss: 0.146126\n",
            "[38]\ttraining's auc: 0.854608\ttraining's binary_logloss: 0.139431\tvalid_1's auc: 0.822062\tvalid_1's binary_logloss: 0.145886\n",
            "[39]\ttraining's auc: 0.854734\ttraining's binary_logloss: 0.139104\tvalid_1's auc: 0.822033\tvalid_1's binary_logloss: 0.145647\n",
            "[40]\ttraining's auc: 0.856741\ttraining's binary_logloss: 0.13879\tvalid_1's auc: 0.82254\tvalid_1's binary_logloss: 0.145423\n",
            "[41]\ttraining's auc: 0.856929\ttraining's binary_logloss: 0.138468\tvalid_1's auc: 0.822554\tvalid_1's binary_logloss: 0.14522\n",
            "[42]\ttraining's auc: 0.857316\ttraining's binary_logloss: 0.138143\tvalid_1's auc: 0.822722\tvalid_1's binary_logloss: 0.144994\n",
            "[43]\ttraining's auc: 0.857671\ttraining's binary_logloss: 0.137831\tvalid_1's auc: 0.823236\tvalid_1's binary_logloss: 0.14478\n",
            "[44]\ttraining's auc: 0.857844\ttraining's binary_logloss: 0.137517\tvalid_1's auc: 0.823202\tvalid_1's binary_logloss: 0.144577\n",
            "[45]\ttraining's auc: 0.858039\ttraining's binary_logloss: 0.137225\tvalid_1's auc: 0.823135\tvalid_1's binary_logloss: 0.14438\n",
            "[46]\ttraining's auc: 0.858562\ttraining's binary_logloss: 0.136932\tvalid_1's auc: 0.823303\tvalid_1's binary_logloss: 0.144172\n",
            "[47]\ttraining's auc: 0.858851\ttraining's binary_logloss: 0.136637\tvalid_1's auc: 0.823288\tvalid_1's binary_logloss: 0.143997\n",
            "[48]\ttraining's auc: 0.85897\ttraining's binary_logloss: 0.13636\tvalid_1's auc: 0.823293\tvalid_1's binary_logloss: 0.14382\n",
            "[49]\ttraining's auc: 0.859199\ttraining's binary_logloss: 0.136086\tvalid_1's auc: 0.823091\tvalid_1's binary_logloss: 0.143658\n",
            "[50]\ttraining's auc: 0.85949\ttraining's binary_logloss: 0.135816\tvalid_1's auc: 0.823271\tvalid_1's binary_logloss: 0.143473\n",
            "[51]\ttraining's auc: 0.859676\ttraining's binary_logloss: 0.13557\tvalid_1's auc: 0.82351\tvalid_1's binary_logloss: 0.143288\n",
            "[52]\ttraining's auc: 0.860342\ttraining's binary_logloss: 0.135291\tvalid_1's auc: 0.823659\tvalid_1's binary_logloss: 0.143115\n",
            "[53]\ttraining's auc: 0.861285\ttraining's binary_logloss: 0.135034\tvalid_1's auc: 0.824056\tvalid_1's binary_logloss: 0.142945\n",
            "[54]\ttraining's auc: 0.861791\ttraining's binary_logloss: 0.134777\tvalid_1's auc: 0.824046\tvalid_1's binary_logloss: 0.142786\n",
            "[55]\ttraining's auc: 0.862023\ttraining's binary_logloss: 0.134542\tvalid_1's auc: 0.82421\tvalid_1's binary_logloss: 0.142623\n",
            "[56]\ttraining's auc: 0.8621\ttraining's binary_logloss: 0.134307\tvalid_1's auc: 0.824326\tvalid_1's binary_logloss: 0.142462\n",
            "[57]\ttraining's auc: 0.862471\ttraining's binary_logloss: 0.134077\tvalid_1's auc: 0.824554\tvalid_1's binary_logloss: 0.142291\n",
            "[58]\ttraining's auc: 0.862823\ttraining's binary_logloss: 0.133853\tvalid_1's auc: 0.824713\tvalid_1's binary_logloss: 0.142132\n",
            "[59]\ttraining's auc: 0.863297\ttraining's binary_logloss: 0.133631\tvalid_1's auc: 0.824901\tvalid_1's binary_logloss: 0.14199\n",
            "[60]\ttraining's auc: 0.863562\ttraining's binary_logloss: 0.133418\tvalid_1's auc: 0.825156\tvalid_1's binary_logloss: 0.141848\n",
            "[61]\ttraining's auc: 0.863924\ttraining's binary_logloss: 0.133192\tvalid_1's auc: 0.82518\tvalid_1's binary_logloss: 0.14172\n",
            "[62]\ttraining's auc: 0.864464\ttraining's binary_logloss: 0.13298\tvalid_1's auc: 0.825379\tvalid_1's binary_logloss: 0.141574\n",
            "[63]\ttraining's auc: 0.864779\ttraining's binary_logloss: 0.13277\tvalid_1's auc: 0.825652\tvalid_1's binary_logloss: 0.141448\n",
            "[64]\ttraining's auc: 0.865108\ttraining's binary_logloss: 0.132568\tvalid_1's auc: 0.825631\tvalid_1's binary_logloss: 0.14132\n",
            "[65]\ttraining's auc: 0.865332\ttraining's binary_logloss: 0.132348\tvalid_1's auc: 0.825644\tvalid_1's binary_logloss: 0.141179\n",
            "[66]\ttraining's auc: 0.865712\ttraining's binary_logloss: 0.13215\tvalid_1's auc: 0.82576\tvalid_1's binary_logloss: 0.141064\n",
            "[67]\ttraining's auc: 0.866058\ttraining's binary_logloss: 0.131958\tvalid_1's auc: 0.826084\tvalid_1's binary_logloss: 0.140948\n",
            "[68]\ttraining's auc: 0.866182\ttraining's binary_logloss: 0.131764\tvalid_1's auc: 0.826073\tvalid_1's binary_logloss: 0.140836\n",
            "[69]\ttraining's auc: 0.866457\ttraining's binary_logloss: 0.131566\tvalid_1's auc: 0.826356\tvalid_1's binary_logloss: 0.140718\n",
            "[70]\ttraining's auc: 0.866851\ttraining's binary_logloss: 0.131374\tvalid_1's auc: 0.826547\tvalid_1's binary_logloss: 0.140594\n",
            "[71]\ttraining's auc: 0.866987\ttraining's binary_logloss: 0.131182\tvalid_1's auc: 0.826554\tvalid_1's binary_logloss: 0.140483\n",
            "[72]\ttraining's auc: 0.867353\ttraining's binary_logloss: 0.130993\tvalid_1's auc: 0.826787\tvalid_1's binary_logloss: 0.140377\n",
            "[73]\ttraining's auc: 0.867569\ttraining's binary_logloss: 0.130816\tvalid_1's auc: 0.826601\tvalid_1's binary_logloss: 0.14028\n",
            "[74]\ttraining's auc: 0.868059\ttraining's binary_logloss: 0.130639\tvalid_1's auc: 0.8269\tvalid_1's binary_logloss: 0.140182\n",
            "[75]\ttraining's auc: 0.868431\ttraining's binary_logloss: 0.130467\tvalid_1's auc: 0.826987\tvalid_1's binary_logloss: 0.140093\n",
            "[76]\ttraining's auc: 0.868643\ttraining's binary_logloss: 0.130282\tvalid_1's auc: 0.827023\tvalid_1's binary_logloss: 0.139999\n",
            "[77]\ttraining's auc: 0.869073\ttraining's binary_logloss: 0.130107\tvalid_1's auc: 0.827003\tvalid_1's binary_logloss: 0.139912\n",
            "[78]\ttraining's auc: 0.869367\ttraining's binary_logloss: 0.129941\tvalid_1's auc: 0.827106\tvalid_1's binary_logloss: 0.139829\n",
            "[79]\ttraining's auc: 0.869534\ttraining's binary_logloss: 0.129773\tvalid_1's auc: 0.827076\tvalid_1's binary_logloss: 0.139742\n",
            "[80]\ttraining's auc: 0.869931\ttraining's binary_logloss: 0.129607\tvalid_1's auc: 0.827225\tvalid_1's binary_logloss: 0.139658\n",
            "[81]\ttraining's auc: 0.870097\ttraining's binary_logloss: 0.129445\tvalid_1's auc: 0.827229\tvalid_1's binary_logloss: 0.139572\n",
            "[82]\ttraining's auc: 0.870459\ttraining's binary_logloss: 0.129288\tvalid_1's auc: 0.827356\tvalid_1's binary_logloss: 0.1395\n",
            "[83]\ttraining's auc: 0.870674\ttraining's binary_logloss: 0.129138\tvalid_1's auc: 0.827426\tvalid_1's binary_logloss: 0.139422\n",
            "[84]\ttraining's auc: 0.870858\ttraining's binary_logloss: 0.128989\tvalid_1's auc: 0.827476\tvalid_1's binary_logloss: 0.139351\n",
            "[85]\ttraining's auc: 0.870993\ttraining's binary_logloss: 0.128843\tvalid_1's auc: 0.827616\tvalid_1's binary_logloss: 0.139283\n",
            "[86]\ttraining's auc: 0.871181\ttraining's binary_logloss: 0.128708\tvalid_1's auc: 0.827597\tvalid_1's binary_logloss: 0.139202\n",
            "[87]\ttraining's auc: 0.871355\ttraining's binary_logloss: 0.128561\tvalid_1's auc: 0.82754\tvalid_1's binary_logloss: 0.13913\n",
            "[88]\ttraining's auc: 0.871534\ttraining's binary_logloss: 0.128416\tvalid_1's auc: 0.827546\tvalid_1's binary_logloss: 0.139057\n",
            "[89]\ttraining's auc: 0.871787\ttraining's binary_logloss: 0.128275\tvalid_1's auc: 0.827607\tvalid_1's binary_logloss: 0.138991\n",
            "[90]\ttraining's auc: 0.872293\ttraining's binary_logloss: 0.128119\tvalid_1's auc: 0.827818\tvalid_1's binary_logloss: 0.13892\n",
            "[91]\ttraining's auc: 0.872386\ttraining's binary_logloss: 0.127992\tvalid_1's auc: 0.827886\tvalid_1's binary_logloss: 0.13885\n",
            "[92]\ttraining's auc: 0.872793\ttraining's binary_logloss: 0.127844\tvalid_1's auc: 0.828024\tvalid_1's binary_logloss: 0.138775\n",
            "[93]\ttraining's auc: 0.872964\ttraining's binary_logloss: 0.127709\tvalid_1's auc: 0.828005\tvalid_1's binary_logloss: 0.138709\n",
            "[94]\ttraining's auc: 0.87318\ttraining's binary_logloss: 0.127578\tvalid_1's auc: 0.828073\tvalid_1's binary_logloss: 0.138649\n",
            "[95]\ttraining's auc: 0.873582\ttraining's binary_logloss: 0.12744\tvalid_1's auc: 0.827952\tvalid_1's binary_logloss: 0.138606\n",
            "[96]\ttraining's auc: 0.873826\ttraining's binary_logloss: 0.127311\tvalid_1's auc: 0.827984\tvalid_1's binary_logloss: 0.138553\n",
            "[97]\ttraining's auc: 0.874106\ttraining's binary_logloss: 0.127178\tvalid_1's auc: 0.827918\tvalid_1's binary_logloss: 0.138505\n",
            "[98]\ttraining's auc: 0.8744\ttraining's binary_logloss: 0.127038\tvalid_1's auc: 0.827896\tvalid_1's binary_logloss: 0.138449\n",
            "[99]\ttraining's auc: 0.874597\ttraining's binary_logloss: 0.126903\tvalid_1's auc: 0.828045\tvalid_1's binary_logloss: 0.138387\n",
            "[100]\ttraining's auc: 0.874875\ttraining's binary_logloss: 0.12677\tvalid_1's auc: 0.828001\tvalid_1's binary_logloss: 0.138335\n",
            "[101]\ttraining's auc: 0.875102\ttraining's binary_logloss: 0.126646\tvalid_1's auc: 0.828123\tvalid_1's binary_logloss: 0.13828\n",
            "[102]\ttraining's auc: 0.875566\ttraining's binary_logloss: 0.126513\tvalid_1's auc: 0.828351\tvalid_1's binary_logloss: 0.138226\n",
            "[103]\ttraining's auc: 0.8758\ttraining's binary_logloss: 0.126383\tvalid_1's auc: 0.828342\tvalid_1's binary_logloss: 0.138179\n",
            "[104]\ttraining's auc: 0.876441\ttraining's binary_logloss: 0.12625\tvalid_1's auc: 0.828366\tvalid_1's binary_logloss: 0.138129\n",
            "[105]\ttraining's auc: 0.876556\ttraining's binary_logloss: 0.126133\tvalid_1's auc: 0.828354\tvalid_1's binary_logloss: 0.138078\n",
            "[106]\ttraining's auc: 0.876718\ttraining's binary_logloss: 0.126016\tvalid_1's auc: 0.828389\tvalid_1's binary_logloss: 0.138033\n",
            "[107]\ttraining's auc: 0.876778\ttraining's binary_logloss: 0.125903\tvalid_1's auc: 0.828499\tvalid_1's binary_logloss: 0.13798\n",
            "[108]\ttraining's auc: 0.876931\ttraining's binary_logloss: 0.125788\tvalid_1's auc: 0.828582\tvalid_1's binary_logloss: 0.137941\n",
            "[109]\ttraining's auc: 0.87741\ttraining's binary_logloss: 0.125667\tvalid_1's auc: 0.828546\tvalid_1's binary_logloss: 0.137894\n",
            "[110]\ttraining's auc: 0.87753\ttraining's binary_logloss: 0.125558\tvalid_1's auc: 0.828561\tvalid_1's binary_logloss: 0.137846\n",
            "[111]\ttraining's auc: 0.877746\ttraining's binary_logloss: 0.12544\tvalid_1's auc: 0.828553\tvalid_1's binary_logloss: 0.137809\n",
            "[112]\ttraining's auc: 0.878415\ttraining's binary_logloss: 0.125314\tvalid_1's auc: 0.82843\tvalid_1's binary_logloss: 0.137761\n",
            "[113]\ttraining's auc: 0.878668\ttraining's binary_logloss: 0.125207\tvalid_1's auc: 0.828581\tvalid_1's binary_logloss: 0.137716\n",
            "[114]\ttraining's auc: 0.8789\ttraining's binary_logloss: 0.125096\tvalid_1's auc: 0.828546\tvalid_1's binary_logloss: 0.137675\n",
            "[115]\ttraining's auc: 0.878992\ttraining's binary_logloss: 0.124993\tvalid_1's auc: 0.828604\tvalid_1's binary_logloss: 0.13764\n",
            "[116]\ttraining's auc: 0.879148\ttraining's binary_logloss: 0.124893\tvalid_1's auc: 0.82873\tvalid_1's binary_logloss: 0.137595\n",
            "[117]\ttraining's auc: 0.879656\ttraining's binary_logloss: 0.124766\tvalid_1's auc: 0.828852\tvalid_1's binary_logloss: 0.137547\n",
            "[118]\ttraining's auc: 0.879856\ttraining's binary_logloss: 0.124655\tvalid_1's auc: 0.82888\tvalid_1's binary_logloss: 0.137509\n",
            "[119]\ttraining's auc: 0.879953\ttraining's binary_logloss: 0.124555\tvalid_1's auc: 0.828932\tvalid_1's binary_logloss: 0.137473\n",
            "[120]\ttraining's auc: 0.88009\ttraining's binary_logloss: 0.124457\tvalid_1's auc: 0.828961\tvalid_1's binary_logloss: 0.137435\n",
            "[121]\ttraining's auc: 0.880264\ttraining's binary_logloss: 0.124361\tvalid_1's auc: 0.82906\tvalid_1's binary_logloss: 0.137395\n",
            "[122]\ttraining's auc: 0.880431\ttraining's binary_logloss: 0.124263\tvalid_1's auc: 0.829116\tvalid_1's binary_logloss: 0.137343\n",
            "[123]\ttraining's auc: 0.88054\ttraining's binary_logloss: 0.124161\tvalid_1's auc: 0.82931\tvalid_1's binary_logloss: 0.137288\n",
            "[124]\ttraining's auc: 0.880901\ttraining's binary_logloss: 0.124053\tvalid_1's auc: 0.829354\tvalid_1's binary_logloss: 0.137244\n",
            "[125]\ttraining's auc: 0.881297\ttraining's binary_logloss: 0.123942\tvalid_1's auc: 0.829244\tvalid_1's binary_logloss: 0.137213\n",
            "[126]\ttraining's auc: 0.881583\ttraining's binary_logloss: 0.123837\tvalid_1's auc: 0.829232\tvalid_1's binary_logloss: 0.137184\n",
            "[127]\ttraining's auc: 0.881883\ttraining's binary_logloss: 0.12373\tvalid_1's auc: 0.829251\tvalid_1's binary_logloss: 0.137153\n",
            "[128]\ttraining's auc: 0.882122\ttraining's binary_logloss: 0.123629\tvalid_1's auc: 0.829165\tvalid_1's binary_logloss: 0.137134\n",
            "[129]\ttraining's auc: 0.882291\ttraining's binary_logloss: 0.123529\tvalid_1's auc: 0.829196\tvalid_1's binary_logloss: 0.137103\n",
            "[130]\ttraining's auc: 0.882597\ttraining's binary_logloss: 0.123427\tvalid_1's auc: 0.829161\tvalid_1's binary_logloss: 0.137074\n",
            "[131]\ttraining's auc: 0.882742\ttraining's binary_logloss: 0.123334\tvalid_1's auc: 0.829269\tvalid_1's binary_logloss: 0.137066\n",
            "[132]\ttraining's auc: 0.882979\ttraining's binary_logloss: 0.12323\tvalid_1's auc: 0.829253\tvalid_1's binary_logloss: 0.13704\n",
            "[133]\ttraining's auc: 0.883418\ttraining's binary_logloss: 0.12312\tvalid_1's auc: 0.829336\tvalid_1's binary_logloss: 0.136998\n",
            "[134]\ttraining's auc: 0.883617\ttraining's binary_logloss: 0.123028\tvalid_1's auc: 0.829304\tvalid_1's binary_logloss: 0.136981\n",
            "[135]\ttraining's auc: 0.883911\ttraining's binary_logloss: 0.122927\tvalid_1's auc: 0.829472\tvalid_1's binary_logloss: 0.136946\n",
            "[136]\ttraining's auc: 0.884098\ttraining's binary_logloss: 0.122838\tvalid_1's auc: 0.829363\tvalid_1's binary_logloss: 0.13693\n",
            "[137]\ttraining's auc: 0.884453\ttraining's binary_logloss: 0.122749\tvalid_1's auc: 0.829303\tvalid_1's binary_logloss: 0.136911\n",
            "[138]\ttraining's auc: 0.884648\ttraining's binary_logloss: 0.122653\tvalid_1's auc: 0.829378\tvalid_1's binary_logloss: 0.136884\n",
            "[139]\ttraining's auc: 0.885031\ttraining's binary_logloss: 0.122548\tvalid_1's auc: 0.829561\tvalid_1's binary_logloss: 0.136849\n",
            "[140]\ttraining's auc: 0.885201\ttraining's binary_logloss: 0.122462\tvalid_1's auc: 0.829484\tvalid_1's binary_logloss: 0.136834\n",
            "[141]\ttraining's auc: 0.885386\ttraining's binary_logloss: 0.122373\tvalid_1's auc: 0.829527\tvalid_1's binary_logloss: 0.136812\n",
            "[142]\ttraining's auc: 0.885618\ttraining's binary_logloss: 0.122287\tvalid_1's auc: 0.829481\tvalid_1's binary_logloss: 0.136796\n",
            "[143]\ttraining's auc: 0.885811\ttraining's binary_logloss: 0.122193\tvalid_1's auc: 0.829629\tvalid_1's binary_logloss: 0.136769\n",
            "[144]\ttraining's auc: 0.886248\ttraining's binary_logloss: 0.122079\tvalid_1's auc: 0.829605\tvalid_1's binary_logloss: 0.136756\n",
            "[145]\ttraining's auc: 0.886511\ttraining's binary_logloss: 0.12198\tvalid_1's auc: 0.829601\tvalid_1's binary_logloss: 0.136739\n",
            "[146]\ttraining's auc: 0.886741\ttraining's binary_logloss: 0.121885\tvalid_1's auc: 0.82954\tvalid_1's binary_logloss: 0.136716\n",
            "[147]\ttraining's auc: 0.887045\ttraining's binary_logloss: 0.121782\tvalid_1's auc: 0.829539\tvalid_1's binary_logloss: 0.136706\n",
            "[148]\ttraining's auc: 0.887272\ttraining's binary_logloss: 0.121693\tvalid_1's auc: 0.829599\tvalid_1's binary_logloss: 0.136678\n",
            "[149]\ttraining's auc: 0.887542\ttraining's binary_logloss: 0.121594\tvalid_1's auc: 0.829619\tvalid_1's binary_logloss: 0.136666\n",
            "[150]\ttraining's auc: 0.887759\ttraining's binary_logloss: 0.121501\tvalid_1's auc: 0.829591\tvalid_1's binary_logloss: 0.136657\n",
            "[151]\ttraining's auc: 0.887916\ttraining's binary_logloss: 0.12142\tvalid_1's auc: 0.829551\tvalid_1's binary_logloss: 0.136639\n",
            "[152]\ttraining's auc: 0.888286\ttraining's binary_logloss: 0.121329\tvalid_1's auc: 0.829722\tvalid_1's binary_logloss: 0.136611\n",
            "[153]\ttraining's auc: 0.888398\ttraining's binary_logloss: 0.121251\tvalid_1's auc: 0.8297\tvalid_1's binary_logloss: 0.136594\n",
            "[154]\ttraining's auc: 0.888627\ttraining's binary_logloss: 0.121163\tvalid_1's auc: 0.829772\tvalid_1's binary_logloss: 0.136583\n",
            "[155]\ttraining's auc: 0.888735\ttraining's binary_logloss: 0.12108\tvalid_1's auc: 0.82979\tvalid_1's binary_logloss: 0.136558\n",
            "[156]\ttraining's auc: 0.8889\ttraining's binary_logloss: 0.121003\tvalid_1's auc: 0.829727\tvalid_1's binary_logloss: 0.136541\n",
            "[157]\ttraining's auc: 0.889063\ttraining's binary_logloss: 0.12092\tvalid_1's auc: 0.82982\tvalid_1's binary_logloss: 0.136531\n",
            "[158]\ttraining's auc: 0.889462\ttraining's binary_logloss: 0.120823\tvalid_1's auc: 0.829793\tvalid_1's binary_logloss: 0.136513\n",
            "[159]\ttraining's auc: 0.889803\ttraining's binary_logloss: 0.120744\tvalid_1's auc: 0.829943\tvalid_1's binary_logloss: 0.1365\n",
            "[160]\ttraining's auc: 0.89007\ttraining's binary_logloss: 0.120645\tvalid_1's auc: 0.830114\tvalid_1's binary_logloss: 0.136467\n",
            "[161]\ttraining's auc: 0.890213\ttraining's binary_logloss: 0.12057\tvalid_1's auc: 0.830116\tvalid_1's binary_logloss: 0.136456\n",
            "[162]\ttraining's auc: 0.890308\ttraining's binary_logloss: 0.120497\tvalid_1's auc: 0.830117\tvalid_1's binary_logloss: 0.136439\n",
            "[163]\ttraining's auc: 0.890478\ttraining's binary_logloss: 0.12042\tvalid_1's auc: 0.830131\tvalid_1's binary_logloss: 0.136431\n",
            "[164]\ttraining's auc: 0.890812\ttraining's binary_logloss: 0.120331\tvalid_1's auc: 0.830184\tvalid_1's binary_logloss: 0.136414\n",
            "[165]\ttraining's auc: 0.890935\ttraining's binary_logloss: 0.12026\tvalid_1's auc: 0.830222\tvalid_1's binary_logloss: 0.136399\n",
            "[166]\ttraining's auc: 0.891047\ttraining's binary_logloss: 0.120188\tvalid_1's auc: 0.830322\tvalid_1's binary_logloss: 0.136386\n",
            "[167]\ttraining's auc: 0.891463\ttraining's binary_logloss: 0.120098\tvalid_1's auc: 0.830298\tvalid_1's binary_logloss: 0.136365\n",
            "[168]\ttraining's auc: 0.891667\ttraining's binary_logloss: 0.120027\tvalid_1's auc: 0.830316\tvalid_1's binary_logloss: 0.136359\n",
            "[169]\ttraining's auc: 0.892005\ttraining's binary_logloss: 0.119939\tvalid_1's auc: 0.830351\tvalid_1's binary_logloss: 0.136328\n",
            "[170]\ttraining's auc: 0.89217\ttraining's binary_logloss: 0.119866\tvalid_1's auc: 0.830372\tvalid_1's binary_logloss: 0.136315\n",
            "[171]\ttraining's auc: 0.892315\ttraining's binary_logloss: 0.119795\tvalid_1's auc: 0.830337\tvalid_1's binary_logloss: 0.136308\n",
            "[172]\ttraining's auc: 0.892614\ttraining's binary_logloss: 0.119712\tvalid_1's auc: 0.830441\tvalid_1's binary_logloss: 0.136284\n",
            "[173]\ttraining's auc: 0.892705\ttraining's binary_logloss: 0.119646\tvalid_1's auc: 0.830447\tvalid_1's binary_logloss: 0.13627\n",
            "[174]\ttraining's auc: 0.892885\ttraining's binary_logloss: 0.119574\tvalid_1's auc: 0.830518\tvalid_1's binary_logloss: 0.13626\n",
            "[175]\ttraining's auc: 0.893094\ttraining's binary_logloss: 0.119493\tvalid_1's auc: 0.830599\tvalid_1's binary_logloss: 0.136236\n",
            "[176]\ttraining's auc: 0.893184\ttraining's binary_logloss: 0.119424\tvalid_1's auc: 0.83054\tvalid_1's binary_logloss: 0.136225\n",
            "[177]\ttraining's auc: 0.89335\ttraining's binary_logloss: 0.119356\tvalid_1's auc: 0.830692\tvalid_1's binary_logloss: 0.13621\n",
            "[178]\ttraining's auc: 0.89349\ttraining's binary_logloss: 0.119291\tvalid_1's auc: 0.830749\tvalid_1's binary_logloss: 0.136198\n",
            "[179]\ttraining's auc: 0.893797\ttraining's binary_logloss: 0.119206\tvalid_1's auc: 0.8309\tvalid_1's binary_logloss: 0.136161\n",
            "[180]\ttraining's auc: 0.89392\ttraining's binary_logloss: 0.119133\tvalid_1's auc: 0.830807\tvalid_1's binary_logloss: 0.136166\n",
            "[181]\ttraining's auc: 0.894191\ttraining's binary_logloss: 0.119056\tvalid_1's auc: 0.830883\tvalid_1's binary_logloss: 0.136149\n",
            "[182]\ttraining's auc: 0.894296\ttraining's binary_logloss: 0.118988\tvalid_1's auc: 0.83086\tvalid_1's binary_logloss: 0.136132\n",
            "[183]\ttraining's auc: 0.894405\ttraining's binary_logloss: 0.118922\tvalid_1's auc: 0.830914\tvalid_1's binary_logloss: 0.136127\n",
            "[184]\ttraining's auc: 0.894617\ttraining's binary_logloss: 0.118848\tvalid_1's auc: 0.830998\tvalid_1's binary_logloss: 0.136108\n",
            "[185]\ttraining's auc: 0.894816\ttraining's binary_logloss: 0.118776\tvalid_1's auc: 0.831048\tvalid_1's binary_logloss: 0.136087\n",
            "[186]\ttraining's auc: 0.895058\ttraining's binary_logloss: 0.118705\tvalid_1's auc: 0.830977\tvalid_1's binary_logloss: 0.136078\n",
            "[187]\ttraining's auc: 0.895187\ttraining's binary_logloss: 0.118636\tvalid_1's auc: 0.831027\tvalid_1's binary_logloss: 0.136058\n",
            "[188]\ttraining's auc: 0.895322\ttraining's binary_logloss: 0.118568\tvalid_1's auc: 0.831068\tvalid_1's binary_logloss: 0.136041\n",
            "[189]\ttraining's auc: 0.895497\ttraining's binary_logloss: 0.118495\tvalid_1's auc: 0.831137\tvalid_1's binary_logloss: 0.136025\n",
            "[190]\ttraining's auc: 0.895725\ttraining's binary_logloss: 0.118429\tvalid_1's auc: 0.831135\tvalid_1's binary_logloss: 0.136017\n",
            "[191]\ttraining's auc: 0.895845\ttraining's binary_logloss: 0.118362\tvalid_1's auc: 0.831142\tvalid_1's binary_logloss: 0.136015\n",
            "[192]\ttraining's auc: 0.895969\ttraining's binary_logloss: 0.118294\tvalid_1's auc: 0.831089\tvalid_1's binary_logloss: 0.136013\n",
            "[193]\ttraining's auc: 0.896131\ttraining's binary_logloss: 0.118226\tvalid_1's auc: 0.831181\tvalid_1's binary_logloss: 0.135995\n",
            "[194]\ttraining's auc: 0.896257\ttraining's binary_logloss: 0.118157\tvalid_1's auc: 0.831191\tvalid_1's binary_logloss: 0.135994\n",
            "[195]\ttraining's auc: 0.896615\ttraining's binary_logloss: 0.118081\tvalid_1's auc: 0.831338\tvalid_1's binary_logloss: 0.135965\n",
            "[196]\ttraining's auc: 0.896767\ttraining's binary_logloss: 0.118011\tvalid_1's auc: 0.831346\tvalid_1's binary_logloss: 0.135962\n",
            "[197]\ttraining's auc: 0.897082\ttraining's binary_logloss: 0.117939\tvalid_1's auc: 0.831376\tvalid_1's binary_logloss: 0.135949\n",
            "[198]\ttraining's auc: 0.897355\ttraining's binary_logloss: 0.11787\tvalid_1's auc: 0.831523\tvalid_1's binary_logloss: 0.135925\n",
            "[199]\ttraining's auc: 0.897494\ttraining's binary_logloss: 0.11781\tvalid_1's auc: 0.831494\tvalid_1's binary_logloss: 0.135925\n",
            "[200]\ttraining's auc: 0.897612\ttraining's binary_logloss: 0.117748\tvalid_1's auc: 0.831405\tvalid_1's binary_logloss: 0.135932\n",
            "[201]\ttraining's auc: 0.897738\ttraining's binary_logloss: 0.117682\tvalid_1's auc: 0.831289\tvalid_1's binary_logloss: 0.13594\n",
            "[202]\ttraining's auc: 0.89798\ttraining's binary_logloss: 0.11762\tvalid_1's auc: 0.831301\tvalid_1's binary_logloss: 0.135927\n",
            "[203]\ttraining's auc: 0.898177\ttraining's binary_logloss: 0.117556\tvalid_1's auc: 0.831258\tvalid_1's binary_logloss: 0.135927\n",
            "[204]\ttraining's auc: 0.898346\ttraining's binary_logloss: 0.117493\tvalid_1's auc: 0.831269\tvalid_1's binary_logloss: 0.13593\n",
            "[205]\ttraining's auc: 0.898494\ttraining's binary_logloss: 0.117426\tvalid_1's auc: 0.83123\tvalid_1's binary_logloss: 0.135927\n",
            "[206]\ttraining's auc: 0.898661\ttraining's binary_logloss: 0.117364\tvalid_1's auc: 0.831257\tvalid_1's binary_logloss: 0.135922\n",
            "[207]\ttraining's auc: 0.898745\ttraining's binary_logloss: 0.117305\tvalid_1's auc: 0.831181\tvalid_1's binary_logloss: 0.135932\n",
            "[208]\ttraining's auc: 0.898896\ttraining's binary_logloss: 0.117244\tvalid_1's auc: 0.83115\tvalid_1's binary_logloss: 0.135933\n",
            "[209]\ttraining's auc: 0.899178\ttraining's binary_logloss: 0.117179\tvalid_1's auc: 0.831308\tvalid_1's binary_logloss: 0.135912\n",
            "[210]\ttraining's auc: 0.899308\ttraining's binary_logloss: 0.117122\tvalid_1's auc: 0.831263\tvalid_1's binary_logloss: 0.135913\n",
            "[211]\ttraining's auc: 0.899464\ttraining's binary_logloss: 0.117059\tvalid_1's auc: 0.831316\tvalid_1's binary_logloss: 0.135911\n",
            "[212]\ttraining's auc: 0.899588\ttraining's binary_logloss: 0.116994\tvalid_1's auc: 0.831465\tvalid_1's binary_logloss: 0.135891\n",
            "[213]\ttraining's auc: 0.899697\ttraining's binary_logloss: 0.116937\tvalid_1's auc: 0.831461\tvalid_1's binary_logloss: 0.135887\n",
            "[214]\ttraining's auc: 0.89978\ttraining's binary_logloss: 0.116882\tvalid_1's auc: 0.831444\tvalid_1's binary_logloss: 0.135885\n",
            "[215]\ttraining's auc: 0.899969\ttraining's binary_logloss: 0.116825\tvalid_1's auc: 0.831368\tvalid_1's binary_logloss: 0.135892\n",
            "[216]\ttraining's auc: 0.900186\ttraining's binary_logloss: 0.116763\tvalid_1's auc: 0.831478\tvalid_1's binary_logloss: 0.135873\n",
            "[217]\ttraining's auc: 0.900583\ttraining's binary_logloss: 0.116688\tvalid_1's auc: 0.831477\tvalid_1's binary_logloss: 0.135861\n",
            "[218]\ttraining's auc: 0.900744\ttraining's binary_logloss: 0.116631\tvalid_1's auc: 0.83143\tvalid_1's binary_logloss: 0.135863\n",
            "[219]\ttraining's auc: 0.900984\ttraining's binary_logloss: 0.116569\tvalid_1's auc: 0.831477\tvalid_1's binary_logloss: 0.135847\n",
            "[220]\ttraining's auc: 0.901131\ttraining's binary_logloss: 0.116514\tvalid_1's auc: 0.831448\tvalid_1's binary_logloss: 0.135845\n",
            "[221]\ttraining's auc: 0.901314\ttraining's binary_logloss: 0.116458\tvalid_1's auc: 0.83146\tvalid_1's binary_logloss: 0.135837\n",
            "[222]\ttraining's auc: 0.901456\ttraining's binary_logloss: 0.116393\tvalid_1's auc: 0.83144\tvalid_1's binary_logloss: 0.135842\n",
            "[223]\ttraining's auc: 0.901597\ttraining's binary_logloss: 0.116337\tvalid_1's auc: 0.831479\tvalid_1's binary_logloss: 0.135826\n",
            "[224]\ttraining's auc: 0.901825\ttraining's binary_logloss: 0.11626\tvalid_1's auc: 0.831494\tvalid_1's binary_logloss: 0.135828\n",
            "[225]\ttraining's auc: 0.90195\ttraining's binary_logloss: 0.116209\tvalid_1's auc: 0.831446\tvalid_1's binary_logloss: 0.135831\n",
            "[226]\ttraining's auc: 0.902051\ttraining's binary_logloss: 0.116155\tvalid_1's auc: 0.831358\tvalid_1's binary_logloss: 0.135836\n",
            "[227]\ttraining's auc: 0.90221\ttraining's binary_logloss: 0.116106\tvalid_1's auc: 0.831328\tvalid_1's binary_logloss: 0.135844\n",
            "[228]\ttraining's auc: 0.902392\ttraining's binary_logloss: 0.116049\tvalid_1's auc: 0.831364\tvalid_1's binary_logloss: 0.13583\n",
            " 58%|█████▊    | 29/50 [14:45<12:04, 34.49s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.165533\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.159643\n",
            "[2]\ttraining's auc: 0.819273\ttraining's binary_logloss: 0.164247\tvalid_1's auc: 0.802595\tvalid_1's binary_logloss: 0.158613\n",
            "[3]\ttraining's auc: 0.82201\ttraining's binary_logloss: 0.163055\tvalid_1's auc: 0.804735\tvalid_1's binary_logloss: 0.157639\n",
            "[4]\ttraining's auc: 0.823228\ttraining's binary_logloss: 0.161926\tvalid_1's auc: 0.805231\tvalid_1's binary_logloss: 0.156725\n",
            "[5]\ttraining's auc: 0.823695\ttraining's binary_logloss: 0.160854\tvalid_1's auc: 0.805756\tvalid_1's binary_logloss: 0.155878\n",
            "[6]\ttraining's auc: 0.829511\ttraining's binary_logloss: 0.159842\tvalid_1's auc: 0.816813\tvalid_1's binary_logloss: 0.155049\n",
            "[7]\ttraining's auc: 0.830426\ttraining's binary_logloss: 0.158868\tvalid_1's auc: 0.816828\tvalid_1's binary_logloss: 0.154298\n",
            "[8]\ttraining's auc: 0.832034\ttraining's binary_logloss: 0.157945\tvalid_1's auc: 0.818158\tvalid_1's binary_logloss: 0.153546\n",
            "[9]\ttraining's auc: 0.83329\ttraining's binary_logloss: 0.15705\tvalid_1's auc: 0.818826\tvalid_1's binary_logloss: 0.152853\n",
            "[10]\ttraining's auc: 0.834233\ttraining's binary_logloss: 0.156212\tvalid_1's auc: 0.819035\tvalid_1's binary_logloss: 0.152184\n",
            "[11]\ttraining's auc: 0.8344\ttraining's binary_logloss: 0.155419\tvalid_1's auc: 0.819182\tvalid_1's binary_logloss: 0.151554\n",
            "[12]\ttraining's auc: 0.834758\ttraining's binary_logloss: 0.154666\tvalid_1's auc: 0.819342\tvalid_1's binary_logloss: 0.150951\n",
            "[13]\ttraining's auc: 0.835407\ttraining's binary_logloss: 0.153924\tvalid_1's auc: 0.819395\tvalid_1's binary_logloss: 0.150365\n",
            "[14]\ttraining's auc: 0.8359\ttraining's binary_logloss: 0.153215\tvalid_1's auc: 0.819571\tvalid_1's binary_logloss: 0.149825\n",
            "[15]\ttraining's auc: 0.837022\ttraining's binary_logloss: 0.152543\tvalid_1's auc: 0.820147\tvalid_1's binary_logloss: 0.149308\n",
            "[16]\ttraining's auc: 0.837295\ttraining's binary_logloss: 0.151897\tvalid_1's auc: 0.820643\tvalid_1's binary_logloss: 0.148792\n",
            "[17]\ttraining's auc: 0.837654\ttraining's binary_logloss: 0.15127\tvalid_1's auc: 0.820883\tvalid_1's binary_logloss: 0.148308\n",
            "[18]\ttraining's auc: 0.837842\ttraining's binary_logloss: 0.150675\tvalid_1's auc: 0.820819\tvalid_1's binary_logloss: 0.147849\n",
            "[19]\ttraining's auc: 0.840769\ttraining's binary_logloss: 0.150083\tvalid_1's auc: 0.823259\tvalid_1's binary_logloss: 0.147408\n",
            "[20]\ttraining's auc: 0.841133\ttraining's binary_logloss: 0.149519\tvalid_1's auc: 0.82327\tvalid_1's binary_logloss: 0.146986\n",
            "[21]\ttraining's auc: 0.841518\ttraining's binary_logloss: 0.148971\tvalid_1's auc: 0.823295\tvalid_1's binary_logloss: 0.146574\n",
            "[22]\ttraining's auc: 0.841702\ttraining's binary_logloss: 0.148446\tvalid_1's auc: 0.823292\tvalid_1's binary_logloss: 0.146188\n",
            "[23]\ttraining's auc: 0.84343\ttraining's binary_logloss: 0.147923\tvalid_1's auc: 0.824454\tvalid_1's binary_logloss: 0.145787\n",
            "[24]\ttraining's auc: 0.844018\ttraining's binary_logloss: 0.147424\tvalid_1's auc: 0.824436\tvalid_1's binary_logloss: 0.145407\n",
            "[25]\ttraining's auc: 0.844445\ttraining's binary_logloss: 0.146941\tvalid_1's auc: 0.824871\tvalid_1's binary_logloss: 0.145051\n",
            "[26]\ttraining's auc: 0.846861\ttraining's binary_logloss: 0.146455\tvalid_1's auc: 0.827259\tvalid_1's binary_logloss: 0.144698\n",
            "[27]\ttraining's auc: 0.848171\ttraining's binary_logloss: 0.145985\tvalid_1's auc: 0.827858\tvalid_1's binary_logloss: 0.144356\n",
            "[28]\ttraining's auc: 0.849058\ttraining's binary_logloss: 0.145535\tvalid_1's auc: 0.82797\tvalid_1's binary_logloss: 0.144021\n",
            "[29]\ttraining's auc: 0.849225\ttraining's binary_logloss: 0.145094\tvalid_1's auc: 0.8285\tvalid_1's binary_logloss: 0.143696\n",
            "[30]\ttraining's auc: 0.849674\ttraining's binary_logloss: 0.144672\tvalid_1's auc: 0.828635\tvalid_1's binary_logloss: 0.143387\n",
            "[31]\ttraining's auc: 0.849744\ttraining's binary_logloss: 0.144262\tvalid_1's auc: 0.828752\tvalid_1's binary_logloss: 0.143085\n",
            "[32]\ttraining's auc: 0.850729\ttraining's binary_logloss: 0.143847\tvalid_1's auc: 0.828688\tvalid_1's binary_logloss: 0.142804\n",
            "[33]\ttraining's auc: 0.851173\ttraining's binary_logloss: 0.143457\tvalid_1's auc: 0.829081\tvalid_1's binary_logloss: 0.142514\n",
            "[34]\ttraining's auc: 0.851649\ttraining's binary_logloss: 0.143078\tvalid_1's auc: 0.829665\tvalid_1's binary_logloss: 0.142225\n",
            "[35]\ttraining's auc: 0.852017\ttraining's binary_logloss: 0.14271\tvalid_1's auc: 0.829645\tvalid_1's binary_logloss: 0.141955\n",
            "[36]\ttraining's auc: 0.852347\ttraining's binary_logloss: 0.142355\tvalid_1's auc: 0.830036\tvalid_1's binary_logloss: 0.141684\n",
            "[37]\ttraining's auc: 0.852818\ttraining's binary_logloss: 0.141995\tvalid_1's auc: 0.830178\tvalid_1's binary_logloss: 0.141423\n",
            "[38]\ttraining's auc: 0.854076\ttraining's binary_logloss: 0.141645\tvalid_1's auc: 0.830113\tvalid_1's binary_logloss: 0.141174\n",
            "[39]\ttraining's auc: 0.854403\ttraining's binary_logloss: 0.141293\tvalid_1's auc: 0.830177\tvalid_1's binary_logloss: 0.140914\n",
            "[40]\ttraining's auc: 0.855207\ttraining's binary_logloss: 0.14096\tvalid_1's auc: 0.830276\tvalid_1's binary_logloss: 0.140662\n",
            "[41]\ttraining's auc: 0.855845\ttraining's binary_logloss: 0.140631\tvalid_1's auc: 0.830209\tvalid_1's binary_logloss: 0.140429\n",
            "[42]\ttraining's auc: 0.85642\ttraining's binary_logloss: 0.140314\tvalid_1's auc: 0.831138\tvalid_1's binary_logloss: 0.140181\n",
            "[43]\ttraining's auc: 0.856839\ttraining's binary_logloss: 0.140004\tvalid_1's auc: 0.831255\tvalid_1's binary_logloss: 0.139954\n",
            "[44]\ttraining's auc: 0.857589\ttraining's binary_logloss: 0.139701\tvalid_1's auc: 0.832782\tvalid_1's binary_logloss: 0.139721\n",
            "[45]\ttraining's auc: 0.857914\ttraining's binary_logloss: 0.139403\tvalid_1's auc: 0.832769\tvalid_1's binary_logloss: 0.13952\n",
            "[46]\ttraining's auc: 0.858141\ttraining's binary_logloss: 0.139116\tvalid_1's auc: 0.832618\tvalid_1's binary_logloss: 0.139324\n",
            "[47]\ttraining's auc: 0.858481\ttraining's binary_logloss: 0.13884\tvalid_1's auc: 0.832727\tvalid_1's binary_logloss: 0.139118\n",
            "[48]\ttraining's auc: 0.858914\ttraining's binary_logloss: 0.138565\tvalid_1's auc: 0.832648\tvalid_1's binary_logloss: 0.138919\n",
            "[49]\ttraining's auc: 0.859146\ttraining's binary_logloss: 0.138287\tvalid_1's auc: 0.832734\tvalid_1's binary_logloss: 0.138732\n",
            "[50]\ttraining's auc: 0.859442\ttraining's binary_logloss: 0.138014\tvalid_1's auc: 0.832928\tvalid_1's binary_logloss: 0.138548\n",
            "[51]\ttraining's auc: 0.859547\ttraining's binary_logloss: 0.137749\tvalid_1's auc: 0.83295\tvalid_1's binary_logloss: 0.138369\n",
            "[52]\ttraining's auc: 0.860005\ttraining's binary_logloss: 0.137486\tvalid_1's auc: 0.832952\tvalid_1's binary_logloss: 0.138197\n",
            "[53]\ttraining's auc: 0.860208\ttraining's binary_logloss: 0.137238\tvalid_1's auc: 0.83284\tvalid_1's binary_logloss: 0.138027\n",
            "[54]\ttraining's auc: 0.861423\ttraining's binary_logloss: 0.136991\tvalid_1's auc: 0.833505\tvalid_1's binary_logloss: 0.137864\n",
            "[55]\ttraining's auc: 0.861581\ttraining's binary_logloss: 0.136742\tvalid_1's auc: 0.833429\tvalid_1's binary_logloss: 0.137691\n",
            "[56]\ttraining's auc: 0.861819\ttraining's binary_logloss: 0.13651\tvalid_1's auc: 0.833591\tvalid_1's binary_logloss: 0.137536\n",
            "[57]\ttraining's auc: 0.861873\ttraining's binary_logloss: 0.136276\tvalid_1's auc: 0.833495\tvalid_1's binary_logloss: 0.137378\n",
            "[58]\ttraining's auc: 0.862253\ttraining's binary_logloss: 0.13604\tvalid_1's auc: 0.833476\tvalid_1's binary_logloss: 0.137227\n",
            "[59]\ttraining's auc: 0.862804\ttraining's binary_logloss: 0.135809\tvalid_1's auc: 0.833522\tvalid_1's binary_logloss: 0.137059\n",
            "[60]\ttraining's auc: 0.863078\ttraining's binary_logloss: 0.13558\tvalid_1's auc: 0.833413\tvalid_1's binary_logloss: 0.136928\n",
            "[61]\ttraining's auc: 0.863354\ttraining's binary_logloss: 0.135348\tvalid_1's auc: 0.833636\tvalid_1's binary_logloss: 0.136791\n",
            "[62]\ttraining's auc: 0.863525\ttraining's binary_logloss: 0.135132\tvalid_1's auc: 0.833715\tvalid_1's binary_logloss: 0.136651\n",
            "[63]\ttraining's auc: 0.863831\ttraining's binary_logloss: 0.134919\tvalid_1's auc: 0.833758\tvalid_1's binary_logloss: 0.13651\n",
            "[64]\ttraining's auc: 0.864076\ttraining's binary_logloss: 0.134703\tvalid_1's auc: 0.83362\tvalid_1's binary_logloss: 0.136386\n",
            "[65]\ttraining's auc: 0.864964\ttraining's binary_logloss: 0.134485\tvalid_1's auc: 0.834021\tvalid_1's binary_logloss: 0.136249\n",
            "[66]\ttraining's auc: 0.865691\ttraining's binary_logloss: 0.134269\tvalid_1's auc: 0.833947\tvalid_1's binary_logloss: 0.136131\n",
            "[67]\ttraining's auc: 0.866355\ttraining's binary_logloss: 0.134065\tvalid_1's auc: 0.834063\tvalid_1's binary_logloss: 0.136014\n",
            "[68]\ttraining's auc: 0.866672\ttraining's binary_logloss: 0.133866\tvalid_1's auc: 0.834188\tvalid_1's binary_logloss: 0.135905\n",
            "[69]\ttraining's auc: 0.867026\ttraining's binary_logloss: 0.133669\tvalid_1's auc: 0.83404\tvalid_1's binary_logloss: 0.135804\n",
            "[70]\ttraining's auc: 0.867625\ttraining's binary_logloss: 0.133469\tvalid_1's auc: 0.834329\tvalid_1's binary_logloss: 0.135681\n",
            "[71]\ttraining's auc: 0.867901\ttraining's binary_logloss: 0.133277\tvalid_1's auc: 0.834169\tvalid_1's binary_logloss: 0.135572\n",
            "[72]\ttraining's auc: 0.868225\ttraining's binary_logloss: 0.133088\tvalid_1's auc: 0.834249\tvalid_1's binary_logloss: 0.135468\n",
            "[73]\ttraining's auc: 0.868727\ttraining's binary_logloss: 0.132894\tvalid_1's auc: 0.834381\tvalid_1's binary_logloss: 0.135372\n",
            "[74]\ttraining's auc: 0.868928\ttraining's binary_logloss: 0.132716\tvalid_1's auc: 0.834427\tvalid_1's binary_logloss: 0.135262\n",
            "[75]\ttraining's auc: 0.869451\ttraining's binary_logloss: 0.13254\tvalid_1's auc: 0.834589\tvalid_1's binary_logloss: 0.135171\n",
            "[76]\ttraining's auc: 0.869769\ttraining's binary_logloss: 0.132357\tvalid_1's auc: 0.834717\tvalid_1's binary_logloss: 0.135072\n",
            "[77]\ttraining's auc: 0.869983\ttraining's binary_logloss: 0.132186\tvalid_1's auc: 0.834613\tvalid_1's binary_logloss: 0.134995\n",
            "[78]\ttraining's auc: 0.870492\ttraining's binary_logloss: 0.132007\tvalid_1's auc: 0.834606\tvalid_1's binary_logloss: 0.134906\n",
            "[79]\ttraining's auc: 0.870717\ttraining's binary_logloss: 0.131838\tvalid_1's auc: 0.834554\tvalid_1's binary_logloss: 0.134814\n",
            "[80]\ttraining's auc: 0.870886\ttraining's binary_logloss: 0.131675\tvalid_1's auc: 0.834554\tvalid_1's binary_logloss: 0.134737\n",
            "[81]\ttraining's auc: 0.87122\ttraining's binary_logloss: 0.131504\tvalid_1's auc: 0.834404\tvalid_1's binary_logloss: 0.134667\n",
            "[82]\ttraining's auc: 0.871398\ttraining's binary_logloss: 0.131348\tvalid_1's auc: 0.834396\tvalid_1's binary_logloss: 0.134584\n",
            "[83]\ttraining's auc: 0.87171\ttraining's binary_logloss: 0.131176\tvalid_1's auc: 0.834541\tvalid_1's binary_logloss: 0.134498\n",
            "[84]\ttraining's auc: 0.871901\ttraining's binary_logloss: 0.131017\tvalid_1's auc: 0.834555\tvalid_1's binary_logloss: 0.13442\n",
            "[85]\ttraining's auc: 0.872108\ttraining's binary_logloss: 0.130858\tvalid_1's auc: 0.834497\tvalid_1's binary_logloss: 0.134349\n",
            "[86]\ttraining's auc: 0.872259\ttraining's binary_logloss: 0.130708\tvalid_1's auc: 0.834512\tvalid_1's binary_logloss: 0.134268\n",
            "[87]\ttraining's auc: 0.872491\ttraining's binary_logloss: 0.130555\tvalid_1's auc: 0.834467\tvalid_1's binary_logloss: 0.134203\n",
            "[88]\ttraining's auc: 0.872718\ttraining's binary_logloss: 0.130405\tvalid_1's auc: 0.834379\tvalid_1's binary_logloss: 0.134142\n",
            "[89]\ttraining's auc: 0.872956\ttraining's binary_logloss: 0.130257\tvalid_1's auc: 0.834369\tvalid_1's binary_logloss: 0.134077\n",
            "[90]\ttraining's auc: 0.873118\ttraining's binary_logloss: 0.130116\tvalid_1's auc: 0.8343\tvalid_1's binary_logloss: 0.134014\n",
            "[91]\ttraining's auc: 0.873299\ttraining's binary_logloss: 0.129974\tvalid_1's auc: 0.834199\tvalid_1's binary_logloss: 0.133957\n",
            "[92]\ttraining's auc: 0.873447\ttraining's binary_logloss: 0.129834\tvalid_1's auc: 0.834287\tvalid_1's binary_logloss: 0.133902\n",
            "[93]\ttraining's auc: 0.87362\ttraining's binary_logloss: 0.129699\tvalid_1's auc: 0.834226\tvalid_1's binary_logloss: 0.133844\n",
            "[94]\ttraining's auc: 0.873753\ttraining's binary_logloss: 0.129565\tvalid_1's auc: 0.834317\tvalid_1's binary_logloss: 0.133771\n",
            "[95]\ttraining's auc: 0.873932\ttraining's binary_logloss: 0.129429\tvalid_1's auc: 0.834281\tvalid_1's binary_logloss: 0.1337\n",
            "[96]\ttraining's auc: 0.874025\ttraining's binary_logloss: 0.129299\tvalid_1's auc: 0.834238\tvalid_1's binary_logloss: 0.133648\n",
            "[97]\ttraining's auc: 0.874237\ttraining's binary_logloss: 0.129169\tvalid_1's auc: 0.83426\tvalid_1's binary_logloss: 0.133594\n",
            "[98]\ttraining's auc: 0.874473\ttraining's binary_logloss: 0.129032\tvalid_1's auc: 0.834225\tvalid_1's binary_logloss: 0.133542\n",
            "[99]\ttraining's auc: 0.874508\ttraining's binary_logloss: 0.128907\tvalid_1's auc: 0.834107\tvalid_1's binary_logloss: 0.133491\n",
            "[100]\ttraining's auc: 0.87475\ttraining's binary_logloss: 0.128773\tvalid_1's auc: 0.834113\tvalid_1's binary_logloss: 0.133439\n",
            "[101]\ttraining's auc: 0.874798\ttraining's binary_logloss: 0.128651\tvalid_1's auc: 0.834153\tvalid_1's binary_logloss: 0.133388\n",
            "[102]\ttraining's auc: 0.874925\ttraining's binary_logloss: 0.128525\tvalid_1's auc: 0.834216\tvalid_1's binary_logloss: 0.133338\n",
            "[103]\ttraining's auc: 0.875075\ttraining's binary_logloss: 0.128399\tvalid_1's auc: 0.834201\tvalid_1's binary_logloss: 0.133289\n",
            "[104]\ttraining's auc: 0.875356\ttraining's binary_logloss: 0.128281\tvalid_1's auc: 0.834256\tvalid_1's binary_logloss: 0.133234\n",
            "[105]\ttraining's auc: 0.875443\ttraining's binary_logloss: 0.128164\tvalid_1's auc: 0.834213\tvalid_1's binary_logloss: 0.133183\n",
            "[106]\ttraining's auc: 0.875675\ttraining's binary_logloss: 0.128047\tvalid_1's auc: 0.834179\tvalid_1's binary_logloss: 0.133132\n",
            " 58%|█████▊    | 29/50 [14:56<12:04, 34.49s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.161753\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.167279\n",
            "[2]\ttraining's auc: 0.827205\ttraining's binary_logloss: 0.160527\tvalid_1's auc: 0.811332\tvalid_1's binary_logloss: 0.166144\n",
            "[3]\ttraining's auc: 0.831122\ttraining's binary_logloss: 0.15936\tvalid_1's auc: 0.815258\tvalid_1's binary_logloss: 0.165073\n",
            "[4]\ttraining's auc: 0.831109\ttraining's binary_logloss: 0.158278\tvalid_1's auc: 0.815366\tvalid_1's binary_logloss: 0.164086\n",
            "[5]\ttraining's auc: 0.832055\ttraining's binary_logloss: 0.157263\tvalid_1's auc: 0.815971\tvalid_1's binary_logloss: 0.163182\n",
            "[6]\ttraining's auc: 0.832609\ttraining's binary_logloss: 0.1563\tvalid_1's auc: 0.815899\tvalid_1's binary_logloss: 0.162321\n",
            "[7]\ttraining's auc: 0.833983\ttraining's binary_logloss: 0.155381\tvalid_1's auc: 0.816933\tvalid_1's binary_logloss: 0.161473\n",
            "[8]\ttraining's auc: 0.834274\ttraining's binary_logloss: 0.154512\tvalid_1's auc: 0.816579\tvalid_1's binary_logloss: 0.160684\n",
            "[9]\ttraining's auc: 0.834767\ttraining's binary_logloss: 0.153682\tvalid_1's auc: 0.817282\tvalid_1's binary_logloss: 0.159964\n",
            "[10]\ttraining's auc: 0.835337\ttraining's binary_logloss: 0.152882\tvalid_1's auc: 0.817289\tvalid_1's binary_logloss: 0.159264\n",
            "[11]\ttraining's auc: 0.836949\ttraining's binary_logloss: 0.152124\tvalid_1's auc: 0.818195\tvalid_1's binary_logloss: 0.158583\n",
            "[12]\ttraining's auc: 0.837835\ttraining's binary_logloss: 0.151378\tvalid_1's auc: 0.818738\tvalid_1's binary_logloss: 0.157907\n",
            "[13]\ttraining's auc: 0.838215\ttraining's binary_logloss: 0.150685\tvalid_1's auc: 0.818551\tvalid_1's binary_logloss: 0.157308\n",
            "[14]\ttraining's auc: 0.838396\ttraining's binary_logloss: 0.150021\tvalid_1's auc: 0.818741\tvalid_1's binary_logloss: 0.156695\n",
            "[15]\ttraining's auc: 0.839073\ttraining's binary_logloss: 0.149357\tvalid_1's auc: 0.819406\tvalid_1's binary_logloss: 0.15612\n",
            "[16]\ttraining's auc: 0.839429\ttraining's binary_logloss: 0.14874\tvalid_1's auc: 0.819251\tvalid_1's binary_logloss: 0.155581\n",
            "[17]\ttraining's auc: 0.841908\ttraining's binary_logloss: 0.148137\tvalid_1's auc: 0.820301\tvalid_1's binary_logloss: 0.155033\n",
            "[18]\ttraining's auc: 0.84254\ttraining's binary_logloss: 0.147548\tvalid_1's auc: 0.820586\tvalid_1's binary_logloss: 0.154533\n",
            "[19]\ttraining's auc: 0.842834\ttraining's binary_logloss: 0.146983\tvalid_1's auc: 0.821001\tvalid_1's binary_logloss: 0.154045\n",
            "[20]\ttraining's auc: 0.846023\ttraining's binary_logloss: 0.1464\tvalid_1's auc: 0.82396\tvalid_1's binary_logloss: 0.153564\n",
            "[21]\ttraining's auc: 0.84752\ttraining's binary_logloss: 0.145847\tvalid_1's auc: 0.825298\tvalid_1's binary_logloss: 0.153095\n",
            "[22]\ttraining's auc: 0.848331\ttraining's binary_logloss: 0.145328\tvalid_1's auc: 0.825739\tvalid_1's binary_logloss: 0.152641\n",
            "[23]\ttraining's auc: 0.849054\ttraining's binary_logloss: 0.144816\tvalid_1's auc: 0.826495\tvalid_1's binary_logloss: 0.152203\n",
            "[24]\ttraining's auc: 0.849302\ttraining's binary_logloss: 0.144328\tvalid_1's auc: 0.826498\tvalid_1's binary_logloss: 0.151775\n",
            "[25]\ttraining's auc: 0.850074\ttraining's binary_logloss: 0.143854\tvalid_1's auc: 0.827116\tvalid_1's binary_logloss: 0.151376\n",
            "[26]\ttraining's auc: 0.850681\ttraining's binary_logloss: 0.143389\tvalid_1's auc: 0.827434\tvalid_1's binary_logloss: 0.150988\n",
            "[27]\ttraining's auc: 0.851072\ttraining's binary_logloss: 0.142946\tvalid_1's auc: 0.82764\tvalid_1's binary_logloss: 0.150614\n",
            "[28]\ttraining's auc: 0.851247\ttraining's binary_logloss: 0.142517\tvalid_1's auc: 0.827512\tvalid_1's binary_logloss: 0.150263\n",
            "[29]\ttraining's auc: 0.851561\ttraining's binary_logloss: 0.142107\tvalid_1's auc: 0.827636\tvalid_1's binary_logloss: 0.149918\n",
            "[30]\ttraining's auc: 0.851516\ttraining's binary_logloss: 0.141706\tvalid_1's auc: 0.827735\tvalid_1's binary_logloss: 0.149585\n",
            "[31]\ttraining's auc: 0.851856\ttraining's binary_logloss: 0.141306\tvalid_1's auc: 0.828265\tvalid_1's binary_logloss: 0.149244\n",
            "[32]\ttraining's auc: 0.852307\ttraining's binary_logloss: 0.140911\tvalid_1's auc: 0.828372\tvalid_1's binary_logloss: 0.148927\n",
            "[33]\ttraining's auc: 0.852375\ttraining's binary_logloss: 0.140504\tvalid_1's auc: 0.828536\tvalid_1's binary_logloss: 0.148622\n",
            "[34]\ttraining's auc: 0.852777\ttraining's binary_logloss: 0.140135\tvalid_1's auc: 0.828781\tvalid_1's binary_logloss: 0.148303\n",
            "[35]\ttraining's auc: 0.853122\ttraining's binary_logloss: 0.139758\tvalid_1's auc: 0.828578\tvalid_1's binary_logloss: 0.148004\n",
            "[36]\ttraining's auc: 0.853227\ttraining's binary_logloss: 0.139394\tvalid_1's auc: 0.828951\tvalid_1's binary_logloss: 0.147715\n",
            "[37]\ttraining's auc: 0.853538\ttraining's binary_logloss: 0.139031\tvalid_1's auc: 0.829005\tvalid_1's binary_logloss: 0.14743\n",
            "[38]\ttraining's auc: 0.853608\ttraining's binary_logloss: 0.138687\tvalid_1's auc: 0.828958\tvalid_1's binary_logloss: 0.147163\n",
            "[39]\ttraining's auc: 0.854089\ttraining's binary_logloss: 0.138357\tvalid_1's auc: 0.829491\tvalid_1's binary_logloss: 0.146906\n",
            "[40]\ttraining's auc: 0.854285\ttraining's binary_logloss: 0.13803\tvalid_1's auc: 0.829693\tvalid_1's binary_logloss: 0.146645\n",
            "[41]\ttraining's auc: 0.8545\ttraining's binary_logloss: 0.137706\tvalid_1's auc: 0.829829\tvalid_1's binary_logloss: 0.146411\n",
            "[42]\ttraining's auc: 0.855233\ttraining's binary_logloss: 0.137386\tvalid_1's auc: 0.830072\tvalid_1's binary_logloss: 0.146167\n",
            "[43]\ttraining's auc: 0.855597\ttraining's binary_logloss: 0.137077\tvalid_1's auc: 0.830096\tvalid_1's binary_logloss: 0.145932\n",
            "[44]\ttraining's auc: 0.856162\ttraining's binary_logloss: 0.136777\tvalid_1's auc: 0.830295\tvalid_1's binary_logloss: 0.145696\n",
            "[45]\ttraining's auc: 0.85632\ttraining's binary_logloss: 0.136485\tvalid_1's auc: 0.830386\tvalid_1's binary_logloss: 0.145482\n",
            "[46]\ttraining's auc: 0.85684\ttraining's binary_logloss: 0.136188\tvalid_1's auc: 0.830438\tvalid_1's binary_logloss: 0.145261\n",
            "[47]\ttraining's auc: 0.857143\ttraining's binary_logloss: 0.1359\tvalid_1's auc: 0.830693\tvalid_1's binary_logloss: 0.145042\n",
            "[48]\ttraining's auc: 0.857563\ttraining's binary_logloss: 0.135626\tvalid_1's auc: 0.830828\tvalid_1's binary_logloss: 0.144832\n",
            "[49]\ttraining's auc: 0.85788\ttraining's binary_logloss: 0.13536\tvalid_1's auc: 0.83106\tvalid_1's binary_logloss: 0.144623\n",
            "[50]\ttraining's auc: 0.858343\ttraining's binary_logloss: 0.135095\tvalid_1's auc: 0.830997\tvalid_1's binary_logloss: 0.144419\n",
            "[51]\ttraining's auc: 0.858744\ttraining's binary_logloss: 0.134836\tvalid_1's auc: 0.831016\tvalid_1's binary_logloss: 0.144224\n",
            "[52]\ttraining's auc: 0.858976\ttraining's binary_logloss: 0.134581\tvalid_1's auc: 0.831212\tvalid_1's binary_logloss: 0.144038\n",
            "[53]\ttraining's auc: 0.859042\ttraining's binary_logloss: 0.134338\tvalid_1's auc: 0.831154\tvalid_1's binary_logloss: 0.143856\n",
            "[54]\ttraining's auc: 0.85937\ttraining's binary_logloss: 0.1341\tvalid_1's auc: 0.831241\tvalid_1's binary_logloss: 0.143678\n",
            "[55]\ttraining's auc: 0.859442\ttraining's binary_logloss: 0.13387\tvalid_1's auc: 0.831293\tvalid_1's binary_logloss: 0.143508\n",
            "[56]\ttraining's auc: 0.859857\ttraining's binary_logloss: 0.13364\tvalid_1's auc: 0.831308\tvalid_1's binary_logloss: 0.143335\n",
            "[57]\ttraining's auc: 0.860521\ttraining's binary_logloss: 0.133415\tvalid_1's auc: 0.831341\tvalid_1's binary_logloss: 0.143171\n",
            "[58]\ttraining's auc: 0.861099\ttraining's binary_logloss: 0.133195\tvalid_1's auc: 0.831632\tvalid_1's binary_logloss: 0.143007\n",
            "[59]\ttraining's auc: 0.861437\ttraining's binary_logloss: 0.132973\tvalid_1's auc: 0.831713\tvalid_1's binary_logloss: 0.142856\n",
            "[60]\ttraining's auc: 0.861839\ttraining's binary_logloss: 0.132761\tvalid_1's auc: 0.831681\tvalid_1's binary_logloss: 0.142698\n",
            "[61]\ttraining's auc: 0.862443\ttraining's binary_logloss: 0.132544\tvalid_1's auc: 0.831928\tvalid_1's binary_logloss: 0.142553\n",
            "[62]\ttraining's auc: 0.862702\ttraining's binary_logloss: 0.132337\tvalid_1's auc: 0.83181\tvalid_1's binary_logloss: 0.142411\n",
            "[63]\ttraining's auc: 0.862992\ttraining's binary_logloss: 0.132124\tvalid_1's auc: 0.831724\tvalid_1's binary_logloss: 0.142284\n",
            "[64]\ttraining's auc: 0.86328\ttraining's binary_logloss: 0.131924\tvalid_1's auc: 0.831941\tvalid_1's binary_logloss: 0.142151\n",
            "[65]\ttraining's auc: 0.863534\ttraining's binary_logloss: 0.131728\tvalid_1's auc: 0.831991\tvalid_1's binary_logloss: 0.142016\n",
            "[66]\ttraining's auc: 0.864339\ttraining's binary_logloss: 0.131536\tvalid_1's auc: 0.832257\tvalid_1's binary_logloss: 0.141882\n",
            "[67]\ttraining's auc: 0.864628\ttraining's binary_logloss: 0.131338\tvalid_1's auc: 0.832281\tvalid_1's binary_logloss: 0.141759\n",
            "[68]\ttraining's auc: 0.864886\ttraining's binary_logloss: 0.131146\tvalid_1's auc: 0.83242\tvalid_1's binary_logloss: 0.141642\n",
            "[69]\ttraining's auc: 0.865041\ttraining's binary_logloss: 0.130968\tvalid_1's auc: 0.832315\tvalid_1's binary_logloss: 0.141539\n",
            "[70]\ttraining's auc: 0.865237\ttraining's binary_logloss: 0.130796\tvalid_1's auc: 0.832295\tvalid_1's binary_logloss: 0.141422\n",
            "[71]\ttraining's auc: 0.865523\ttraining's binary_logloss: 0.130615\tvalid_1's auc: 0.832296\tvalid_1's binary_logloss: 0.141311\n",
            "[72]\ttraining's auc: 0.865842\ttraining's binary_logloss: 0.130445\tvalid_1's auc: 0.832256\tvalid_1's binary_logloss: 0.141202\n",
            "[73]\ttraining's auc: 0.866483\ttraining's binary_logloss: 0.130264\tvalid_1's auc: 0.832219\tvalid_1's binary_logloss: 0.141095\n",
            "[74]\ttraining's auc: 0.867062\ttraining's binary_logloss: 0.130085\tvalid_1's auc: 0.832297\tvalid_1's binary_logloss: 0.14099\n",
            "[75]\ttraining's auc: 0.867417\ttraining's binary_logloss: 0.129903\tvalid_1's auc: 0.832443\tvalid_1's binary_logloss: 0.140875\n",
            "[76]\ttraining's auc: 0.867828\ttraining's binary_logloss: 0.129726\tvalid_1's auc: 0.832496\tvalid_1's binary_logloss: 0.140762\n",
            "[77]\ttraining's auc: 0.868184\ttraining's binary_logloss: 0.129564\tvalid_1's auc: 0.832426\tvalid_1's binary_logloss: 0.140668\n",
            "[78]\ttraining's auc: 0.868469\ttraining's binary_logloss: 0.129395\tvalid_1's auc: 0.832514\tvalid_1's binary_logloss: 0.140563\n",
            "[79]\ttraining's auc: 0.869009\ttraining's binary_logloss: 0.129221\tvalid_1's auc: 0.832461\tvalid_1's binary_logloss: 0.140483\n",
            "[80]\ttraining's auc: 0.86937\ttraining's binary_logloss: 0.129054\tvalid_1's auc: 0.832412\tvalid_1's binary_logloss: 0.140392\n",
            "[81]\ttraining's auc: 0.869641\ttraining's binary_logloss: 0.128894\tvalid_1's auc: 0.832452\tvalid_1's binary_logloss: 0.140309\n",
            "[82]\ttraining's auc: 0.870558\ttraining's binary_logloss: 0.128745\tvalid_1's auc: 0.83415\tvalid_1's binary_logloss: 0.140221\n",
            "[83]\ttraining's auc: 0.870896\ttraining's binary_logloss: 0.128591\tvalid_1's auc: 0.834188\tvalid_1's binary_logloss: 0.14014\n",
            "[84]\ttraining's auc: 0.871039\ttraining's binary_logloss: 0.128437\tvalid_1's auc: 0.834285\tvalid_1's binary_logloss: 0.14005\n",
            "[85]\ttraining's auc: 0.871317\ttraining's binary_logloss: 0.128285\tvalid_1's auc: 0.834334\tvalid_1's binary_logloss: 0.139976\n",
            "[86]\ttraining's auc: 0.871833\ttraining's binary_logloss: 0.128139\tvalid_1's auc: 0.834712\tvalid_1's binary_logloss: 0.139885\n",
            "[87]\ttraining's auc: 0.872109\ttraining's binary_logloss: 0.127988\tvalid_1's auc: 0.834686\tvalid_1's binary_logloss: 0.139807\n",
            "[88]\ttraining's auc: 0.872459\ttraining's binary_logloss: 0.127831\tvalid_1's auc: 0.834666\tvalid_1's binary_logloss: 0.139734\n",
            "[89]\ttraining's auc: 0.872756\ttraining's binary_logloss: 0.12768\tvalid_1's auc: 0.834656\tvalid_1's binary_logloss: 0.139658\n",
            "[90]\ttraining's auc: 0.87301\ttraining's binary_logloss: 0.127534\tvalid_1's auc: 0.834665\tvalid_1's binary_logloss: 0.139571\n",
            "[91]\ttraining's auc: 0.873196\ttraining's binary_logloss: 0.127394\tvalid_1's auc: 0.834687\tvalid_1's binary_logloss: 0.139496\n",
            "[92]\ttraining's auc: 0.873311\ttraining's binary_logloss: 0.127267\tvalid_1's auc: 0.834671\tvalid_1's binary_logloss: 0.139422\n",
            "[93]\ttraining's auc: 0.873773\ttraining's binary_logloss: 0.12713\tvalid_1's auc: 0.835063\tvalid_1's binary_logloss: 0.139345\n",
            "[94]\ttraining's auc: 0.874294\ttraining's binary_logloss: 0.126993\tvalid_1's auc: 0.835304\tvalid_1's binary_logloss: 0.13927\n",
            "[95]\ttraining's auc: 0.874493\ttraining's binary_logloss: 0.126857\tvalid_1's auc: 0.835359\tvalid_1's binary_logloss: 0.139204\n",
            "[96]\ttraining's auc: 0.87469\ttraining's binary_logloss: 0.12672\tvalid_1's auc: 0.835307\tvalid_1's binary_logloss: 0.139139\n",
            "[97]\ttraining's auc: 0.874803\ttraining's binary_logloss: 0.126591\tvalid_1's auc: 0.835359\tvalid_1's binary_logloss: 0.139072\n",
            "[98]\ttraining's auc: 0.875114\ttraining's binary_logloss: 0.126464\tvalid_1's auc: 0.835723\tvalid_1's binary_logloss: 0.138998\n",
            "[99]\ttraining's auc: 0.875351\ttraining's binary_logloss: 0.126338\tvalid_1's auc: 0.835693\tvalid_1's binary_logloss: 0.138945\n",
            "[100]\ttraining's auc: 0.875672\ttraining's binary_logloss: 0.126201\tvalid_1's auc: 0.835709\tvalid_1's binary_logloss: 0.138893\n",
            "[101]\ttraining's auc: 0.875792\ttraining's binary_logloss: 0.126082\tvalid_1's auc: 0.835558\tvalid_1's binary_logloss: 0.138836\n",
            "[102]\ttraining's auc: 0.876359\ttraining's binary_logloss: 0.125936\tvalid_1's auc: 0.83568\tvalid_1's binary_logloss: 0.138774\n",
            "[103]\ttraining's auc: 0.876548\ttraining's binary_logloss: 0.125818\tvalid_1's auc: 0.835627\tvalid_1's binary_logloss: 0.138713\n",
            "[104]\ttraining's auc: 0.876673\ttraining's binary_logloss: 0.125699\tvalid_1's auc: 0.835562\tvalid_1's binary_logloss: 0.138666\n",
            "[105]\ttraining's auc: 0.876899\ttraining's binary_logloss: 0.125579\tvalid_1's auc: 0.835646\tvalid_1's binary_logloss: 0.138613\n",
            "[106]\ttraining's auc: 0.877389\ttraining's binary_logloss: 0.125453\tvalid_1's auc: 0.835476\tvalid_1's binary_logloss: 0.138562\n",
            "[107]\ttraining's auc: 0.877853\ttraining's binary_logloss: 0.125328\tvalid_1's auc: 0.835399\tvalid_1's binary_logloss: 0.138522\n",
            "[108]\ttraining's auc: 0.878259\ttraining's binary_logloss: 0.125203\tvalid_1's auc: 0.835461\tvalid_1's binary_logloss: 0.138461\n",
            "[109]\ttraining's auc: 0.878551\ttraining's binary_logloss: 0.125084\tvalid_1's auc: 0.835539\tvalid_1's binary_logloss: 0.138409\n",
            "[110]\ttraining's auc: 0.878796\ttraining's binary_logloss: 0.124957\tvalid_1's auc: 0.835559\tvalid_1's binary_logloss: 0.138354\n",
            "[111]\ttraining's auc: 0.879213\ttraining's binary_logloss: 0.124842\tvalid_1's auc: 0.835597\tvalid_1's binary_logloss: 0.1383\n",
            "[112]\ttraining's auc: 0.879512\ttraining's binary_logloss: 0.124725\tvalid_1's auc: 0.835731\tvalid_1's binary_logloss: 0.13824\n",
            "[113]\ttraining's auc: 0.879771\ttraining's binary_logloss: 0.124611\tvalid_1's auc: 0.835781\tvalid_1's binary_logloss: 0.138191\n",
            "[114]\ttraining's auc: 0.879997\ttraining's binary_logloss: 0.124499\tvalid_1's auc: 0.83574\tvalid_1's binary_logloss: 0.138141\n",
            "[115]\ttraining's auc: 0.880174\ttraining's binary_logloss: 0.124388\tvalid_1's auc: 0.835867\tvalid_1's binary_logloss: 0.138096\n",
            "[116]\ttraining's auc: 0.880538\ttraining's binary_logloss: 0.124267\tvalid_1's auc: 0.835777\tvalid_1's binary_logloss: 0.13806\n",
            "[117]\ttraining's auc: 0.880823\ttraining's binary_logloss: 0.124152\tvalid_1's auc: 0.835694\tvalid_1's binary_logloss: 0.138021\n",
            "[118]\ttraining's auc: 0.88101\ttraining's binary_logloss: 0.124044\tvalid_1's auc: 0.83574\tvalid_1's binary_logloss: 0.137974\n",
            "[119]\ttraining's auc: 0.881229\ttraining's binary_logloss: 0.123931\tvalid_1's auc: 0.835811\tvalid_1's binary_logloss: 0.137937\n",
            "[120]\ttraining's auc: 0.881508\ttraining's binary_logloss: 0.123827\tvalid_1's auc: 0.83585\tvalid_1's binary_logloss: 0.137896\n",
            "[121]\ttraining's auc: 0.881715\ttraining's binary_logloss: 0.123725\tvalid_1's auc: 0.835854\tvalid_1's binary_logloss: 0.137858\n",
            "[122]\ttraining's auc: 0.881928\ttraining's binary_logloss: 0.123614\tvalid_1's auc: 0.835922\tvalid_1's binary_logloss: 0.137818\n",
            "[123]\ttraining's auc: 0.882114\ttraining's binary_logloss: 0.123509\tvalid_1's auc: 0.835937\tvalid_1's binary_logloss: 0.137776\n",
            "[124]\ttraining's auc: 0.882542\ttraining's binary_logloss: 0.123394\tvalid_1's auc: 0.835924\tvalid_1's binary_logloss: 0.137747\n",
            "[125]\ttraining's auc: 0.882624\ttraining's binary_logloss: 0.1233\tvalid_1's auc: 0.835978\tvalid_1's binary_logloss: 0.137709\n",
            "[126]\ttraining's auc: 0.882862\ttraining's binary_logloss: 0.123197\tvalid_1's auc: 0.836012\tvalid_1's binary_logloss: 0.137677\n",
            "[127]\ttraining's auc: 0.883139\ttraining's binary_logloss: 0.123094\tvalid_1's auc: 0.835873\tvalid_1's binary_logloss: 0.137651\n",
            "[128]\ttraining's auc: 0.883418\ttraining's binary_logloss: 0.122987\tvalid_1's auc: 0.835962\tvalid_1's binary_logloss: 0.137613\n",
            "[129]\ttraining's auc: 0.883697\ttraining's binary_logloss: 0.122893\tvalid_1's auc: 0.835935\tvalid_1's binary_logloss: 0.137571\n",
            "[130]\ttraining's auc: 0.883946\ttraining's binary_logloss: 0.122797\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.137538\n",
            "[131]\ttraining's auc: 0.884287\ttraining's binary_logloss: 0.12269\tvalid_1's auc: 0.83615\tvalid_1's binary_logloss: 0.137495\n",
            "[132]\ttraining's auc: 0.884523\ttraining's binary_logloss: 0.122596\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.137455\n",
            "[133]\ttraining's auc: 0.884804\ttraining's binary_logloss: 0.122494\tvalid_1's auc: 0.836022\tvalid_1's binary_logloss: 0.137412\n",
            "[134]\ttraining's auc: 0.885059\ttraining's binary_logloss: 0.122391\tvalid_1's auc: 0.836081\tvalid_1's binary_logloss: 0.137381\n",
            "[135]\ttraining's auc: 0.885284\ttraining's binary_logloss: 0.122303\tvalid_1's auc: 0.836067\tvalid_1's binary_logloss: 0.137339\n",
            "[136]\ttraining's auc: 0.885548\ttraining's binary_logloss: 0.122199\tvalid_1's auc: 0.836122\tvalid_1's binary_logloss: 0.137315\n",
            "[137]\ttraining's auc: 0.885792\ttraining's binary_logloss: 0.122105\tvalid_1's auc: 0.836141\tvalid_1's binary_logloss: 0.137286\n",
            "[138]\ttraining's auc: 0.886161\ttraining's binary_logloss: 0.12201\tvalid_1's auc: 0.836318\tvalid_1's binary_logloss: 0.137259\n",
            "[139]\ttraining's auc: 0.886451\ttraining's binary_logloss: 0.121911\tvalid_1's auc: 0.836294\tvalid_1's binary_logloss: 0.137224\n",
            "[140]\ttraining's auc: 0.886646\ttraining's binary_logloss: 0.121815\tvalid_1's auc: 0.836448\tvalid_1's binary_logloss: 0.137177\n",
            "[141]\ttraining's auc: 0.886892\ttraining's binary_logloss: 0.121718\tvalid_1's auc: 0.836409\tvalid_1's binary_logloss: 0.137159\n",
            "[142]\ttraining's auc: 0.887077\ttraining's binary_logloss: 0.121631\tvalid_1's auc: 0.836442\tvalid_1's binary_logloss: 0.137128\n",
            "[143]\ttraining's auc: 0.887272\ttraining's binary_logloss: 0.121547\tvalid_1's auc: 0.836496\tvalid_1's binary_logloss: 0.1371\n",
            "[144]\ttraining's auc: 0.887405\ttraining's binary_logloss: 0.121459\tvalid_1's auc: 0.836558\tvalid_1's binary_logloss: 0.137071\n",
            "[145]\ttraining's auc: 0.88765\ttraining's binary_logloss: 0.12137\tvalid_1's auc: 0.836495\tvalid_1's binary_logloss: 0.137052\n",
            "[146]\ttraining's auc: 0.887873\ttraining's binary_logloss: 0.121274\tvalid_1's auc: 0.836508\tvalid_1's binary_logloss: 0.137026\n",
            "[147]\ttraining's auc: 0.88804\ttraining's binary_logloss: 0.121196\tvalid_1's auc: 0.836485\tvalid_1's binary_logloss: 0.137006\n",
            "[148]\ttraining's auc: 0.888234\ttraining's binary_logloss: 0.121115\tvalid_1's auc: 0.836633\tvalid_1's binary_logloss: 0.13697\n",
            "[149]\ttraining's auc: 0.888485\ttraining's binary_logloss: 0.121024\tvalid_1's auc: 0.836427\tvalid_1's binary_logloss: 0.13696\n",
            "[150]\ttraining's auc: 0.888792\ttraining's binary_logloss: 0.12093\tvalid_1's auc: 0.836398\tvalid_1's binary_logloss: 0.136942\n",
            "[151]\ttraining's auc: 0.889005\ttraining's binary_logloss: 0.120847\tvalid_1's auc: 0.836396\tvalid_1's binary_logloss: 0.136923\n",
            "[152]\ttraining's auc: 0.889142\ttraining's binary_logloss: 0.120767\tvalid_1's auc: 0.836356\tvalid_1's binary_logloss: 0.136905\n",
            "[153]\ttraining's auc: 0.889328\ttraining's binary_logloss: 0.120688\tvalid_1's auc: 0.836292\tvalid_1's binary_logloss: 0.136888\n",
            "[154]\ttraining's auc: 0.889523\ttraining's binary_logloss: 0.120608\tvalid_1's auc: 0.836312\tvalid_1's binary_logloss: 0.136865\n",
            "[155]\ttraining's auc: 0.889747\ttraining's binary_logloss: 0.120522\tvalid_1's auc: 0.836311\tvalid_1's binary_logloss: 0.136853\n",
            "[156]\ttraining's auc: 0.889976\ttraining's binary_logloss: 0.12044\tvalid_1's auc: 0.836278\tvalid_1's binary_logloss: 0.136838\n",
            "[157]\ttraining's auc: 0.890207\ttraining's binary_logloss: 0.120355\tvalid_1's auc: 0.83637\tvalid_1's binary_logloss: 0.136812\n",
            "[158]\ttraining's auc: 0.890383\ttraining's binary_logloss: 0.120264\tvalid_1's auc: 0.836494\tvalid_1's binary_logloss: 0.136791\n",
            "[159]\ttraining's auc: 0.890561\ttraining's binary_logloss: 0.120178\tvalid_1's auc: 0.836539\tvalid_1's binary_logloss: 0.13677\n",
            "[160]\ttraining's auc: 0.890722\ttraining's binary_logloss: 0.120096\tvalid_1's auc: 0.836626\tvalid_1's binary_logloss: 0.13675\n",
            "[161]\ttraining's auc: 0.890955\ttraining's binary_logloss: 0.120008\tvalid_1's auc: 0.836672\tvalid_1's binary_logloss: 0.136734\n",
            "[162]\ttraining's auc: 0.891139\ttraining's binary_logloss: 0.119932\tvalid_1's auc: 0.836698\tvalid_1's binary_logloss: 0.136713\n",
            "[163]\ttraining's auc: 0.891271\ttraining's binary_logloss: 0.119861\tvalid_1's auc: 0.836682\tvalid_1's binary_logloss: 0.136701\n",
            "[164]\ttraining's auc: 0.891385\ttraining's binary_logloss: 0.119791\tvalid_1's auc: 0.836645\tvalid_1's binary_logloss: 0.136692\n",
            "[165]\ttraining's auc: 0.891515\ttraining's binary_logloss: 0.119722\tvalid_1's auc: 0.836658\tvalid_1's binary_logloss: 0.136681\n",
            "[166]\ttraining's auc: 0.891738\ttraining's binary_logloss: 0.119649\tvalid_1's auc: 0.836633\tvalid_1's binary_logloss: 0.136664\n",
            "[167]\ttraining's auc: 0.892071\ttraining's binary_logloss: 0.119558\tvalid_1's auc: 0.836547\tvalid_1's binary_logloss: 0.136657\n",
            "[168]\ttraining's auc: 0.892204\ttraining's binary_logloss: 0.119495\tvalid_1's auc: 0.836558\tvalid_1's binary_logloss: 0.136646\n",
            "[169]\ttraining's auc: 0.892388\ttraining's binary_logloss: 0.119432\tvalid_1's auc: 0.836488\tvalid_1's binary_logloss: 0.136633\n",
            "[170]\ttraining's auc: 0.892521\ttraining's binary_logloss: 0.119365\tvalid_1's auc: 0.836449\tvalid_1's binary_logloss: 0.136627\n",
            "[171]\ttraining's auc: 0.892715\ttraining's binary_logloss: 0.119296\tvalid_1's auc: 0.836428\tvalid_1's binary_logloss: 0.136617\n",
            "[172]\ttraining's auc: 0.892877\ttraining's binary_logloss: 0.119227\tvalid_1's auc: 0.836463\tvalid_1's binary_logloss: 0.136598\n",
            "[173]\ttraining's auc: 0.893023\ttraining's binary_logloss: 0.119157\tvalid_1's auc: 0.836482\tvalid_1's binary_logloss: 0.136589\n",
            "[174]\ttraining's auc: 0.893212\ttraining's binary_logloss: 0.119087\tvalid_1's auc: 0.836484\tvalid_1's binary_logloss: 0.136578\n",
            "[175]\ttraining's auc: 0.89348\ttraining's binary_logloss: 0.119006\tvalid_1's auc: 0.836467\tvalid_1's binary_logloss: 0.136568\n",
            "[176]\ttraining's auc: 0.893671\ttraining's binary_logloss: 0.118936\tvalid_1's auc: 0.836501\tvalid_1's binary_logloss: 0.13655\n",
            "[177]\ttraining's auc: 0.893829\ttraining's binary_logloss: 0.118871\tvalid_1's auc: 0.836598\tvalid_1's binary_logloss: 0.136532\n",
            "[178]\ttraining's auc: 0.894033\ttraining's binary_logloss: 0.118802\tvalid_1's auc: 0.83654\tvalid_1's binary_logloss: 0.136528\n",
            "[179]\ttraining's auc: 0.894193\ttraining's binary_logloss: 0.118732\tvalid_1's auc: 0.836492\tvalid_1's binary_logloss: 0.136525\n",
            "[180]\ttraining's auc: 0.894287\ttraining's binary_logloss: 0.118669\tvalid_1's auc: 0.836521\tvalid_1's binary_logloss: 0.136508\n",
            "[181]\ttraining's auc: 0.894401\ttraining's binary_logloss: 0.118608\tvalid_1's auc: 0.836497\tvalid_1's binary_logloss: 0.136498\n",
            "[182]\ttraining's auc: 0.89461\ttraining's binary_logloss: 0.11853\tvalid_1's auc: 0.836411\tvalid_1's binary_logloss: 0.136491\n",
            "[183]\ttraining's auc: 0.894781\ttraining's binary_logloss: 0.118467\tvalid_1's auc: 0.836393\tvalid_1's binary_logloss: 0.136484\n",
            "[184]\ttraining's auc: 0.894904\ttraining's binary_logloss: 0.118401\tvalid_1's auc: 0.836456\tvalid_1's binary_logloss: 0.136468\n",
            "[185]\ttraining's auc: 0.895076\ttraining's binary_logloss: 0.118333\tvalid_1's auc: 0.836423\tvalid_1's binary_logloss: 0.136464\n",
            "[186]\ttraining's auc: 0.895223\ttraining's binary_logloss: 0.118268\tvalid_1's auc: 0.836397\tvalid_1's binary_logloss: 0.136461\n",
            "[187]\ttraining's auc: 0.895359\ttraining's binary_logloss: 0.118208\tvalid_1's auc: 0.836351\tvalid_1's binary_logloss: 0.136458\n",
            "[188]\ttraining's auc: 0.895521\ttraining's binary_logloss: 0.118138\tvalid_1's auc: 0.836273\tvalid_1's binary_logloss: 0.136454\n",
            "[189]\ttraining's auc: 0.895734\ttraining's binary_logloss: 0.118056\tvalid_1's auc: 0.836305\tvalid_1's binary_logloss: 0.136447\n",
            "[190]\ttraining's auc: 0.895902\ttraining's binary_logloss: 0.11799\tvalid_1's auc: 0.836266\tvalid_1's binary_logloss: 0.136434\n",
            "[191]\ttraining's auc: 0.896083\ttraining's binary_logloss: 0.117919\tvalid_1's auc: 0.8362\tvalid_1's binary_logloss: 0.136429\n",
            "[192]\ttraining's auc: 0.896224\ttraining's binary_logloss: 0.117855\tvalid_1's auc: 0.836195\tvalid_1's binary_logloss: 0.136421\n",
            " 60%|██████    | 30/50 [15:19<14:08, 42.42s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.157561\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.159629\n",
            "[2]\ttraining's auc: 0.833814\ttraining's binary_logloss: 0.152812\tvalid_1's auc: 0.808075\tvalid_1's binary_logloss: 0.155826\n",
            "[3]\ttraining's auc: 0.837109\ttraining's binary_logloss: 0.149086\tvalid_1's auc: 0.809566\tvalid_1's binary_logloss: 0.153093\n",
            "[4]\ttraining's auc: 0.84304\ttraining's binary_logloss: 0.146067\tvalid_1's auc: 0.814183\tvalid_1's binary_logloss: 0.150827\n",
            "[5]\ttraining's auc: 0.84615\ttraining's binary_logloss: 0.143661\tvalid_1's auc: 0.816834\tvalid_1's binary_logloss: 0.148933\n",
            "[6]\ttraining's auc: 0.849259\ttraining's binary_logloss: 0.141432\tvalid_1's auc: 0.818057\tvalid_1's binary_logloss: 0.147339\n",
            "[7]\ttraining's auc: 0.851053\ttraining's binary_logloss: 0.139569\tvalid_1's auc: 0.818421\tvalid_1's binary_logloss: 0.146048\n",
            "[8]\ttraining's auc: 0.851984\ttraining's binary_logloss: 0.137919\tvalid_1's auc: 0.81899\tvalid_1's binary_logloss: 0.144847\n",
            "[9]\ttraining's auc: 0.853273\ttraining's binary_logloss: 0.136409\tvalid_1's auc: 0.819769\tvalid_1's binary_logloss: 0.143791\n",
            "[10]\ttraining's auc: 0.855386\ttraining's binary_logloss: 0.135081\tvalid_1's auc: 0.820975\tvalid_1's binary_logloss: 0.142839\n",
            "[11]\ttraining's auc: 0.856509\ttraining's binary_logloss: 0.133884\tvalid_1's auc: 0.821696\tvalid_1's binary_logloss: 0.142053\n",
            "[12]\ttraining's auc: 0.8601\ttraining's binary_logloss: 0.132724\tvalid_1's auc: 0.822412\tvalid_1's binary_logloss: 0.141306\n",
            "[13]\ttraining's auc: 0.862928\ttraining's binary_logloss: 0.131708\tvalid_1's auc: 0.823881\tvalid_1's binary_logloss: 0.140687\n",
            "[14]\ttraining's auc: 0.864619\ttraining's binary_logloss: 0.130722\tvalid_1's auc: 0.825938\tvalid_1's binary_logloss: 0.140066\n",
            "[15]\ttraining's auc: 0.867595\ttraining's binary_logloss: 0.129858\tvalid_1's auc: 0.826617\tvalid_1's binary_logloss: 0.139603\n",
            "[16]\ttraining's auc: 0.868591\ttraining's binary_logloss: 0.129062\tvalid_1's auc: 0.827066\tvalid_1's binary_logloss: 0.139202\n",
            "[17]\ttraining's auc: 0.870638\ttraining's binary_logloss: 0.128253\tvalid_1's auc: 0.827686\tvalid_1's binary_logloss: 0.13885\n",
            "[18]\ttraining's auc: 0.872084\ttraining's binary_logloss: 0.127506\tvalid_1's auc: 0.828238\tvalid_1's binary_logloss: 0.138499\n",
            "[19]\ttraining's auc: 0.873507\ttraining's binary_logloss: 0.126788\tvalid_1's auc: 0.828336\tvalid_1's binary_logloss: 0.138214\n",
            "[20]\ttraining's auc: 0.87446\ttraining's binary_logloss: 0.126144\tvalid_1's auc: 0.828375\tvalid_1's binary_logloss: 0.138007\n",
            "[21]\ttraining's auc: 0.876487\ttraining's binary_logloss: 0.125539\tvalid_1's auc: 0.828082\tvalid_1's binary_logloss: 0.137829\n",
            "[22]\ttraining's auc: 0.878054\ttraining's binary_logloss: 0.12494\tvalid_1's auc: 0.82858\tvalid_1's binary_logloss: 0.137637\n",
            "[23]\ttraining's auc: 0.879381\ttraining's binary_logloss: 0.124357\tvalid_1's auc: 0.829239\tvalid_1's binary_logloss: 0.137334\n",
            "[24]\ttraining's auc: 0.88187\ttraining's binary_logloss: 0.123739\tvalid_1's auc: 0.828976\tvalid_1's binary_logloss: 0.137204\n",
            "[25]\ttraining's auc: 0.8829\ttraining's binary_logloss: 0.12323\tvalid_1's auc: 0.828931\tvalid_1's binary_logloss: 0.13709\n",
            "[26]\ttraining's auc: 0.884144\ttraining's binary_logloss: 0.12269\tvalid_1's auc: 0.829877\tvalid_1's binary_logloss: 0.136862\n",
            "[27]\ttraining's auc: 0.885194\ttraining's binary_logloss: 0.12223\tvalid_1's auc: 0.830004\tvalid_1's binary_logloss: 0.136769\n",
            "[28]\ttraining's auc: 0.88646\ttraining's binary_logloss: 0.121766\tvalid_1's auc: 0.829736\tvalid_1's binary_logloss: 0.136714\n",
            "[29]\ttraining's auc: 0.887125\ttraining's binary_logloss: 0.121325\tvalid_1's auc: 0.829518\tvalid_1's binary_logloss: 0.136669\n",
            "[30]\ttraining's auc: 0.887704\ttraining's binary_logloss: 0.120907\tvalid_1's auc: 0.82927\tvalid_1's binary_logloss: 0.136665\n",
            "[31]\ttraining's auc: 0.88884\ttraining's binary_logloss: 0.120436\tvalid_1's auc: 0.829387\tvalid_1's binary_logloss: 0.136633\n",
            "[32]\ttraining's auc: 0.889429\ttraining's binary_logloss: 0.120098\tvalid_1's auc: 0.829349\tvalid_1's binary_logloss: 0.136573\n",
            "[33]\ttraining's auc: 0.891393\ttraining's binary_logloss: 0.119627\tvalid_1's auc: 0.830035\tvalid_1's binary_logloss: 0.136411\n",
            "[34]\ttraining's auc: 0.89219\ttraining's binary_logloss: 0.119261\tvalid_1's auc: 0.830177\tvalid_1's binary_logloss: 0.136365\n",
            "[35]\ttraining's auc: 0.892805\ttraining's binary_logloss: 0.118922\tvalid_1's auc: 0.829811\tvalid_1's binary_logloss: 0.13638\n",
            "[36]\ttraining's auc: 0.8945\ttraining's binary_logloss: 0.118491\tvalid_1's auc: 0.830747\tvalid_1's binary_logloss: 0.136192\n",
            "[37]\ttraining's auc: 0.894915\ttraining's binary_logloss: 0.118192\tvalid_1's auc: 0.830676\tvalid_1's binary_logloss: 0.136152\n",
            "[38]\ttraining's auc: 0.896186\ttraining's binary_logloss: 0.117812\tvalid_1's auc: 0.83065\tvalid_1's binary_logloss: 0.136115\n",
            "[39]\ttraining's auc: 0.897159\ttraining's binary_logloss: 0.117424\tvalid_1's auc: 0.831007\tvalid_1's binary_logloss: 0.13607\n",
            "[40]\ttraining's auc: 0.897772\ttraining's binary_logloss: 0.117097\tvalid_1's auc: 0.83104\tvalid_1's binary_logloss: 0.136037\n",
            "[41]\ttraining's auc: 0.898544\ttraining's binary_logloss: 0.116767\tvalid_1's auc: 0.831075\tvalid_1's binary_logloss: 0.136042\n",
            "[42]\ttraining's auc: 0.899356\ttraining's binary_logloss: 0.116439\tvalid_1's auc: 0.831152\tvalid_1's binary_logloss: 0.136024\n",
            "[43]\ttraining's auc: 0.900057\ttraining's binary_logloss: 0.116152\tvalid_1's auc: 0.830609\tvalid_1's binary_logloss: 0.136107\n",
            "[44]\ttraining's auc: 0.900651\ttraining's binary_logloss: 0.11587\tvalid_1's auc: 0.83051\tvalid_1's binary_logloss: 0.136087\n",
            "[45]\ttraining's auc: 0.901592\ttraining's binary_logloss: 0.115513\tvalid_1's auc: 0.830914\tvalid_1's binary_logloss: 0.136017\n",
            "[46]\ttraining's auc: 0.902382\ttraining's binary_logloss: 0.115238\tvalid_1's auc: 0.831164\tvalid_1's binary_logloss: 0.135974\n",
            "[47]\ttraining's auc: 0.90374\ttraining's binary_logloss: 0.114901\tvalid_1's auc: 0.83171\tvalid_1's binary_logloss: 0.135883\n",
            "[48]\ttraining's auc: 0.904346\ttraining's binary_logloss: 0.114649\tvalid_1's auc: 0.831612\tvalid_1's binary_logloss: 0.135866\n",
            "[49]\ttraining's auc: 0.904912\ttraining's binary_logloss: 0.114388\tvalid_1's auc: 0.83158\tvalid_1's binary_logloss: 0.135867\n",
            "[50]\ttraining's auc: 0.90534\ttraining's binary_logloss: 0.114136\tvalid_1's auc: 0.831575\tvalid_1's binary_logloss: 0.135885\n",
            "[51]\ttraining's auc: 0.905938\ttraining's binary_logloss: 0.113835\tvalid_1's auc: 0.831607\tvalid_1's binary_logloss: 0.135854\n",
            "[52]\ttraining's auc: 0.906343\ttraining's binary_logloss: 0.113598\tvalid_1's auc: 0.831499\tvalid_1's binary_logloss: 0.135873\n",
            "[53]\ttraining's auc: 0.907313\ttraining's binary_logloss: 0.113376\tvalid_1's auc: 0.831385\tvalid_1's binary_logloss: 0.135887\n",
            "[54]\ttraining's auc: 0.907736\ttraining's binary_logloss: 0.11313\tvalid_1's auc: 0.831111\tvalid_1's binary_logloss: 0.135957\n",
            "[55]\ttraining's auc: 0.908512\ttraining's binary_logloss: 0.112898\tvalid_1's auc: 0.830937\tvalid_1's binary_logloss: 0.135983\n",
            "[56]\ttraining's auc: 0.909556\ttraining's binary_logloss: 0.112642\tvalid_1's auc: 0.831002\tvalid_1's binary_logloss: 0.13598\n",
            "[57]\ttraining's auc: 0.909865\ttraining's binary_logloss: 0.112474\tvalid_1's auc: 0.830853\tvalid_1's binary_logloss: 0.136028\n",
            "[58]\ttraining's auc: 0.910325\ttraining's binary_logloss: 0.112242\tvalid_1's auc: 0.830536\tvalid_1's binary_logloss: 0.136089\n",
            "[59]\ttraining's auc: 0.910876\ttraining's binary_logloss: 0.112028\tvalid_1's auc: 0.830448\tvalid_1's binary_logloss: 0.136105\n",
            "[60]\ttraining's auc: 0.91226\ttraining's binary_logloss: 0.111632\tvalid_1's auc: 0.83031\tvalid_1's binary_logloss: 0.136151\n",
            "[61]\ttraining's auc: 0.91267\ttraining's binary_logloss: 0.111402\tvalid_1's auc: 0.830189\tvalid_1's binary_logloss: 0.136151\n",
            "[62]\ttraining's auc: 0.912939\ttraining's binary_logloss: 0.111232\tvalid_1's auc: 0.830039\tvalid_1's binary_logloss: 0.13619\n",
            "[63]\ttraining's auc: 0.913997\ttraining's binary_logloss: 0.110927\tvalid_1's auc: 0.829809\tvalid_1's binary_logloss: 0.136222\n",
            "[64]\ttraining's auc: 0.914435\ttraining's binary_logloss: 0.110712\tvalid_1's auc: 0.829923\tvalid_1's binary_logloss: 0.136251\n",
            "[65]\ttraining's auc: 0.914766\ttraining's binary_logloss: 0.110536\tvalid_1's auc: 0.829993\tvalid_1's binary_logloss: 0.136244\n",
            "[66]\ttraining's auc: 0.915488\ttraining's binary_logloss: 0.110339\tvalid_1's auc: 0.830059\tvalid_1's binary_logloss: 0.13624\n",
            "[67]\ttraining's auc: 0.915966\ttraining's binary_logloss: 0.110134\tvalid_1's auc: 0.82977\tvalid_1's binary_logloss: 0.136309\n",
            "[68]\ttraining's auc: 0.916217\ttraining's binary_logloss: 0.109938\tvalid_1's auc: 0.829624\tvalid_1's binary_logloss: 0.136332\n",
            "[69]\ttraining's auc: 0.916709\ttraining's binary_logloss: 0.109694\tvalid_1's auc: 0.829804\tvalid_1's binary_logloss: 0.13631\n",
            "[70]\ttraining's auc: 0.916929\ttraining's binary_logloss: 0.109522\tvalid_1's auc: 0.829632\tvalid_1's binary_logloss: 0.136374\n",
            "[71]\ttraining's auc: 0.917111\ttraining's binary_logloss: 0.109399\tvalid_1's auc: 0.829244\tvalid_1's binary_logloss: 0.136447\n",
            "[72]\ttraining's auc: 0.917505\ttraining's binary_logloss: 0.109192\tvalid_1's auc: 0.829079\tvalid_1's binary_logloss: 0.136444\n",
            "[73]\ttraining's auc: 0.91782\ttraining's binary_logloss: 0.109008\tvalid_1's auc: 0.829161\tvalid_1's binary_logloss: 0.136481\n",
            "[74]\ttraining's auc: 0.91865\ttraining's binary_logloss: 0.108808\tvalid_1's auc: 0.8292\tvalid_1's binary_logloss: 0.136477\n",
            "[75]\ttraining's auc: 0.919019\ttraining's binary_logloss: 0.108629\tvalid_1's auc: 0.828996\tvalid_1's binary_logloss: 0.136508\n",
            "[76]\ttraining's auc: 0.919162\ttraining's binary_logloss: 0.108511\tvalid_1's auc: 0.829193\tvalid_1's binary_logloss: 0.13647\n",
            "[77]\ttraining's auc: 0.919587\ttraining's binary_logloss: 0.108356\tvalid_1's auc: 0.829192\tvalid_1's binary_logloss: 0.136493\n",
            " 60%|██████    | 30/50 [15:29<14:08, 42.42s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.159968\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.155393\n",
            "[2]\ttraining's auc: 0.826638\ttraining's binary_logloss: 0.155111\tvalid_1's auc: 0.816063\tvalid_1's binary_logloss: 0.15166\n",
            "[3]\ttraining's auc: 0.83236\ttraining's binary_logloss: 0.151346\tvalid_1's auc: 0.817456\tvalid_1's binary_logloss: 0.148792\n",
            "[4]\ttraining's auc: 0.838866\ttraining's binary_logloss: 0.148254\tvalid_1's auc: 0.820007\tvalid_1's binary_logloss: 0.146432\n",
            "[5]\ttraining's auc: 0.845175\ttraining's binary_logloss: 0.145612\tvalid_1's auc: 0.825357\tvalid_1's binary_logloss: 0.144485\n",
            "[6]\ttraining's auc: 0.849479\ttraining's binary_logloss: 0.143415\tvalid_1's auc: 0.828464\tvalid_1's binary_logloss: 0.142899\n",
            "[7]\ttraining's auc: 0.851912\ttraining's binary_logloss: 0.141505\tvalid_1's auc: 0.829062\tvalid_1's binary_logloss: 0.141538\n",
            "[8]\ttraining's auc: 0.853251\ttraining's binary_logloss: 0.139833\tvalid_1's auc: 0.829933\tvalid_1's binary_logloss: 0.140294\n",
            "[9]\ttraining's auc: 0.857096\ttraining's binary_logloss: 0.138302\tvalid_1's auc: 0.831925\tvalid_1's binary_logloss: 0.139282\n",
            "[10]\ttraining's auc: 0.858394\ttraining's binary_logloss: 0.13689\tvalid_1's auc: 0.832034\tvalid_1's binary_logloss: 0.138366\n",
            "[11]\ttraining's auc: 0.859378\ttraining's binary_logloss: 0.135624\tvalid_1's auc: 0.832027\tvalid_1's binary_logloss: 0.137535\n",
            "[12]\ttraining's auc: 0.862183\ttraining's binary_logloss: 0.134508\tvalid_1's auc: 0.832952\tvalid_1's binary_logloss: 0.136838\n",
            "[13]\ttraining's auc: 0.864139\ttraining's binary_logloss: 0.133435\tvalid_1's auc: 0.832806\tvalid_1's binary_logloss: 0.136263\n",
            "[14]\ttraining's auc: 0.867007\ttraining's binary_logloss: 0.13242\tvalid_1's auc: 0.834322\tvalid_1's binary_logloss: 0.135674\n",
            "[15]\ttraining's auc: 0.869216\ttraining's binary_logloss: 0.131498\tvalid_1's auc: 0.835816\tvalid_1's binary_logloss: 0.135109\n",
            "[16]\ttraining's auc: 0.87072\ttraining's binary_logloss: 0.130632\tvalid_1's auc: 0.835564\tvalid_1's binary_logloss: 0.134757\n",
            "[17]\ttraining's auc: 0.872668\ttraining's binary_logloss: 0.129817\tvalid_1's auc: 0.83529\tvalid_1's binary_logloss: 0.13435\n",
            "[18]\ttraining's auc: 0.873559\ttraining's binary_logloss: 0.129057\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.134017\n",
            "[19]\ttraining's auc: 0.874744\ttraining's binary_logloss: 0.128399\tvalid_1's auc: 0.834765\tvalid_1's binary_logloss: 0.133747\n",
            "[20]\ttraining's auc: 0.875383\ttraining's binary_logloss: 0.127754\tvalid_1's auc: 0.835021\tvalid_1's binary_logloss: 0.133459\n",
            "[21]\ttraining's auc: 0.87626\ttraining's binary_logloss: 0.127113\tvalid_1's auc: 0.834921\tvalid_1's binary_logloss: 0.133231\n",
            "[22]\ttraining's auc: 0.877734\ttraining's binary_logloss: 0.126517\tvalid_1's auc: 0.834892\tvalid_1's binary_logloss: 0.133007\n",
            "[23]\ttraining's auc: 0.8788\ttraining's binary_logloss: 0.125979\tvalid_1's auc: 0.83542\tvalid_1's binary_logloss: 0.132752\n",
            "[24]\ttraining's auc: 0.880156\ttraining's binary_logloss: 0.125415\tvalid_1's auc: 0.835342\tvalid_1's binary_logloss: 0.132539\n",
            "[25]\ttraining's auc: 0.881602\ttraining's binary_logloss: 0.124798\tvalid_1's auc: 0.835852\tvalid_1's binary_logloss: 0.132291\n",
            "[26]\ttraining's auc: 0.882121\ttraining's binary_logloss: 0.124317\tvalid_1's auc: 0.835821\tvalid_1's binary_logloss: 0.132166\n",
            "[27]\ttraining's auc: 0.883592\ttraining's binary_logloss: 0.123788\tvalid_1's auc: 0.835687\tvalid_1's binary_logloss: 0.132024\n",
            "[28]\ttraining's auc: 0.885189\ttraining's binary_logloss: 0.123314\tvalid_1's auc: 0.835798\tvalid_1's binary_logloss: 0.131901\n",
            "[29]\ttraining's auc: 0.886077\ttraining's binary_logloss: 0.1229\tvalid_1's auc: 0.835714\tvalid_1's binary_logloss: 0.131828\n",
            "[30]\ttraining's auc: 0.887088\ttraining's binary_logloss: 0.122463\tvalid_1's auc: 0.835751\tvalid_1's binary_logloss: 0.131731\n",
            "[31]\ttraining's auc: 0.88768\ttraining's binary_logloss: 0.12209\tvalid_1's auc: 0.835879\tvalid_1's binary_logloss: 0.131602\n",
            "[32]\ttraining's auc: 0.888407\ttraining's binary_logloss: 0.121665\tvalid_1's auc: 0.835568\tvalid_1's binary_logloss: 0.131577\n",
            "[33]\ttraining's auc: 0.890246\ttraining's binary_logloss: 0.121153\tvalid_1's auc: 0.836125\tvalid_1's binary_logloss: 0.131507\n",
            "[34]\ttraining's auc: 0.891119\ttraining's binary_logloss: 0.120749\tvalid_1's auc: 0.836515\tvalid_1's binary_logloss: 0.131386\n",
            "[35]\ttraining's auc: 0.891645\ttraining's binary_logloss: 0.120423\tvalid_1's auc: 0.836404\tvalid_1's binary_logloss: 0.13134\n",
            "[36]\ttraining's auc: 0.892391\ttraining's binary_logloss: 0.120077\tvalid_1's auc: 0.836683\tvalid_1's binary_logloss: 0.131229\n",
            "[37]\ttraining's auc: 0.892681\ttraining's binary_logloss: 0.119763\tvalid_1's auc: 0.837333\tvalid_1's binary_logloss: 0.131092\n",
            "[38]\ttraining's auc: 0.893714\ttraining's binary_logloss: 0.11942\tvalid_1's auc: 0.83738\tvalid_1's binary_logloss: 0.131074\n",
            "[39]\ttraining's auc: 0.894154\ttraining's binary_logloss: 0.119156\tvalid_1's auc: 0.837341\tvalid_1's binary_logloss: 0.131035\n",
            "[40]\ttraining's auc: 0.895356\ttraining's binary_logloss: 0.118849\tvalid_1's auc: 0.83727\tvalid_1's binary_logloss: 0.131006\n",
            "[41]\ttraining's auc: 0.896351\ttraining's binary_logloss: 0.118549\tvalid_1's auc: 0.83704\tvalid_1's binary_logloss: 0.131007\n",
            "[42]\ttraining's auc: 0.897246\ttraining's binary_logloss: 0.11824\tvalid_1's auc: 0.836965\tvalid_1's binary_logloss: 0.13099\n",
            "[43]\ttraining's auc: 0.898145\ttraining's binary_logloss: 0.117954\tvalid_1's auc: 0.836867\tvalid_1's binary_logloss: 0.130987\n",
            "[44]\ttraining's auc: 0.899175\ttraining's binary_logloss: 0.117633\tvalid_1's auc: 0.836854\tvalid_1's binary_logloss: 0.130961\n",
            "[45]\ttraining's auc: 0.899964\ttraining's binary_logloss: 0.117361\tvalid_1's auc: 0.837187\tvalid_1's binary_logloss: 0.13087\n",
            "[46]\ttraining's auc: 0.900561\ttraining's binary_logloss: 0.117096\tvalid_1's auc: 0.83721\tvalid_1's binary_logloss: 0.130843\n",
            "[47]\ttraining's auc: 0.901251\ttraining's binary_logloss: 0.116853\tvalid_1's auc: 0.837282\tvalid_1's binary_logloss: 0.130826\n",
            "[48]\ttraining's auc: 0.902047\ttraining's binary_logloss: 0.116566\tvalid_1's auc: 0.837527\tvalid_1's binary_logloss: 0.130791\n",
            "[49]\ttraining's auc: 0.902709\ttraining's binary_logloss: 0.116351\tvalid_1's auc: 0.837763\tvalid_1's binary_logloss: 0.130752\n",
            "[50]\ttraining's auc: 0.90422\ttraining's binary_logloss: 0.115996\tvalid_1's auc: 0.837507\tvalid_1's binary_logloss: 0.130778\n",
            "[51]\ttraining's auc: 0.90491\ttraining's binary_logloss: 0.115687\tvalid_1's auc: 0.837392\tvalid_1's binary_logloss: 0.130816\n",
            "[52]\ttraining's auc: 0.906047\ttraining's binary_logloss: 0.115415\tvalid_1's auc: 0.837479\tvalid_1's binary_logloss: 0.130788\n",
            "[53]\ttraining's auc: 0.906694\ttraining's binary_logloss: 0.115127\tvalid_1's auc: 0.837179\tvalid_1's binary_logloss: 0.130828\n",
            "[54]\ttraining's auc: 0.907267\ttraining's binary_logloss: 0.114834\tvalid_1's auc: 0.837129\tvalid_1's binary_logloss: 0.130852\n",
            "[55]\ttraining's auc: 0.907956\ttraining's binary_logloss: 0.114545\tvalid_1's auc: 0.83704\tvalid_1's binary_logloss: 0.130862\n",
            "[56]\ttraining's auc: 0.909091\ttraining's binary_logloss: 0.114292\tvalid_1's auc: 0.837305\tvalid_1's binary_logloss: 0.130839\n",
            "[57]\ttraining's auc: 0.910313\ttraining's binary_logloss: 0.113943\tvalid_1's auc: 0.837054\tvalid_1's binary_logloss: 0.130865\n",
            "[58]\ttraining's auc: 0.911068\ttraining's binary_logloss: 0.113676\tvalid_1's auc: 0.837152\tvalid_1's binary_logloss: 0.130854\n",
            "[59]\ttraining's auc: 0.911539\ttraining's binary_logloss: 0.113433\tvalid_1's auc: 0.836993\tvalid_1's binary_logloss: 0.130862\n",
            "[60]\ttraining's auc: 0.912182\ttraining's binary_logloss: 0.113159\tvalid_1's auc: 0.837141\tvalid_1's binary_logloss: 0.130849\n",
            "[61]\ttraining's auc: 0.912564\ttraining's binary_logloss: 0.112932\tvalid_1's auc: 0.837323\tvalid_1's binary_logloss: 0.130852\n",
            "[62]\ttraining's auc: 0.912877\ttraining's binary_logloss: 0.112737\tvalid_1's auc: 0.837251\tvalid_1's binary_logloss: 0.130872\n",
            "[63]\ttraining's auc: 0.913412\ttraining's binary_logloss: 0.112536\tvalid_1's auc: 0.837136\tvalid_1's binary_logloss: 0.130877\n",
            "[64]\ttraining's auc: 0.91387\ttraining's binary_logloss: 0.1123\tvalid_1's auc: 0.837068\tvalid_1's binary_logloss: 0.130893\n",
            "[65]\ttraining's auc: 0.914394\ttraining's binary_logloss: 0.112044\tvalid_1's auc: 0.836906\tvalid_1's binary_logloss: 0.130931\n",
            "[66]\ttraining's auc: 0.914942\ttraining's binary_logloss: 0.111797\tvalid_1's auc: 0.836638\tvalid_1's binary_logloss: 0.130967\n",
            "[67]\ttraining's auc: 0.915179\ttraining's binary_logloss: 0.11163\tvalid_1's auc: 0.83674\tvalid_1's binary_logloss: 0.130953\n",
            "[68]\ttraining's auc: 0.915717\ttraining's binary_logloss: 0.111403\tvalid_1's auc: 0.836726\tvalid_1's binary_logloss: 0.130961\n",
            "[69]\ttraining's auc: 0.916096\ttraining's binary_logloss: 0.111196\tvalid_1's auc: 0.836646\tvalid_1's binary_logloss: 0.130951\n",
            "[70]\ttraining's auc: 0.916502\ttraining's binary_logloss: 0.11099\tvalid_1's auc: 0.836522\tvalid_1's binary_logloss: 0.13097\n",
            "[71]\ttraining's auc: 0.917081\ttraining's binary_logloss: 0.110742\tvalid_1's auc: 0.836679\tvalid_1's binary_logloss: 0.130931\n",
            "[72]\ttraining's auc: 0.917741\ttraining's binary_logloss: 0.110543\tvalid_1's auc: 0.836708\tvalid_1's binary_logloss: 0.130943\n",
            "[73]\ttraining's auc: 0.918362\ttraining's binary_logloss: 0.110306\tvalid_1's auc: 0.836663\tvalid_1's binary_logloss: 0.130945\n",
            "[74]\ttraining's auc: 0.918771\ttraining's binary_logloss: 0.110081\tvalid_1's auc: 0.836643\tvalid_1's binary_logloss: 0.130955\n",
            "[75]\ttraining's auc: 0.919122\ttraining's binary_logloss: 0.1099\tvalid_1's auc: 0.836529\tvalid_1's binary_logloss: 0.13097\n",
            "[76]\ttraining's auc: 0.919443\ttraining's binary_logloss: 0.109719\tvalid_1's auc: 0.836533\tvalid_1's binary_logloss: 0.130951\n",
            "[77]\ttraining's auc: 0.919805\ttraining's binary_logloss: 0.109541\tvalid_1's auc: 0.836461\tvalid_1's binary_logloss: 0.130971\n",
            "[78]\ttraining's auc: 0.92005\ttraining's binary_logloss: 0.109372\tvalid_1's auc: 0.836411\tvalid_1's binary_logloss: 0.130988\n",
            "[79]\ttraining's auc: 0.920415\ttraining's binary_logloss: 0.109215\tvalid_1's auc: 0.836405\tvalid_1's binary_logloss: 0.130987\n",
            " 60%|██████    | 30/50 [15:38<14:08, 42.42s/trial, best loss: -0.8353391867718458]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.156536\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.162596\n",
            "[2]\ttraining's auc: 0.832575\ttraining's binary_logloss: 0.151836\tvalid_1's auc: 0.815421\tvalid_1's binary_logloss: 0.158344\n",
            "[3]\ttraining's auc: 0.837703\ttraining's binary_logloss: 0.14821\tvalid_1's auc: 0.817989\tvalid_1's binary_logloss: 0.155217\n",
            "[4]\ttraining's auc: 0.840798\ttraining's binary_logloss: 0.145282\tvalid_1's auc: 0.819554\tvalid_1's binary_logloss: 0.152709\n",
            "[5]\ttraining's auc: 0.84521\ttraining's binary_logloss: 0.142793\tvalid_1's auc: 0.822886\tvalid_1's binary_logloss: 0.15062\n",
            "[6]\ttraining's auc: 0.848548\ttraining's binary_logloss: 0.140572\tvalid_1's auc: 0.826007\tvalid_1's binary_logloss: 0.148814\n",
            "[7]\ttraining's auc: 0.849969\ttraining's binary_logloss: 0.138652\tvalid_1's auc: 0.827\tvalid_1's binary_logloss: 0.147275\n",
            "[8]\ttraining's auc: 0.852732\ttraining's binary_logloss: 0.137025\tvalid_1's auc: 0.82878\tvalid_1's binary_logloss: 0.146052\n",
            "[9]\ttraining's auc: 0.854911\ttraining's binary_logloss: 0.135532\tvalid_1's auc: 0.829176\tvalid_1's binary_logloss: 0.144933\n",
            "[10]\ttraining's auc: 0.856159\ttraining's binary_logloss: 0.134204\tvalid_1's auc: 0.829909\tvalid_1's binary_logloss: 0.143964\n",
            "[11]\ttraining's auc: 0.857971\ttraining's binary_logloss: 0.132997\tvalid_1's auc: 0.829785\tvalid_1's binary_logloss: 0.143135\n",
            "[12]\ttraining's auc: 0.859746\ttraining's binary_logloss: 0.13194\tvalid_1's auc: 0.830574\tvalid_1's binary_logloss: 0.142391\n",
            "[13]\ttraining's auc: 0.862118\ttraining's binary_logloss: 0.13096\tvalid_1's auc: 0.83073\tvalid_1's binary_logloss: 0.141751\n",
            "[14]\ttraining's auc: 0.86437\ttraining's binary_logloss: 0.129976\tvalid_1's auc: 0.83082\tvalid_1's binary_logloss: 0.141204\n",
            "[15]\ttraining's auc: 0.866034\ttraining's binary_logloss: 0.129131\tvalid_1's auc: 0.830922\tvalid_1's binary_logloss: 0.140706\n",
            "[16]\ttraining's auc: 0.868688\ttraining's binary_logloss: 0.128324\tvalid_1's auc: 0.833442\tvalid_1's binary_logloss: 0.140283\n",
            "[17]\ttraining's auc: 0.869988\ttraining's binary_logloss: 0.127528\tvalid_1's auc: 0.834096\tvalid_1's binary_logloss: 0.139777\n",
            "[18]\ttraining's auc: 0.871269\ttraining's binary_logloss: 0.126841\tvalid_1's auc: 0.83481\tvalid_1's binary_logloss: 0.139381\n",
            "[19]\ttraining's auc: 0.872527\ttraining's binary_logloss: 0.126149\tvalid_1's auc: 0.835271\tvalid_1's binary_logloss: 0.138999\n",
            "[20]\ttraining's auc: 0.87325\ttraining's binary_logloss: 0.125512\tvalid_1's auc: 0.83534\tvalid_1's binary_logloss: 0.138678\n",
            "[21]\ttraining's auc: 0.875025\ttraining's binary_logloss: 0.12486\tvalid_1's auc: 0.834961\tvalid_1's binary_logloss: 0.138428\n",
            "[22]\ttraining's auc: 0.876516\ttraining's binary_logloss: 0.124242\tvalid_1's auc: 0.836042\tvalid_1's binary_logloss: 0.138109\n",
            "[23]\ttraining's auc: 0.878653\ttraining's binary_logloss: 0.123676\tvalid_1's auc: 0.835883\tvalid_1's binary_logloss: 0.137924\n",
            "[24]\ttraining's auc: 0.880507\ttraining's binary_logloss: 0.123115\tvalid_1's auc: 0.836264\tvalid_1's binary_logloss: 0.137749\n",
            "[25]\ttraining's auc: 0.881679\ttraining's binary_logloss: 0.12257\tvalid_1's auc: 0.83597\tvalid_1's binary_logloss: 0.137678\n",
            "[26]\ttraining's auc: 0.884463\ttraining's binary_logloss: 0.121943\tvalid_1's auc: 0.835778\tvalid_1's binary_logloss: 0.137516\n",
            "[27]\ttraining's auc: 0.885503\ttraining's binary_logloss: 0.121478\tvalid_1's auc: 0.836399\tvalid_1's binary_logloss: 0.137343\n",
            "[28]\ttraining's auc: 0.887181\ttraining's binary_logloss: 0.120972\tvalid_1's auc: 0.83667\tvalid_1's binary_logloss: 0.137172\n",
            "[29]\ttraining's auc: 0.888596\ttraining's binary_logloss: 0.12051\tvalid_1's auc: 0.836532\tvalid_1's binary_logloss: 0.137084\n",
            "[30]\ttraining's auc: 0.889972\ttraining's binary_logloss: 0.120054\tvalid_1's auc: 0.836709\tvalid_1's binary_logloss: 0.136985\n",
            "[31]\ttraining's auc: 0.890737\ttraining's binary_logloss: 0.119642\tvalid_1's auc: 0.836918\tvalid_1's binary_logloss: 0.136841\n",
            "[32]\ttraining's auc: 0.891592\ttraining's binary_logloss: 0.119278\tvalid_1's auc: 0.836626\tvalid_1's binary_logloss: 0.136815\n",
            "[33]\ttraining's auc: 0.892511\ttraining's binary_logloss: 0.118897\tvalid_1's auc: 0.836587\tvalid_1's binary_logloss: 0.136717\n",
            "[34]\ttraining's auc: 0.893369\ttraining's binary_logloss: 0.118535\tvalid_1's auc: 0.836617\tvalid_1's binary_logloss: 0.136659\n",
            "[35]\ttraining's auc: 0.894488\ttraining's binary_logloss: 0.118146\tvalid_1's auc: 0.836599\tvalid_1's binary_logloss: 0.136544\n",
            "[36]\ttraining's auc: 0.895738\ttraining's binary_logloss: 0.117732\tvalid_1's auc: 0.83641\tvalid_1's binary_logloss: 0.136513\n",
            "[37]\ttraining's auc: 0.896771\ttraining's binary_logloss: 0.11737\tvalid_1's auc: 0.836209\tvalid_1's binary_logloss: 0.1365\n",
            "[38]\ttraining's auc: 0.897487\ttraining's binary_logloss: 0.117034\tvalid_1's auc: 0.835996\tvalid_1's binary_logloss: 0.136494\n",
            "[39]\ttraining's auc: 0.898282\ttraining's binary_logloss: 0.116702\tvalid_1's auc: 0.836052\tvalid_1's binary_logloss: 0.136477\n",
            "[40]\ttraining's auc: 0.899513\ttraining's binary_logloss: 0.116382\tvalid_1's auc: 0.835665\tvalid_1's binary_logloss: 0.136461\n",
            "[41]\ttraining's auc: 0.900158\ttraining's binary_logloss: 0.116091\tvalid_1's auc: 0.835604\tvalid_1's binary_logloss: 0.13646\n",
            "[42]\ttraining's auc: 0.900583\ttraining's binary_logloss: 0.115853\tvalid_1's auc: 0.835649\tvalid_1's binary_logloss: 0.136426\n",
            "[43]\ttraining's auc: 0.901444\ttraining's binary_logloss: 0.115581\tvalid_1's auc: 0.835743\tvalid_1's binary_logloss: 0.136402\n",
            "[44]\ttraining's auc: 0.902459\ttraining's binary_logloss: 0.115212\tvalid_1's auc: 0.835821\tvalid_1's binary_logloss: 0.136388\n",
            "[45]\ttraining's auc: 0.902967\ttraining's binary_logloss: 0.114973\tvalid_1's auc: 0.835736\tvalid_1's binary_logloss: 0.136351\n",
            "[46]\ttraining's auc: 0.903497\ttraining's binary_logloss: 0.114705\tvalid_1's auc: 0.836057\tvalid_1's binary_logloss: 0.136307\n",
            "[47]\ttraining's auc: 0.904035\ttraining's binary_logloss: 0.114448\tvalid_1's auc: 0.835787\tvalid_1's binary_logloss: 0.136354\n",
            "[48]\ttraining's auc: 0.904609\ttraining's binary_logloss: 0.114235\tvalid_1's auc: 0.835438\tvalid_1's binary_logloss: 0.136365\n",
            "[49]\ttraining's auc: 0.905652\ttraining's binary_logloss: 0.113886\tvalid_1's auc: 0.835622\tvalid_1's binary_logloss: 0.136344\n",
            "[50]\ttraining's auc: 0.906458\ttraining's binary_logloss: 0.113569\tvalid_1's auc: 0.835369\tvalid_1's binary_logloss: 0.136385\n",
            "[51]\ttraining's auc: 0.907097\ttraining's binary_logloss: 0.113318\tvalid_1's auc: 0.83559\tvalid_1's binary_logloss: 0.136365\n",
            "[52]\ttraining's auc: 0.90793\ttraining's binary_logloss: 0.112967\tvalid_1's auc: 0.835747\tvalid_1's binary_logloss: 0.136368\n",
            "[53]\ttraining's auc: 0.908591\ttraining's binary_logloss: 0.112641\tvalid_1's auc: 0.835581\tvalid_1's binary_logloss: 0.136373\n",
            "[54]\ttraining's auc: 0.90907\ttraining's binary_logloss: 0.11239\tvalid_1's auc: 0.835783\tvalid_1's binary_logloss: 0.136375\n",
            "[55]\ttraining's auc: 0.909721\ttraining's binary_logloss: 0.112129\tvalid_1's auc: 0.835733\tvalid_1's binary_logloss: 0.136382\n",
            "[56]\ttraining's auc: 0.910437\ttraining's binary_logloss: 0.111837\tvalid_1's auc: 0.835501\tvalid_1's binary_logloss: 0.136455\n",
            "[57]\ttraining's auc: 0.911057\ttraining's binary_logloss: 0.111601\tvalid_1's auc: 0.83552\tvalid_1's binary_logloss: 0.136455\n",
            "[58]\ttraining's auc: 0.911525\ttraining's binary_logloss: 0.111366\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.136463\n",
            "[59]\ttraining's auc: 0.912273\ttraining's binary_logloss: 0.111061\tvalid_1's auc: 0.835324\tvalid_1's binary_logloss: 0.136497\n",
            "[60]\ttraining's auc: 0.912608\ttraining's binary_logloss: 0.110869\tvalid_1's auc: 0.83519\tvalid_1's binary_logloss: 0.136518\n",
            "[61]\ttraining's auc: 0.913081\ttraining's binary_logloss: 0.110685\tvalid_1's auc: 0.835311\tvalid_1's binary_logloss: 0.136513\n",
            " 62%|██████▏   | 31/50 [15:48<12:06, 38.22s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.157569\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.159635\n",
            "[2]\ttraining's auc: 0.833814\ttraining's binary_logloss: 0.152823\tvalid_1's auc: 0.808075\tvalid_1's binary_logloss: 0.155835\n",
            "[3]\ttraining's auc: 0.837105\ttraining's binary_logloss: 0.149099\tvalid_1's auc: 0.809562\tvalid_1's binary_logloss: 0.153103\n",
            "[4]\ttraining's auc: 0.84304\ttraining's binary_logloss: 0.146081\tvalid_1's auc: 0.814181\tvalid_1's binary_logloss: 0.150838\n",
            "[5]\ttraining's auc: 0.84612\ttraining's binary_logloss: 0.143676\tvalid_1's auc: 0.8168\tvalid_1's binary_logloss: 0.148944\n",
            "[6]\ttraining's auc: 0.849254\ttraining's binary_logloss: 0.141447\tvalid_1's auc: 0.818054\tvalid_1's binary_logloss: 0.14735\n",
            "[7]\ttraining's auc: 0.851052\ttraining's binary_logloss: 0.139585\tvalid_1's auc: 0.818412\tvalid_1's binary_logloss: 0.146059\n",
            "[8]\ttraining's auc: 0.851983\ttraining's binary_logloss: 0.137934\tvalid_1's auc: 0.818989\tvalid_1's binary_logloss: 0.144858\n",
            "[9]\ttraining's auc: 0.853273\ttraining's binary_logloss: 0.136424\tvalid_1's auc: 0.819769\tvalid_1's binary_logloss: 0.143801\n",
            "[10]\ttraining's auc: 0.855384\ttraining's binary_logloss: 0.135096\tvalid_1's auc: 0.820972\tvalid_1's binary_logloss: 0.142849\n",
            "[11]\ttraining's auc: 0.856509\ttraining's binary_logloss: 0.133899\tvalid_1's auc: 0.821698\tvalid_1's binary_logloss: 0.142062\n",
            "[12]\ttraining's auc: 0.860096\ttraining's binary_logloss: 0.132739\tvalid_1's auc: 0.822414\tvalid_1's binary_logloss: 0.141316\n",
            "[13]\ttraining's auc: 0.862926\ttraining's binary_logloss: 0.131722\tvalid_1's auc: 0.823881\tvalid_1's binary_logloss: 0.140696\n",
            "[14]\ttraining's auc: 0.864612\ttraining's binary_logloss: 0.130737\tvalid_1's auc: 0.825946\tvalid_1's binary_logloss: 0.140075\n",
            "[15]\ttraining's auc: 0.867588\ttraining's binary_logloss: 0.129873\tvalid_1's auc: 0.826621\tvalid_1's binary_logloss: 0.139611\n",
            "[16]\ttraining's auc: 0.868579\ttraining's binary_logloss: 0.129077\tvalid_1's auc: 0.827064\tvalid_1's binary_logloss: 0.13921\n",
            "[17]\ttraining's auc: 0.870643\ttraining's binary_logloss: 0.128267\tvalid_1's auc: 0.82769\tvalid_1's binary_logloss: 0.138857\n",
            "[18]\ttraining's auc: 0.872074\ttraining's binary_logloss: 0.127521\tvalid_1's auc: 0.828236\tvalid_1's binary_logloss: 0.138506\n",
            "[19]\ttraining's auc: 0.873489\ttraining's binary_logloss: 0.126802\tvalid_1's auc: 0.828331\tvalid_1's binary_logloss: 0.138221\n",
            "[20]\ttraining's auc: 0.874451\ttraining's binary_logloss: 0.126158\tvalid_1's auc: 0.828377\tvalid_1's binary_logloss: 0.138013\n",
            "[21]\ttraining's auc: 0.87648\ttraining's binary_logloss: 0.125552\tvalid_1's auc: 0.828076\tvalid_1's binary_logloss: 0.137834\n",
            "[22]\ttraining's auc: 0.878043\ttraining's binary_logloss: 0.124954\tvalid_1's auc: 0.828573\tvalid_1's binary_logloss: 0.137642\n",
            "[23]\ttraining's auc: 0.879375\ttraining's binary_logloss: 0.12437\tvalid_1's auc: 0.829235\tvalid_1's binary_logloss: 0.137339\n",
            "[24]\ttraining's auc: 0.881862\ttraining's binary_logloss: 0.123752\tvalid_1's auc: 0.828971\tvalid_1's binary_logloss: 0.137209\n",
            "[25]\ttraining's auc: 0.882853\ttraining's binary_logloss: 0.123226\tvalid_1's auc: 0.82909\tvalid_1's binary_logloss: 0.137057\n",
            "[26]\ttraining's auc: 0.884135\ttraining's binary_logloss: 0.122691\tvalid_1's auc: 0.829866\tvalid_1's binary_logloss: 0.136866\n",
            "[27]\ttraining's auc: 0.885259\ttraining's binary_logloss: 0.122236\tvalid_1's auc: 0.829726\tvalid_1's binary_logloss: 0.136797\n",
            "[28]\ttraining's auc: 0.88579\ttraining's binary_logloss: 0.121845\tvalid_1's auc: 0.830373\tvalid_1's binary_logloss: 0.136589\n",
            "[29]\ttraining's auc: 0.88648\ttraining's binary_logloss: 0.121394\tvalid_1's auc: 0.830434\tvalid_1's binary_logloss: 0.136502\n",
            "[30]\ttraining's auc: 0.887884\ttraining's binary_logloss: 0.120949\tvalid_1's auc: 0.830175\tvalid_1's binary_logloss: 0.136459\n",
            "[31]\ttraining's auc: 0.888726\ttraining's binary_logloss: 0.120594\tvalid_1's auc: 0.830308\tvalid_1's binary_logloss: 0.136385\n",
            "[32]\ttraining's auc: 0.890323\ttraining's binary_logloss: 0.120089\tvalid_1's auc: 0.830645\tvalid_1's binary_logloss: 0.13624\n",
            "[33]\ttraining's auc: 0.891207\ttraining's binary_logloss: 0.119699\tvalid_1's auc: 0.830521\tvalid_1's binary_logloss: 0.136202\n",
            "[34]\ttraining's auc: 0.891782\ttraining's binary_logloss: 0.119354\tvalid_1's auc: 0.830714\tvalid_1's binary_logloss: 0.136144\n",
            "[35]\ttraining's auc: 0.893516\ttraining's binary_logloss: 0.118934\tvalid_1's auc: 0.830894\tvalid_1's binary_logloss: 0.136048\n",
            "[36]\ttraining's auc: 0.894692\ttraining's binary_logloss: 0.11858\tvalid_1's auc: 0.830851\tvalid_1's binary_logloss: 0.135986\n",
            "[37]\ttraining's auc: 0.89547\ttraining's binary_logloss: 0.118227\tvalid_1's auc: 0.830915\tvalid_1's binary_logloss: 0.135958\n",
            "[38]\ttraining's auc: 0.897113\ttraining's binary_logloss: 0.117802\tvalid_1's auc: 0.830634\tvalid_1's binary_logloss: 0.135974\n",
            "[39]\ttraining's auc: 0.898801\ttraining's binary_logloss: 0.117386\tvalid_1's auc: 0.831294\tvalid_1's binary_logloss: 0.135837\n",
            "[40]\ttraining's auc: 0.899393\ttraining's binary_logloss: 0.117068\tvalid_1's auc: 0.831507\tvalid_1's binary_logloss: 0.135781\n",
            "[41]\ttraining's auc: 0.899975\ttraining's binary_logloss: 0.116741\tvalid_1's auc: 0.831182\tvalid_1's binary_logloss: 0.135843\n",
            "[42]\ttraining's auc: 0.900814\ttraining's binary_logloss: 0.116416\tvalid_1's auc: 0.830765\tvalid_1's binary_logloss: 0.135917\n",
            "[43]\ttraining's auc: 0.90154\ttraining's binary_logloss: 0.116124\tvalid_1's auc: 0.830741\tvalid_1's binary_logloss: 0.135905\n",
            "[44]\ttraining's auc: 0.902211\ttraining's binary_logloss: 0.115828\tvalid_1's auc: 0.830746\tvalid_1's binary_logloss: 0.135908\n",
            "[45]\ttraining's auc: 0.902779\ttraining's binary_logloss: 0.11556\tvalid_1's auc: 0.830903\tvalid_1's binary_logloss: 0.135876\n",
            "[46]\ttraining's auc: 0.903843\ttraining's binary_logloss: 0.115259\tvalid_1's auc: 0.831208\tvalid_1's binary_logloss: 0.135831\n",
            "[47]\ttraining's auc: 0.904638\ttraining's binary_logloss: 0.114968\tvalid_1's auc: 0.83109\tvalid_1's binary_logloss: 0.135846\n",
            "[48]\ttraining's auc: 0.905141\ttraining's binary_logloss: 0.114697\tvalid_1's auc: 0.831119\tvalid_1's binary_logloss: 0.135853\n",
            "[49]\ttraining's auc: 0.90561\ttraining's binary_logloss: 0.114457\tvalid_1's auc: 0.831166\tvalid_1's binary_logloss: 0.135846\n",
            "[50]\ttraining's auc: 0.906096\ttraining's binary_logloss: 0.1142\tvalid_1's auc: 0.831206\tvalid_1's binary_logloss: 0.135854\n",
            "[51]\ttraining's auc: 0.90661\ttraining's binary_logloss: 0.113918\tvalid_1's auc: 0.83101\tvalid_1's binary_logloss: 0.135901\n",
            "[52]\ttraining's auc: 0.907474\ttraining's binary_logloss: 0.11364\tvalid_1's auc: 0.830837\tvalid_1's binary_logloss: 0.135956\n",
            "[53]\ttraining's auc: 0.907985\ttraining's binary_logloss: 0.113395\tvalid_1's auc: 0.830893\tvalid_1's binary_logloss: 0.135952\n",
            "[54]\ttraining's auc: 0.908904\ttraining's binary_logloss: 0.11309\tvalid_1's auc: 0.83084\tvalid_1's binary_logloss: 0.135932\n",
            "[55]\ttraining's auc: 0.909657\ttraining's binary_logloss: 0.112855\tvalid_1's auc: 0.830884\tvalid_1's binary_logloss: 0.13591\n",
            "[56]\ttraining's auc: 0.910074\ttraining's binary_logloss: 0.112599\tvalid_1's auc: 0.831011\tvalid_1's binary_logloss: 0.13593\n",
            "[57]\ttraining's auc: 0.910591\ttraining's binary_logloss: 0.112337\tvalid_1's auc: 0.830698\tvalid_1's binary_logloss: 0.135976\n",
            "[58]\ttraining's auc: 0.911161\ttraining's binary_logloss: 0.112113\tvalid_1's auc: 0.830624\tvalid_1's binary_logloss: 0.135998\n",
            "[59]\ttraining's auc: 0.911691\ttraining's binary_logloss: 0.111876\tvalid_1's auc: 0.830593\tvalid_1's binary_logloss: 0.136023\n",
            "[60]\ttraining's auc: 0.912183\ttraining's binary_logloss: 0.111632\tvalid_1's auc: 0.830587\tvalid_1's binary_logloss: 0.136006\n",
            "[61]\ttraining's auc: 0.912767\ttraining's binary_logloss: 0.111381\tvalid_1's auc: 0.830349\tvalid_1's binary_logloss: 0.136075\n",
            "[62]\ttraining's auc: 0.913561\ttraining's binary_logloss: 0.111128\tvalid_1's auc: 0.830264\tvalid_1's binary_logloss: 0.136105\n",
            "[63]\ttraining's auc: 0.913881\ttraining's binary_logloss: 0.110949\tvalid_1's auc: 0.830078\tvalid_1's binary_logloss: 0.13614\n",
            "[64]\ttraining's auc: 0.914252\ttraining's binary_logloss: 0.110769\tvalid_1's auc: 0.829822\tvalid_1's binary_logloss: 0.136202\n",
            "[65]\ttraining's auc: 0.914455\ttraining's binary_logloss: 0.110636\tvalid_1's auc: 0.829644\tvalid_1's binary_logloss: 0.136231\n",
            "[66]\ttraining's auc: 0.915157\ttraining's binary_logloss: 0.110363\tvalid_1's auc: 0.829611\tvalid_1's binary_logloss: 0.136254\n",
            "[67]\ttraining's auc: 0.915641\ttraining's binary_logloss: 0.110178\tvalid_1's auc: 0.829642\tvalid_1's binary_logloss: 0.136278\n",
            "[68]\ttraining's auc: 0.916068\ttraining's binary_logloss: 0.109953\tvalid_1's auc: 0.82931\tvalid_1's binary_logloss: 0.136358\n",
            "[69]\ttraining's auc: 0.916527\ttraining's binary_logloss: 0.109773\tvalid_1's auc: 0.829341\tvalid_1's binary_logloss: 0.136359\n",
            "[70]\ttraining's auc: 0.916873\ttraining's binary_logloss: 0.109591\tvalid_1's auc: 0.829212\tvalid_1's binary_logloss: 0.136396\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 62%|██████▏   | 31/50 [15:57<12:06, 38.22s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.159976\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.155399\n",
            "[2]\ttraining's auc: 0.826638\ttraining's binary_logloss: 0.155122\tvalid_1's auc: 0.816063\tvalid_1's binary_logloss: 0.151669\n",
            "[3]\ttraining's auc: 0.83236\ttraining's binary_logloss: 0.151359\tvalid_1's auc: 0.817457\tvalid_1's binary_logloss: 0.148802\n",
            "[4]\ttraining's auc: 0.838866\ttraining's binary_logloss: 0.148268\tvalid_1's auc: 0.820008\tvalid_1's binary_logloss: 0.146443\n",
            "[5]\ttraining's auc: 0.845174\ttraining's binary_logloss: 0.145627\tvalid_1's auc: 0.825357\tvalid_1's binary_logloss: 0.144496\n",
            "[6]\ttraining's auc: 0.848861\ttraining's binary_logloss: 0.143398\tvalid_1's auc: 0.827715\tvalid_1's binary_logloss: 0.142943\n",
            "[7]\ttraining's auc: 0.851992\ttraining's binary_logloss: 0.141509\tvalid_1's auc: 0.828745\tvalid_1's binary_logloss: 0.141522\n",
            "[8]\ttraining's auc: 0.854373\ttraining's binary_logloss: 0.139838\tvalid_1's auc: 0.829402\tvalid_1's binary_logloss: 0.140347\n",
            "[9]\ttraining's auc: 0.856963\ttraining's binary_logloss: 0.138298\tvalid_1's auc: 0.832575\tvalid_1's binary_logloss: 0.139199\n",
            "[10]\ttraining's auc: 0.859503\ttraining's binary_logloss: 0.136888\tvalid_1's auc: 0.832226\tvalid_1's binary_logloss: 0.138268\n",
            "[11]\ttraining's auc: 0.860667\ttraining's binary_logloss: 0.13564\tvalid_1's auc: 0.831743\tvalid_1's binary_logloss: 0.137552\n",
            "[12]\ttraining's auc: 0.862141\ttraining's binary_logloss: 0.134493\tvalid_1's auc: 0.832334\tvalid_1's binary_logloss: 0.136831\n",
            "[13]\ttraining's auc: 0.8652\ttraining's binary_logloss: 0.133389\tvalid_1's auc: 0.83279\tvalid_1's binary_logloss: 0.136257\n",
            "[14]\ttraining's auc: 0.867288\ttraining's binary_logloss: 0.132396\tvalid_1's auc: 0.833165\tvalid_1's binary_logloss: 0.135714\n",
            "[15]\ttraining's auc: 0.86913\ttraining's binary_logloss: 0.131489\tvalid_1's auc: 0.834196\tvalid_1's binary_logloss: 0.135236\n",
            "[16]\ttraining's auc: 0.870978\ttraining's binary_logloss: 0.130631\tvalid_1's auc: 0.833978\tvalid_1's binary_logloss: 0.134845\n",
            "[17]\ttraining's auc: 0.872238\ttraining's binary_logloss: 0.129845\tvalid_1's auc: 0.834414\tvalid_1's binary_logloss: 0.134422\n",
            "[18]\ttraining's auc: 0.873539\ttraining's binary_logloss: 0.129069\tvalid_1's auc: 0.834242\tvalid_1's binary_logloss: 0.134055\n",
            "[19]\ttraining's auc: 0.874555\ttraining's binary_logloss: 0.128393\tvalid_1's auc: 0.833967\tvalid_1's binary_logloss: 0.133798\n",
            "[20]\ttraining's auc: 0.875467\ttraining's binary_logloss: 0.127779\tvalid_1's auc: 0.834072\tvalid_1's binary_logloss: 0.133496\n",
            "[21]\ttraining's auc: 0.87643\ttraining's binary_logloss: 0.127154\tvalid_1's auc: 0.834167\tvalid_1's binary_logloss: 0.133261\n",
            "[22]\ttraining's auc: 0.878336\ttraining's binary_logloss: 0.12655\tvalid_1's auc: 0.834419\tvalid_1's binary_logloss: 0.133059\n",
            "[23]\ttraining's auc: 0.879123\ttraining's binary_logloss: 0.125998\tvalid_1's auc: 0.834233\tvalid_1's binary_logloss: 0.132875\n",
            "[24]\ttraining's auc: 0.880219\ttraining's binary_logloss: 0.12546\tvalid_1's auc: 0.834216\tvalid_1's binary_logloss: 0.132711\n",
            "[25]\ttraining's auc: 0.881658\ttraining's binary_logloss: 0.124883\tvalid_1's auc: 0.834583\tvalid_1's binary_logloss: 0.1325\n",
            "[26]\ttraining's auc: 0.882357\ttraining's binary_logloss: 0.124407\tvalid_1's auc: 0.834436\tvalid_1's binary_logloss: 0.132371\n",
            "[27]\ttraining's auc: 0.883202\ttraining's binary_logloss: 0.123928\tvalid_1's auc: 0.833944\tvalid_1's binary_logloss: 0.132297\n",
            "[28]\ttraining's auc: 0.884363\ttraining's binary_logloss: 0.123447\tvalid_1's auc: 0.834352\tvalid_1's binary_logloss: 0.132155\n",
            "[29]\ttraining's auc: 0.885943\ttraining's binary_logloss: 0.122956\tvalid_1's auc: 0.835007\tvalid_1's binary_logloss: 0.132017\n",
            "[30]\ttraining's auc: 0.887312\ttraining's binary_logloss: 0.1225\tvalid_1's auc: 0.834725\tvalid_1's binary_logloss: 0.131928\n",
            "[31]\ttraining's auc: 0.888514\ttraining's binary_logloss: 0.122087\tvalid_1's auc: 0.834419\tvalid_1's binary_logloss: 0.131873\n",
            "[32]\ttraining's auc: 0.889227\ttraining's binary_logloss: 0.121699\tvalid_1's auc: 0.834348\tvalid_1's binary_logloss: 0.131825\n",
            "[33]\ttraining's auc: 0.88996\ttraining's binary_logloss: 0.121292\tvalid_1's auc: 0.834295\tvalid_1's binary_logloss: 0.131777\n",
            "[34]\ttraining's auc: 0.891249\ttraining's binary_logloss: 0.120798\tvalid_1's auc: 0.83468\tvalid_1's binary_logloss: 0.131693\n",
            "[35]\ttraining's auc: 0.892472\ttraining's binary_logloss: 0.12043\tvalid_1's auc: 0.834796\tvalid_1's binary_logloss: 0.131616\n",
            "[36]\ttraining's auc: 0.893499\ttraining's binary_logloss: 0.120076\tvalid_1's auc: 0.834927\tvalid_1's binary_logloss: 0.131527\n",
            "[37]\ttraining's auc: 0.894443\ttraining's binary_logloss: 0.119737\tvalid_1's auc: 0.834851\tvalid_1's binary_logloss: 0.131474\n",
            "[38]\ttraining's auc: 0.894998\ttraining's binary_logloss: 0.119391\tvalid_1's auc: 0.834736\tvalid_1's binary_logloss: 0.131445\n",
            "[39]\ttraining's auc: 0.896091\ttraining's binary_logloss: 0.119054\tvalid_1's auc: 0.834528\tvalid_1's binary_logloss: 0.131431\n",
            "[40]\ttraining's auc: 0.896996\ttraining's binary_logloss: 0.118704\tvalid_1's auc: 0.834482\tvalid_1's binary_logloss: 0.13141\n",
            "[41]\ttraining's auc: 0.897633\ttraining's binary_logloss: 0.118451\tvalid_1's auc: 0.834852\tvalid_1's binary_logloss: 0.131328\n",
            "[42]\ttraining's auc: 0.899504\ttraining's binary_logloss: 0.118092\tvalid_1's auc: 0.83454\tvalid_1's binary_logloss: 0.131337\n",
            "[43]\ttraining's auc: 0.900591\ttraining's binary_logloss: 0.117807\tvalid_1's auc: 0.834549\tvalid_1's binary_logloss: 0.131337\n",
            "[44]\ttraining's auc: 0.90189\ttraining's binary_logloss: 0.117442\tvalid_1's auc: 0.834559\tvalid_1's binary_logloss: 0.131315\n",
            "[45]\ttraining's auc: 0.902495\ttraining's binary_logloss: 0.11719\tvalid_1's auc: 0.834601\tvalid_1's binary_logloss: 0.131284\n",
            "[46]\ttraining's auc: 0.903059\ttraining's binary_logloss: 0.116886\tvalid_1's auc: 0.834836\tvalid_1's binary_logloss: 0.131227\n",
            "[47]\ttraining's auc: 0.903854\ttraining's binary_logloss: 0.116629\tvalid_1's auc: 0.834729\tvalid_1's binary_logloss: 0.131218\n",
            "[48]\ttraining's auc: 0.904612\ttraining's binary_logloss: 0.11635\tvalid_1's auc: 0.834554\tvalid_1's binary_logloss: 0.131226\n",
            "[49]\ttraining's auc: 0.905306\ttraining's binary_logloss: 0.116056\tvalid_1's auc: 0.834459\tvalid_1's binary_logloss: 0.131248\n",
            "[50]\ttraining's auc: 0.905758\ttraining's binary_logloss: 0.115797\tvalid_1's auc: 0.834269\tvalid_1's binary_logloss: 0.131261\n",
            "[51]\ttraining's auc: 0.906872\ttraining's binary_logloss: 0.115438\tvalid_1's auc: 0.834599\tvalid_1's binary_logloss: 0.131216\n",
            "[52]\ttraining's auc: 0.907379\ttraining's binary_logloss: 0.115151\tvalid_1's auc: 0.834528\tvalid_1's binary_logloss: 0.131242\n",
            "[53]\ttraining's auc: 0.90795\ttraining's binary_logloss: 0.114947\tvalid_1's auc: 0.834596\tvalid_1's binary_logloss: 0.131218\n",
            "[54]\ttraining's auc: 0.908479\ttraining's binary_logloss: 0.114643\tvalid_1's auc: 0.834707\tvalid_1's binary_logloss: 0.131222\n",
            "[55]\ttraining's auc: 0.909145\ttraining's binary_logloss: 0.114413\tvalid_1's auc: 0.834908\tvalid_1's binary_logloss: 0.131205\n",
            "[56]\ttraining's auc: 0.909895\ttraining's binary_logloss: 0.114133\tvalid_1's auc: 0.834747\tvalid_1's binary_logloss: 0.131232\n",
            "[57]\ttraining's auc: 0.910265\ttraining's binary_logloss: 0.113931\tvalid_1's auc: 0.834637\tvalid_1's binary_logloss: 0.131266\n",
            "[58]\ttraining's auc: 0.910844\ttraining's binary_logloss: 0.113702\tvalid_1's auc: 0.834505\tvalid_1's binary_logloss: 0.131284\n",
            "[59]\ttraining's auc: 0.911365\ttraining's binary_logloss: 0.113468\tvalid_1's auc: 0.834428\tvalid_1's binary_logloss: 0.131287\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 62%|██████▏   | 31/50 [16:06<12:06, 38.22s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.156544\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.162603\n",
            "[2]\ttraining's auc: 0.832575\ttraining's binary_logloss: 0.151847\tvalid_1's auc: 0.815421\tvalid_1's binary_logloss: 0.158353\n",
            "[3]\ttraining's auc: 0.837703\ttraining's binary_logloss: 0.148222\tvalid_1's auc: 0.817988\tvalid_1's binary_logloss: 0.155228\n",
            "[4]\ttraining's auc: 0.840798\ttraining's binary_logloss: 0.145296\tvalid_1's auc: 0.819554\tvalid_1's binary_logloss: 0.152721\n",
            "[5]\ttraining's auc: 0.84521\ttraining's binary_logloss: 0.142808\tvalid_1's auc: 0.822886\tvalid_1's binary_logloss: 0.150632\n",
            "[6]\ttraining's auc: 0.848547\ttraining's binary_logloss: 0.140587\tvalid_1's auc: 0.826007\tvalid_1's binary_logloss: 0.148826\n",
            "[7]\ttraining's auc: 0.849968\ttraining's binary_logloss: 0.138668\tvalid_1's auc: 0.827\tvalid_1's binary_logloss: 0.147287\n",
            "[8]\ttraining's auc: 0.852731\ttraining's binary_logloss: 0.13704\tvalid_1's auc: 0.828754\tvalid_1's binary_logloss: 0.146064\n",
            "[9]\ttraining's auc: 0.854908\ttraining's binary_logloss: 0.135547\tvalid_1's auc: 0.829179\tvalid_1's binary_logloss: 0.144944\n",
            "[10]\ttraining's auc: 0.856157\ttraining's binary_logloss: 0.13422\tvalid_1's auc: 0.829911\tvalid_1's binary_logloss: 0.143975\n",
            "[11]\ttraining's auc: 0.857969\ttraining's binary_logloss: 0.133012\tvalid_1's auc: 0.829789\tvalid_1's binary_logloss: 0.143145\n",
            "[12]\ttraining's auc: 0.859748\ttraining's binary_logloss: 0.131955\tvalid_1's auc: 0.830576\tvalid_1's binary_logloss: 0.142401\n",
            "[13]\ttraining's auc: 0.862116\ttraining's binary_logloss: 0.130974\tvalid_1's auc: 0.830734\tvalid_1's binary_logloss: 0.14176\n",
            "[14]\ttraining's auc: 0.864349\ttraining's binary_logloss: 0.129991\tvalid_1's auc: 0.830818\tvalid_1's binary_logloss: 0.141213\n",
            "[15]\ttraining's auc: 0.866023\ttraining's binary_logloss: 0.129146\tvalid_1's auc: 0.83092\tvalid_1's binary_logloss: 0.140715\n",
            "[16]\ttraining's auc: 0.868677\ttraining's binary_logloss: 0.128338\tvalid_1's auc: 0.833436\tvalid_1's binary_logloss: 0.140291\n",
            "[17]\ttraining's auc: 0.869984\ttraining's binary_logloss: 0.127543\tvalid_1's auc: 0.834095\tvalid_1's binary_logloss: 0.139784\n",
            "[18]\ttraining's auc: 0.871263\ttraining's binary_logloss: 0.126855\tvalid_1's auc: 0.83481\tvalid_1's binary_logloss: 0.139388\n",
            "[19]\ttraining's auc: 0.872522\ttraining's binary_logloss: 0.126163\tvalid_1's auc: 0.835268\tvalid_1's binary_logloss: 0.139005\n",
            "[20]\ttraining's auc: 0.873247\ttraining's binary_logloss: 0.125526\tvalid_1's auc: 0.835339\tvalid_1's binary_logloss: 0.138685\n",
            "[21]\ttraining's auc: 0.875021\ttraining's binary_logloss: 0.124874\tvalid_1's auc: 0.834979\tvalid_1's binary_logloss: 0.138433\n",
            "[22]\ttraining's auc: 0.876505\ttraining's binary_logloss: 0.124256\tvalid_1's auc: 0.836045\tvalid_1's binary_logloss: 0.138115\n",
            "[23]\ttraining's auc: 0.878647\ttraining's binary_logloss: 0.12369\tvalid_1's auc: 0.835889\tvalid_1's binary_logloss: 0.137929\n",
            "[24]\ttraining's auc: 0.880492\ttraining's binary_logloss: 0.123129\tvalid_1's auc: 0.836265\tvalid_1's binary_logloss: 0.137753\n",
            "[25]\ttraining's auc: 0.881672\ttraining's binary_logloss: 0.122584\tvalid_1's auc: 0.835974\tvalid_1's binary_logloss: 0.137683\n",
            "[26]\ttraining's auc: 0.884457\ttraining's binary_logloss: 0.121957\tvalid_1's auc: 0.835784\tvalid_1's binary_logloss: 0.137519\n",
            "[27]\ttraining's auc: 0.88549\ttraining's binary_logloss: 0.121492\tvalid_1's auc: 0.836397\tvalid_1's binary_logloss: 0.137347\n",
            "[28]\ttraining's auc: 0.886854\ttraining's binary_logloss: 0.121033\tvalid_1's auc: 0.836159\tvalid_1's binary_logloss: 0.137237\n",
            "[29]\ttraining's auc: 0.887733\ttraining's binary_logloss: 0.120577\tvalid_1's auc: 0.836701\tvalid_1's binary_logloss: 0.137066\n",
            "[30]\ttraining's auc: 0.889155\ttraining's binary_logloss: 0.12014\tvalid_1's auc: 0.83679\tvalid_1's binary_logloss: 0.136958\n",
            "[31]\ttraining's auc: 0.890053\ttraining's binary_logloss: 0.119729\tvalid_1's auc: 0.83712\tvalid_1's binary_logloss: 0.136839\n",
            "[32]\ttraining's auc: 0.890826\ttraining's binary_logloss: 0.119348\tvalid_1's auc: 0.837288\tvalid_1's binary_logloss: 0.136703\n",
            "[33]\ttraining's auc: 0.891792\ttraining's binary_logloss: 0.118996\tvalid_1's auc: 0.836905\tvalid_1's binary_logloss: 0.136666\n",
            "[34]\ttraining's auc: 0.892538\ttraining's binary_logloss: 0.118632\tvalid_1's auc: 0.837054\tvalid_1's binary_logloss: 0.136612\n",
            "[35]\ttraining's auc: 0.893411\ttraining's binary_logloss: 0.118292\tvalid_1's auc: 0.836928\tvalid_1's binary_logloss: 0.136542\n",
            "[36]\ttraining's auc: 0.894495\ttraining's binary_logloss: 0.117935\tvalid_1's auc: 0.836767\tvalid_1's binary_logloss: 0.136487\n",
            "[37]\ttraining's auc: 0.895562\ttraining's binary_logloss: 0.117529\tvalid_1's auc: 0.836279\tvalid_1's binary_logloss: 0.1365\n",
            "[38]\ttraining's auc: 0.896455\ttraining's binary_logloss: 0.117181\tvalid_1's auc: 0.836352\tvalid_1's binary_logloss: 0.136451\n",
            "[39]\ttraining's auc: 0.897178\ttraining's binary_logloss: 0.116889\tvalid_1's auc: 0.836053\tvalid_1's binary_logloss: 0.136456\n",
            "[40]\ttraining's auc: 0.898331\ttraining's binary_logloss: 0.116498\tvalid_1's auc: 0.835902\tvalid_1's binary_logloss: 0.136446\n",
            "[41]\ttraining's auc: 0.899487\ttraining's binary_logloss: 0.116131\tvalid_1's auc: 0.835729\tvalid_1's binary_logloss: 0.136453\n",
            "[42]\ttraining's auc: 0.900586\ttraining's binary_logloss: 0.115772\tvalid_1's auc: 0.835716\tvalid_1's binary_logloss: 0.136448\n",
            "[43]\ttraining's auc: 0.901142\ttraining's binary_logloss: 0.115542\tvalid_1's auc: 0.835595\tvalid_1's binary_logloss: 0.136456\n",
            "[44]\ttraining's auc: 0.902155\ttraining's binary_logloss: 0.115204\tvalid_1's auc: 0.835236\tvalid_1's binary_logloss: 0.136471\n",
            "[45]\ttraining's auc: 0.903002\ttraining's binary_logloss: 0.11489\tvalid_1's auc: 0.835333\tvalid_1's binary_logloss: 0.136452\n",
            "[46]\ttraining's auc: 0.903388\ttraining's binary_logloss: 0.114627\tvalid_1's auc: 0.835141\tvalid_1's binary_logloss: 0.136468\n",
            "[47]\ttraining's auc: 0.903789\ttraining's binary_logloss: 0.1144\tvalid_1's auc: 0.835131\tvalid_1's binary_logloss: 0.136464\n",
            "[48]\ttraining's auc: 0.904672\ttraining's binary_logloss: 0.114015\tvalid_1's auc: 0.835086\tvalid_1's binary_logloss: 0.136468\n",
            "[49]\ttraining's auc: 0.905605\ttraining's binary_logloss: 0.113666\tvalid_1's auc: 0.835019\tvalid_1's binary_logloss: 0.136485\n",
            "[50]\ttraining's auc: 0.906199\ttraining's binary_logloss: 0.113369\tvalid_1's auc: 0.835051\tvalid_1's binary_logloss: 0.136474\n",
            "[51]\ttraining's auc: 0.906937\ttraining's binary_logloss: 0.113085\tvalid_1's auc: 0.83498\tvalid_1's binary_logloss: 0.136486\n",
            "[52]\ttraining's auc: 0.907648\ttraining's binary_logloss: 0.112792\tvalid_1's auc: 0.8352\tvalid_1's binary_logloss: 0.136458\n",
            "[53]\ttraining's auc: 0.908249\ttraining's binary_logloss: 0.112565\tvalid_1's auc: 0.835068\tvalid_1's binary_logloss: 0.136486\n",
            "[54]\ttraining's auc: 0.908836\ttraining's binary_logloss: 0.112311\tvalid_1's auc: 0.834971\tvalid_1's binary_logloss: 0.13651\n",
            "[55]\ttraining's auc: 0.909386\ttraining's binary_logloss: 0.112049\tvalid_1's auc: 0.835256\tvalid_1's binary_logloss: 0.13647\n",
            "[56]\ttraining's auc: 0.910068\ttraining's binary_logloss: 0.111776\tvalid_1's auc: 0.8349\tvalid_1's binary_logloss: 0.136525\n",
            "[57]\ttraining's auc: 0.910418\ttraining's binary_logloss: 0.111563\tvalid_1's auc: 0.834799\tvalid_1's binary_logloss: 0.136539\n",
            "[58]\ttraining's auc: 0.911263\ttraining's binary_logloss: 0.111296\tvalid_1's auc: 0.834716\tvalid_1's binary_logloss: 0.13658\n",
            "[59]\ttraining's auc: 0.912103\ttraining's binary_logloss: 0.111009\tvalid_1's auc: 0.834606\tvalid_1's binary_logloss: 0.136616\n",
            "[60]\ttraining's auc: 0.91251\ttraining's binary_logloss: 0.110789\tvalid_1's auc: 0.834503\tvalid_1's binary_logloss: 0.136638\n",
            "[61]\ttraining's auc: 0.913054\ttraining's binary_logloss: 0.110591\tvalid_1's auc: 0.834575\tvalid_1's binary_logloss: 0.136632\n",
            "[62]\ttraining's auc: 0.913738\ttraining's binary_logloss: 0.110305\tvalid_1's auc: 0.834584\tvalid_1's binary_logloss: 0.136632\n",
            " 64%|██████▍   | 32/50 [16:13<10:17, 34.32s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.15587\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.158248\n",
            "[2]\ttraining's auc: 0.833092\ttraining's binary_logloss: 0.150465\tvalid_1's auc: 0.806252\tvalid_1's binary_logloss: 0.154038\n",
            "[3]\ttraining's auc: 0.840893\ttraining's binary_logloss: 0.146428\tvalid_1's auc: 0.811446\tvalid_1's binary_logloss: 0.150894\n",
            "[4]\ttraining's auc: 0.846834\ttraining's binary_logloss: 0.143147\tvalid_1's auc: 0.817277\tvalid_1's binary_logloss: 0.148431\n",
            "[5]\ttraining's auc: 0.850288\ttraining's binary_logloss: 0.140534\tvalid_1's auc: 0.819178\tvalid_1's binary_logloss: 0.146569\n",
            "[6]\ttraining's auc: 0.852317\ttraining's binary_logloss: 0.138366\tvalid_1's auc: 0.820151\tvalid_1's binary_logloss: 0.144991\n",
            "[7]\ttraining's auc: 0.855956\ttraining's binary_logloss: 0.136466\tvalid_1's auc: 0.821605\tvalid_1's binary_logloss: 0.143728\n",
            "[8]\ttraining's auc: 0.857053\ttraining's binary_logloss: 0.134758\tvalid_1's auc: 0.821335\tvalid_1's binary_logloss: 0.142708\n",
            "[9]\ttraining's auc: 0.859084\ttraining's binary_logloss: 0.133264\tvalid_1's auc: 0.822762\tvalid_1's binary_logloss: 0.141656\n",
            "[10]\ttraining's auc: 0.860255\ttraining's binary_logloss: 0.131957\tvalid_1's auc: 0.823158\tvalid_1's binary_logloss: 0.140857\n",
            "[11]\ttraining's auc: 0.863215\ttraining's binary_logloss: 0.130669\tvalid_1's auc: 0.825027\tvalid_1's binary_logloss: 0.14011\n",
            "[12]\ttraining's auc: 0.865948\ttraining's binary_logloss: 0.129599\tvalid_1's auc: 0.826106\tvalid_1's binary_logloss: 0.139507\n",
            "[13]\ttraining's auc: 0.868695\ttraining's binary_logloss: 0.128575\tvalid_1's auc: 0.826413\tvalid_1's binary_logloss: 0.139017\n",
            "[14]\ttraining's auc: 0.870466\ttraining's binary_logloss: 0.127647\tvalid_1's auc: 0.826589\tvalid_1's binary_logloss: 0.138652\n",
            "[15]\ttraining's auc: 0.872375\ttraining's binary_logloss: 0.126816\tvalid_1's auc: 0.82594\tvalid_1's binary_logloss: 0.138344\n",
            "[16]\ttraining's auc: 0.873177\ttraining's binary_logloss: 0.126043\tvalid_1's auc: 0.82609\tvalid_1's binary_logloss: 0.138121\n",
            "[17]\ttraining's auc: 0.875185\ttraining's binary_logloss: 0.125278\tvalid_1's auc: 0.825804\tvalid_1's binary_logloss: 0.137877\n",
            "[18]\ttraining's auc: 0.877199\ttraining's binary_logloss: 0.124565\tvalid_1's auc: 0.825991\tvalid_1's binary_logloss: 0.13775\n",
            "[19]\ttraining's auc: 0.87861\ttraining's binary_logloss: 0.123864\tvalid_1's auc: 0.82648\tvalid_1's binary_logloss: 0.137495\n",
            "[20]\ttraining's auc: 0.880042\ttraining's binary_logloss: 0.123214\tvalid_1's auc: 0.827362\tvalid_1's binary_logloss: 0.137264\n",
            "[21]\ttraining's auc: 0.88263\ttraining's binary_logloss: 0.122517\tvalid_1's auc: 0.828391\tvalid_1's binary_logloss: 0.137026\n",
            "[22]\ttraining's auc: 0.883591\ttraining's binary_logloss: 0.12199\tvalid_1's auc: 0.8292\tvalid_1's binary_logloss: 0.13682\n",
            "[23]\ttraining's auc: 0.885638\ttraining's binary_logloss: 0.121382\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.136728\n",
            "[24]\ttraining's auc: 0.886624\ttraining's binary_logloss: 0.12085\tvalid_1's auc: 0.828826\tvalid_1's binary_logloss: 0.13667\n",
            "[25]\ttraining's auc: 0.887666\ttraining's binary_logloss: 0.120385\tvalid_1's auc: 0.828877\tvalid_1's binary_logloss: 0.136577\n",
            "[26]\ttraining's auc: 0.888414\ttraining's binary_logloss: 0.119948\tvalid_1's auc: 0.828361\tvalid_1's binary_logloss: 0.136579\n",
            "[27]\ttraining's auc: 0.889849\ttraining's binary_logloss: 0.11944\tvalid_1's auc: 0.827958\tvalid_1's binary_logloss: 0.136548\n",
            "[28]\ttraining's auc: 0.89221\ttraining's binary_logloss: 0.118906\tvalid_1's auc: 0.828927\tvalid_1's binary_logloss: 0.136357\n",
            "[29]\ttraining's auc: 0.89402\ttraining's binary_logloss: 0.118406\tvalid_1's auc: 0.829031\tvalid_1's binary_logloss: 0.136332\n",
            "[30]\ttraining's auc: 0.895323\ttraining's binary_logloss: 0.118013\tvalid_1's auc: 0.828975\tvalid_1's binary_logloss: 0.136348\n",
            "[31]\ttraining's auc: 0.896584\ttraining's binary_logloss: 0.117556\tvalid_1's auc: 0.829237\tvalid_1's binary_logloss: 0.136295\n",
            "[32]\ttraining's auc: 0.897435\ttraining's binary_logloss: 0.117166\tvalid_1's auc: 0.829305\tvalid_1's binary_logloss: 0.136306\n",
            "[33]\ttraining's auc: 0.898348\ttraining's binary_logloss: 0.116746\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.136303\n",
            "[34]\ttraining's auc: 0.900566\ttraining's binary_logloss: 0.116234\tvalid_1's auc: 0.829866\tvalid_1's binary_logloss: 0.136172\n",
            "[35]\ttraining's auc: 0.901484\ttraining's binary_logloss: 0.115899\tvalid_1's auc: 0.830224\tvalid_1's binary_logloss: 0.136126\n",
            "[36]\ttraining's auc: 0.902791\ttraining's binary_logloss: 0.115477\tvalid_1's auc: 0.830205\tvalid_1's binary_logloss: 0.136113\n",
            "[37]\ttraining's auc: 0.903371\ttraining's binary_logloss: 0.115097\tvalid_1's auc: 0.830626\tvalid_1's binary_logloss: 0.136058\n",
            "[38]\ttraining's auc: 0.904124\ttraining's binary_logloss: 0.114798\tvalid_1's auc: 0.830281\tvalid_1's binary_logloss: 0.136119\n",
            "[39]\ttraining's auc: 0.904792\ttraining's binary_logloss: 0.114474\tvalid_1's auc: 0.830002\tvalid_1's binary_logloss: 0.136174\n",
            "[40]\ttraining's auc: 0.905497\ttraining's binary_logloss: 0.114138\tvalid_1's auc: 0.830118\tvalid_1's binary_logloss: 0.136144\n",
            "[41]\ttraining's auc: 0.90638\ttraining's binary_logloss: 0.113799\tvalid_1's auc: 0.829816\tvalid_1's binary_logloss: 0.136224\n",
            "[42]\ttraining's auc: 0.907183\ttraining's binary_logloss: 0.113432\tvalid_1's auc: 0.829594\tvalid_1's binary_logloss: 0.136272\n",
            "[43]\ttraining's auc: 0.907886\ttraining's binary_logloss: 0.113117\tvalid_1's auc: 0.829366\tvalid_1's binary_logloss: 0.136316\n",
            "[44]\ttraining's auc: 0.90842\ttraining's binary_logloss: 0.112851\tvalid_1's auc: 0.829574\tvalid_1's binary_logloss: 0.13629\n",
            "[45]\ttraining's auc: 0.909853\ttraining's binary_logloss: 0.112551\tvalid_1's auc: 0.829228\tvalid_1's binary_logloss: 0.136342\n",
            "[46]\ttraining's auc: 0.91113\ttraining's binary_logloss: 0.112184\tvalid_1's auc: 0.829386\tvalid_1's binary_logloss: 0.13635\n",
            "[47]\ttraining's auc: 0.912019\ttraining's binary_logloss: 0.111861\tvalid_1's auc: 0.829426\tvalid_1's binary_logloss: 0.136357\n",
            "[48]\ttraining's auc: 0.912783\ttraining's binary_logloss: 0.111559\tvalid_1's auc: 0.829556\tvalid_1's binary_logloss: 0.136351\n",
            "[49]\ttraining's auc: 0.913132\ttraining's binary_logloss: 0.111284\tvalid_1's auc: 0.829351\tvalid_1's binary_logloss: 0.136382\n",
            "[50]\ttraining's auc: 0.913455\ttraining's binary_logloss: 0.111093\tvalid_1's auc: 0.82899\tvalid_1's binary_logloss: 0.136459\n",
            "[51]\ttraining's auc: 0.914282\ttraining's binary_logloss: 0.110818\tvalid_1's auc: 0.829025\tvalid_1's binary_logloss: 0.13649\n",
            "[52]\ttraining's auc: 0.914615\ttraining's binary_logloss: 0.110639\tvalid_1's auc: 0.828946\tvalid_1's binary_logloss: 0.136507\n",
            "[53]\ttraining's auc: 0.915291\ttraining's binary_logloss: 0.110347\tvalid_1's auc: 0.828794\tvalid_1's binary_logloss: 0.136555\n",
            "[54]\ttraining's auc: 0.915692\ttraining's binary_logloss: 0.110143\tvalid_1's auc: 0.82857\tvalid_1's binary_logloss: 0.136599\n",
            "[55]\ttraining's auc: 0.916151\ttraining's binary_logloss: 0.10988\tvalid_1's auc: 0.828479\tvalid_1's binary_logloss: 0.13662\n",
            "[56]\ttraining's auc: 0.916514\ttraining's binary_logloss: 0.109654\tvalid_1's auc: 0.828115\tvalid_1's binary_logloss: 0.136683\n",
            "[57]\ttraining's auc: 0.9169\ttraining's binary_logloss: 0.109446\tvalid_1's auc: 0.827805\tvalid_1's binary_logloss: 0.136754\n",
            "[58]\ttraining's auc: 0.917726\ttraining's binary_logloss: 0.10923\tvalid_1's auc: 0.827833\tvalid_1's binary_logloss: 0.136762\n",
            "[59]\ttraining's auc: 0.91815\ttraining's binary_logloss: 0.109022\tvalid_1's auc: 0.827523\tvalid_1's binary_logloss: 0.136826\n",
            "[60]\ttraining's auc: 0.918408\ttraining's binary_logloss: 0.108841\tvalid_1's auc: 0.827125\tvalid_1's binary_logloss: 0.136922\n",
            "[61]\ttraining's auc: 0.918773\ttraining's binary_logloss: 0.108682\tvalid_1's auc: 0.826985\tvalid_1's binary_logloss: 0.136968\n",
            "[62]\ttraining's auc: 0.919659\ttraining's binary_logloss: 0.108325\tvalid_1's auc: 0.826778\tvalid_1's binary_logloss: 0.137058\n",
            "[63]\ttraining's auc: 0.919849\ttraining's binary_logloss: 0.108168\tvalid_1's auc: 0.826268\tvalid_1's binary_logloss: 0.137185\n",
            "[64]\ttraining's auc: 0.920032\ttraining's binary_logloss: 0.108029\tvalid_1's auc: 0.825981\tvalid_1's binary_logloss: 0.137272\n",
            "[65]\ttraining's auc: 0.920344\ttraining's binary_logloss: 0.107849\tvalid_1's auc: 0.825752\tvalid_1's binary_logloss: 0.137321\n",
            "[66]\ttraining's auc: 0.921328\ttraining's binary_logloss: 0.107589\tvalid_1's auc: 0.825941\tvalid_1's binary_logloss: 0.137313\n",
            "[67]\ttraining's auc: 0.921949\ttraining's binary_logloss: 0.107277\tvalid_1's auc: 0.825665\tvalid_1's binary_logloss: 0.137341\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 64%|██████▍   | 32/50 [16:23<10:17, 34.32s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.158288\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.154133\n",
            "[2]\ttraining's auc: 0.8279\ttraining's binary_logloss: 0.152855\tvalid_1's auc: 0.815279\tvalid_1's binary_logloss: 0.150015\n",
            "[3]\ttraining's auc: 0.833551\ttraining's binary_logloss: 0.148829\tvalid_1's auc: 0.818027\tvalid_1's binary_logloss: 0.146769\n",
            "[4]\ttraining's auc: 0.839933\ttraining's binary_logloss: 0.145463\tvalid_1's auc: 0.821257\tvalid_1's binary_logloss: 0.144299\n",
            "[5]\ttraining's auc: 0.845495\ttraining's binary_logloss: 0.142773\tvalid_1's auc: 0.826513\tvalid_1's binary_logloss: 0.142274\n",
            "[6]\ttraining's auc: 0.84957\ttraining's binary_logloss: 0.140554\tvalid_1's auc: 0.829352\tvalid_1's binary_logloss: 0.140735\n",
            "[7]\ttraining's auc: 0.852907\ttraining's binary_logloss: 0.138563\tvalid_1's auc: 0.828957\tvalid_1's binary_logloss: 0.139542\n",
            "[8]\ttraining's auc: 0.856335\ttraining's binary_logloss: 0.136803\tvalid_1's auc: 0.830322\tvalid_1's binary_logloss: 0.138446\n",
            "[9]\ttraining's auc: 0.8579\ttraining's binary_logloss: 0.135334\tvalid_1's auc: 0.829946\tvalid_1's binary_logloss: 0.137503\n",
            "[10]\ttraining's auc: 0.86333\ttraining's binary_logloss: 0.133953\tvalid_1's auc: 0.831717\tvalid_1's binary_logloss: 0.136605\n",
            "[11]\ttraining's auc: 0.865875\ttraining's binary_logloss: 0.1327\tvalid_1's auc: 0.831607\tvalid_1's binary_logloss: 0.135987\n",
            "[12]\ttraining's auc: 0.868504\ttraining's binary_logloss: 0.131508\tvalid_1's auc: 0.831605\tvalid_1's binary_logloss: 0.13542\n",
            "[13]\ttraining's auc: 0.869593\ttraining's binary_logloss: 0.130498\tvalid_1's auc: 0.832046\tvalid_1's binary_logloss: 0.1349\n",
            "[14]\ttraining's auc: 0.871417\ttraining's binary_logloss: 0.129507\tvalid_1's auc: 0.831611\tvalid_1's binary_logloss: 0.134455\n",
            "[15]\ttraining's auc: 0.872441\ttraining's binary_logloss: 0.128675\tvalid_1's auc: 0.832699\tvalid_1's binary_logloss: 0.134019\n",
            "[16]\ttraining's auc: 0.874148\ttraining's binary_logloss: 0.127802\tvalid_1's auc: 0.832415\tvalid_1's binary_logloss: 0.133739\n",
            "[17]\ttraining's auc: 0.876408\ttraining's binary_logloss: 0.127011\tvalid_1's auc: 0.832736\tvalid_1's binary_logloss: 0.133493\n",
            "[18]\ttraining's auc: 0.878533\ttraining's binary_logloss: 0.126235\tvalid_1's auc: 0.833545\tvalid_1's binary_logloss: 0.13313\n",
            "[19]\ttraining's auc: 0.879604\ttraining's binary_logloss: 0.125537\tvalid_1's auc: 0.833373\tvalid_1's binary_logloss: 0.132932\n",
            "[20]\ttraining's auc: 0.880819\ttraining's binary_logloss: 0.124903\tvalid_1's auc: 0.833302\tvalid_1's binary_logloss: 0.13271\n",
            "[21]\ttraining's auc: 0.882075\ttraining's binary_logloss: 0.124256\tvalid_1's auc: 0.83325\tvalid_1's binary_logloss: 0.13256\n",
            "[22]\ttraining's auc: 0.883713\ttraining's binary_logloss: 0.123635\tvalid_1's auc: 0.833926\tvalid_1's binary_logloss: 0.13233\n",
            "[23]\ttraining's auc: 0.884973\ttraining's binary_logloss: 0.1231\tvalid_1's auc: 0.83381\tvalid_1's binary_logloss: 0.132207\n",
            "[24]\ttraining's auc: 0.886259\ttraining's binary_logloss: 0.122573\tvalid_1's auc: 0.833694\tvalid_1's binary_logloss: 0.13207\n",
            "[25]\ttraining's auc: 0.887283\ttraining's binary_logloss: 0.122067\tvalid_1's auc: 0.833569\tvalid_1's binary_logloss: 0.132016\n",
            "[26]\ttraining's auc: 0.889244\ttraining's binary_logloss: 0.121511\tvalid_1's auc: 0.833941\tvalid_1's binary_logloss: 0.131983\n",
            "[27]\ttraining's auc: 0.890483\ttraining's binary_logloss: 0.121014\tvalid_1's auc: 0.834305\tvalid_1's binary_logloss: 0.131873\n",
            "[28]\ttraining's auc: 0.89125\ttraining's binary_logloss: 0.120587\tvalid_1's auc: 0.834549\tvalid_1's binary_logloss: 0.1318\n",
            "[29]\ttraining's auc: 0.89253\ttraining's binary_logloss: 0.120164\tvalid_1's auc: 0.834828\tvalid_1's binary_logloss: 0.131734\n",
            "[30]\ttraining's auc: 0.89361\ttraining's binary_logloss: 0.119769\tvalid_1's auc: 0.834796\tvalid_1's binary_logloss: 0.131661\n",
            "[31]\ttraining's auc: 0.894836\ttraining's binary_logloss: 0.119346\tvalid_1's auc: 0.834665\tvalid_1's binary_logloss: 0.131634\n",
            "[32]\ttraining's auc: 0.896159\ttraining's binary_logloss: 0.11894\tvalid_1's auc: 0.834488\tvalid_1's binary_logloss: 0.131628\n",
            "[33]\ttraining's auc: 0.897227\ttraining's binary_logloss: 0.118574\tvalid_1's auc: 0.834424\tvalid_1's binary_logloss: 0.131594\n",
            "[34]\ttraining's auc: 0.898882\ttraining's binary_logloss: 0.118131\tvalid_1's auc: 0.834489\tvalid_1's binary_logloss: 0.131558\n",
            "[35]\ttraining's auc: 0.899852\ttraining's binary_logloss: 0.117748\tvalid_1's auc: 0.83436\tvalid_1's binary_logloss: 0.131572\n",
            "[36]\ttraining's auc: 0.900562\ttraining's binary_logloss: 0.117413\tvalid_1's auc: 0.834615\tvalid_1's binary_logloss: 0.131545\n",
            "[37]\ttraining's auc: 0.901344\ttraining's binary_logloss: 0.117089\tvalid_1's auc: 0.834613\tvalid_1's binary_logloss: 0.131537\n",
            "[38]\ttraining's auc: 0.902838\ttraining's binary_logloss: 0.116689\tvalid_1's auc: 0.834495\tvalid_1's binary_logloss: 0.131544\n",
            "[39]\ttraining's auc: 0.903671\ttraining's binary_logloss: 0.116359\tvalid_1's auc: 0.834479\tvalid_1's binary_logloss: 0.13154\n",
            "[40]\ttraining's auc: 0.904494\ttraining's binary_logloss: 0.116017\tvalid_1's auc: 0.835428\tvalid_1's binary_logloss: 0.131371\n",
            "[41]\ttraining's auc: 0.905045\ttraining's binary_logloss: 0.115676\tvalid_1's auc: 0.83537\tvalid_1's binary_logloss: 0.131387\n",
            "[42]\ttraining's auc: 0.905846\ttraining's binary_logloss: 0.11532\tvalid_1's auc: 0.835426\tvalid_1's binary_logloss: 0.131391\n",
            "[43]\ttraining's auc: 0.906972\ttraining's binary_logloss: 0.114919\tvalid_1's auc: 0.835294\tvalid_1's binary_logloss: 0.131415\n",
            "[44]\ttraining's auc: 0.907889\ttraining's binary_logloss: 0.114519\tvalid_1's auc: 0.835468\tvalid_1's binary_logloss: 0.131401\n",
            "[45]\ttraining's auc: 0.908266\ttraining's binary_logloss: 0.1143\tvalid_1's auc: 0.835535\tvalid_1's binary_logloss: 0.131387\n",
            "[46]\ttraining's auc: 0.909334\ttraining's binary_logloss: 0.113943\tvalid_1's auc: 0.835679\tvalid_1's binary_logloss: 0.131356\n",
            "[47]\ttraining's auc: 0.909897\ttraining's binary_logloss: 0.11366\tvalid_1's auc: 0.835722\tvalid_1's binary_logloss: 0.131339\n",
            "[48]\ttraining's auc: 0.910675\ttraining's binary_logloss: 0.113323\tvalid_1's auc: 0.835576\tvalid_1's binary_logloss: 0.131385\n",
            "[49]\ttraining's auc: 0.911215\ttraining's binary_logloss: 0.113072\tvalid_1's auc: 0.83541\tvalid_1's binary_logloss: 0.131414\n",
            "[50]\ttraining's auc: 0.911757\ttraining's binary_logloss: 0.112755\tvalid_1's auc: 0.835469\tvalid_1's binary_logloss: 0.131429\n",
            "[51]\ttraining's auc: 0.912389\ttraining's binary_logloss: 0.11244\tvalid_1's auc: 0.835589\tvalid_1's binary_logloss: 0.131418\n",
            "[52]\ttraining's auc: 0.912846\ttraining's binary_logloss: 0.112173\tvalid_1's auc: 0.835492\tvalid_1's binary_logloss: 0.131442\n",
            "[53]\ttraining's auc: 0.91329\ttraining's binary_logloss: 0.111972\tvalid_1's auc: 0.835413\tvalid_1's binary_logloss: 0.131454\n",
            "[54]\ttraining's auc: 0.913755\ttraining's binary_logloss: 0.111714\tvalid_1's auc: 0.835322\tvalid_1's binary_logloss: 0.131461\n",
            "[55]\ttraining's auc: 0.914281\ttraining's binary_logloss: 0.111508\tvalid_1's auc: 0.835255\tvalid_1's binary_logloss: 0.131477\n",
            "[56]\ttraining's auc: 0.914638\ttraining's binary_logloss: 0.111286\tvalid_1's auc: 0.835127\tvalid_1's binary_logloss: 0.131489\n",
            "[57]\ttraining's auc: 0.915173\ttraining's binary_logloss: 0.110994\tvalid_1's auc: 0.834933\tvalid_1's binary_logloss: 0.131551\n",
            "[58]\ttraining's auc: 0.915683\ttraining's binary_logloss: 0.110735\tvalid_1's auc: 0.834748\tvalid_1's binary_logloss: 0.131603\n",
            "[59]\ttraining's auc: 0.916161\ttraining's binary_logloss: 0.110481\tvalid_1's auc: 0.834557\tvalid_1's binary_logloss: 0.13162\n",
            "[60]\ttraining's auc: 0.916803\ttraining's binary_logloss: 0.110183\tvalid_1's auc: 0.834282\tvalid_1's binary_logloss: 0.131684\n",
            "[61]\ttraining's auc: 0.917117\ttraining's binary_logloss: 0.109985\tvalid_1's auc: 0.834312\tvalid_1's binary_logloss: 0.131675\n",
            "[62]\ttraining's auc: 0.917854\ttraining's binary_logloss: 0.109653\tvalid_1's auc: 0.833954\tvalid_1's binary_logloss: 0.13172\n",
            "[63]\ttraining's auc: 0.918078\ttraining's binary_logloss: 0.109503\tvalid_1's auc: 0.833916\tvalid_1's binary_logloss: 0.13171\n",
            "[64]\ttraining's auc: 0.918595\ttraining's binary_logloss: 0.109285\tvalid_1's auc: 0.833818\tvalid_1's binary_logloss: 0.131751\n",
            "[65]\ttraining's auc: 0.918935\ttraining's binary_logloss: 0.109067\tvalid_1's auc: 0.833624\tvalid_1's binary_logloss: 0.131796\n",
            "[66]\ttraining's auc: 0.919986\ttraining's binary_logloss: 0.108808\tvalid_1's auc: 0.83341\tvalid_1's binary_logloss: 0.131836\n",
            "[67]\ttraining's auc: 0.920612\ttraining's binary_logloss: 0.108615\tvalid_1's auc: 0.833488\tvalid_1's binary_logloss: 0.131832\n",
            "[68]\ttraining's auc: 0.920926\ttraining's binary_logloss: 0.108424\tvalid_1's auc: 0.833614\tvalid_1's binary_logloss: 0.131823\n",
            "[69]\ttraining's auc: 0.921346\ttraining's binary_logloss: 0.108214\tvalid_1's auc: 0.833753\tvalid_1's binary_logloss: 0.131825\n",
            "[70]\ttraining's auc: 0.921798\ttraining's binary_logloss: 0.10806\tvalid_1's auc: 0.833475\tvalid_1's binary_logloss: 0.131882\n",
            "[71]\ttraining's auc: 0.921996\ttraining's binary_logloss: 0.107911\tvalid_1's auc: 0.833487\tvalid_1's binary_logloss: 0.131889\n",
            "[72]\ttraining's auc: 0.922304\ttraining's binary_logloss: 0.107686\tvalid_1's auc: 0.833461\tvalid_1's binary_logloss: 0.131929\n",
            "[73]\ttraining's auc: 0.922597\ttraining's binary_logloss: 0.107503\tvalid_1's auc: 0.833263\tvalid_1's binary_logloss: 0.131974\n",
            "[74]\ttraining's auc: 0.923376\ttraining's binary_logloss: 0.107273\tvalid_1's auc: 0.832957\tvalid_1's binary_logloss: 0.132007\n",
            "[75]\ttraining's auc: 0.923821\ttraining's binary_logloss: 0.107057\tvalid_1's auc: 0.832757\tvalid_1's binary_logloss: 0.132041\n",
            "[76]\ttraining's auc: 0.924004\ttraining's binary_logloss: 0.10691\tvalid_1's auc: 0.832763\tvalid_1's binary_logloss: 0.132028\n",
            "[77]\ttraining's auc: 0.924546\ttraining's binary_logloss: 0.106692\tvalid_1's auc: 0.832663\tvalid_1's binary_logloss: 0.13206\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 64%|██████▍   | 32/50 [16:31<10:17, 34.32s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.154957\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.16119\n",
            "[2]\ttraining's auc: 0.833076\ttraining's binary_logloss: 0.149537\tvalid_1's auc: 0.815157\tvalid_1's binary_logloss: 0.156271\n",
            "[3]\ttraining's auc: 0.8385\ttraining's binary_logloss: 0.145674\tvalid_1's auc: 0.818127\tvalid_1's binary_logloss: 0.15294\n",
            "[4]\ttraining's auc: 0.846229\ttraining's binary_logloss: 0.142244\tvalid_1's auc: 0.823575\tvalid_1's binary_logloss: 0.150352\n",
            "[5]\ttraining's auc: 0.848168\ttraining's binary_logloss: 0.139538\tvalid_1's auc: 0.825928\tvalid_1's binary_logloss: 0.148234\n",
            "[6]\ttraining's auc: 0.851489\ttraining's binary_logloss: 0.137288\tvalid_1's auc: 0.827216\tvalid_1's binary_logloss: 0.146494\n",
            "[7]\ttraining's auc: 0.85406\ttraining's binary_logloss: 0.135441\tvalid_1's auc: 0.829405\tvalid_1's binary_logloss: 0.144971\n",
            "[8]\ttraining's auc: 0.856899\ttraining's binary_logloss: 0.133791\tvalid_1's auc: 0.82996\tvalid_1's binary_logloss: 0.143752\n",
            "[9]\ttraining's auc: 0.858184\ttraining's binary_logloss: 0.132307\tvalid_1's auc: 0.830422\tvalid_1's binary_logloss: 0.14267\n",
            "[10]\ttraining's auc: 0.860343\ttraining's binary_logloss: 0.131002\tvalid_1's auc: 0.831468\tvalid_1's binary_logloss: 0.141705\n",
            "[11]\ttraining's auc: 0.863584\ttraining's binary_logloss: 0.129808\tvalid_1's auc: 0.831712\tvalid_1's binary_logloss: 0.140954\n",
            "[12]\ttraining's auc: 0.867212\ttraining's binary_logloss: 0.128673\tvalid_1's auc: 0.831652\tvalid_1's binary_logloss: 0.140374\n",
            "[13]\ttraining's auc: 0.869349\ttraining's binary_logloss: 0.127728\tvalid_1's auc: 0.831307\tvalid_1's binary_logloss: 0.13988\n",
            "[14]\ttraining's auc: 0.87178\ttraining's binary_logloss: 0.126814\tvalid_1's auc: 0.833214\tvalid_1's binary_logloss: 0.139429\n",
            "[15]\ttraining's auc: 0.873733\ttraining's binary_logloss: 0.126013\tvalid_1's auc: 0.834889\tvalid_1's binary_logloss: 0.138922\n",
            "[16]\ttraining's auc: 0.875135\ttraining's binary_logloss: 0.125219\tvalid_1's auc: 0.835173\tvalid_1's binary_logloss: 0.138587\n",
            "[17]\ttraining's auc: 0.877838\ttraining's binary_logloss: 0.12446\tvalid_1's auc: 0.835589\tvalid_1's binary_logloss: 0.138284\n",
            "[18]\ttraining's auc: 0.879205\ttraining's binary_logloss: 0.123769\tvalid_1's auc: 0.835053\tvalid_1's binary_logloss: 0.138058\n",
            "[19]\ttraining's auc: 0.880904\ttraining's binary_logloss: 0.123135\tvalid_1's auc: 0.835172\tvalid_1's binary_logloss: 0.137819\n",
            "[20]\ttraining's auc: 0.882999\ttraining's binary_logloss: 0.122405\tvalid_1's auc: 0.834754\tvalid_1's binary_logloss: 0.137675\n",
            "[21]\ttraining's auc: 0.884958\ttraining's binary_logloss: 0.121763\tvalid_1's auc: 0.834347\tvalid_1's binary_logloss: 0.137579\n",
            "[22]\ttraining's auc: 0.886467\ttraining's binary_logloss: 0.121176\tvalid_1's auc: 0.834384\tvalid_1's binary_logloss: 0.137414\n",
            "[23]\ttraining's auc: 0.887317\ttraining's binary_logloss: 0.120647\tvalid_1's auc: 0.834812\tvalid_1's binary_logloss: 0.137194\n",
            "[24]\ttraining's auc: 0.888656\ttraining's binary_logloss: 0.120126\tvalid_1's auc: 0.83452\tvalid_1's binary_logloss: 0.137129\n",
            "[25]\ttraining's auc: 0.889568\ttraining's binary_logloss: 0.119655\tvalid_1's auc: 0.83476\tvalid_1's binary_logloss: 0.137025\n",
            "[26]\ttraining's auc: 0.890858\ttraining's binary_logloss: 0.11919\tvalid_1's auc: 0.835058\tvalid_1's binary_logloss: 0.136899\n",
            "[27]\ttraining's auc: 0.891796\ttraining's binary_logloss: 0.118709\tvalid_1's auc: 0.834971\tvalid_1's binary_logloss: 0.136854\n",
            "[28]\ttraining's auc: 0.894432\ttraining's binary_logloss: 0.118079\tvalid_1's auc: 0.834885\tvalid_1's binary_logloss: 0.13682\n",
            "[29]\ttraining's auc: 0.896701\ttraining's binary_logloss: 0.11751\tvalid_1's auc: 0.834818\tvalid_1's binary_logloss: 0.136785\n",
            "[30]\ttraining's auc: 0.89763\ttraining's binary_logloss: 0.117088\tvalid_1's auc: 0.834538\tvalid_1's binary_logloss: 0.136738\n",
            "[31]\ttraining's auc: 0.898549\ttraining's binary_logloss: 0.116616\tvalid_1's auc: 0.834673\tvalid_1's binary_logloss: 0.136645\n",
            "[32]\ttraining's auc: 0.899973\ttraining's binary_logloss: 0.116179\tvalid_1's auc: 0.834303\tvalid_1's binary_logloss: 0.136646\n",
            "[33]\ttraining's auc: 0.900871\ttraining's binary_logloss: 0.115762\tvalid_1's auc: 0.834421\tvalid_1's binary_logloss: 0.136557\n",
            "[34]\ttraining's auc: 0.901883\ttraining's binary_logloss: 0.115405\tvalid_1's auc: 0.834162\tvalid_1's binary_logloss: 0.136574\n",
            "[35]\ttraining's auc: 0.902852\ttraining's binary_logloss: 0.114936\tvalid_1's auc: 0.834129\tvalid_1's binary_logloss: 0.136579\n",
            "[36]\ttraining's auc: 0.903483\ttraining's binary_logloss: 0.11454\tvalid_1's auc: 0.833818\tvalid_1's binary_logloss: 0.136627\n",
            "[37]\ttraining's auc: 0.904062\ttraining's binary_logloss: 0.114156\tvalid_1's auc: 0.834075\tvalid_1's binary_logloss: 0.136575\n",
            "[38]\ttraining's auc: 0.904818\ttraining's binary_logloss: 0.113769\tvalid_1's auc: 0.834037\tvalid_1's binary_logloss: 0.136596\n",
            "[39]\ttraining's auc: 0.905617\ttraining's binary_logloss: 0.113448\tvalid_1's auc: 0.833908\tvalid_1's binary_logloss: 0.136608\n",
            "[40]\ttraining's auc: 0.906713\ttraining's binary_logloss: 0.113094\tvalid_1's auc: 0.834028\tvalid_1's binary_logloss: 0.136613\n",
            "[41]\ttraining's auc: 0.907561\ttraining's binary_logloss: 0.112723\tvalid_1's auc: 0.834225\tvalid_1's binary_logloss: 0.136557\n",
            "[42]\ttraining's auc: 0.908618\ttraining's binary_logloss: 0.112339\tvalid_1's auc: 0.834217\tvalid_1's binary_logloss: 0.136576\n",
            "[43]\ttraining's auc: 0.909027\ttraining's binary_logloss: 0.112073\tvalid_1's auc: 0.834403\tvalid_1's binary_logloss: 0.13657\n",
            "[44]\ttraining's auc: 0.909653\ttraining's binary_logloss: 0.111793\tvalid_1's auc: 0.834409\tvalid_1's binary_logloss: 0.136569\n",
            "[45]\ttraining's auc: 0.910315\ttraining's binary_logloss: 0.11148\tvalid_1's auc: 0.834412\tvalid_1's binary_logloss: 0.136593\n",
            "[46]\ttraining's auc: 0.91069\ttraining's binary_logloss: 0.111248\tvalid_1's auc: 0.834422\tvalid_1's binary_logloss: 0.136586\n",
            "[47]\ttraining's auc: 0.911367\ttraining's binary_logloss: 0.110924\tvalid_1's auc: 0.834498\tvalid_1's binary_logloss: 0.136574\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 66%|██████▌   | 33/50 [16:40<09:03, 32.00s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.15382\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.156592\n",
            "[2]\ttraining's auc: 0.834499\ttraining's binary_logloss: 0.147803\tvalid_1's auc: 0.808698\tvalid_1's binary_logloss: 0.15194\n",
            "[3]\ttraining's auc: 0.842822\ttraining's binary_logloss: 0.143557\tvalid_1's auc: 0.813473\tvalid_1's binary_logloss: 0.148825\n",
            "[4]\ttraining's auc: 0.848747\ttraining's binary_logloss: 0.140112\tvalid_1's auc: 0.816428\tvalid_1's binary_logloss: 0.146536\n",
            "[5]\ttraining's auc: 0.852492\ttraining's binary_logloss: 0.137388\tvalid_1's auc: 0.818968\tvalid_1's binary_logloss: 0.144567\n",
            "[6]\ttraining's auc: 0.854675\ttraining's binary_logloss: 0.13512\tvalid_1's auc: 0.81924\tvalid_1's binary_logloss: 0.143134\n",
            "[7]\ttraining's auc: 0.856317\ttraining's binary_logloss: 0.133212\tvalid_1's auc: 0.820546\tvalid_1's binary_logloss: 0.141965\n",
            "[8]\ttraining's auc: 0.861002\ttraining's binary_logloss: 0.131513\tvalid_1's auc: 0.821499\tvalid_1's binary_logloss: 0.141026\n",
            "[9]\ttraining's auc: 0.863675\ttraining's binary_logloss: 0.130098\tvalid_1's auc: 0.821681\tvalid_1's binary_logloss: 0.140214\n",
            "[10]\ttraining's auc: 0.8671\ttraining's binary_logloss: 0.128799\tvalid_1's auc: 0.823242\tvalid_1's binary_logloss: 0.139573\n",
            "[11]\ttraining's auc: 0.869065\ttraining's binary_logloss: 0.127527\tvalid_1's auc: 0.823771\tvalid_1's binary_logloss: 0.13912\n",
            "[12]\ttraining's auc: 0.871282\ttraining's binary_logloss: 0.126429\tvalid_1's auc: 0.824025\tvalid_1's binary_logloss: 0.138662\n",
            "[13]\ttraining's auc: 0.874258\ttraining's binary_logloss: 0.125416\tvalid_1's auc: 0.824503\tvalid_1's binary_logloss: 0.138254\n",
            "[14]\ttraining's auc: 0.875499\ttraining's binary_logloss: 0.124568\tvalid_1's auc: 0.825412\tvalid_1's binary_logloss: 0.13791\n",
            "[15]\ttraining's auc: 0.877812\ttraining's binary_logloss: 0.12371\tvalid_1's auc: 0.826048\tvalid_1's binary_logloss: 0.137627\n",
            "[16]\ttraining's auc: 0.88123\ttraining's binary_logloss: 0.122774\tvalid_1's auc: 0.825827\tvalid_1's binary_logloss: 0.137422\n",
            "[17]\ttraining's auc: 0.882983\ttraining's binary_logloss: 0.122061\tvalid_1's auc: 0.826394\tvalid_1's binary_logloss: 0.137253\n",
            "[18]\ttraining's auc: 0.884886\ttraining's binary_logloss: 0.121387\tvalid_1's auc: 0.826544\tvalid_1's binary_logloss: 0.137061\n",
            "[19]\ttraining's auc: 0.886321\ttraining's binary_logloss: 0.120722\tvalid_1's auc: 0.826775\tvalid_1's binary_logloss: 0.136983\n",
            "[20]\ttraining's auc: 0.887123\ttraining's binary_logloss: 0.120171\tvalid_1's auc: 0.826985\tvalid_1's binary_logloss: 0.136887\n",
            "[21]\ttraining's auc: 0.889867\ttraining's binary_logloss: 0.119486\tvalid_1's auc: 0.827684\tvalid_1's binary_logloss: 0.136692\n",
            "[22]\ttraining's auc: 0.892558\ttraining's binary_logloss: 0.118779\tvalid_1's auc: 0.827488\tvalid_1's binary_logloss: 0.136562\n",
            "[23]\ttraining's auc: 0.893925\ttraining's binary_logloss: 0.118229\tvalid_1's auc: 0.827332\tvalid_1's binary_logloss: 0.136554\n",
            "[24]\ttraining's auc: 0.895107\ttraining's binary_logloss: 0.117673\tvalid_1's auc: 0.827487\tvalid_1's binary_logloss: 0.136549\n",
            "[25]\ttraining's auc: 0.89695\ttraining's binary_logloss: 0.117164\tvalid_1's auc: 0.827033\tvalid_1's binary_logloss: 0.136613\n",
            "[26]\ttraining's auc: 0.899065\ttraining's binary_logloss: 0.116574\tvalid_1's auc: 0.827886\tvalid_1's binary_logloss: 0.136403\n",
            "[27]\ttraining's auc: 0.900326\ttraining's binary_logloss: 0.116097\tvalid_1's auc: 0.827735\tvalid_1's binary_logloss: 0.136476\n",
            "[28]\ttraining's auc: 0.901294\ttraining's binary_logloss: 0.115684\tvalid_1's auc: 0.827737\tvalid_1's binary_logloss: 0.136478\n",
            "[29]\ttraining's auc: 0.90262\ttraining's binary_logloss: 0.115208\tvalid_1's auc: 0.827736\tvalid_1's binary_logloss: 0.136509\n",
            "[30]\ttraining's auc: 0.903451\ttraining's binary_logloss: 0.114809\tvalid_1's auc: 0.82793\tvalid_1's binary_logloss: 0.136526\n",
            "[31]\ttraining's auc: 0.904381\ttraining's binary_logloss: 0.114312\tvalid_1's auc: 0.827463\tvalid_1's binary_logloss: 0.136626\n",
            "[32]\ttraining's auc: 0.90591\ttraining's binary_logloss: 0.113904\tvalid_1's auc: 0.82736\tvalid_1's binary_logloss: 0.136637\n",
            "[33]\ttraining's auc: 0.906578\ttraining's binary_logloss: 0.113499\tvalid_1's auc: 0.82718\tvalid_1's binary_logloss: 0.13667\n",
            "[34]\ttraining's auc: 0.907554\ttraining's binary_logloss: 0.113096\tvalid_1's auc: 0.827482\tvalid_1's binary_logloss: 0.136635\n",
            "[35]\ttraining's auc: 0.908942\ttraining's binary_logloss: 0.112577\tvalid_1's auc: 0.827068\tvalid_1's binary_logloss: 0.136743\n",
            "[36]\ttraining's auc: 0.909815\ttraining's binary_logloss: 0.112248\tvalid_1's auc: 0.827222\tvalid_1's binary_logloss: 0.136768\n",
            "[37]\ttraining's auc: 0.91058\ttraining's binary_logloss: 0.111873\tvalid_1's auc: 0.826548\tvalid_1's binary_logloss: 0.136882\n",
            "[38]\ttraining's auc: 0.911734\ttraining's binary_logloss: 0.111489\tvalid_1's auc: 0.827238\tvalid_1's binary_logloss: 0.136841\n",
            "[39]\ttraining's auc: 0.912561\ttraining's binary_logloss: 0.111091\tvalid_1's auc: 0.826894\tvalid_1's binary_logloss: 0.136889\n",
            "[40]\ttraining's auc: 0.913285\ttraining's binary_logloss: 0.110749\tvalid_1's auc: 0.826733\tvalid_1's binary_logloss: 0.136923\n",
            "[41]\ttraining's auc: 0.913807\ttraining's binary_logloss: 0.110435\tvalid_1's auc: 0.82642\tvalid_1's binary_logloss: 0.137001\n",
            "[42]\ttraining's auc: 0.914407\ttraining's binary_logloss: 0.110139\tvalid_1's auc: 0.826237\tvalid_1's binary_logloss: 0.137093\n",
            "[43]\ttraining's auc: 0.915077\ttraining's binary_logloss: 0.109747\tvalid_1's auc: 0.826259\tvalid_1's binary_logloss: 0.137081\n",
            "[44]\ttraining's auc: 0.916847\ttraining's binary_logloss: 0.109348\tvalid_1's auc: 0.82606\tvalid_1's binary_logloss: 0.137131\n",
            "[45]\ttraining's auc: 0.917701\ttraining's binary_logloss: 0.109106\tvalid_1's auc: 0.826162\tvalid_1's binary_logloss: 0.137135\n",
            "[46]\ttraining's auc: 0.918178\ttraining's binary_logloss: 0.108846\tvalid_1's auc: 0.82589\tvalid_1's binary_logloss: 0.137205\n",
            "[47]\ttraining's auc: 0.918809\ttraining's binary_logloss: 0.108521\tvalid_1's auc: 0.825593\tvalid_1's binary_logloss: 0.13732\n",
            "[48]\ttraining's auc: 0.919325\ttraining's binary_logloss: 0.108259\tvalid_1's auc: 0.825309\tvalid_1's binary_logloss: 0.137423\n",
            "[49]\ttraining's auc: 0.920847\ttraining's binary_logloss: 0.107888\tvalid_1's auc: 0.825242\tvalid_1's binary_logloss: 0.137429\n",
            "[50]\ttraining's auc: 0.921233\ttraining's binary_logloss: 0.10765\tvalid_1's auc: 0.825482\tvalid_1's binary_logloss: 0.137402\n",
            "[51]\ttraining's auc: 0.921694\ttraining's binary_logloss: 0.107378\tvalid_1's auc: 0.825425\tvalid_1's binary_logloss: 0.137431\n",
            "[52]\ttraining's auc: 0.922332\ttraining's binary_logloss: 0.107043\tvalid_1's auc: 0.82517\tvalid_1's binary_logloss: 0.137525\n",
            "[53]\ttraining's auc: 0.92266\ttraining's binary_logloss: 0.10683\tvalid_1's auc: 0.824897\tvalid_1's binary_logloss: 0.137595\n",
            "[54]\ttraining's auc: 0.923146\ttraining's binary_logloss: 0.106577\tvalid_1's auc: 0.824647\tvalid_1's binary_logloss: 0.137691\n",
            "[55]\ttraining's auc: 0.923465\ttraining's binary_logloss: 0.106366\tvalid_1's auc: 0.824928\tvalid_1's binary_logloss: 0.137669\n",
            "[56]\ttraining's auc: 0.924488\ttraining's binary_logloss: 0.106042\tvalid_1's auc: 0.82517\tvalid_1's binary_logloss: 0.137671\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 66%|██████▌   | 33/50 [16:46<09:03, 32.00s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.156253\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.152629\n",
            "[2]\ttraining's auc: 0.831344\ttraining's binary_logloss: 0.150158\tvalid_1's auc: 0.817342\tvalid_1's binary_logloss: 0.147877\n",
            "[3]\ttraining's auc: 0.838066\ttraining's binary_logloss: 0.14574\tvalid_1's auc: 0.820928\tvalid_1's binary_logloss: 0.144536\n",
            "[4]\ttraining's auc: 0.844703\ttraining's binary_logloss: 0.142355\tvalid_1's auc: 0.826213\tvalid_1's binary_logloss: 0.142194\n",
            "[5]\ttraining's auc: 0.850166\ttraining's binary_logloss: 0.139688\tvalid_1's auc: 0.829588\tvalid_1's binary_logloss: 0.140151\n",
            "[6]\ttraining's auc: 0.855071\ttraining's binary_logloss: 0.137326\tvalid_1's auc: 0.830353\tvalid_1's binary_logloss: 0.138696\n",
            "[7]\ttraining's auc: 0.856896\ttraining's binary_logloss: 0.135343\tvalid_1's auc: 0.830583\tvalid_1's binary_logloss: 0.137468\n",
            "[8]\ttraining's auc: 0.860014\ttraining's binary_logloss: 0.133646\tvalid_1's auc: 0.830373\tvalid_1's binary_logloss: 0.136427\n",
            "[9]\ttraining's auc: 0.865386\ttraining's binary_logloss: 0.132083\tvalid_1's auc: 0.830976\tvalid_1's binary_logloss: 0.135549\n",
            "[10]\ttraining's auc: 0.868294\ttraining's binary_logloss: 0.130737\tvalid_1's auc: 0.831784\tvalid_1's binary_logloss: 0.134981\n",
            "[11]\ttraining's auc: 0.870617\ttraining's binary_logloss: 0.129468\tvalid_1's auc: 0.8316\tvalid_1's binary_logloss: 0.134456\n",
            "[12]\ttraining's auc: 0.871879\ttraining's binary_logloss: 0.128421\tvalid_1's auc: 0.831297\tvalid_1's binary_logloss: 0.134026\n",
            "[13]\ttraining's auc: 0.873328\ttraining's binary_logloss: 0.127385\tvalid_1's auc: 0.831762\tvalid_1's binary_logloss: 0.133588\n",
            "[14]\ttraining's auc: 0.875703\ttraining's binary_logloss: 0.126416\tvalid_1's auc: 0.832443\tvalid_1's binary_logloss: 0.133229\n",
            "[15]\ttraining's auc: 0.87803\ttraining's binary_logloss: 0.125496\tvalid_1's auc: 0.832402\tvalid_1's binary_logloss: 0.132946\n",
            "[16]\ttraining's auc: 0.87972\ttraining's binary_logloss: 0.124707\tvalid_1's auc: 0.831965\tvalid_1's binary_logloss: 0.132786\n",
            "[17]\ttraining's auc: 0.881901\ttraining's binary_logloss: 0.123875\tvalid_1's auc: 0.833115\tvalid_1's binary_logloss: 0.132558\n",
            "[18]\ttraining's auc: 0.883913\ttraining's binary_logloss: 0.123116\tvalid_1's auc: 0.833915\tvalid_1's binary_logloss: 0.132237\n",
            "[19]\ttraining's auc: 0.885103\ttraining's binary_logloss: 0.122444\tvalid_1's auc: 0.834315\tvalid_1's binary_logloss: 0.13211\n",
            "[20]\ttraining's auc: 0.886363\ttraining's binary_logloss: 0.121803\tvalid_1's auc: 0.834043\tvalid_1's binary_logloss: 0.132022\n",
            "[21]\ttraining's auc: 0.88819\ttraining's binary_logloss: 0.121224\tvalid_1's auc: 0.834998\tvalid_1's binary_logloss: 0.131867\n",
            "[22]\ttraining's auc: 0.889261\ttraining's binary_logloss: 0.120673\tvalid_1's auc: 0.83508\tvalid_1's binary_logloss: 0.131723\n",
            "[23]\ttraining's auc: 0.891449\ttraining's binary_logloss: 0.120055\tvalid_1's auc: 0.835008\tvalid_1's binary_logloss: 0.131671\n",
            "[24]\ttraining's auc: 0.892004\ttraining's binary_logloss: 0.119592\tvalid_1's auc: 0.835329\tvalid_1's binary_logloss: 0.131526\n",
            "[25]\ttraining's auc: 0.893393\ttraining's binary_logloss: 0.119094\tvalid_1's auc: 0.835586\tvalid_1's binary_logloss: 0.131421\n",
            "[26]\ttraining's auc: 0.894723\ttraining's binary_logloss: 0.118674\tvalid_1's auc: 0.835657\tvalid_1's binary_logloss: 0.131377\n",
            "[27]\ttraining's auc: 0.895991\ttraining's binary_logloss: 0.118224\tvalid_1's auc: 0.835384\tvalid_1's binary_logloss: 0.131409\n",
            "[28]\ttraining's auc: 0.897573\ttraining's binary_logloss: 0.117777\tvalid_1's auc: 0.835345\tvalid_1's binary_logloss: 0.131367\n",
            "[29]\ttraining's auc: 0.899664\ttraining's binary_logloss: 0.117132\tvalid_1's auc: 0.835418\tvalid_1's binary_logloss: 0.131347\n",
            "[30]\ttraining's auc: 0.901391\ttraining's binary_logloss: 0.116631\tvalid_1's auc: 0.835207\tvalid_1's binary_logloss: 0.131393\n",
            "[31]\ttraining's auc: 0.902933\ttraining's binary_logloss: 0.116231\tvalid_1's auc: 0.835262\tvalid_1's binary_logloss: 0.131365\n",
            "[32]\ttraining's auc: 0.903917\ttraining's binary_logloss: 0.115751\tvalid_1's auc: 0.835244\tvalid_1's binary_logloss: 0.131372\n",
            "[33]\ttraining's auc: 0.904434\ttraining's binary_logloss: 0.115448\tvalid_1's auc: 0.835594\tvalid_1's binary_logloss: 0.131323\n",
            "[34]\ttraining's auc: 0.905353\ttraining's binary_logloss: 0.115071\tvalid_1's auc: 0.835481\tvalid_1's binary_logloss: 0.131355\n",
            "[35]\ttraining's auc: 0.906453\ttraining's binary_logloss: 0.114661\tvalid_1's auc: 0.835105\tvalid_1's binary_logloss: 0.131387\n",
            "[36]\ttraining's auc: 0.907753\ttraining's binary_logloss: 0.114259\tvalid_1's auc: 0.835234\tvalid_1's binary_logloss: 0.131363\n",
            "[37]\ttraining's auc: 0.908851\ttraining's binary_logloss: 0.113815\tvalid_1's auc: 0.835069\tvalid_1's binary_logloss: 0.131398\n",
            "[38]\ttraining's auc: 0.909599\ttraining's binary_logloss: 0.113414\tvalid_1's auc: 0.834861\tvalid_1's binary_logloss: 0.131401\n",
            "[39]\ttraining's auc: 0.910437\ttraining's binary_logloss: 0.113092\tvalid_1's auc: 0.835139\tvalid_1's binary_logloss: 0.131323\n",
            "[40]\ttraining's auc: 0.911594\ttraining's binary_logloss: 0.112635\tvalid_1's auc: 0.8347\tvalid_1's binary_logloss: 0.131421\n",
            "[41]\ttraining's auc: 0.912198\ttraining's binary_logloss: 0.112282\tvalid_1's auc: 0.834817\tvalid_1's binary_logloss: 0.13142\n",
            "[42]\ttraining's auc: 0.913178\ttraining's binary_logloss: 0.111906\tvalid_1's auc: 0.834389\tvalid_1's binary_logloss: 0.131476\n",
            "[43]\ttraining's auc: 0.913867\ttraining's binary_logloss: 0.111624\tvalid_1's auc: 0.834133\tvalid_1's binary_logloss: 0.131487\n",
            "[44]\ttraining's auc: 0.914552\ttraining's binary_logloss: 0.111237\tvalid_1's auc: 0.834077\tvalid_1's binary_logloss: 0.131511\n",
            "[45]\ttraining's auc: 0.91526\ttraining's binary_logloss: 0.110941\tvalid_1's auc: 0.834533\tvalid_1's binary_logloss: 0.131431\n",
            "[46]\ttraining's auc: 0.916153\ttraining's binary_logloss: 0.110537\tvalid_1's auc: 0.83436\tvalid_1's binary_logloss: 0.131467\n",
            "[47]\ttraining's auc: 0.91676\ttraining's binary_logloss: 0.110173\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.131493\n",
            "[48]\ttraining's auc: 0.91781\ttraining's binary_logloss: 0.109786\tvalid_1's auc: 0.834226\tvalid_1's binary_logloss: 0.131523\n",
            "[49]\ttraining's auc: 0.918548\ttraining's binary_logloss: 0.109462\tvalid_1's auc: 0.834259\tvalid_1's binary_logloss: 0.131527\n",
            "[50]\ttraining's auc: 0.919616\ttraining's binary_logloss: 0.109052\tvalid_1's auc: 0.834039\tvalid_1's binary_logloss: 0.131578\n",
            "[51]\ttraining's auc: 0.920018\ttraining's binary_logloss: 0.108802\tvalid_1's auc: 0.83372\tvalid_1's binary_logloss: 0.131673\n",
            "[52]\ttraining's auc: 0.92076\ttraining's binary_logloss: 0.108565\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.131716\n",
            "[53]\ttraining's auc: 0.921213\ttraining's binary_logloss: 0.108311\tvalid_1's auc: 0.833378\tvalid_1's binary_logloss: 0.131753\n",
            "[54]\ttraining's auc: 0.9215\ttraining's binary_logloss: 0.108101\tvalid_1's auc: 0.833404\tvalid_1's binary_logloss: 0.131747\n",
            "[55]\ttraining's auc: 0.922347\ttraining's binary_logloss: 0.107802\tvalid_1's auc: 0.833199\tvalid_1's binary_logloss: 0.131773\n",
            "[56]\ttraining's auc: 0.923088\ttraining's binary_logloss: 0.107465\tvalid_1's auc: 0.833114\tvalid_1's binary_logloss: 0.131809\n",
            " 66%|██████▌   | 33/50 [16:51<09:03, 32.00s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.153037\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.15949\n",
            "[2]\ttraining's auc: 0.834337\ttraining's binary_logloss: 0.147244\tvalid_1's auc: 0.816859\tvalid_1's binary_logloss: 0.154248\n",
            "[3]\ttraining's auc: 0.84269\ttraining's binary_logloss: 0.142864\tvalid_1's auc: 0.822382\tvalid_1's binary_logloss: 0.150656\n",
            "[4]\ttraining's auc: 0.847599\ttraining's binary_logloss: 0.1395\tvalid_1's auc: 0.826982\tvalid_1's binary_logloss: 0.147931\n",
            "[5]\ttraining's auc: 0.850816\ttraining's binary_logloss: 0.136787\tvalid_1's auc: 0.827141\tvalid_1's binary_logloss: 0.145858\n",
            "[6]\ttraining's auc: 0.854052\ttraining's binary_logloss: 0.134571\tvalid_1's auc: 0.829844\tvalid_1's binary_logloss: 0.144083\n",
            "[7]\ttraining's auc: 0.856758\ttraining's binary_logloss: 0.132738\tvalid_1's auc: 0.83025\tvalid_1's binary_logloss: 0.142848\n",
            "[8]\ttraining's auc: 0.860313\ttraining's binary_logloss: 0.131026\tvalid_1's auc: 0.831195\tvalid_1's binary_logloss: 0.141758\n",
            "[9]\ttraining's auc: 0.863397\ttraining's binary_logloss: 0.129624\tvalid_1's auc: 0.830221\tvalid_1's binary_logloss: 0.140998\n",
            "[10]\ttraining's auc: 0.867046\ttraining's binary_logloss: 0.128305\tvalid_1's auc: 0.831084\tvalid_1's binary_logloss: 0.140271\n",
            "[11]\ttraining's auc: 0.869414\ttraining's binary_logloss: 0.127234\tvalid_1's auc: 0.833528\tvalid_1's binary_logloss: 0.139615\n",
            "[12]\ttraining's auc: 0.872025\ttraining's binary_logloss: 0.126143\tvalid_1's auc: 0.833383\tvalid_1's binary_logloss: 0.139157\n",
            "[13]\ttraining's auc: 0.874839\ttraining's binary_logloss: 0.125115\tvalid_1's auc: 0.833723\tvalid_1's binary_logloss: 0.138752\n",
            "[14]\ttraining's auc: 0.877023\ttraining's binary_logloss: 0.124122\tvalid_1's auc: 0.834372\tvalid_1's binary_logloss: 0.138364\n",
            "[15]\ttraining's auc: 0.87969\ttraining's binary_logloss: 0.123186\tvalid_1's auc: 0.833996\tvalid_1's binary_logloss: 0.138089\n",
            "[16]\ttraining's auc: 0.88145\ttraining's binary_logloss: 0.122386\tvalid_1's auc: 0.834211\tvalid_1's binary_logloss: 0.137862\n",
            "[17]\ttraining's auc: 0.883803\ttraining's binary_logloss: 0.121581\tvalid_1's auc: 0.834402\tvalid_1's binary_logloss: 0.137705\n",
            "[18]\ttraining's auc: 0.886412\ttraining's binary_logloss: 0.120808\tvalid_1's auc: 0.834889\tvalid_1's binary_logloss: 0.137455\n",
            "[19]\ttraining's auc: 0.888576\ttraining's binary_logloss: 0.120024\tvalid_1's auc: 0.833886\tvalid_1's binary_logloss: 0.137456\n",
            "[20]\ttraining's auc: 0.890078\ttraining's binary_logloss: 0.119426\tvalid_1's auc: 0.834899\tvalid_1's binary_logloss: 0.137243\n",
            "[21]\ttraining's auc: 0.891345\ttraining's binary_logloss: 0.118875\tvalid_1's auc: 0.83518\tvalid_1's binary_logloss: 0.137109\n",
            "[22]\ttraining's auc: 0.89218\ttraining's binary_logloss: 0.118319\tvalid_1's auc: 0.835515\tvalid_1's binary_logloss: 0.136988\n",
            "[23]\ttraining's auc: 0.893164\ttraining's binary_logloss: 0.117808\tvalid_1's auc: 0.835685\tvalid_1's binary_logloss: 0.136862\n",
            "[24]\ttraining's auc: 0.89507\ttraining's binary_logloss: 0.117236\tvalid_1's auc: 0.8352\tvalid_1's binary_logloss: 0.136847\n",
            "[25]\ttraining's auc: 0.896347\ttraining's binary_logloss: 0.116705\tvalid_1's auc: 0.835255\tvalid_1's binary_logloss: 0.136765\n",
            "[26]\ttraining's auc: 0.898259\ttraining's binary_logloss: 0.116152\tvalid_1's auc: 0.834632\tvalid_1's binary_logloss: 0.136818\n",
            "[27]\ttraining's auc: 0.899328\ttraining's binary_logloss: 0.115716\tvalid_1's auc: 0.835033\tvalid_1's binary_logloss: 0.136762\n",
            "[28]\ttraining's auc: 0.900682\ttraining's binary_logloss: 0.115158\tvalid_1's auc: 0.835492\tvalid_1's binary_logloss: 0.136658\n",
            "[29]\ttraining's auc: 0.901606\ttraining's binary_logloss: 0.114777\tvalid_1's auc: 0.835736\tvalid_1's binary_logloss: 0.136626\n",
            "[30]\ttraining's auc: 0.902697\ttraining's binary_logloss: 0.114396\tvalid_1's auc: 0.83552\tvalid_1's binary_logloss: 0.136595\n",
            "[31]\ttraining's auc: 0.903958\ttraining's binary_logloss: 0.114032\tvalid_1's auc: 0.835635\tvalid_1's binary_logloss: 0.136552\n",
            "[32]\ttraining's auc: 0.905102\ttraining's binary_logloss: 0.113533\tvalid_1's auc: 0.835641\tvalid_1's binary_logloss: 0.136556\n",
            "[33]\ttraining's auc: 0.906215\ttraining's binary_logloss: 0.11307\tvalid_1's auc: 0.835422\tvalid_1's binary_logloss: 0.136661\n",
            "[34]\ttraining's auc: 0.907516\ttraining's binary_logloss: 0.112602\tvalid_1's auc: 0.835277\tvalid_1's binary_logloss: 0.136707\n",
            "[35]\ttraining's auc: 0.908843\ttraining's binary_logloss: 0.112121\tvalid_1's auc: 0.835594\tvalid_1's binary_logloss: 0.136611\n",
            "[36]\ttraining's auc: 0.909829\ttraining's binary_logloss: 0.11164\tvalid_1's auc: 0.835584\tvalid_1's binary_logloss: 0.13663\n",
            "[37]\ttraining's auc: 0.910837\ttraining's binary_logloss: 0.111202\tvalid_1's auc: 0.835649\tvalid_1's binary_logloss: 0.13663\n",
            "[38]\ttraining's auc: 0.911551\ttraining's binary_logloss: 0.110815\tvalid_1's auc: 0.835832\tvalid_1's binary_logloss: 0.136618\n",
            "[39]\ttraining's auc: 0.912068\ttraining's binary_logloss: 0.110523\tvalid_1's auc: 0.835547\tvalid_1's binary_logloss: 0.136668\n",
            "[40]\ttraining's auc: 0.912733\ttraining's binary_logloss: 0.110181\tvalid_1's auc: 0.835383\tvalid_1's binary_logloss: 0.136692\n",
            "[41]\ttraining's auc: 0.913572\ttraining's binary_logloss: 0.109771\tvalid_1's auc: 0.835387\tvalid_1's binary_logloss: 0.136726\n",
            "[42]\ttraining's auc: 0.914212\ttraining's binary_logloss: 0.109495\tvalid_1's auc: 0.835318\tvalid_1's binary_logloss: 0.136772\n",
            "[43]\ttraining's auc: 0.914813\ttraining's binary_logloss: 0.109236\tvalid_1's auc: 0.835265\tvalid_1's binary_logloss: 0.1368\n",
            "[44]\ttraining's auc: 0.915997\ttraining's binary_logloss: 0.108748\tvalid_1's auc: 0.835678\tvalid_1's binary_logloss: 0.136745\n",
            "[45]\ttraining's auc: 0.916391\ttraining's binary_logloss: 0.108483\tvalid_1's auc: 0.835626\tvalid_1's binary_logloss: 0.136742\n",
            "[46]\ttraining's auc: 0.9177\ttraining's binary_logloss: 0.108133\tvalid_1's auc: 0.835745\tvalid_1's binary_logloss: 0.136711\n",
            "[47]\ttraining's auc: 0.918211\ttraining's binary_logloss: 0.107854\tvalid_1's auc: 0.835852\tvalid_1's binary_logloss: 0.136717\n",
            "[48]\ttraining's auc: 0.91907\ttraining's binary_logloss: 0.107491\tvalid_1's auc: 0.835616\tvalid_1's binary_logloss: 0.136798\n",
            "[49]\ttraining's auc: 0.919954\ttraining's binary_logloss: 0.10712\tvalid_1's auc: 0.835454\tvalid_1's binary_logloss: 0.136828\n",
            "[50]\ttraining's auc: 0.920341\ttraining's binary_logloss: 0.106938\tvalid_1's auc: 0.835827\tvalid_1's binary_logloss: 0.136762\n",
            "[51]\ttraining's auc: 0.920692\ttraining's binary_logloss: 0.106664\tvalid_1's auc: 0.835743\tvalid_1's binary_logloss: 0.136749\n",
            "[52]\ttraining's auc: 0.92134\ttraining's binary_logloss: 0.106317\tvalid_1's auc: 0.835643\tvalid_1's binary_logloss: 0.136769\n",
            "[53]\ttraining's auc: 0.921874\ttraining's binary_logloss: 0.106056\tvalid_1's auc: 0.835375\tvalid_1's binary_logloss: 0.136847\n",
            "[54]\ttraining's auc: 0.922207\ttraining's binary_logloss: 0.105827\tvalid_1's auc: 0.83538\tvalid_1's binary_logloss: 0.136901\n",
            "[55]\ttraining's auc: 0.922638\ttraining's binary_logloss: 0.105605\tvalid_1's auc: 0.835197\tvalid_1's binary_logloss: 0.136962\n",
            "[56]\ttraining's auc: 0.923219\ttraining's binary_logloss: 0.105314\tvalid_1's auc: 0.835228\tvalid_1's binary_logloss: 0.136991\n",
            "[57]\ttraining's auc: 0.92388\ttraining's binary_logloss: 0.105013\tvalid_1's auc: 0.835196\tvalid_1's binary_logloss: 0.136989\n",
            "[58]\ttraining's auc: 0.924921\ttraining's binary_logloss: 0.104553\tvalid_1's auc: 0.835003\tvalid_1's binary_logloss: 0.137091\n",
            "[59]\ttraining's auc: 0.925278\ttraining's binary_logloss: 0.104346\tvalid_1's auc: 0.834805\tvalid_1's binary_logloss: 0.137113\n",
            "[60]\ttraining's auc: 0.925611\ttraining's binary_logloss: 0.104144\tvalid_1's auc: 0.834762\tvalid_1's binary_logloss: 0.13715\n",
            "[61]\ttraining's auc: 0.926209\ttraining's binary_logloss: 0.103924\tvalid_1's auc: 0.834795\tvalid_1's binary_logloss: 0.137156\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 68%|██████▊   | 34/50 [17:01<07:40, 28.75s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.154371\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.157035\n",
            "[2]\ttraining's auc: 0.834591\ttraining's binary_logloss: 0.148479\tvalid_1's auc: 0.808884\tvalid_1's binary_logloss: 0.152386\n",
            "[3]\ttraining's auc: 0.844625\ttraining's binary_logloss: 0.144319\tvalid_1's auc: 0.814225\tvalid_1's binary_logloss: 0.149252\n",
            "[4]\ttraining's auc: 0.84901\ttraining's binary_logloss: 0.14103\tvalid_1's auc: 0.814453\tvalid_1's binary_logloss: 0.147029\n",
            "[5]\ttraining's auc: 0.852482\ttraining's binary_logloss: 0.138271\tvalid_1's auc: 0.816106\tvalid_1's binary_logloss: 0.145229\n",
            "[6]\ttraining's auc: 0.854593\ttraining's binary_logloss: 0.135955\tvalid_1's auc: 0.816905\tvalid_1's binary_logloss: 0.14369\n",
            "[7]\ttraining's auc: 0.856834\ttraining's binary_logloss: 0.133935\tvalid_1's auc: 0.819419\tvalid_1's binary_logloss: 0.142267\n",
            "[8]\ttraining's auc: 0.858773\ttraining's binary_logloss: 0.132292\tvalid_1's auc: 0.820593\tvalid_1's binary_logloss: 0.14126\n",
            "[9]\ttraining's auc: 0.862878\ttraining's binary_logloss: 0.130907\tvalid_1's auc: 0.8228\tvalid_1's binary_logloss: 0.140267\n",
            "[10]\ttraining's auc: 0.866877\ttraining's binary_logloss: 0.129582\tvalid_1's auc: 0.824095\tvalid_1's binary_logloss: 0.139564\n",
            "[11]\ttraining's auc: 0.869512\ttraining's binary_logloss: 0.128325\tvalid_1's auc: 0.824287\tvalid_1's binary_logloss: 0.139162\n",
            "[12]\ttraining's auc: 0.871755\ttraining's binary_logloss: 0.127249\tvalid_1's auc: 0.824675\tvalid_1's binary_logloss: 0.138705\n",
            "[13]\ttraining's auc: 0.873599\ttraining's binary_logloss: 0.126299\tvalid_1's auc: 0.824366\tvalid_1's binary_logloss: 0.138371\n",
            "[14]\ttraining's auc: 0.87564\ttraining's binary_logloss: 0.125365\tvalid_1's auc: 0.824966\tvalid_1's binary_logloss: 0.137997\n",
            "[15]\ttraining's auc: 0.878031\ttraining's binary_logloss: 0.124505\tvalid_1's auc: 0.826339\tvalid_1's binary_logloss: 0.137657\n",
            "[16]\ttraining's auc: 0.881176\ttraining's binary_logloss: 0.123545\tvalid_1's auc: 0.827003\tvalid_1's binary_logloss: 0.137324\n",
            "[17]\ttraining's auc: 0.882733\ttraining's binary_logloss: 0.122794\tvalid_1's auc: 0.827774\tvalid_1's binary_logloss: 0.137045\n",
            "[18]\ttraining's auc: 0.883819\ttraining's binary_logloss: 0.12211\tvalid_1's auc: 0.827943\tvalid_1's binary_logloss: 0.136965\n",
            "[19]\ttraining's auc: 0.884798\ttraining's binary_logloss: 0.121489\tvalid_1's auc: 0.828112\tvalid_1's binary_logloss: 0.136822\n",
            "[20]\ttraining's auc: 0.885681\ttraining's binary_logloss: 0.120938\tvalid_1's auc: 0.828618\tvalid_1's binary_logloss: 0.136657\n",
            "[21]\ttraining's auc: 0.886498\ttraining's binary_logloss: 0.120429\tvalid_1's auc: 0.828885\tvalid_1's binary_logloss: 0.136511\n",
            "[22]\ttraining's auc: 0.888535\ttraining's binary_logloss: 0.119758\tvalid_1's auc: 0.829318\tvalid_1's binary_logloss: 0.136395\n",
            "[23]\ttraining's auc: 0.89016\ttraining's binary_logloss: 0.119184\tvalid_1's auc: 0.829058\tvalid_1's binary_logloss: 0.136381\n",
            "[24]\ttraining's auc: 0.892641\ttraining's binary_logloss: 0.118536\tvalid_1's auc: 0.829687\tvalid_1's binary_logloss: 0.136203\n",
            "[25]\ttraining's auc: 0.894609\ttraining's binary_logloss: 0.118009\tvalid_1's auc: 0.829313\tvalid_1's binary_logloss: 0.136234\n",
            "[26]\ttraining's auc: 0.895726\ttraining's binary_logloss: 0.117489\tvalid_1's auc: 0.829175\tvalid_1's binary_logloss: 0.136184\n",
            "[27]\ttraining's auc: 0.897064\ttraining's binary_logloss: 0.116986\tvalid_1's auc: 0.829341\tvalid_1's binary_logloss: 0.136092\n",
            "[28]\ttraining's auc: 0.898776\ttraining's binary_logloss: 0.116557\tvalid_1's auc: 0.830196\tvalid_1's binary_logloss: 0.135975\n",
            "[29]\ttraining's auc: 0.900843\ttraining's binary_logloss: 0.11604\tvalid_1's auc: 0.83066\tvalid_1's binary_logloss: 0.135918\n",
            "[30]\ttraining's auc: 0.90153\ttraining's binary_logloss: 0.115642\tvalid_1's auc: 0.830704\tvalid_1's binary_logloss: 0.135953\n",
            "[31]\ttraining's auc: 0.902564\ttraining's binary_logloss: 0.115241\tvalid_1's auc: 0.830153\tvalid_1's binary_logloss: 0.136051\n",
            "[32]\ttraining's auc: 0.903436\ttraining's binary_logloss: 0.114738\tvalid_1's auc: 0.830367\tvalid_1's binary_logloss: 0.136017\n",
            "[33]\ttraining's auc: 0.904164\ttraining's binary_logloss: 0.114367\tvalid_1's auc: 0.830332\tvalid_1's binary_logloss: 0.136003\n",
            "[34]\ttraining's auc: 0.905164\ttraining's binary_logloss: 0.113982\tvalid_1's auc: 0.830043\tvalid_1's binary_logloss: 0.136108\n",
            "[35]\ttraining's auc: 0.905981\ttraining's binary_logloss: 0.113596\tvalid_1's auc: 0.830061\tvalid_1's binary_logloss: 0.136097\n",
            "[36]\ttraining's auc: 0.907299\ttraining's binary_logloss: 0.113177\tvalid_1's auc: 0.82968\tvalid_1's binary_logloss: 0.136168\n",
            "[37]\ttraining's auc: 0.907783\ttraining's binary_logloss: 0.112854\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.136277\n",
            "[38]\ttraining's auc: 0.908588\ttraining's binary_logloss: 0.112576\tvalid_1's auc: 0.829473\tvalid_1's binary_logloss: 0.136265\n",
            "[39]\ttraining's auc: 0.909363\ttraining's binary_logloss: 0.112228\tvalid_1's auc: 0.829096\tvalid_1's binary_logloss: 0.136379\n",
            "[40]\ttraining's auc: 0.910108\ttraining's binary_logloss: 0.11189\tvalid_1's auc: 0.829197\tvalid_1's binary_logloss: 0.136392\n",
            "[41]\ttraining's auc: 0.910754\ttraining's binary_logloss: 0.111579\tvalid_1's auc: 0.829093\tvalid_1's binary_logloss: 0.136435\n",
            "[42]\ttraining's auc: 0.911333\ttraining's binary_logloss: 0.111302\tvalid_1's auc: 0.828949\tvalid_1's binary_logloss: 0.13649\n",
            "[43]\ttraining's auc: 0.912296\ttraining's binary_logloss: 0.110983\tvalid_1's auc: 0.829243\tvalid_1's binary_logloss: 0.136447\n",
            "[44]\ttraining's auc: 0.913265\ttraining's binary_logloss: 0.110712\tvalid_1's auc: 0.829331\tvalid_1's binary_logloss: 0.136438\n",
            "[45]\ttraining's auc: 0.913587\ttraining's binary_logloss: 0.110498\tvalid_1's auc: 0.828948\tvalid_1's binary_logloss: 0.136514\n",
            "[46]\ttraining's auc: 0.915263\ttraining's binary_logloss: 0.109945\tvalid_1's auc: 0.828525\tvalid_1's binary_logloss: 0.13663\n",
            "[47]\ttraining's auc: 0.915708\ttraining's binary_logloss: 0.109691\tvalid_1's auc: 0.828102\tvalid_1's binary_logloss: 0.136724\n",
            "[48]\ttraining's auc: 0.916887\ttraining's binary_logloss: 0.109417\tvalid_1's auc: 0.827981\tvalid_1's binary_logloss: 0.136745\n",
            "[49]\ttraining's auc: 0.917833\ttraining's binary_logloss: 0.109059\tvalid_1's auc: 0.827637\tvalid_1's binary_logloss: 0.136829\n",
            "[50]\ttraining's auc: 0.918418\ttraining's binary_logloss: 0.108761\tvalid_1's auc: 0.82744\tvalid_1's binary_logloss: 0.136873\n",
            "[51]\ttraining's auc: 0.918844\ttraining's binary_logloss: 0.108524\tvalid_1's auc: 0.827437\tvalid_1's binary_logloss: 0.136886\n",
            "[52]\ttraining's auc: 0.919185\ttraining's binary_logloss: 0.108317\tvalid_1's auc: 0.827051\tvalid_1's binary_logloss: 0.136987\n",
            "[53]\ttraining's auc: 0.92009\ttraining's binary_logloss: 0.108047\tvalid_1's auc: 0.82724\tvalid_1's binary_logloss: 0.136993\n",
            "[54]\ttraining's auc: 0.920388\ttraining's binary_logloss: 0.107836\tvalid_1's auc: 0.82692\tvalid_1's binary_logloss: 0.13708\n",
            "[55]\ttraining's auc: 0.920978\ttraining's binary_logloss: 0.107529\tvalid_1's auc: 0.826662\tvalid_1's binary_logloss: 0.137139\n",
            "[56]\ttraining's auc: 0.9212\ttraining's binary_logloss: 0.107367\tvalid_1's auc: 0.826146\tvalid_1's binary_logloss: 0.137249\n",
            "[57]\ttraining's auc: 0.921598\ttraining's binary_logloss: 0.107122\tvalid_1's auc: 0.826066\tvalid_1's binary_logloss: 0.13728\n",
            "[58]\ttraining's auc: 0.922074\ttraining's binary_logloss: 0.106861\tvalid_1's auc: 0.825513\tvalid_1's binary_logloss: 0.137446\n",
            "[59]\ttraining's auc: 0.923307\ttraining's binary_logloss: 0.106434\tvalid_1's auc: 0.825301\tvalid_1's binary_logloss: 0.13748\n",
            " 68%|██████▊   | 34/50 [17:08<07:40, 28.75s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.1568\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.153031\n",
            "[2]\ttraining's auc: 0.831242\ttraining's binary_logloss: 0.150804\tvalid_1's auc: 0.816825\tvalid_1's binary_logloss: 0.148347\n",
            "[3]\ttraining's auc: 0.838662\ttraining's binary_logloss: 0.146508\tvalid_1's auc: 0.820585\tvalid_1's binary_logloss: 0.145107\n",
            "[4]\ttraining's auc: 0.844517\ttraining's binary_logloss: 0.14315\tvalid_1's auc: 0.824988\tvalid_1's binary_logloss: 0.142721\n",
            "[5]\ttraining's auc: 0.8503\ttraining's binary_logloss: 0.140359\tvalid_1's auc: 0.825499\tvalid_1's binary_logloss: 0.140831\n",
            "[6]\ttraining's auc: 0.853391\ttraining's binary_logloss: 0.138122\tvalid_1's auc: 0.828949\tvalid_1's binary_logloss: 0.139181\n",
            "[7]\ttraining's auc: 0.855982\ttraining's binary_logloss: 0.136212\tvalid_1's auc: 0.830375\tvalid_1's binary_logloss: 0.137898\n",
            "[8]\ttraining's auc: 0.858113\ttraining's binary_logloss: 0.134553\tvalid_1's auc: 0.83162\tvalid_1's binary_logloss: 0.136819\n",
            "[9]\ttraining's auc: 0.861328\ttraining's binary_logloss: 0.13304\tvalid_1's auc: 0.832329\tvalid_1's binary_logloss: 0.135918\n",
            "[10]\ttraining's auc: 0.865937\ttraining's binary_logloss: 0.131601\tvalid_1's auc: 0.832436\tvalid_1's binary_logloss: 0.135288\n",
            "[11]\ttraining's auc: 0.869373\ttraining's binary_logloss: 0.130292\tvalid_1's auc: 0.833322\tvalid_1's binary_logloss: 0.134723\n",
            "[12]\ttraining's auc: 0.871166\ttraining's binary_logloss: 0.129151\tvalid_1's auc: 0.834383\tvalid_1's binary_logloss: 0.134098\n",
            "[13]\ttraining's auc: 0.872845\ttraining's binary_logloss: 0.128173\tvalid_1's auc: 0.833912\tvalid_1's binary_logloss: 0.133736\n",
            "[14]\ttraining's auc: 0.874445\ttraining's binary_logloss: 0.127177\tvalid_1's auc: 0.833872\tvalid_1's binary_logloss: 0.13341\n",
            "[15]\ttraining's auc: 0.877024\ttraining's binary_logloss: 0.126311\tvalid_1's auc: 0.834068\tvalid_1's binary_logloss: 0.13316\n",
            "[16]\ttraining's auc: 0.878221\ttraining's binary_logloss: 0.125446\tvalid_1's auc: 0.834057\tvalid_1's binary_logloss: 0.132889\n",
            "[17]\ttraining's auc: 0.880506\ttraining's binary_logloss: 0.124611\tvalid_1's auc: 0.834132\tvalid_1's binary_logloss: 0.132663\n",
            "[18]\ttraining's auc: 0.882403\ttraining's binary_logloss: 0.123874\tvalid_1's auc: 0.834407\tvalid_1's binary_logloss: 0.132487\n",
            "[19]\ttraining's auc: 0.884367\ttraining's binary_logloss: 0.12318\tvalid_1's auc: 0.834023\tvalid_1's binary_logloss: 0.13239\n",
            "[20]\ttraining's auc: 0.886571\ttraining's binary_logloss: 0.122515\tvalid_1's auc: 0.834686\tvalid_1's binary_logloss: 0.132204\n",
            "[21]\ttraining's auc: 0.887679\ttraining's binary_logloss: 0.121862\tvalid_1's auc: 0.835549\tvalid_1's binary_logloss: 0.132019\n",
            "[22]\ttraining's auc: 0.888828\ttraining's binary_logloss: 0.121306\tvalid_1's auc: 0.836336\tvalid_1's binary_logloss: 0.131844\n",
            "[23]\ttraining's auc: 0.890198\ttraining's binary_logloss: 0.120765\tvalid_1's auc: 0.835837\tvalid_1's binary_logloss: 0.131769\n",
            "[24]\ttraining's auc: 0.891952\ttraining's binary_logloss: 0.120213\tvalid_1's auc: 0.835767\tvalid_1's binary_logloss: 0.131714\n",
            "[25]\ttraining's auc: 0.893989\ttraining's binary_logloss: 0.119593\tvalid_1's auc: 0.835599\tvalid_1's binary_logloss: 0.131671\n",
            "[26]\ttraining's auc: 0.895756\ttraining's binary_logloss: 0.119048\tvalid_1's auc: 0.836513\tvalid_1's binary_logloss: 0.13153\n",
            "[27]\ttraining's auc: 0.896798\ttraining's binary_logloss: 0.118577\tvalid_1's auc: 0.836097\tvalid_1's binary_logloss: 0.131524\n",
            "[28]\ttraining's auc: 0.897563\ttraining's binary_logloss: 0.118128\tvalid_1's auc: 0.83611\tvalid_1's binary_logloss: 0.131511\n",
            "[29]\ttraining's auc: 0.89942\ttraining's binary_logloss: 0.117637\tvalid_1's auc: 0.836358\tvalid_1's binary_logloss: 0.131446\n",
            "[30]\ttraining's auc: 0.90135\ttraining's binary_logloss: 0.117164\tvalid_1's auc: 0.836308\tvalid_1's binary_logloss: 0.131422\n",
            "[31]\ttraining's auc: 0.902604\ttraining's binary_logloss: 0.116666\tvalid_1's auc: 0.836199\tvalid_1's binary_logloss: 0.131453\n",
            "[32]\ttraining's auc: 0.904032\ttraining's binary_logloss: 0.116249\tvalid_1's auc: 0.83616\tvalid_1's binary_logloss: 0.131463\n",
            "[33]\ttraining's auc: 0.905685\ttraining's binary_logloss: 0.115735\tvalid_1's auc: 0.836238\tvalid_1's binary_logloss: 0.131475\n",
            "[34]\ttraining's auc: 0.906597\ttraining's binary_logloss: 0.11529\tvalid_1's auc: 0.836553\tvalid_1's binary_logloss: 0.13139\n",
            "[35]\ttraining's auc: 0.90739\ttraining's binary_logloss: 0.114891\tvalid_1's auc: 0.836303\tvalid_1's binary_logloss: 0.131446\n",
            "[36]\ttraining's auc: 0.908149\ttraining's binary_logloss: 0.114609\tvalid_1's auc: 0.83628\tvalid_1's binary_logloss: 0.131417\n",
            "[37]\ttraining's auc: 0.908864\ttraining's binary_logloss: 0.114245\tvalid_1's auc: 0.836456\tvalid_1's binary_logloss: 0.131364\n",
            "[38]\ttraining's auc: 0.910279\ttraining's binary_logloss: 0.113771\tvalid_1's auc: 0.836052\tvalid_1's binary_logloss: 0.131424\n",
            "[39]\ttraining's auc: 0.910848\ttraining's binary_logloss: 0.113423\tvalid_1's auc: 0.836201\tvalid_1's binary_logloss: 0.131397\n",
            "[40]\ttraining's auc: 0.911662\ttraining's binary_logloss: 0.113017\tvalid_1's auc: 0.835533\tvalid_1's binary_logloss: 0.131546\n",
            "[41]\ttraining's auc: 0.912268\ttraining's binary_logloss: 0.112768\tvalid_1's auc: 0.835428\tvalid_1's binary_logloss: 0.131556\n",
            "[42]\ttraining's auc: 0.913026\ttraining's binary_logloss: 0.112363\tvalid_1's auc: 0.835445\tvalid_1's binary_logloss: 0.131588\n",
            "[43]\ttraining's auc: 0.914856\ttraining's binary_logloss: 0.111844\tvalid_1's auc: 0.835631\tvalid_1's binary_logloss: 0.131562\n",
            "[44]\ttraining's auc: 0.915409\ttraining's binary_logloss: 0.111517\tvalid_1's auc: 0.835711\tvalid_1's binary_logloss: 0.131526\n",
            "[45]\ttraining's auc: 0.916223\ttraining's binary_logloss: 0.111148\tvalid_1's auc: 0.83586\tvalid_1's binary_logloss: 0.131494\n",
            "[46]\ttraining's auc: 0.916563\ttraining's binary_logloss: 0.110905\tvalid_1's auc: 0.835673\tvalid_1's binary_logloss: 0.131468\n",
            "[47]\ttraining's auc: 0.917322\ttraining's binary_logloss: 0.110659\tvalid_1's auc: 0.835873\tvalid_1's binary_logloss: 0.13145\n",
            "[48]\ttraining's auc: 0.917853\ttraining's binary_logloss: 0.110405\tvalid_1's auc: 0.836018\tvalid_1's binary_logloss: 0.131424\n",
            "[49]\ttraining's auc: 0.918179\ttraining's binary_logloss: 0.110165\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.131458\n",
            "[50]\ttraining's auc: 0.918714\ttraining's binary_logloss: 0.109845\tvalid_1's auc: 0.835927\tvalid_1's binary_logloss: 0.131428\n",
            "[51]\ttraining's auc: 0.919073\ttraining's binary_logloss: 0.109589\tvalid_1's auc: 0.835759\tvalid_1's binary_logloss: 0.13147\n",
            "[52]\ttraining's auc: 0.919828\ttraining's binary_logloss: 0.109271\tvalid_1's auc: 0.8357\tvalid_1's binary_logloss: 0.131476\n",
            "[53]\ttraining's auc: 0.920221\ttraining's binary_logloss: 0.10902\tvalid_1's auc: 0.835648\tvalid_1's binary_logloss: 0.131469\n",
            "[54]\ttraining's auc: 0.920681\ttraining's binary_logloss: 0.108828\tvalid_1's auc: 0.835411\tvalid_1's binary_logloss: 0.131507\n",
            "[55]\ttraining's auc: 0.921022\ttraining's binary_logloss: 0.108626\tvalid_1's auc: 0.835483\tvalid_1's binary_logloss: 0.131504\n",
            "[56]\ttraining's auc: 0.9214\ttraining's binary_logloss: 0.108394\tvalid_1's auc: 0.835018\tvalid_1's binary_logloss: 0.131588\n",
            "[57]\ttraining's auc: 0.921765\ttraining's binary_logloss: 0.108177\tvalid_1's auc: 0.83502\tvalid_1's binary_logloss: 0.13156\n",
            "[58]\ttraining's auc: 0.922263\ttraining's binary_logloss: 0.107903\tvalid_1's auc: 0.834825\tvalid_1's binary_logloss: 0.131632\n",
            "[59]\ttraining's auc: 0.922635\ttraining's binary_logloss: 0.107692\tvalid_1's auc: 0.834787\tvalid_1's binary_logloss: 0.131628\n",
            "[60]\ttraining's auc: 0.922885\ttraining's binary_logloss: 0.107513\tvalid_1's auc: 0.834664\tvalid_1's binary_logloss: 0.131671\n",
            "[61]\ttraining's auc: 0.92332\ttraining's binary_logloss: 0.10724\tvalid_1's auc: 0.834009\tvalid_1's binary_logloss: 0.131778\n",
            "[62]\ttraining's auc: 0.924153\ttraining's binary_logloss: 0.106892\tvalid_1's auc: 0.833912\tvalid_1's binary_logloss: 0.131808\n",
            "[63]\ttraining's auc: 0.924559\ttraining's binary_logloss: 0.106656\tvalid_1's auc: 0.834038\tvalid_1's binary_logloss: 0.131806\n",
            "[64]\ttraining's auc: 0.92506\ttraining's binary_logloss: 0.106417\tvalid_1's auc: 0.834117\tvalid_1's binary_logloss: 0.131808\n",
            " 68%|██████▊   | 34/50 [17:17<07:40, 28.75s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.153554\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.159947\n",
            "[2]\ttraining's auc: 0.834306\ttraining's binary_logloss: 0.14789\tvalid_1's auc: 0.816965\tvalid_1's binary_logloss: 0.1548\n",
            "[3]\ttraining's auc: 0.844297\ttraining's binary_logloss: 0.143713\tvalid_1's auc: 0.823354\tvalid_1's binary_logloss: 0.151143\n",
            "[4]\ttraining's auc: 0.848819\ttraining's binary_logloss: 0.140411\tvalid_1's auc: 0.824705\tvalid_1's binary_logloss: 0.148594\n",
            "[5]\ttraining's auc: 0.851015\ttraining's binary_logloss: 0.137654\tvalid_1's auc: 0.826705\tvalid_1's binary_logloss: 0.146558\n",
            "[6]\ttraining's auc: 0.852483\ttraining's binary_logloss: 0.135432\tvalid_1's auc: 0.827839\tvalid_1's binary_logloss: 0.144827\n",
            "[7]\ttraining's auc: 0.855885\ttraining's binary_logloss: 0.133593\tvalid_1's auc: 0.829793\tvalid_1's binary_logloss: 0.143304\n",
            "[8]\ttraining's auc: 0.857785\ttraining's binary_logloss: 0.131969\tvalid_1's auc: 0.830678\tvalid_1's binary_logloss: 0.142176\n",
            "[9]\ttraining's auc: 0.860413\ttraining's binary_logloss: 0.130484\tvalid_1's auc: 0.83126\tvalid_1's binary_logloss: 0.141231\n",
            "[10]\ttraining's auc: 0.864308\ttraining's binary_logloss: 0.129164\tvalid_1's auc: 0.831224\tvalid_1's binary_logloss: 0.140472\n",
            "[11]\ttraining's auc: 0.866791\ttraining's binary_logloss: 0.128045\tvalid_1's auc: 0.833972\tvalid_1's binary_logloss: 0.139735\n",
            "[12]\ttraining's auc: 0.869794\ttraining's binary_logloss: 0.126904\tvalid_1's auc: 0.834942\tvalid_1's binary_logloss: 0.139139\n",
            "[13]\ttraining's auc: 0.872495\ttraining's binary_logloss: 0.12584\tvalid_1's auc: 0.834047\tvalid_1's binary_logloss: 0.138748\n",
            "[14]\ttraining's auc: 0.874518\ttraining's binary_logloss: 0.124911\tvalid_1's auc: 0.834495\tvalid_1's binary_logloss: 0.138297\n",
            "[15]\ttraining's auc: 0.877159\ttraining's binary_logloss: 0.123992\tvalid_1's auc: 0.835347\tvalid_1's binary_logloss: 0.137888\n",
            "[16]\ttraining's auc: 0.878991\ttraining's binary_logloss: 0.123205\tvalid_1's auc: 0.835654\tvalid_1's binary_logloss: 0.137577\n",
            "[17]\ttraining's auc: 0.881277\ttraining's binary_logloss: 0.122422\tvalid_1's auc: 0.835423\tvalid_1's binary_logloss: 0.137416\n",
            "[18]\ttraining's auc: 0.883704\ttraining's binary_logloss: 0.121673\tvalid_1's auc: 0.8354\tvalid_1's binary_logloss: 0.137169\n",
            "[19]\ttraining's auc: 0.884743\ttraining's binary_logloss: 0.121056\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.136862\n",
            "[20]\ttraining's auc: 0.886647\ttraining's binary_logloss: 0.120459\tvalid_1's auc: 0.836083\tvalid_1's binary_logloss: 0.136717\n",
            "[21]\ttraining's auc: 0.88815\ttraining's binary_logloss: 0.119868\tvalid_1's auc: 0.836576\tvalid_1's binary_logloss: 0.136503\n",
            "[22]\ttraining's auc: 0.88943\ttraining's binary_logloss: 0.119303\tvalid_1's auc: 0.836786\tvalid_1's binary_logloss: 0.136409\n",
            "[23]\ttraining's auc: 0.890933\ttraining's binary_logloss: 0.118744\tvalid_1's auc: 0.836626\tvalid_1's binary_logloss: 0.136358\n",
            "[24]\ttraining's auc: 0.892561\ttraining's binary_logloss: 0.118241\tvalid_1's auc: 0.836116\tvalid_1's binary_logloss: 0.136381\n",
            "[25]\ttraining's auc: 0.894002\ttraining's binary_logloss: 0.117697\tvalid_1's auc: 0.835971\tvalid_1's binary_logloss: 0.13637\n",
            "[26]\ttraining's auc: 0.895457\ttraining's binary_logloss: 0.117173\tvalid_1's auc: 0.836204\tvalid_1's binary_logloss: 0.136298\n",
            "[27]\ttraining's auc: 0.896724\ttraining's binary_logloss: 0.116692\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.136289\n",
            "[28]\ttraining's auc: 0.897868\ttraining's binary_logloss: 0.116292\tvalid_1's auc: 0.835884\tvalid_1's binary_logloss: 0.136297\n",
            "[29]\ttraining's auc: 0.898971\ttraining's binary_logloss: 0.11589\tvalid_1's auc: 0.835619\tvalid_1's binary_logloss: 0.13627\n",
            "[30]\ttraining's auc: 0.900068\ttraining's binary_logloss: 0.115468\tvalid_1's auc: 0.835415\tvalid_1's binary_logloss: 0.136277\n",
            "[31]\ttraining's auc: 0.902164\ttraining's binary_logloss: 0.114789\tvalid_1's auc: 0.835461\tvalid_1's binary_logloss: 0.136224\n",
            "[32]\ttraining's auc: 0.903473\ttraining's binary_logloss: 0.114274\tvalid_1's auc: 0.83541\tvalid_1's binary_logloss: 0.136192\n",
            "[33]\ttraining's auc: 0.904609\ttraining's binary_logloss: 0.113784\tvalid_1's auc: 0.834825\tvalid_1's binary_logloss: 0.136318\n",
            "[34]\ttraining's auc: 0.905649\ttraining's binary_logloss: 0.113306\tvalid_1's auc: 0.834503\tvalid_1's binary_logloss: 0.136338\n",
            "[35]\ttraining's auc: 0.906456\ttraining's binary_logloss: 0.112877\tvalid_1's auc: 0.834476\tvalid_1's binary_logloss: 0.136347\n",
            "[36]\ttraining's auc: 0.907048\ttraining's binary_logloss: 0.112548\tvalid_1's auc: 0.834458\tvalid_1's binary_logloss: 0.136395\n",
            "[37]\ttraining's auc: 0.907736\ttraining's binary_logloss: 0.112202\tvalid_1's auc: 0.83423\tvalid_1's binary_logloss: 0.136452\n",
            "[38]\ttraining's auc: 0.908966\ttraining's binary_logloss: 0.111719\tvalid_1's auc: 0.834486\tvalid_1's binary_logloss: 0.136391\n",
            "[39]\ttraining's auc: 0.909745\ttraining's binary_logloss: 0.111369\tvalid_1's auc: 0.834105\tvalid_1's binary_logloss: 0.136469\n",
            "[40]\ttraining's auc: 0.910983\ttraining's binary_logloss: 0.110922\tvalid_1's auc: 0.833389\tvalid_1's binary_logloss: 0.136616\n",
            "[41]\ttraining's auc: 0.911571\ttraining's binary_logloss: 0.110634\tvalid_1's auc: 0.833283\tvalid_1's binary_logloss: 0.136708\n",
            "[42]\ttraining's auc: 0.912248\ttraining's binary_logloss: 0.110306\tvalid_1's auc: 0.833597\tvalid_1's binary_logloss: 0.13664\n",
            "[43]\ttraining's auc: 0.912752\ttraining's binary_logloss: 0.110033\tvalid_1's auc: 0.83351\tvalid_1's binary_logloss: 0.136665\n",
            "[44]\ttraining's auc: 0.913816\ttraining's binary_logloss: 0.109728\tvalid_1's auc: 0.834443\tvalid_1's binary_logloss: 0.136552\n",
            "[45]\ttraining's auc: 0.914718\ttraining's binary_logloss: 0.109374\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.136609\n",
            "[46]\ttraining's auc: 0.91565\ttraining's binary_logloss: 0.109073\tvalid_1's auc: 0.834353\tvalid_1's binary_logloss: 0.136628\n",
            "[47]\ttraining's auc: 0.916163\ttraining's binary_logloss: 0.108826\tvalid_1's auc: 0.834168\tvalid_1's binary_logloss: 0.136679\n",
            "[48]\ttraining's auc: 0.916463\ttraining's binary_logloss: 0.108551\tvalid_1's auc: 0.834017\tvalid_1's binary_logloss: 0.136736\n",
            "[49]\ttraining's auc: 0.916819\ttraining's binary_logloss: 0.108337\tvalid_1's auc: 0.833808\tvalid_1's binary_logloss: 0.136792\n",
            "[50]\ttraining's auc: 0.917851\ttraining's binary_logloss: 0.107918\tvalid_1's auc: 0.833655\tvalid_1's binary_logloss: 0.136826\n",
            "[51]\ttraining's auc: 0.918624\ttraining's binary_logloss: 0.107605\tvalid_1's auc: 0.833658\tvalid_1's binary_logloss: 0.136868\n",
            "[52]\ttraining's auc: 0.91906\ttraining's binary_logloss: 0.107332\tvalid_1's auc: 0.833727\tvalid_1's binary_logloss: 0.13692\n",
            " 70%|███████   | 35/50 [17:26<06:55, 27.73s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.155693\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.158105\n",
            "[2]\ttraining's auc: 0.833418\ttraining's binary_logloss: 0.150199\tvalid_1's auc: 0.806522\tvalid_1's binary_logloss: 0.153904\n",
            "[3]\ttraining's auc: 0.843409\ttraining's binary_logloss: 0.146171\tvalid_1's auc: 0.815488\tvalid_1's binary_logloss: 0.150807\n",
            "[4]\ttraining's auc: 0.846491\ttraining's binary_logloss: 0.142967\tvalid_1's auc: 0.815084\tvalid_1's binary_logloss: 0.148702\n",
            "[5]\ttraining's auc: 0.849583\ttraining's binary_logloss: 0.140313\tvalid_1's auc: 0.816707\tvalid_1's binary_logloss: 0.146784\n",
            "[6]\ttraining's auc: 0.852631\ttraining's binary_logloss: 0.138045\tvalid_1's auc: 0.818733\tvalid_1's binary_logloss: 0.145065\n",
            "[7]\ttraining's auc: 0.854234\ttraining's binary_logloss: 0.136094\tvalid_1's auc: 0.818676\tvalid_1's binary_logloss: 0.14373\n",
            "[8]\ttraining's auc: 0.855\ttraining's binary_logloss: 0.134474\tvalid_1's auc: 0.819765\tvalid_1's binary_logloss: 0.142621\n",
            "[9]\ttraining's auc: 0.859303\ttraining's binary_logloss: 0.132967\tvalid_1's auc: 0.82167\tvalid_1's binary_logloss: 0.141662\n",
            "[10]\ttraining's auc: 0.862994\ttraining's binary_logloss: 0.131733\tvalid_1's auc: 0.823077\tvalid_1's binary_logloss: 0.140804\n",
            "[11]\ttraining's auc: 0.864436\ttraining's binary_logloss: 0.130522\tvalid_1's auc: 0.824678\tvalid_1's binary_logloss: 0.140104\n",
            "[12]\ttraining's auc: 0.867317\ttraining's binary_logloss: 0.129393\tvalid_1's auc: 0.82494\tvalid_1's binary_logloss: 0.139645\n",
            "[13]\ttraining's auc: 0.869784\ttraining's binary_logloss: 0.128388\tvalid_1's auc: 0.825383\tvalid_1's binary_logloss: 0.139134\n",
            "[14]\ttraining's auc: 0.871393\ttraining's binary_logloss: 0.127458\tvalid_1's auc: 0.826563\tvalid_1's binary_logloss: 0.138721\n",
            "[15]\ttraining's auc: 0.873389\ttraining's binary_logloss: 0.126611\tvalid_1's auc: 0.826991\tvalid_1's binary_logloss: 0.138343\n",
            "[16]\ttraining's auc: 0.875213\ttraining's binary_logloss: 0.125749\tvalid_1's auc: 0.826919\tvalid_1's binary_logloss: 0.13802\n",
            "[17]\ttraining's auc: 0.876767\ttraining's binary_logloss: 0.125013\tvalid_1's auc: 0.827126\tvalid_1's binary_logloss: 0.137764\n",
            "[18]\ttraining's auc: 0.87968\ttraining's binary_logloss: 0.124263\tvalid_1's auc: 0.827061\tvalid_1's binary_logloss: 0.137595\n",
            "[19]\ttraining's auc: 0.881073\ttraining's binary_logloss: 0.123621\tvalid_1's auc: 0.827481\tvalid_1's binary_logloss: 0.137367\n",
            "[20]\ttraining's auc: 0.882338\ttraining's binary_logloss: 0.123034\tvalid_1's auc: 0.827886\tvalid_1's binary_logloss: 0.13716\n",
            "[21]\ttraining's auc: 0.88392\ttraining's binary_logloss: 0.122434\tvalid_1's auc: 0.827653\tvalid_1's binary_logloss: 0.137022\n",
            "[22]\ttraining's auc: 0.885259\ttraining's binary_logloss: 0.12187\tvalid_1's auc: 0.828376\tvalid_1's binary_logloss: 0.136863\n",
            "[23]\ttraining's auc: 0.886945\ttraining's binary_logloss: 0.121281\tvalid_1's auc: 0.828639\tvalid_1's binary_logloss: 0.136701\n",
            "[24]\ttraining's auc: 0.888014\ttraining's binary_logloss: 0.120752\tvalid_1's auc: 0.828308\tvalid_1's binary_logloss: 0.136725\n",
            "[25]\ttraining's auc: 0.890172\ttraining's binary_logloss: 0.120176\tvalid_1's auc: 0.828576\tvalid_1's binary_logloss: 0.136606\n",
            "[26]\ttraining's auc: 0.891126\ttraining's binary_logloss: 0.119698\tvalid_1's auc: 0.828631\tvalid_1's binary_logloss: 0.136578\n",
            "[27]\ttraining's auc: 0.891648\ttraining's binary_logloss: 0.119315\tvalid_1's auc: 0.828614\tvalid_1's binary_logloss: 0.136521\n",
            "[28]\ttraining's auc: 0.893046\ttraining's binary_logloss: 0.118825\tvalid_1's auc: 0.828787\tvalid_1's binary_logloss: 0.136489\n",
            "[29]\ttraining's auc: 0.894643\ttraining's binary_logloss: 0.118328\tvalid_1's auc: 0.830104\tvalid_1's binary_logloss: 0.136289\n",
            "[30]\ttraining's auc: 0.895623\ttraining's binary_logloss: 0.117837\tvalid_1's auc: 0.830264\tvalid_1's binary_logloss: 0.136215\n",
            "[31]\ttraining's auc: 0.896605\ttraining's binary_logloss: 0.11741\tvalid_1's auc: 0.830291\tvalid_1's binary_logloss: 0.136187\n",
            "[32]\ttraining's auc: 0.897999\ttraining's binary_logloss: 0.116992\tvalid_1's auc: 0.830326\tvalid_1's binary_logloss: 0.136166\n",
            "[33]\ttraining's auc: 0.899412\ttraining's binary_logloss: 0.116605\tvalid_1's auc: 0.830457\tvalid_1's binary_logloss: 0.136141\n",
            "[34]\ttraining's auc: 0.901792\ttraining's binary_logloss: 0.116065\tvalid_1's auc: 0.830429\tvalid_1's binary_logloss: 0.13612\n",
            "[35]\ttraining's auc: 0.902581\ttraining's binary_logloss: 0.115644\tvalid_1's auc: 0.830743\tvalid_1's binary_logloss: 0.136115\n",
            "[36]\ttraining's auc: 0.903025\ttraining's binary_logloss: 0.115315\tvalid_1's auc: 0.830774\tvalid_1's binary_logloss: 0.136107\n",
            "[37]\ttraining's auc: 0.904104\ttraining's binary_logloss: 0.114975\tvalid_1's auc: 0.830541\tvalid_1's binary_logloss: 0.136131\n",
            "[38]\ttraining's auc: 0.905135\ttraining's binary_logloss: 0.114632\tvalid_1's auc: 0.830705\tvalid_1's binary_logloss: 0.136093\n",
            "[39]\ttraining's auc: 0.906005\ttraining's binary_logloss: 0.114249\tvalid_1's auc: 0.830593\tvalid_1's binary_logloss: 0.136168\n",
            "[40]\ttraining's auc: 0.906718\ttraining's binary_logloss: 0.113928\tvalid_1's auc: 0.83047\tvalid_1's binary_logloss: 0.136194\n",
            "[41]\ttraining's auc: 0.907432\ttraining's binary_logloss: 0.113656\tvalid_1's auc: 0.830056\tvalid_1's binary_logloss: 0.136299\n",
            "[42]\ttraining's auc: 0.908041\ttraining's binary_logloss: 0.113347\tvalid_1's auc: 0.830136\tvalid_1's binary_logloss: 0.136243\n",
            "[43]\ttraining's auc: 0.90885\ttraining's binary_logloss: 0.113013\tvalid_1's auc: 0.830068\tvalid_1's binary_logloss: 0.136261\n",
            "[44]\ttraining's auc: 0.909796\ttraining's binary_logloss: 0.112653\tvalid_1's auc: 0.830202\tvalid_1's binary_logloss: 0.136274\n",
            "[45]\ttraining's auc: 0.910667\ttraining's binary_logloss: 0.112275\tvalid_1's auc: 0.830143\tvalid_1's binary_logloss: 0.13625\n",
            "[46]\ttraining's auc: 0.911197\ttraining's binary_logloss: 0.111972\tvalid_1's auc: 0.829778\tvalid_1's binary_logloss: 0.136317\n",
            "[47]\ttraining's auc: 0.912174\ttraining's binary_logloss: 0.111689\tvalid_1's auc: 0.829743\tvalid_1's binary_logloss: 0.136366\n",
            "[48]\ttraining's auc: 0.912478\ttraining's binary_logloss: 0.111461\tvalid_1's auc: 0.829439\tvalid_1's binary_logloss: 0.136466\n",
            "[49]\ttraining's auc: 0.912926\ttraining's binary_logloss: 0.111203\tvalid_1's auc: 0.829216\tvalid_1's binary_logloss: 0.136536\n",
            "[50]\ttraining's auc: 0.913657\ttraining's binary_logloss: 0.110909\tvalid_1's auc: 0.829071\tvalid_1's binary_logloss: 0.136561\n",
            "[51]\ttraining's auc: 0.914352\ttraining's binary_logloss: 0.110639\tvalid_1's auc: 0.82891\tvalid_1's binary_logloss: 0.136591\n",
            "[52]\ttraining's auc: 0.914679\ttraining's binary_logloss: 0.110425\tvalid_1's auc: 0.828984\tvalid_1's binary_logloss: 0.136628\n",
            "[53]\ttraining's auc: 0.916825\ttraining's binary_logloss: 0.109941\tvalid_1's auc: 0.828875\tvalid_1's binary_logloss: 0.136679\n",
            "[54]\ttraining's auc: 0.917764\ttraining's binary_logloss: 0.109681\tvalid_1's auc: 0.829197\tvalid_1's binary_logloss: 0.136611\n",
            "[55]\ttraining's auc: 0.918704\ttraining's binary_logloss: 0.109425\tvalid_1's auc: 0.829244\tvalid_1's binary_logloss: 0.136617\n",
            "[56]\ttraining's auc: 0.918961\ttraining's binary_logloss: 0.109226\tvalid_1's auc: 0.828923\tvalid_1's binary_logloss: 0.1367\n",
            "[57]\ttraining's auc: 0.919383\ttraining's binary_logloss: 0.108991\tvalid_1's auc: 0.828933\tvalid_1's binary_logloss: 0.136716\n",
            "[58]\ttraining's auc: 0.919899\ttraining's binary_logloss: 0.108744\tvalid_1's auc: 0.828662\tvalid_1's binary_logloss: 0.136756\n",
            "[59]\ttraining's auc: 0.920523\ttraining's binary_logloss: 0.108454\tvalid_1's auc: 0.828602\tvalid_1's binary_logloss: 0.136773\n",
            "[60]\ttraining's auc: 0.920895\ttraining's binary_logloss: 0.108257\tvalid_1's auc: 0.828212\tvalid_1's binary_logloss: 0.13683\n",
            "[61]\ttraining's auc: 0.921291\ttraining's binary_logloss: 0.108012\tvalid_1's auc: 0.828061\tvalid_1's binary_logloss: 0.136863\n",
            "[62]\ttraining's auc: 0.922398\ttraining's binary_logloss: 0.107765\tvalid_1's auc: 0.827784\tvalid_1's binary_logloss: 0.136924\n",
            "[63]\ttraining's auc: 0.922786\ttraining's binary_logloss: 0.107547\tvalid_1's auc: 0.827309\tvalid_1's binary_logloss: 0.137015\n",
            "[64]\ttraining's auc: 0.923077\ttraining's binary_logloss: 0.107351\tvalid_1's auc: 0.826925\tvalid_1's binary_logloss: 0.137091\n",
            "[65]\ttraining's auc: 0.923835\ttraining's binary_logloss: 0.107128\tvalid_1's auc: 0.826815\tvalid_1's binary_logloss: 0.137131\n",
            "[66]\ttraining's auc: 0.924075\ttraining's binary_logloss: 0.106946\tvalid_1's auc: 0.826792\tvalid_1's binary_logloss: 0.137153\n",
            " 70%|███████   | 35/50 [17:33<06:55, 27.73s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.158113\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.154003\n",
            "[2]\ttraining's auc: 0.827901\ttraining's binary_logloss: 0.152625\tvalid_1's auc: 0.815278\tvalid_1's binary_logloss: 0.149846\n",
            "[3]\ttraining's auc: 0.833562\ttraining's binary_logloss: 0.148573\tvalid_1's auc: 0.818014\tvalid_1's binary_logloss: 0.146583\n",
            "[4]\ttraining's auc: 0.839986\ttraining's binary_logloss: 0.145199\tvalid_1's auc: 0.820799\tvalid_1's binary_logloss: 0.144121\n",
            "[5]\ttraining's auc: 0.845593\ttraining's binary_logloss: 0.142533\tvalid_1's auc: 0.827025\tvalid_1's binary_logloss: 0.142067\n",
            "[6]\ttraining's auc: 0.850018\ttraining's binary_logloss: 0.140313\tvalid_1's auc: 0.829229\tvalid_1's binary_logloss: 0.140531\n",
            "[7]\ttraining's auc: 0.852773\ttraining's binary_logloss: 0.138369\tvalid_1's auc: 0.829658\tvalid_1's binary_logloss: 0.13927\n",
            "[8]\ttraining's auc: 0.856668\ttraining's binary_logloss: 0.136571\tvalid_1's auc: 0.831225\tvalid_1's binary_logloss: 0.138165\n",
            "[9]\ttraining's auc: 0.860402\ttraining's binary_logloss: 0.135118\tvalid_1's auc: 0.832052\tvalid_1's binary_logloss: 0.13723\n",
            "[10]\ttraining's auc: 0.864175\ttraining's binary_logloss: 0.133725\tvalid_1's auc: 0.83316\tvalid_1's binary_logloss: 0.136352\n",
            "[11]\ttraining's auc: 0.866652\ttraining's binary_logloss: 0.132549\tvalid_1's auc: 0.833416\tvalid_1's binary_logloss: 0.135696\n",
            "[12]\ttraining's auc: 0.868567\ttraining's binary_logloss: 0.13144\tvalid_1's auc: 0.8335\tvalid_1's binary_logloss: 0.135101\n",
            "[13]\ttraining's auc: 0.869877\ttraining's binary_logloss: 0.130361\tvalid_1's auc: 0.833899\tvalid_1's binary_logloss: 0.134571\n",
            "[14]\ttraining's auc: 0.87115\ttraining's binary_logloss: 0.129434\tvalid_1's auc: 0.834122\tvalid_1's binary_logloss: 0.134107\n",
            "[15]\ttraining's auc: 0.873203\ttraining's binary_logloss: 0.128558\tvalid_1's auc: 0.834012\tvalid_1's binary_logloss: 0.133754\n",
            "[16]\ttraining's auc: 0.87456\ttraining's binary_logloss: 0.127772\tvalid_1's auc: 0.834364\tvalid_1's binary_logloss: 0.13338\n",
            "[17]\ttraining's auc: 0.876017\ttraining's binary_logloss: 0.126963\tvalid_1's auc: 0.834375\tvalid_1's binary_logloss: 0.133103\n",
            "[18]\ttraining's auc: 0.877712\ttraining's binary_logloss: 0.126193\tvalid_1's auc: 0.834044\tvalid_1's binary_logloss: 0.132872\n",
            "[19]\ttraining's auc: 0.879035\ttraining's binary_logloss: 0.125482\tvalid_1's auc: 0.833797\tvalid_1's binary_logloss: 0.132673\n",
            "[20]\ttraining's auc: 0.879797\ttraining's binary_logloss: 0.124908\tvalid_1's auc: 0.833518\tvalid_1's binary_logloss: 0.132477\n",
            "[21]\ttraining's auc: 0.881626\ttraining's binary_logloss: 0.124269\tvalid_1's auc: 0.83369\tvalid_1's binary_logloss: 0.132285\n",
            "[22]\ttraining's auc: 0.883098\ttraining's binary_logloss: 0.123665\tvalid_1's auc: 0.833778\tvalid_1's binary_logloss: 0.132159\n",
            "[23]\ttraining's auc: 0.884332\ttraining's binary_logloss: 0.123101\tvalid_1's auc: 0.833662\tvalid_1's binary_logloss: 0.132081\n",
            "[24]\ttraining's auc: 0.885956\ttraining's binary_logloss: 0.122507\tvalid_1's auc: 0.833331\tvalid_1's binary_logloss: 0.132006\n",
            "[25]\ttraining's auc: 0.88752\ttraining's binary_logloss: 0.121924\tvalid_1's auc: 0.834109\tvalid_1's binary_logloss: 0.131856\n",
            "[26]\ttraining's auc: 0.889198\ttraining's binary_logloss: 0.121395\tvalid_1's auc: 0.833926\tvalid_1's binary_logloss: 0.131779\n",
            "[27]\ttraining's auc: 0.890613\ttraining's binary_logloss: 0.120912\tvalid_1's auc: 0.834244\tvalid_1's binary_logloss: 0.131694\n",
            "[28]\ttraining's auc: 0.891658\ttraining's binary_logloss: 0.120342\tvalid_1's auc: 0.834403\tvalid_1's binary_logloss: 0.131662\n",
            "[29]\ttraining's auc: 0.892764\ttraining's binary_logloss: 0.119883\tvalid_1's auc: 0.834623\tvalid_1's binary_logloss: 0.131634\n",
            "[30]\ttraining's auc: 0.893593\ttraining's binary_logloss: 0.119476\tvalid_1's auc: 0.83468\tvalid_1's binary_logloss: 0.131568\n",
            "[31]\ttraining's auc: 0.894387\ttraining's binary_logloss: 0.11907\tvalid_1's auc: 0.834527\tvalid_1's binary_logloss: 0.131559\n",
            "[32]\ttraining's auc: 0.895944\ttraining's binary_logloss: 0.118597\tvalid_1's auc: 0.834494\tvalid_1's binary_logloss: 0.131558\n",
            "[33]\ttraining's auc: 0.897356\ttraining's binary_logloss: 0.118177\tvalid_1's auc: 0.834325\tvalid_1's binary_logloss: 0.131545\n",
            "[34]\ttraining's auc: 0.899039\ttraining's binary_logloss: 0.117707\tvalid_1's auc: 0.834692\tvalid_1's binary_logloss: 0.131482\n",
            "[35]\ttraining's auc: 0.900997\ttraining's binary_logloss: 0.117262\tvalid_1's auc: 0.834627\tvalid_1's binary_logloss: 0.131473\n",
            "[36]\ttraining's auc: 0.902296\ttraining's binary_logloss: 0.116913\tvalid_1's auc: 0.834349\tvalid_1's binary_logloss: 0.131483\n",
            "[37]\ttraining's auc: 0.90337\ttraining's binary_logloss: 0.116535\tvalid_1's auc: 0.834904\tvalid_1's binary_logloss: 0.131409\n",
            "[38]\ttraining's auc: 0.903826\ttraining's binary_logloss: 0.116285\tvalid_1's auc: 0.835414\tvalid_1's binary_logloss: 0.131347\n",
            "[39]\ttraining's auc: 0.904959\ttraining's binary_logloss: 0.115899\tvalid_1's auc: 0.835909\tvalid_1's binary_logloss: 0.131248\n",
            "[40]\ttraining's auc: 0.906029\ttraining's binary_logloss: 0.115523\tvalid_1's auc: 0.835699\tvalid_1's binary_logloss: 0.131267\n",
            "[41]\ttraining's auc: 0.906716\ttraining's binary_logloss: 0.115157\tvalid_1's auc: 0.835587\tvalid_1's binary_logloss: 0.131287\n",
            "[42]\ttraining's auc: 0.907663\ttraining's binary_logloss: 0.114852\tvalid_1's auc: 0.835469\tvalid_1's binary_logloss: 0.131279\n",
            "[43]\ttraining's auc: 0.908629\ttraining's binary_logloss: 0.114495\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.131319\n",
            "[44]\ttraining's auc: 0.90932\ttraining's binary_logloss: 0.114112\tvalid_1's auc: 0.836054\tvalid_1's binary_logloss: 0.131223\n",
            "[45]\ttraining's auc: 0.910071\ttraining's binary_logloss: 0.11377\tvalid_1's auc: 0.835999\tvalid_1's binary_logloss: 0.13124\n",
            "[46]\ttraining's auc: 0.911176\ttraining's binary_logloss: 0.113378\tvalid_1's auc: 0.835824\tvalid_1's binary_logloss: 0.13126\n",
            "[47]\ttraining's auc: 0.911939\ttraining's binary_logloss: 0.113032\tvalid_1's auc: 0.835869\tvalid_1's binary_logloss: 0.131281\n",
            "[48]\ttraining's auc: 0.912315\ttraining's binary_logloss: 0.112787\tvalid_1's auc: 0.836107\tvalid_1's binary_logloss: 0.131246\n",
            "[49]\ttraining's auc: 0.913329\ttraining's binary_logloss: 0.112402\tvalid_1's auc: 0.835942\tvalid_1's binary_logloss: 0.131274\n",
            "[50]\ttraining's auc: 0.914163\ttraining's binary_logloss: 0.112047\tvalid_1's auc: 0.835844\tvalid_1's binary_logloss: 0.13128\n",
            "[51]\ttraining's auc: 0.91489\ttraining's binary_logloss: 0.111771\tvalid_1's auc: 0.835743\tvalid_1's binary_logloss: 0.131286\n",
            "[52]\ttraining's auc: 0.91543\ttraining's binary_logloss: 0.111462\tvalid_1's auc: 0.835913\tvalid_1's binary_logloss: 0.131247\n",
            "[53]\ttraining's auc: 0.9162\ttraining's binary_logloss: 0.111161\tvalid_1's auc: 0.8356\tvalid_1's binary_logloss: 0.131292\n",
            "[54]\ttraining's auc: 0.916857\ttraining's binary_logloss: 0.11094\tvalid_1's auc: 0.835588\tvalid_1's binary_logloss: 0.131293\n",
            "[55]\ttraining's auc: 0.917902\ttraining's binary_logloss: 0.110568\tvalid_1's auc: 0.835518\tvalid_1's binary_logloss: 0.131304\n",
            "[56]\ttraining's auc: 0.918535\ttraining's binary_logloss: 0.110223\tvalid_1's auc: 0.835565\tvalid_1's binary_logloss: 0.131319\n",
            "[57]\ttraining's auc: 0.91887\ttraining's binary_logloss: 0.110011\tvalid_1's auc: 0.835474\tvalid_1's binary_logloss: 0.13133\n",
            "[58]\ttraining's auc: 0.919121\ttraining's binary_logloss: 0.109803\tvalid_1's auc: 0.835333\tvalid_1's binary_logloss: 0.131359\n",
            "[59]\ttraining's auc: 0.919668\ttraining's binary_logloss: 0.109512\tvalid_1's auc: 0.835631\tvalid_1's binary_logloss: 0.131275\n",
            "[60]\ttraining's auc: 0.920533\ttraining's binary_logloss: 0.109167\tvalid_1's auc: 0.835812\tvalid_1's binary_logloss: 0.131229\n",
            "[61]\ttraining's auc: 0.92119\ttraining's binary_logloss: 0.108873\tvalid_1's auc: 0.835535\tvalid_1's binary_logloss: 0.131293\n",
            "[62]\ttraining's auc: 0.921602\ttraining's binary_logloss: 0.108671\tvalid_1's auc: 0.835346\tvalid_1's binary_logloss: 0.131311\n",
            "[63]\ttraining's auc: 0.922267\ttraining's binary_logloss: 0.108436\tvalid_1's auc: 0.835208\tvalid_1's binary_logloss: 0.131357\n",
            "[64]\ttraining's auc: 0.922649\ttraining's binary_logloss: 0.108205\tvalid_1's auc: 0.835263\tvalid_1's binary_logloss: 0.131362\n",
            "[65]\ttraining's auc: 0.922883\ttraining's binary_logloss: 0.108047\tvalid_1's auc: 0.835247\tvalid_1's binary_logloss: 0.131367\n",
            "[66]\ttraining's auc: 0.923397\ttraining's binary_logloss: 0.107779\tvalid_1's auc: 0.835111\tvalid_1's binary_logloss: 0.131402\n",
            "[67]\ttraining's auc: 0.923738\ttraining's binary_logloss: 0.107564\tvalid_1's auc: 0.835\tvalid_1's binary_logloss: 0.131401\n",
            "[68]\ttraining's auc: 0.92429\ttraining's binary_logloss: 0.10728\tvalid_1's auc: 0.834824\tvalid_1's binary_logloss: 0.131399\n",
            "[69]\ttraining's auc: 0.924688\ttraining's binary_logloss: 0.107062\tvalid_1's auc: 0.834746\tvalid_1's binary_logloss: 0.131434\n",
            "[70]\ttraining's auc: 0.925113\ttraining's binary_logloss: 0.106882\tvalid_1's auc: 0.835016\tvalid_1's binary_logloss: 0.131417\n",
            "[71]\ttraining's auc: 0.925535\ttraining's binary_logloss: 0.106612\tvalid_1's auc: 0.835022\tvalid_1's binary_logloss: 0.131425\n",
            "[72]\ttraining's auc: 0.925838\ttraining's binary_logloss: 0.106404\tvalid_1's auc: 0.83487\tvalid_1's binary_logloss: 0.131447\n",
            "[73]\ttraining's auc: 0.926474\ttraining's binary_logloss: 0.106207\tvalid_1's auc: 0.834681\tvalid_1's binary_logloss: 0.131478\n",
            "[74]\ttraining's auc: 0.926737\ttraining's binary_logloss: 0.106047\tvalid_1's auc: 0.834497\tvalid_1's binary_logloss: 0.131513\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 70%|███████   | 35/50 [17:45<06:55, 27.73s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.154791\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.161043\n",
            "[2]\ttraining's auc: 0.833067\ttraining's binary_logloss: 0.149313\tvalid_1's auc: 0.815144\tvalid_1's binary_logloss: 0.156077\n",
            "[3]\ttraining's auc: 0.838459\ttraining's binary_logloss: 0.145424\tvalid_1's auc: 0.818085\tvalid_1's binary_logloss: 0.15273\n",
            "[4]\ttraining's auc: 0.846919\ttraining's binary_logloss: 0.141995\tvalid_1's auc: 0.823899\tvalid_1's binary_logloss: 0.150152\n",
            "[5]\ttraining's auc: 0.849732\ttraining's binary_logloss: 0.139286\tvalid_1's auc: 0.826519\tvalid_1's binary_logloss: 0.148038\n",
            "[6]\ttraining's auc: 0.851424\ttraining's binary_logloss: 0.137056\tvalid_1's auc: 0.82703\tvalid_1's binary_logloss: 0.146308\n",
            "[7]\ttraining's auc: 0.854479\ttraining's binary_logloss: 0.135211\tvalid_1's auc: 0.829009\tvalid_1's binary_logloss: 0.144792\n",
            "[8]\ttraining's auc: 0.856875\ttraining's binary_logloss: 0.133592\tvalid_1's auc: 0.829623\tvalid_1's binary_logloss: 0.143587\n",
            "[9]\ttraining's auc: 0.858701\ttraining's binary_logloss: 0.132156\tvalid_1's auc: 0.830386\tvalid_1's binary_logloss: 0.142596\n",
            "[10]\ttraining's auc: 0.861586\ttraining's binary_logloss: 0.13087\tvalid_1's auc: 0.830366\tvalid_1's binary_logloss: 0.141778\n",
            "[11]\ttraining's auc: 0.86371\ttraining's binary_logloss: 0.129687\tvalid_1's auc: 0.830959\tvalid_1's binary_logloss: 0.141105\n",
            "[12]\ttraining's auc: 0.867294\ttraining's binary_logloss: 0.128578\tvalid_1's auc: 0.831172\tvalid_1's binary_logloss: 0.140494\n",
            "[13]\ttraining's auc: 0.869837\ttraining's binary_logloss: 0.127609\tvalid_1's auc: 0.832883\tvalid_1's binary_logloss: 0.139879\n",
            "[14]\ttraining's auc: 0.870722\ttraining's binary_logloss: 0.126711\tvalid_1's auc: 0.832788\tvalid_1's binary_logloss: 0.139435\n",
            "[15]\ttraining's auc: 0.873065\ttraining's binary_logloss: 0.12587\tvalid_1's auc: 0.834003\tvalid_1's binary_logloss: 0.139046\n",
            "[16]\ttraining's auc: 0.875848\ttraining's binary_logloss: 0.124999\tvalid_1's auc: 0.834193\tvalid_1's binary_logloss: 0.138679\n",
            "[17]\ttraining's auc: 0.8781\ttraining's binary_logloss: 0.124215\tvalid_1's auc: 0.834181\tvalid_1's binary_logloss: 0.138375\n",
            "[18]\ttraining's auc: 0.879342\ttraining's binary_logloss: 0.123554\tvalid_1's auc: 0.834522\tvalid_1's binary_logloss: 0.138096\n",
            "[19]\ttraining's auc: 0.881822\ttraining's binary_logloss: 0.122823\tvalid_1's auc: 0.834542\tvalid_1's binary_logloss: 0.137864\n",
            "[20]\ttraining's auc: 0.883293\ttraining's binary_logloss: 0.122144\tvalid_1's auc: 0.834502\tvalid_1's binary_logloss: 0.137747\n",
            "[21]\ttraining's auc: 0.884897\ttraining's binary_logloss: 0.121541\tvalid_1's auc: 0.834125\tvalid_1's binary_logloss: 0.137601\n",
            "[22]\ttraining's auc: 0.886508\ttraining's binary_logloss: 0.121014\tvalid_1's auc: 0.834319\tvalid_1's binary_logloss: 0.137474\n",
            "[23]\ttraining's auc: 0.887617\ttraining's binary_logloss: 0.120459\tvalid_1's auc: 0.834327\tvalid_1's binary_logloss: 0.137357\n",
            "[24]\ttraining's auc: 0.888934\ttraining's binary_logloss: 0.119911\tvalid_1's auc: 0.834223\tvalid_1's binary_logloss: 0.137278\n",
            "[25]\ttraining's auc: 0.889668\ttraining's binary_logloss: 0.119438\tvalid_1's auc: 0.834739\tvalid_1's binary_logloss: 0.137087\n",
            "[26]\ttraining's auc: 0.891259\ttraining's binary_logloss: 0.118866\tvalid_1's auc: 0.834631\tvalid_1's binary_logloss: 0.137043\n",
            "[27]\ttraining's auc: 0.89284\ttraining's binary_logloss: 0.118385\tvalid_1's auc: 0.834544\tvalid_1's binary_logloss: 0.136998\n",
            "[28]\ttraining's auc: 0.895162\ttraining's binary_logloss: 0.117765\tvalid_1's auc: 0.83456\tvalid_1's binary_logloss: 0.136953\n",
            "[29]\ttraining's auc: 0.896146\ttraining's binary_logloss: 0.117329\tvalid_1's auc: 0.834151\tvalid_1's binary_logloss: 0.136947\n",
            "[30]\ttraining's auc: 0.897395\ttraining's binary_logloss: 0.116921\tvalid_1's auc: 0.833761\tvalid_1's binary_logloss: 0.136912\n",
            "[31]\ttraining's auc: 0.898698\ttraining's binary_logloss: 0.116523\tvalid_1's auc: 0.833345\tvalid_1's binary_logloss: 0.13692\n",
            "[32]\ttraining's auc: 0.899842\ttraining's binary_logloss: 0.11601\tvalid_1's auc: 0.833601\tvalid_1's binary_logloss: 0.136843\n",
            "[33]\ttraining's auc: 0.900565\ttraining's binary_logloss: 0.115669\tvalid_1's auc: 0.833488\tvalid_1's binary_logloss: 0.136822\n",
            "[34]\ttraining's auc: 0.901326\ttraining's binary_logloss: 0.115294\tvalid_1's auc: 0.833176\tvalid_1's binary_logloss: 0.13682\n",
            "[35]\ttraining's auc: 0.901921\ttraining's binary_logloss: 0.114957\tvalid_1's auc: 0.833257\tvalid_1's binary_logloss: 0.136827\n",
            "[36]\ttraining's auc: 0.902768\ttraining's binary_logloss: 0.114643\tvalid_1's auc: 0.833002\tvalid_1's binary_logloss: 0.136891\n",
            "[37]\ttraining's auc: 0.903705\ttraining's binary_logloss: 0.114171\tvalid_1's auc: 0.832762\tvalid_1's binary_logloss: 0.136984\n",
            "[38]\ttraining's auc: 0.904757\ttraining's binary_logloss: 0.113729\tvalid_1's auc: 0.832865\tvalid_1's binary_logloss: 0.137016\n",
            "[39]\ttraining's auc: 0.90581\ttraining's binary_logloss: 0.113326\tvalid_1's auc: 0.832817\tvalid_1's binary_logloss: 0.137054\n",
            "[40]\ttraining's auc: 0.906386\ttraining's binary_logloss: 0.112971\tvalid_1's auc: 0.832732\tvalid_1's binary_logloss: 0.137079\n",
            "[41]\ttraining's auc: 0.907028\ttraining's binary_logloss: 0.112647\tvalid_1's auc: 0.832835\tvalid_1's binary_logloss: 0.137035\n",
            "[42]\ttraining's auc: 0.907648\ttraining's binary_logloss: 0.112291\tvalid_1's auc: 0.833201\tvalid_1's binary_logloss: 0.136965\n",
            "[43]\ttraining's auc: 0.908723\ttraining's binary_logloss: 0.111904\tvalid_1's auc: 0.832895\tvalid_1's binary_logloss: 0.137077\n",
            "[44]\ttraining's auc: 0.909074\ttraining's binary_logloss: 0.111663\tvalid_1's auc: 0.832965\tvalid_1's binary_logloss: 0.137061\n",
            "[45]\ttraining's auc: 0.909534\ttraining's binary_logloss: 0.111429\tvalid_1's auc: 0.832838\tvalid_1's binary_logloss: 0.137088\n",
            "[46]\ttraining's auc: 0.910394\ttraining's binary_logloss: 0.111155\tvalid_1's auc: 0.833402\tvalid_1's binary_logloss: 0.137027\n",
            "[47]\ttraining's auc: 0.911114\ttraining's binary_logloss: 0.110865\tvalid_1's auc: 0.833544\tvalid_1's binary_logloss: 0.137026\n",
            "[48]\ttraining's auc: 0.911935\ttraining's binary_logloss: 0.110542\tvalid_1's auc: 0.833748\tvalid_1's binary_logloss: 0.136985\n",
            "[49]\ttraining's auc: 0.912664\ttraining's binary_logloss: 0.110254\tvalid_1's auc: 0.8335\tvalid_1's binary_logloss: 0.137057\n",
            "[50]\ttraining's auc: 0.912999\ttraining's binary_logloss: 0.110006\tvalid_1's auc: 0.833513\tvalid_1's binary_logloss: 0.137085\n",
            "[51]\ttraining's auc: 0.913733\ttraining's binary_logloss: 0.109707\tvalid_1's auc: 0.83322\tvalid_1's binary_logloss: 0.137162\n",
            "[52]\ttraining's auc: 0.914668\ttraining's binary_logloss: 0.109455\tvalid_1's auc: 0.833198\tvalid_1's binary_logloss: 0.13717\n",
            "[53]\ttraining's auc: 0.915116\ttraining's binary_logloss: 0.109221\tvalid_1's auc: 0.833194\tvalid_1's binary_logloss: 0.137204\n",
            "[54]\ttraining's auc: 0.915506\ttraining's binary_logloss: 0.108977\tvalid_1's auc: 0.833005\tvalid_1's binary_logloss: 0.137263\n",
            "[55]\ttraining's auc: 0.916082\ttraining's binary_logloss: 0.108678\tvalid_1's auc: 0.833093\tvalid_1's binary_logloss: 0.137298\n",
            " 72%|███████▏  | 36/50 [17:52<06:19, 27.12s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.152953\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.155899\n",
            "[2]\ttraining's auc: 0.835537\ttraining's binary_logloss: 0.146783\tvalid_1's auc: 0.810454\tvalid_1's binary_logloss: 0.151078\n",
            "[3]\ttraining's auc: 0.843526\ttraining's binary_logloss: 0.142506\tvalid_1's auc: 0.81567\tvalid_1's binary_logloss: 0.147924\n",
            "[4]\ttraining's auc: 0.848715\ttraining's binary_logloss: 0.139041\tvalid_1's auc: 0.81852\tvalid_1's binary_logloss: 0.145525\n",
            "[5]\ttraining's auc: 0.851744\ttraining's binary_logloss: 0.136252\tvalid_1's auc: 0.818953\tvalid_1's binary_logloss: 0.143783\n",
            "[6]\ttraining's auc: 0.857922\ttraining's binary_logloss: 0.134053\tvalid_1's auc: 0.821024\tvalid_1's binary_logloss: 0.142244\n",
            "[7]\ttraining's auc: 0.860369\ttraining's binary_logloss: 0.132012\tvalid_1's auc: 0.821948\tvalid_1's binary_logloss: 0.141069\n",
            "[8]\ttraining's auc: 0.865168\ttraining's binary_logloss: 0.130353\tvalid_1's auc: 0.822432\tvalid_1's binary_logloss: 0.140267\n",
            "[9]\ttraining's auc: 0.868395\ttraining's binary_logloss: 0.128873\tvalid_1's auc: 0.822741\tvalid_1's binary_logloss: 0.139519\n",
            "[10]\ttraining's auc: 0.870417\ttraining's binary_logloss: 0.1275\tvalid_1's auc: 0.823242\tvalid_1's binary_logloss: 0.139078\n",
            "[11]\ttraining's auc: 0.872774\ttraining's binary_logloss: 0.126277\tvalid_1's auc: 0.824677\tvalid_1's binary_logloss: 0.138522\n",
            "[12]\ttraining's auc: 0.875038\ttraining's binary_logloss: 0.125275\tvalid_1's auc: 0.824518\tvalid_1's binary_logloss: 0.138252\n",
            "[13]\ttraining's auc: 0.876593\ttraining's binary_logloss: 0.12427\tvalid_1's auc: 0.825322\tvalid_1's binary_logloss: 0.13785\n",
            "[14]\ttraining's auc: 0.878495\ttraining's binary_logloss: 0.123361\tvalid_1's auc: 0.826468\tvalid_1's binary_logloss: 0.137444\n",
            "[15]\ttraining's auc: 0.882695\ttraining's binary_logloss: 0.122403\tvalid_1's auc: 0.82657\tvalid_1's binary_logloss: 0.137168\n",
            "[16]\ttraining's auc: 0.883781\ttraining's binary_logloss: 0.121703\tvalid_1's auc: 0.827814\tvalid_1's binary_logloss: 0.13682\n",
            "[17]\ttraining's auc: 0.886016\ttraining's binary_logloss: 0.120942\tvalid_1's auc: 0.828241\tvalid_1's binary_logloss: 0.136658\n",
            "[18]\ttraining's auc: 0.887392\ttraining's binary_logloss: 0.120284\tvalid_1's auc: 0.828146\tvalid_1's binary_logloss: 0.136559\n",
            "[19]\ttraining's auc: 0.889989\ttraining's binary_logloss: 0.119593\tvalid_1's auc: 0.829338\tvalid_1's binary_logloss: 0.136419\n",
            "[20]\ttraining's auc: 0.891148\ttraining's binary_logloss: 0.118978\tvalid_1's auc: 0.829462\tvalid_1's binary_logloss: 0.136323\n",
            "[21]\ttraining's auc: 0.894279\ttraining's binary_logloss: 0.118158\tvalid_1's auc: 0.830482\tvalid_1's binary_logloss: 0.136043\n",
            "[22]\ttraining's auc: 0.896312\ttraining's binary_logloss: 0.117534\tvalid_1's auc: 0.830244\tvalid_1's binary_logloss: 0.136005\n",
            "[23]\ttraining's auc: 0.898247\ttraining's binary_logloss: 0.116893\tvalid_1's auc: 0.829274\tvalid_1's binary_logloss: 0.136154\n",
            "[24]\ttraining's auc: 0.899871\ttraining's binary_logloss: 0.116323\tvalid_1's auc: 0.829291\tvalid_1's binary_logloss: 0.136149\n",
            "[25]\ttraining's auc: 0.90074\ttraining's binary_logloss: 0.11587\tvalid_1's auc: 0.829597\tvalid_1's binary_logloss: 0.136076\n",
            "[26]\ttraining's auc: 0.9016\ttraining's binary_logloss: 0.115383\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.136138\n",
            "[27]\ttraining's auc: 0.90356\ttraining's binary_logloss: 0.114806\tvalid_1's auc: 0.829419\tvalid_1's binary_logloss: 0.136125\n",
            "[28]\ttraining's auc: 0.905519\ttraining's binary_logloss: 0.114259\tvalid_1's auc: 0.829783\tvalid_1's binary_logloss: 0.136013\n",
            "[29]\ttraining's auc: 0.9069\ttraining's binary_logloss: 0.113795\tvalid_1's auc: 0.830167\tvalid_1's binary_logloss: 0.135929\n",
            "[30]\ttraining's auc: 0.908071\ttraining's binary_logloss: 0.113292\tvalid_1's auc: 0.830273\tvalid_1's binary_logloss: 0.135918\n",
            "[31]\ttraining's auc: 0.908922\ttraining's binary_logloss: 0.112835\tvalid_1's auc: 0.8301\tvalid_1's binary_logloss: 0.135938\n",
            "[32]\ttraining's auc: 0.910183\ttraining's binary_logloss: 0.11238\tvalid_1's auc: 0.829614\tvalid_1's binary_logloss: 0.136027\n",
            "[33]\ttraining's auc: 0.911729\ttraining's binary_logloss: 0.111969\tvalid_1's auc: 0.829031\tvalid_1's binary_logloss: 0.136153\n",
            "[34]\ttraining's auc: 0.912887\ttraining's binary_logloss: 0.111485\tvalid_1's auc: 0.828751\tvalid_1's binary_logloss: 0.136237\n",
            "[35]\ttraining's auc: 0.913415\ttraining's binary_logloss: 0.111116\tvalid_1's auc: 0.828725\tvalid_1's binary_logloss: 0.136276\n",
            "[36]\ttraining's auc: 0.914137\ttraining's binary_logloss: 0.110697\tvalid_1's auc: 0.828377\tvalid_1's binary_logloss: 0.136352\n",
            "[37]\ttraining's auc: 0.91529\ttraining's binary_logloss: 0.110217\tvalid_1's auc: 0.828067\tvalid_1's binary_logloss: 0.136399\n",
            "[38]\ttraining's auc: 0.915834\ttraining's binary_logloss: 0.109944\tvalid_1's auc: 0.827756\tvalid_1's binary_logloss: 0.136473\n",
            "[39]\ttraining's auc: 0.916818\ttraining's binary_logloss: 0.109546\tvalid_1's auc: 0.827765\tvalid_1's binary_logloss: 0.136532\n",
            "[40]\ttraining's auc: 0.917381\ttraining's binary_logloss: 0.109249\tvalid_1's auc: 0.82821\tvalid_1's binary_logloss: 0.136479\n",
            "[41]\ttraining's auc: 0.918316\ttraining's binary_logloss: 0.108918\tvalid_1's auc: 0.82819\tvalid_1's binary_logloss: 0.136491\n",
            "[42]\ttraining's auc: 0.91897\ttraining's binary_logloss: 0.108575\tvalid_1's auc: 0.827666\tvalid_1's binary_logloss: 0.136606\n",
            "[43]\ttraining's auc: 0.919547\ttraining's binary_logloss: 0.108239\tvalid_1's auc: 0.827455\tvalid_1's binary_logloss: 0.13668\n",
            "[44]\ttraining's auc: 0.920191\ttraining's binary_logloss: 0.107903\tvalid_1's auc: 0.827041\tvalid_1's binary_logloss: 0.13679\n",
            "[45]\ttraining's auc: 0.921012\ttraining's binary_logloss: 0.107542\tvalid_1's auc: 0.827157\tvalid_1's binary_logloss: 0.136771\n",
            "[46]\ttraining's auc: 0.921917\ttraining's binary_logloss: 0.107157\tvalid_1's auc: 0.827347\tvalid_1's binary_logloss: 0.136769\n",
            "[47]\ttraining's auc: 0.922527\ttraining's binary_logloss: 0.106865\tvalid_1's auc: 0.826913\tvalid_1's binary_logloss: 0.136894\n",
            "[48]\ttraining's auc: 0.922984\ttraining's binary_logloss: 0.106575\tvalid_1's auc: 0.826524\tvalid_1's binary_logloss: 0.13699\n",
            "[49]\ttraining's auc: 0.923862\ttraining's binary_logloss: 0.106148\tvalid_1's auc: 0.826301\tvalid_1's binary_logloss: 0.137064\n",
            "[50]\ttraining's auc: 0.924702\ttraining's binary_logloss: 0.105851\tvalid_1's auc: 0.826196\tvalid_1's binary_logloss: 0.137153\n",
            "[51]\ttraining's auc: 0.925128\ttraining's binary_logloss: 0.105579\tvalid_1's auc: 0.825791\tvalid_1's binary_logloss: 0.137241\n",
            " 72%|███████▏  | 36/50 [18:00<06:19, 27.12s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.155393\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.152002\n",
            "[2]\ttraining's auc: 0.831747\ttraining's binary_logloss: 0.149085\tvalid_1's auc: 0.816764\tvalid_1's binary_logloss: 0.147138\n",
            "[3]\ttraining's auc: 0.839216\ttraining's binary_logloss: 0.144683\tvalid_1's auc: 0.819846\tvalid_1's binary_logloss: 0.143896\n",
            "[4]\ttraining's auc: 0.845421\ttraining's binary_logloss: 0.141288\tvalid_1's auc: 0.8262\tvalid_1's binary_logloss: 0.141324\n",
            "[5]\ttraining's auc: 0.851066\ttraining's binary_logloss: 0.138523\tvalid_1's auc: 0.827262\tvalid_1's binary_logloss: 0.139597\n",
            "[6]\ttraining's auc: 0.85467\ttraining's binary_logloss: 0.136212\tvalid_1's auc: 0.828953\tvalid_1's binary_logloss: 0.138205\n",
            "[7]\ttraining's auc: 0.857318\ttraining's binary_logloss: 0.134258\tvalid_1's auc: 0.828034\tvalid_1's binary_logloss: 0.13717\n",
            "[8]\ttraining's auc: 0.864171\ttraining's binary_logloss: 0.132418\tvalid_1's auc: 0.829978\tvalid_1's binary_logloss: 0.136167\n",
            "[9]\ttraining's auc: 0.867516\ttraining's binary_logloss: 0.13082\tvalid_1's auc: 0.830655\tvalid_1's binary_logloss: 0.13539\n",
            "[10]\ttraining's auc: 0.870465\ttraining's binary_logloss: 0.129408\tvalid_1's auc: 0.830258\tvalid_1's binary_logloss: 0.134865\n",
            "[11]\ttraining's auc: 0.872017\ttraining's binary_logloss: 0.128242\tvalid_1's auc: 0.831248\tvalid_1's binary_logloss: 0.134258\n",
            "[12]\ttraining's auc: 0.874659\ttraining's binary_logloss: 0.127109\tvalid_1's auc: 0.831653\tvalid_1's binary_logloss: 0.133868\n",
            "[13]\ttraining's auc: 0.877173\ttraining's binary_logloss: 0.126143\tvalid_1's auc: 0.83194\tvalid_1's binary_logloss: 0.133515\n",
            "[14]\ttraining's auc: 0.878632\ttraining's binary_logloss: 0.125249\tvalid_1's auc: 0.831911\tvalid_1's binary_logloss: 0.13324\n",
            "[15]\ttraining's auc: 0.879999\ttraining's binary_logloss: 0.124401\tvalid_1's auc: 0.831818\tvalid_1's binary_logloss: 0.13302\n",
            "[16]\ttraining's auc: 0.881184\ttraining's binary_logloss: 0.123673\tvalid_1's auc: 0.83213\tvalid_1's binary_logloss: 0.132797\n",
            "[17]\ttraining's auc: 0.882783\ttraining's binary_logloss: 0.122927\tvalid_1's auc: 0.831921\tvalid_1's binary_logloss: 0.132694\n",
            "[18]\ttraining's auc: 0.884861\ttraining's binary_logloss: 0.122195\tvalid_1's auc: 0.831703\tvalid_1's binary_logloss: 0.132573\n",
            "[19]\ttraining's auc: 0.886449\ttraining's binary_logloss: 0.121543\tvalid_1's auc: 0.832539\tvalid_1's binary_logloss: 0.132386\n",
            "[20]\ttraining's auc: 0.887608\ttraining's binary_logloss: 0.120942\tvalid_1's auc: 0.833039\tvalid_1's binary_logloss: 0.132222\n",
            "[21]\ttraining's auc: 0.888997\ttraining's binary_logloss: 0.120345\tvalid_1's auc: 0.833249\tvalid_1's binary_logloss: 0.132139\n",
            "[22]\ttraining's auc: 0.890839\ttraining's binary_logloss: 0.11978\tvalid_1's auc: 0.833564\tvalid_1's binary_logloss: 0.131998\n",
            "[23]\ttraining's auc: 0.892713\ttraining's binary_logloss: 0.119168\tvalid_1's auc: 0.834219\tvalid_1's binary_logloss: 0.131892\n",
            "[24]\ttraining's auc: 0.893903\ttraining's binary_logloss: 0.118641\tvalid_1's auc: 0.834924\tvalid_1's binary_logloss: 0.13174\n",
            "[25]\ttraining's auc: 0.89539\ttraining's binary_logloss: 0.118069\tvalid_1's auc: 0.835303\tvalid_1's binary_logloss: 0.131626\n",
            "[26]\ttraining's auc: 0.897894\ttraining's binary_logloss: 0.117404\tvalid_1's auc: 0.835179\tvalid_1's binary_logloss: 0.1316\n",
            "[27]\ttraining's auc: 0.899687\ttraining's binary_logloss: 0.116891\tvalid_1's auc: 0.8354\tvalid_1's binary_logloss: 0.131589\n",
            "[28]\ttraining's auc: 0.900405\ttraining's binary_logloss: 0.116497\tvalid_1's auc: 0.835025\tvalid_1's binary_logloss: 0.131621\n",
            "[29]\ttraining's auc: 0.902206\ttraining's binary_logloss: 0.116084\tvalid_1's auc: 0.834712\tvalid_1's binary_logloss: 0.13162\n",
            "[30]\ttraining's auc: 0.903015\ttraining's binary_logloss: 0.115631\tvalid_1's auc: 0.83473\tvalid_1's binary_logloss: 0.131659\n",
            "[31]\ttraining's auc: 0.904556\ttraining's binary_logloss: 0.115124\tvalid_1's auc: 0.834905\tvalid_1's binary_logloss: 0.131614\n",
            "[32]\ttraining's auc: 0.906325\ttraining's binary_logloss: 0.114646\tvalid_1's auc: 0.834905\tvalid_1's binary_logloss: 0.131592\n",
            "[33]\ttraining's auc: 0.907282\ttraining's binary_logloss: 0.114233\tvalid_1's auc: 0.835222\tvalid_1's binary_logloss: 0.131555\n",
            "[34]\ttraining's auc: 0.908589\ttraining's binary_logloss: 0.11377\tvalid_1's auc: 0.835463\tvalid_1's binary_logloss: 0.131502\n",
            "[35]\ttraining's auc: 0.909435\ttraining's binary_logloss: 0.113409\tvalid_1's auc: 0.835374\tvalid_1's binary_logloss: 0.131506\n",
            "[36]\ttraining's auc: 0.910212\ttraining's binary_logloss: 0.113013\tvalid_1's auc: 0.835564\tvalid_1's binary_logloss: 0.131515\n",
            "[37]\ttraining's auc: 0.910992\ttraining's binary_logloss: 0.112615\tvalid_1's auc: 0.835912\tvalid_1's binary_logloss: 0.131434\n",
            "[38]\ttraining's auc: 0.911914\ttraining's binary_logloss: 0.112324\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.13146\n",
            "[39]\ttraining's auc: 0.912786\ttraining's binary_logloss: 0.111913\tvalid_1's auc: 0.835774\tvalid_1's binary_logloss: 0.131474\n",
            "[40]\ttraining's auc: 0.913333\ttraining's binary_logloss: 0.111568\tvalid_1's auc: 0.835763\tvalid_1's binary_logloss: 0.131418\n",
            "[41]\ttraining's auc: 0.913894\ttraining's binary_logloss: 0.111304\tvalid_1's auc: 0.835514\tvalid_1's binary_logloss: 0.131457\n",
            "[42]\ttraining's auc: 0.914845\ttraining's binary_logloss: 0.110942\tvalid_1's auc: 0.835683\tvalid_1's binary_logloss: 0.131438\n",
            "[43]\ttraining's auc: 0.915267\ttraining's binary_logloss: 0.110688\tvalid_1's auc: 0.835813\tvalid_1's binary_logloss: 0.13143\n",
            "[44]\ttraining's auc: 0.915588\ttraining's binary_logloss: 0.110442\tvalid_1's auc: 0.835481\tvalid_1's binary_logloss: 0.131496\n",
            "[45]\ttraining's auc: 0.915867\ttraining's binary_logloss: 0.110203\tvalid_1's auc: 0.83535\tvalid_1's binary_logloss: 0.131519\n",
            "[46]\ttraining's auc: 0.916586\ttraining's binary_logloss: 0.109861\tvalid_1's auc: 0.835382\tvalid_1's binary_logloss: 0.131532\n",
            "[47]\ttraining's auc: 0.917032\ttraining's binary_logloss: 0.109566\tvalid_1's auc: 0.835276\tvalid_1's binary_logloss: 0.13154\n",
            "[48]\ttraining's auc: 0.918039\ttraining's binary_logloss: 0.109256\tvalid_1's auc: 0.835015\tvalid_1's binary_logloss: 0.131545\n",
            "[49]\ttraining's auc: 0.918976\ttraining's binary_logloss: 0.108971\tvalid_1's auc: 0.834992\tvalid_1's binary_logloss: 0.131571\n",
            "[50]\ttraining's auc: 0.919573\ttraining's binary_logloss: 0.108696\tvalid_1's auc: 0.834679\tvalid_1's binary_logloss: 0.131631\n",
            "[51]\ttraining's auc: 0.920533\ttraining's binary_logloss: 0.108259\tvalid_1's auc: 0.834229\tvalid_1's binary_logloss: 0.131733\n",
            "[52]\ttraining's auc: 0.921576\ttraining's binary_logloss: 0.107817\tvalid_1's auc: 0.834053\tvalid_1's binary_logloss: 0.131775\n",
            "[53]\ttraining's auc: 0.922017\ttraining's binary_logloss: 0.107635\tvalid_1's auc: 0.83402\tvalid_1's binary_logloss: 0.13181\n",
            "[54]\ttraining's auc: 0.922988\ttraining's binary_logloss: 0.107318\tvalid_1's auc: 0.833779\tvalid_1's binary_logloss: 0.131853\n",
            "[55]\ttraining's auc: 0.92338\ttraining's binary_logloss: 0.107075\tvalid_1's auc: 0.833501\tvalid_1's binary_logloss: 0.13188\n",
            "[56]\ttraining's auc: 0.924027\ttraining's binary_logloss: 0.106799\tvalid_1's auc: 0.833566\tvalid_1's binary_logloss: 0.131891\n",
            "[57]\ttraining's auc: 0.92454\ttraining's binary_logloss: 0.106517\tvalid_1's auc: 0.833016\tvalid_1's binary_logloss: 0.131991\n",
            "[58]\ttraining's auc: 0.924826\ttraining's binary_logloss: 0.106319\tvalid_1's auc: 0.833034\tvalid_1's binary_logloss: 0.131996\n",
            "[59]\ttraining's auc: 0.925192\ttraining's binary_logloss: 0.10605\tvalid_1's auc: 0.832735\tvalid_1's binary_logloss: 0.132044\n",
            "[60]\ttraining's auc: 0.925458\ttraining's binary_logloss: 0.10583\tvalid_1's auc: 0.832478\tvalid_1's binary_logloss: 0.132078\n",
            "[61]\ttraining's auc: 0.926047\ttraining's binary_logloss: 0.105554\tvalid_1's auc: 0.832282\tvalid_1's binary_logloss: 0.132121\n",
            "[62]\ttraining's auc: 0.9263\ttraining's binary_logloss: 0.105347\tvalid_1's auc: 0.832157\tvalid_1's binary_logloss: 0.132135\n",
            "[63]\ttraining's auc: 0.926739\ttraining's binary_logloss: 0.105114\tvalid_1's auc: 0.832058\tvalid_1's binary_logloss: 0.132198\n",
            "[64]\ttraining's auc: 0.927608\ttraining's binary_logloss: 0.104692\tvalid_1's auc: 0.832152\tvalid_1's binary_logloss: 0.132199\n",
            "[65]\ttraining's auc: 0.928182\ttraining's binary_logloss: 0.104447\tvalid_1's auc: 0.831755\tvalid_1's binary_logloss: 0.132289\n",
            "[66]\ttraining's auc: 0.92864\ttraining's binary_logloss: 0.104184\tvalid_1's auc: 0.831545\tvalid_1's binary_logloss: 0.132352\n",
            "[67]\ttraining's auc: 0.929064\ttraining's binary_logloss: 0.103973\tvalid_1's auc: 0.831263\tvalid_1's binary_logloss: 0.132396\n",
            " 72%|███████▏  | 36/50 [18:11<06:19, 27.12s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.152222\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.158774\n",
            "[2]\ttraining's auc: 0.834527\ttraining's binary_logloss: 0.146258\tvalid_1's auc: 0.817266\tvalid_1's binary_logloss: 0.153435\n",
            "[3]\ttraining's auc: 0.842495\ttraining's binary_logloss: 0.141661\tvalid_1's auc: 0.822786\tvalid_1's binary_logloss: 0.149704\n",
            "[4]\ttraining's auc: 0.848161\ttraining's binary_logloss: 0.13832\tvalid_1's auc: 0.826562\tvalid_1's binary_logloss: 0.146921\n",
            "[5]\ttraining's auc: 0.851982\ttraining's binary_logloss: 0.135593\tvalid_1's auc: 0.828197\tvalid_1's binary_logloss: 0.145007\n",
            "[6]\ttraining's auc: 0.856548\ttraining's binary_logloss: 0.133399\tvalid_1's auc: 0.829842\tvalid_1's binary_logloss: 0.143449\n",
            "[7]\ttraining's auc: 0.859139\ttraining's binary_logloss: 0.131541\tvalid_1's auc: 0.830499\tvalid_1's binary_logloss: 0.142002\n",
            "[8]\ttraining's auc: 0.861838\ttraining's binary_logloss: 0.13\tvalid_1's auc: 0.830487\tvalid_1's binary_logloss: 0.141045\n",
            "[9]\ttraining's auc: 0.866911\ttraining's binary_logloss: 0.128497\tvalid_1's auc: 0.831597\tvalid_1's binary_logloss: 0.140155\n",
            "[10]\ttraining's auc: 0.870243\ttraining's binary_logloss: 0.127205\tvalid_1's auc: 0.834132\tvalid_1's binary_logloss: 0.139407\n",
            "[11]\ttraining's auc: 0.872783\ttraining's binary_logloss: 0.126051\tvalid_1's auc: 0.834234\tvalid_1's binary_logloss: 0.138864\n",
            "[12]\ttraining's auc: 0.874255\ttraining's binary_logloss: 0.125053\tvalid_1's auc: 0.834841\tvalid_1's binary_logloss: 0.138493\n",
            "[13]\ttraining's auc: 0.877177\ttraining's binary_logloss: 0.124001\tvalid_1's auc: 0.834785\tvalid_1's binary_logloss: 0.138131\n",
            "[14]\ttraining's auc: 0.879436\ttraining's binary_logloss: 0.123076\tvalid_1's auc: 0.834757\tvalid_1's binary_logloss: 0.137864\n",
            "[15]\ttraining's auc: 0.881274\ttraining's binary_logloss: 0.12226\tvalid_1's auc: 0.835492\tvalid_1's binary_logloss: 0.137559\n",
            "[16]\ttraining's auc: 0.883969\ttraining's binary_logloss: 0.121413\tvalid_1's auc: 0.83491\tvalid_1's binary_logloss: 0.137443\n",
            "[17]\ttraining's auc: 0.885498\ttraining's binary_logloss: 0.120724\tvalid_1's auc: 0.835299\tvalid_1's binary_logloss: 0.137195\n",
            "[18]\ttraining's auc: 0.8876\ttraining's binary_logloss: 0.120011\tvalid_1's auc: 0.835475\tvalid_1's binary_logloss: 0.137024\n",
            "[19]\ttraining's auc: 0.88962\ttraining's binary_logloss: 0.119273\tvalid_1's auc: 0.835531\tvalid_1's binary_logloss: 0.136929\n",
            "[20]\ttraining's auc: 0.89192\ttraining's binary_logloss: 0.118598\tvalid_1's auc: 0.835317\tvalid_1's binary_logloss: 0.136869\n",
            "[21]\ttraining's auc: 0.893478\ttraining's binary_logloss: 0.117929\tvalid_1's auc: 0.835335\tvalid_1's binary_logloss: 0.136787\n",
            "[22]\ttraining's auc: 0.89486\ttraining's binary_logloss: 0.117371\tvalid_1's auc: 0.835082\tvalid_1's binary_logloss: 0.136745\n",
            "[23]\ttraining's auc: 0.896845\ttraining's binary_logloss: 0.116672\tvalid_1's auc: 0.834175\tvalid_1's binary_logloss: 0.136817\n",
            "[24]\ttraining's auc: 0.897978\ttraining's binary_logloss: 0.116139\tvalid_1's auc: 0.833928\tvalid_1's binary_logloss: 0.136819\n",
            "[25]\ttraining's auc: 0.899759\ttraining's binary_logloss: 0.115606\tvalid_1's auc: 0.833674\tvalid_1's binary_logloss: 0.136772\n",
            "[26]\ttraining's auc: 0.901125\ttraining's binary_logloss: 0.11513\tvalid_1's auc: 0.834105\tvalid_1's binary_logloss: 0.136711\n",
            "[27]\ttraining's auc: 0.902872\ttraining's binary_logloss: 0.11443\tvalid_1's auc: 0.834482\tvalid_1's binary_logloss: 0.136633\n",
            "[28]\ttraining's auc: 0.90413\ttraining's binary_logloss: 0.113816\tvalid_1's auc: 0.833953\tvalid_1's binary_logloss: 0.136725\n",
            "[29]\ttraining's auc: 0.904996\ttraining's binary_logloss: 0.113443\tvalid_1's auc: 0.833952\tvalid_1's binary_logloss: 0.136733\n",
            "[30]\ttraining's auc: 0.906312\ttraining's binary_logloss: 0.112891\tvalid_1's auc: 0.833892\tvalid_1's binary_logloss: 0.136756\n",
            "[31]\ttraining's auc: 0.907434\ttraining's binary_logloss: 0.112495\tvalid_1's auc: 0.83343\tvalid_1's binary_logloss: 0.136855\n",
            "[32]\ttraining's auc: 0.908807\ttraining's binary_logloss: 0.112026\tvalid_1's auc: 0.833659\tvalid_1's binary_logloss: 0.136824\n",
            "[33]\ttraining's auc: 0.909893\ttraining's binary_logloss: 0.111597\tvalid_1's auc: 0.833363\tvalid_1's binary_logloss: 0.136912\n",
            "[34]\ttraining's auc: 0.911094\ttraining's binary_logloss: 0.111088\tvalid_1's auc: 0.833452\tvalid_1's binary_logloss: 0.136904\n",
            "[35]\ttraining's auc: 0.911804\ttraining's binary_logloss: 0.110744\tvalid_1's auc: 0.83351\tvalid_1's binary_logloss: 0.13692\n",
            "[36]\ttraining's auc: 0.913027\ttraining's binary_logloss: 0.110375\tvalid_1's auc: 0.834101\tvalid_1's binary_logloss: 0.136844\n",
            "[37]\ttraining's auc: 0.914107\ttraining's binary_logloss: 0.109977\tvalid_1's auc: 0.833831\tvalid_1's binary_logloss: 0.136915\n",
            "[38]\ttraining's auc: 0.91463\ttraining's binary_logloss: 0.109695\tvalid_1's auc: 0.833685\tvalid_1's binary_logloss: 0.136955\n",
            "[39]\ttraining's auc: 0.915604\ttraining's binary_logloss: 0.109279\tvalid_1's auc: 0.833696\tvalid_1's binary_logloss: 0.136982\n",
            "[40]\ttraining's auc: 0.917216\ttraining's binary_logloss: 0.108761\tvalid_1's auc: 0.833564\tvalid_1's binary_logloss: 0.137004\n",
            "[41]\ttraining's auc: 0.918413\ttraining's binary_logloss: 0.108253\tvalid_1's auc: 0.833135\tvalid_1's binary_logloss: 0.137162\n",
            "[42]\ttraining's auc: 0.918956\ttraining's binary_logloss: 0.107944\tvalid_1's auc: 0.833015\tvalid_1's binary_logloss: 0.137171\n",
            "[43]\ttraining's auc: 0.92013\ttraining's binary_logloss: 0.107478\tvalid_1's auc: 0.832885\tvalid_1's binary_logloss: 0.137219\n",
            "[44]\ttraining's auc: 0.920892\ttraining's binary_logloss: 0.107107\tvalid_1's auc: 0.833419\tvalid_1's binary_logloss: 0.137162\n",
            "[45]\ttraining's auc: 0.921562\ttraining's binary_logloss: 0.106725\tvalid_1's auc: 0.833382\tvalid_1's binary_logloss: 0.137185\n",
            "[46]\ttraining's auc: 0.92198\ttraining's binary_logloss: 0.106443\tvalid_1's auc: 0.833335\tvalid_1's binary_logloss: 0.13724\n",
            "[47]\ttraining's auc: 0.922437\ttraining's binary_logloss: 0.106202\tvalid_1's auc: 0.83333\tvalid_1's binary_logloss: 0.137278\n",
            "[48]\ttraining's auc: 0.923399\ttraining's binary_logloss: 0.10576\tvalid_1's auc: 0.833284\tvalid_1's binary_logloss: 0.137334\n",
            "[49]\ttraining's auc: 0.924307\ttraining's binary_logloss: 0.105348\tvalid_1's auc: 0.833303\tvalid_1's binary_logloss: 0.137301\n",
            " 74%|███████▍  | 37/50 [18:17<05:45, 26.55s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.157534\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.159607\n",
            "[2]\ttraining's auc: 0.833814\ttraining's binary_logloss: 0.152774\tvalid_1's auc: 0.808075\tvalid_1's binary_logloss: 0.155795\n",
            "[3]\ttraining's auc: 0.837111\ttraining's binary_logloss: 0.149043\tvalid_1's auc: 0.809565\tvalid_1's binary_logloss: 0.153059\n",
            "[4]\ttraining's auc: 0.843045\ttraining's binary_logloss: 0.14602\tvalid_1's auc: 0.814179\tvalid_1's binary_logloss: 0.150792\n",
            "[5]\ttraining's auc: 0.846147\ttraining's binary_logloss: 0.143613\tvalid_1's auc: 0.816813\tvalid_1's binary_logloss: 0.148896\n",
            "[6]\ttraining's auc: 0.84927\ttraining's binary_logloss: 0.141382\tvalid_1's auc: 0.818057\tvalid_1's binary_logloss: 0.147302\n",
            "[7]\ttraining's auc: 0.851063\ttraining's binary_logloss: 0.139519\tvalid_1's auc: 0.818415\tvalid_1's binary_logloss: 0.146012\n",
            "[8]\ttraining's auc: 0.851987\ttraining's binary_logloss: 0.137864\tvalid_1's auc: 0.8192\tvalid_1's binary_logloss: 0.144783\n",
            "[9]\ttraining's auc: 0.853395\ttraining's binary_logloss: 0.136355\tvalid_1's auc: 0.819838\tvalid_1's binary_logloss: 0.143745\n",
            "[10]\ttraining's auc: 0.855186\ttraining's binary_logloss: 0.135032\tvalid_1's auc: 0.821105\tvalid_1's binary_logloss: 0.14283\n",
            "[11]\ttraining's auc: 0.856683\ttraining's binary_logloss: 0.133836\tvalid_1's auc: 0.822153\tvalid_1's binary_logloss: 0.142032\n",
            "[12]\ttraining's auc: 0.860314\ttraining's binary_logloss: 0.132711\tvalid_1's auc: 0.822673\tvalid_1's binary_logloss: 0.141391\n",
            "[13]\ttraining's auc: 0.862942\ttraining's binary_logloss: 0.13166\tvalid_1's auc: 0.823048\tvalid_1's binary_logloss: 0.140779\n",
            "[14]\ttraining's auc: 0.864358\ttraining's binary_logloss: 0.13066\tvalid_1's auc: 0.824094\tvalid_1's binary_logloss: 0.140186\n",
            "[15]\ttraining's auc: 0.866987\ttraining's binary_logloss: 0.129731\tvalid_1's auc: 0.825017\tvalid_1's binary_logloss: 0.139794\n",
            "[16]\ttraining's auc: 0.868769\ttraining's binary_logloss: 0.12891\tvalid_1's auc: 0.826109\tvalid_1's binary_logloss: 0.139309\n",
            "[17]\ttraining's auc: 0.870502\ttraining's binary_logloss: 0.128183\tvalid_1's auc: 0.826337\tvalid_1's binary_logloss: 0.138994\n",
            "[18]\ttraining's auc: 0.871871\ttraining's binary_logloss: 0.127449\tvalid_1's auc: 0.826606\tvalid_1's binary_logloss: 0.138657\n",
            "[19]\ttraining's auc: 0.872811\ttraining's binary_logloss: 0.126768\tvalid_1's auc: 0.82681\tvalid_1's binary_logloss: 0.138383\n",
            "[20]\ttraining's auc: 0.874241\ttraining's binary_logloss: 0.126126\tvalid_1's auc: 0.826558\tvalid_1's binary_logloss: 0.138146\n",
            "[21]\ttraining's auc: 0.875029\ttraining's binary_logloss: 0.125502\tvalid_1's auc: 0.826673\tvalid_1's binary_logloss: 0.137949\n",
            "[22]\ttraining's auc: 0.876789\ttraining's binary_logloss: 0.124936\tvalid_1's auc: 0.827638\tvalid_1's binary_logloss: 0.137736\n",
            "[23]\ttraining's auc: 0.877748\ttraining's binary_logloss: 0.1244\tvalid_1's auc: 0.827846\tvalid_1's binary_logloss: 0.137539\n",
            "[24]\ttraining's auc: 0.879228\ttraining's binary_logloss: 0.12388\tvalid_1's auc: 0.828275\tvalid_1's binary_logloss: 0.137313\n",
            "[25]\ttraining's auc: 0.880854\ttraining's binary_logloss: 0.123378\tvalid_1's auc: 0.828303\tvalid_1's binary_logloss: 0.137194\n",
            "[26]\ttraining's auc: 0.882695\ttraining's binary_logloss: 0.122858\tvalid_1's auc: 0.827953\tvalid_1's binary_logloss: 0.137076\n",
            "[27]\ttraining's auc: 0.884495\ttraining's binary_logloss: 0.122278\tvalid_1's auc: 0.828199\tvalid_1's binary_logloss: 0.136997\n",
            "[28]\ttraining's auc: 0.885378\ttraining's binary_logloss: 0.12182\tvalid_1's auc: 0.828235\tvalid_1's binary_logloss: 0.136928\n",
            "[29]\ttraining's auc: 0.886653\ttraining's binary_logloss: 0.12135\tvalid_1's auc: 0.827842\tvalid_1's binary_logloss: 0.136884\n",
            "[30]\ttraining's auc: 0.887393\ttraining's binary_logloss: 0.120969\tvalid_1's auc: 0.827754\tvalid_1's binary_logloss: 0.136822\n",
            "[31]\ttraining's auc: 0.888156\ttraining's binary_logloss: 0.12057\tvalid_1's auc: 0.827813\tvalid_1's binary_logloss: 0.136785\n",
            "[32]\ttraining's auc: 0.888901\ttraining's binary_logloss: 0.120224\tvalid_1's auc: 0.827502\tvalid_1's binary_logloss: 0.136763\n",
            "[33]\ttraining's auc: 0.890272\ttraining's binary_logloss: 0.119814\tvalid_1's auc: 0.82718\tvalid_1's binary_logloss: 0.136741\n",
            "[34]\ttraining's auc: 0.891109\ttraining's binary_logloss: 0.119443\tvalid_1's auc: 0.827123\tvalid_1's binary_logloss: 0.136724\n",
            "[35]\ttraining's auc: 0.892662\ttraining's binary_logloss: 0.119006\tvalid_1's auc: 0.827461\tvalid_1's binary_logloss: 0.136642\n",
            "[36]\ttraining's auc: 0.893401\ttraining's binary_logloss: 0.118655\tvalid_1's auc: 0.827502\tvalid_1's binary_logloss: 0.136614\n",
            "[37]\ttraining's auc: 0.895024\ttraining's binary_logloss: 0.118269\tvalid_1's auc: 0.82775\tvalid_1's binary_logloss: 0.136556\n",
            "[38]\ttraining's auc: 0.896053\ttraining's binary_logloss: 0.117879\tvalid_1's auc: 0.828334\tvalid_1's binary_logloss: 0.136482\n",
            "[39]\ttraining's auc: 0.896774\ttraining's binary_logloss: 0.117568\tvalid_1's auc: 0.827886\tvalid_1's binary_logloss: 0.136515\n",
            "[40]\ttraining's auc: 0.897705\ttraining's binary_logloss: 0.11724\tvalid_1's auc: 0.828319\tvalid_1's binary_logloss: 0.136465\n",
            "[41]\ttraining's auc: 0.898794\ttraining's binary_logloss: 0.116907\tvalid_1's auc: 0.82809\tvalid_1's binary_logloss: 0.13646\n",
            "[42]\ttraining's auc: 0.899253\ttraining's binary_logloss: 0.116597\tvalid_1's auc: 0.828115\tvalid_1's binary_logloss: 0.136457\n",
            "[43]\ttraining's auc: 0.900143\ttraining's binary_logloss: 0.116291\tvalid_1's auc: 0.828238\tvalid_1's binary_logloss: 0.136434\n",
            "[44]\ttraining's auc: 0.90097\ttraining's binary_logloss: 0.115964\tvalid_1's auc: 0.828238\tvalid_1's binary_logloss: 0.136427\n",
            "[45]\ttraining's auc: 0.901462\ttraining's binary_logloss: 0.115707\tvalid_1's auc: 0.828155\tvalid_1's binary_logloss: 0.136425\n",
            "[46]\ttraining's auc: 0.901958\ttraining's binary_logloss: 0.115422\tvalid_1's auc: 0.828324\tvalid_1's binary_logloss: 0.136442\n",
            "[47]\ttraining's auc: 0.902378\ttraining's binary_logloss: 0.115129\tvalid_1's auc: 0.828359\tvalid_1's binary_logloss: 0.13649\n",
            "[48]\ttraining's auc: 0.903777\ttraining's binary_logloss: 0.114847\tvalid_1's auc: 0.828441\tvalid_1's binary_logloss: 0.136455\n",
            "[49]\ttraining's auc: 0.904941\ttraining's binary_logloss: 0.114556\tvalid_1's auc: 0.828732\tvalid_1's binary_logloss: 0.136416\n",
            "[50]\ttraining's auc: 0.905501\ttraining's binary_logloss: 0.114275\tvalid_1's auc: 0.828624\tvalid_1's binary_logloss: 0.136428\n",
            "[51]\ttraining's auc: 0.90599\ttraining's binary_logloss: 0.114025\tvalid_1's auc: 0.828635\tvalid_1's binary_logloss: 0.136452\n",
            "[52]\ttraining's auc: 0.906659\ttraining's binary_logloss: 0.113776\tvalid_1's auc: 0.828757\tvalid_1's binary_logloss: 0.136439\n",
            "[53]\ttraining's auc: 0.90741\ttraining's binary_logloss: 0.113496\tvalid_1's auc: 0.828713\tvalid_1's binary_logloss: 0.136481\n",
            "[54]\ttraining's auc: 0.908009\ttraining's binary_logloss: 0.11325\tvalid_1's auc: 0.828683\tvalid_1's binary_logloss: 0.136484\n",
            "[55]\ttraining's auc: 0.908724\ttraining's binary_logloss: 0.113046\tvalid_1's auc: 0.828598\tvalid_1's binary_logloss: 0.136502\n",
            "[56]\ttraining's auc: 0.909139\ttraining's binary_logloss: 0.112832\tvalid_1's auc: 0.828518\tvalid_1's binary_logloss: 0.136506\n",
            "[57]\ttraining's auc: 0.90969\ttraining's binary_logloss: 0.112649\tvalid_1's auc: 0.828533\tvalid_1's binary_logloss: 0.13649\n",
            "[58]\ttraining's auc: 0.910711\ttraining's binary_logloss: 0.11236\tvalid_1's auc: 0.828262\tvalid_1's binary_logloss: 0.136563\n",
            "[59]\ttraining's auc: 0.911484\ttraining's binary_logloss: 0.11209\tvalid_1's auc: 0.828054\tvalid_1's binary_logloss: 0.136607\n",
            "[60]\ttraining's auc: 0.912042\ttraining's binary_logloss: 0.111813\tvalid_1's auc: 0.828148\tvalid_1's binary_logloss: 0.136594\n",
            "[61]\ttraining's auc: 0.912424\ttraining's binary_logloss: 0.111634\tvalid_1's auc: 0.828192\tvalid_1's binary_logloss: 0.1366\n",
            "[62]\ttraining's auc: 0.912946\ttraining's binary_logloss: 0.111397\tvalid_1's auc: 0.827838\tvalid_1's binary_logloss: 0.13668\n",
            "[63]\ttraining's auc: 0.913656\ttraining's binary_logloss: 0.111099\tvalid_1's auc: 0.827841\tvalid_1's binary_logloss: 0.136669\n",
            "[64]\ttraining's auc: 0.914138\ttraining's binary_logloss: 0.110885\tvalid_1's auc: 0.828157\tvalid_1's binary_logloss: 0.136602\n",
            "[65]\ttraining's auc: 0.914928\ttraining's binary_logloss: 0.11071\tvalid_1's auc: 0.82811\tvalid_1's binary_logloss: 0.136602\n",
            "[66]\ttraining's auc: 0.915234\ttraining's binary_logloss: 0.110548\tvalid_1's auc: 0.827998\tvalid_1's binary_logloss: 0.136654\n",
            "[67]\ttraining's auc: 0.915659\ttraining's binary_logloss: 0.110345\tvalid_1's auc: 0.827664\tvalid_1's binary_logloss: 0.136699\n",
            "[68]\ttraining's auc: 0.91638\ttraining's binary_logloss: 0.110111\tvalid_1's auc: 0.827595\tvalid_1's binary_logloss: 0.13673\n",
            "[69]\ttraining's auc: 0.916665\ttraining's binary_logloss: 0.109934\tvalid_1's auc: 0.827512\tvalid_1's binary_logloss: 0.136752\n",
            "[70]\ttraining's auc: 0.916847\ttraining's binary_logloss: 0.109793\tvalid_1's auc: 0.827373\tvalid_1's binary_logloss: 0.136791\n",
            "[71]\ttraining's auc: 0.917343\ttraining's binary_logloss: 0.109596\tvalid_1's auc: 0.82702\tvalid_1's binary_logloss: 0.136869\n",
            "[72]\ttraining's auc: 0.917877\ttraining's binary_logloss: 0.109379\tvalid_1's auc: 0.826883\tvalid_1's binary_logloss: 0.136946\n",
            "[73]\ttraining's auc: 0.918271\ttraining's binary_logloss: 0.109157\tvalid_1's auc: 0.826823\tvalid_1's binary_logloss: 0.136971\n",
            "[74]\ttraining's auc: 0.918877\ttraining's binary_logloss: 0.108996\tvalid_1's auc: 0.826622\tvalid_1's binary_logloss: 0.136999\n",
            "[75]\ttraining's auc: 0.919222\ttraining's binary_logloss: 0.108824\tvalid_1's auc: 0.82656\tvalid_1's binary_logloss: 0.137007\n",
            "[76]\ttraining's auc: 0.919754\ttraining's binary_logloss: 0.10858\tvalid_1's auc: 0.826543\tvalid_1's binary_logloss: 0.13702\n",
            "[77]\ttraining's auc: 0.920105\ttraining's binary_logloss: 0.108428\tvalid_1's auc: 0.826418\tvalid_1's binary_logloss: 0.137055\n",
            "[78]\ttraining's auc: 0.920373\ttraining's binary_logloss: 0.108274\tvalid_1's auc: 0.826308\tvalid_1's binary_logloss: 0.137075\n",
            "[79]\ttraining's auc: 0.920693\ttraining's binary_logloss: 0.108086\tvalid_1's auc: 0.825964\tvalid_1's binary_logloss: 0.137138\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 74%|███████▍  | 37/50 [18:29<05:45, 26.55s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.159941\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.155373\n",
            "[2]\ttraining's auc: 0.826635\ttraining's binary_logloss: 0.155073\tvalid_1's auc: 0.816079\tvalid_1's binary_logloss: 0.151632\n",
            "[3]\ttraining's auc: 0.832354\ttraining's binary_logloss: 0.151303\tvalid_1's auc: 0.817435\tvalid_1's binary_logloss: 0.14876\n",
            "[4]\ttraining's auc: 0.83886\ttraining's binary_logloss: 0.148207\tvalid_1's auc: 0.819984\tvalid_1's binary_logloss: 0.146398\n",
            "[5]\ttraining's auc: 0.845173\ttraining's binary_logloss: 0.145562\tvalid_1's auc: 0.825339\tvalid_1's binary_logloss: 0.14445\n",
            "[6]\ttraining's auc: 0.849479\ttraining's binary_logloss: 0.143364\tvalid_1's auc: 0.828449\tvalid_1's binary_logloss: 0.142863\n",
            "[7]\ttraining's auc: 0.851914\ttraining's binary_logloss: 0.141454\tvalid_1's auc: 0.829054\tvalid_1's binary_logloss: 0.141503\n",
            "[8]\ttraining's auc: 0.85326\ttraining's binary_logloss: 0.139781\tvalid_1's auc: 0.829923\tvalid_1's binary_logloss: 0.140259\n",
            "[9]\ttraining's auc: 0.857113\ttraining's binary_logloss: 0.13825\tvalid_1's auc: 0.831916\tvalid_1's binary_logloss: 0.139248\n",
            "[10]\ttraining's auc: 0.858421\ttraining's binary_logloss: 0.136838\tvalid_1's auc: 0.832021\tvalid_1's binary_logloss: 0.138333\n",
            "[11]\ttraining's auc: 0.859396\ttraining's binary_logloss: 0.135573\tvalid_1's auc: 0.83203\tvalid_1's binary_logloss: 0.137503\n",
            "[12]\ttraining's auc: 0.862221\ttraining's binary_logloss: 0.134458\tvalid_1's auc: 0.832939\tvalid_1's binary_logloss: 0.136808\n",
            "[13]\ttraining's auc: 0.864301\ttraining's binary_logloss: 0.133376\tvalid_1's auc: 0.833041\tvalid_1's binary_logloss: 0.136223\n",
            "[14]\ttraining's auc: 0.867202\ttraining's binary_logloss: 0.13236\tvalid_1's auc: 0.834471\tvalid_1's binary_logloss: 0.135645\n",
            "[15]\ttraining's auc: 0.869457\ttraining's binary_logloss: 0.131415\tvalid_1's auc: 0.834324\tvalid_1's binary_logloss: 0.135189\n",
            "[16]\ttraining's auc: 0.871467\ttraining's binary_logloss: 0.130562\tvalid_1's auc: 0.834154\tvalid_1's binary_logloss: 0.134853\n",
            "[17]\ttraining's auc: 0.872825\ttraining's binary_logloss: 0.129792\tvalid_1's auc: 0.83448\tvalid_1's binary_logloss: 0.134411\n",
            "[18]\ttraining's auc: 0.873732\ttraining's binary_logloss: 0.129078\tvalid_1's auc: 0.834306\tvalid_1's binary_logloss: 0.134057\n",
            "[19]\ttraining's auc: 0.874765\ttraining's binary_logloss: 0.128366\tvalid_1's auc: 0.834073\tvalid_1's binary_logloss: 0.133824\n",
            "[20]\ttraining's auc: 0.875613\ttraining's binary_logloss: 0.127727\tvalid_1's auc: 0.83429\tvalid_1's binary_logloss: 0.133532\n",
            "[21]\ttraining's auc: 0.87677\ttraining's binary_logloss: 0.127148\tvalid_1's auc: 0.834192\tvalid_1's binary_logloss: 0.133303\n",
            "[22]\ttraining's auc: 0.877796\ttraining's binary_logloss: 0.12655\tvalid_1's auc: 0.834412\tvalid_1's binary_logloss: 0.13309\n",
            "[23]\ttraining's auc: 0.879479\ttraining's binary_logloss: 0.125967\tvalid_1's auc: 0.834581\tvalid_1's binary_logloss: 0.132864\n",
            "[24]\ttraining's auc: 0.880424\ttraining's binary_logloss: 0.125401\tvalid_1's auc: 0.834635\tvalid_1's binary_logloss: 0.132695\n",
            "[25]\ttraining's auc: 0.881521\ttraining's binary_logloss: 0.12483\tvalid_1's auc: 0.834027\tvalid_1's binary_logloss: 0.132594\n",
            "[26]\ttraining's auc: 0.882362\ttraining's binary_logloss: 0.124347\tvalid_1's auc: 0.834132\tvalid_1's binary_logloss: 0.132451\n",
            "[27]\ttraining's auc: 0.883204\ttraining's binary_logloss: 0.123883\tvalid_1's auc: 0.834112\tvalid_1's binary_logloss: 0.132344\n",
            "[28]\ttraining's auc: 0.885231\ttraining's binary_logloss: 0.123347\tvalid_1's auc: 0.83429\tvalid_1's binary_logloss: 0.132228\n",
            "[29]\ttraining's auc: 0.886059\ttraining's binary_logloss: 0.1229\tvalid_1's auc: 0.834679\tvalid_1's binary_logloss: 0.132094\n",
            "[30]\ttraining's auc: 0.886805\ttraining's binary_logloss: 0.122542\tvalid_1's auc: 0.834936\tvalid_1's binary_logloss: 0.131996\n",
            "[31]\ttraining's auc: 0.888915\ttraining's binary_logloss: 0.122074\tvalid_1's auc: 0.83491\tvalid_1's binary_logloss: 0.13192\n",
            "[32]\ttraining's auc: 0.889662\ttraining's binary_logloss: 0.121684\tvalid_1's auc: 0.834644\tvalid_1's binary_logloss: 0.131914\n",
            "[33]\ttraining's auc: 0.891123\ttraining's binary_logloss: 0.121247\tvalid_1's auc: 0.83473\tvalid_1's binary_logloss: 0.131842\n",
            "[34]\ttraining's auc: 0.891825\ttraining's binary_logloss: 0.120858\tvalid_1's auc: 0.834803\tvalid_1's binary_logloss: 0.131762\n",
            "[35]\ttraining's auc: 0.892621\ttraining's binary_logloss: 0.120475\tvalid_1's auc: 0.834719\tvalid_1's binary_logloss: 0.13171\n",
            "[36]\ttraining's auc: 0.893343\ttraining's binary_logloss: 0.120132\tvalid_1's auc: 0.835029\tvalid_1's binary_logloss: 0.131637\n",
            "[37]\ttraining's auc: 0.894328\ttraining's binary_logloss: 0.119743\tvalid_1's auc: 0.835115\tvalid_1's binary_logloss: 0.131594\n",
            "[38]\ttraining's auc: 0.895286\ttraining's binary_logloss: 0.119408\tvalid_1's auc: 0.83497\tvalid_1's binary_logloss: 0.131586\n",
            "[39]\ttraining's auc: 0.896272\ttraining's binary_logloss: 0.119092\tvalid_1's auc: 0.834871\tvalid_1's binary_logloss: 0.131541\n",
            "[40]\ttraining's auc: 0.897625\ttraining's binary_logloss: 0.118741\tvalid_1's auc: 0.835088\tvalid_1's binary_logloss: 0.131476\n",
            "[41]\ttraining's auc: 0.898878\ttraining's binary_logloss: 0.118367\tvalid_1's auc: 0.834905\tvalid_1's binary_logloss: 0.131467\n",
            "[42]\ttraining's auc: 0.899765\ttraining's binary_logloss: 0.118026\tvalid_1's auc: 0.835168\tvalid_1's binary_logloss: 0.131434\n",
            "[43]\ttraining's auc: 0.900765\ttraining's binary_logloss: 0.117706\tvalid_1's auc: 0.835266\tvalid_1's binary_logloss: 0.131412\n",
            "[44]\ttraining's auc: 0.901397\ttraining's binary_logloss: 0.117413\tvalid_1's auc: 0.834988\tvalid_1's binary_logloss: 0.131429\n",
            "[45]\ttraining's auc: 0.902058\ttraining's binary_logloss: 0.117141\tvalid_1's auc: 0.835047\tvalid_1's binary_logloss: 0.131403\n",
            "[46]\ttraining's auc: 0.902851\ttraining's binary_logloss: 0.116845\tvalid_1's auc: 0.834913\tvalid_1's binary_logloss: 0.131382\n",
            "[47]\ttraining's auc: 0.903827\ttraining's binary_logloss: 0.116574\tvalid_1's auc: 0.83478\tvalid_1's binary_logloss: 0.131376\n",
            "[48]\ttraining's auc: 0.905136\ttraining's binary_logloss: 0.116264\tvalid_1's auc: 0.834797\tvalid_1's binary_logloss: 0.131371\n",
            "[49]\ttraining's auc: 0.90566\ttraining's binary_logloss: 0.116014\tvalid_1's auc: 0.834765\tvalid_1's binary_logloss: 0.131366\n",
            "[50]\ttraining's auc: 0.905946\ttraining's binary_logloss: 0.115751\tvalid_1's auc: 0.834794\tvalid_1's binary_logloss: 0.131384\n",
            "[51]\ttraining's auc: 0.906693\ttraining's binary_logloss: 0.115482\tvalid_1's auc: 0.835037\tvalid_1's binary_logloss: 0.131347\n",
            "[52]\ttraining's auc: 0.907319\ttraining's binary_logloss: 0.115199\tvalid_1's auc: 0.835174\tvalid_1's binary_logloss: 0.131335\n",
            "[53]\ttraining's auc: 0.908037\ttraining's binary_logloss: 0.114911\tvalid_1's auc: 0.835303\tvalid_1's binary_logloss: 0.131287\n",
            "[54]\ttraining's auc: 0.908723\ttraining's binary_logloss: 0.114652\tvalid_1's auc: 0.83548\tvalid_1's binary_logloss: 0.131258\n",
            "[55]\ttraining's auc: 0.909215\ttraining's binary_logloss: 0.114407\tvalid_1's auc: 0.835411\tvalid_1's binary_logloss: 0.131252\n",
            "[56]\ttraining's auc: 0.909719\ttraining's binary_logloss: 0.114139\tvalid_1's auc: 0.835479\tvalid_1's binary_logloss: 0.131225\n",
            "[57]\ttraining's auc: 0.910275\ttraining's binary_logloss: 0.113906\tvalid_1's auc: 0.835402\tvalid_1's binary_logloss: 0.131241\n",
            "[58]\ttraining's auc: 0.910642\ttraining's binary_logloss: 0.113751\tvalid_1's auc: 0.835554\tvalid_1's binary_logloss: 0.131223\n",
            "[59]\ttraining's auc: 0.91111\ttraining's binary_logloss: 0.113533\tvalid_1's auc: 0.835486\tvalid_1's binary_logloss: 0.131233\n",
            "[60]\ttraining's auc: 0.911903\ttraining's binary_logloss: 0.113253\tvalid_1's auc: 0.835524\tvalid_1's binary_logloss: 0.131216\n",
            "[61]\ttraining's auc: 0.912255\ttraining's binary_logloss: 0.113032\tvalid_1's auc: 0.835569\tvalid_1's binary_logloss: 0.131212\n",
            "[62]\ttraining's auc: 0.912906\ttraining's binary_logloss: 0.112783\tvalid_1's auc: 0.835701\tvalid_1's binary_logloss: 0.131189\n",
            "[63]\ttraining's auc: 0.913566\ttraining's binary_logloss: 0.112521\tvalid_1's auc: 0.835522\tvalid_1's binary_logloss: 0.131218\n",
            "[64]\ttraining's auc: 0.913876\ttraining's binary_logloss: 0.112319\tvalid_1's auc: 0.8357\tvalid_1's binary_logloss: 0.131175\n",
            "[65]\ttraining's auc: 0.914185\ttraining's binary_logloss: 0.112137\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.131216\n",
            "[66]\ttraining's auc: 0.914868\ttraining's binary_logloss: 0.11189\tvalid_1's auc: 0.835599\tvalid_1's binary_logloss: 0.131186\n",
            "[67]\ttraining's auc: 0.915401\ttraining's binary_logloss: 0.111638\tvalid_1's auc: 0.835645\tvalid_1's binary_logloss: 0.13119\n",
            "[68]\ttraining's auc: 0.915791\ttraining's binary_logloss: 0.111414\tvalid_1's auc: 0.835623\tvalid_1's binary_logloss: 0.131211\n",
            "[69]\ttraining's auc: 0.916369\ttraining's binary_logloss: 0.111218\tvalid_1's auc: 0.835643\tvalid_1's binary_logloss: 0.131224\n",
            "[70]\ttraining's auc: 0.916775\ttraining's binary_logloss: 0.111034\tvalid_1's auc: 0.8359\tvalid_1's binary_logloss: 0.131192\n",
            "[71]\ttraining's auc: 0.91706\ttraining's binary_logloss: 0.110871\tvalid_1's auc: 0.83587\tvalid_1's binary_logloss: 0.131191\n",
            "[72]\ttraining's auc: 0.91739\ttraining's binary_logloss: 0.110694\tvalid_1's auc: 0.835641\tvalid_1's binary_logloss: 0.131215\n",
            "[73]\ttraining's auc: 0.917837\ttraining's binary_logloss: 0.110452\tvalid_1's auc: 0.83568\tvalid_1's binary_logloss: 0.131204\n",
            "[74]\ttraining's auc: 0.918039\ttraining's binary_logloss: 0.110297\tvalid_1's auc: 0.835711\tvalid_1's binary_logloss: 0.13121\n",
            "[75]\ttraining's auc: 0.918571\ttraining's binary_logloss: 0.110123\tvalid_1's auc: 0.835584\tvalid_1's binary_logloss: 0.13123\n",
            "[76]\ttraining's auc: 0.918718\ttraining's binary_logloss: 0.109979\tvalid_1's auc: 0.835758\tvalid_1's binary_logloss: 0.131186\n",
            "[77]\ttraining's auc: 0.919225\ttraining's binary_logloss: 0.109778\tvalid_1's auc: 0.835569\tvalid_1's binary_logloss: 0.131229\n",
            "[78]\ttraining's auc: 0.919445\ttraining's binary_logloss: 0.109618\tvalid_1's auc: 0.835635\tvalid_1's binary_logloss: 0.131227\n",
            "[79]\ttraining's auc: 0.919707\ttraining's binary_logloss: 0.109449\tvalid_1's auc: 0.835482\tvalid_1's binary_logloss: 0.131227\n",
            "[80]\ttraining's auc: 0.919927\ttraining's binary_logloss: 0.109331\tvalid_1's auc: 0.835476\tvalid_1's binary_logloss: 0.131222\n",
            "[81]\ttraining's auc: 0.92022\ttraining's binary_logloss: 0.109185\tvalid_1's auc: 0.835379\tvalid_1's binary_logloss: 0.13123\n",
            "[82]\ttraining's auc: 0.92062\ttraining's binary_logloss: 0.109044\tvalid_1's auc: 0.835237\tvalid_1's binary_logloss: 0.131254\n",
            "[83]\ttraining's auc: 0.92078\ttraining's binary_logloss: 0.10892\tvalid_1's auc: 0.835209\tvalid_1's binary_logloss: 0.131265\n",
            "[84]\ttraining's auc: 0.921736\ttraining's binary_logloss: 0.10866\tvalid_1's auc: 0.835336\tvalid_1's binary_logloss: 0.131252\n",
            "[85]\ttraining's auc: 0.921993\ttraining's binary_logloss: 0.108503\tvalid_1's auc: 0.835159\tvalid_1's binary_logloss: 0.131302\n",
            "[86]\ttraining's auc: 0.922245\ttraining's binary_logloss: 0.108349\tvalid_1's auc: 0.835177\tvalid_1's binary_logloss: 0.131296\n",
            "[87]\ttraining's auc: 0.922402\ttraining's binary_logloss: 0.108234\tvalid_1's auc: 0.835087\tvalid_1's binary_logloss: 0.131313\n",
            "[88]\ttraining's auc: 0.922555\ttraining's binary_logloss: 0.108118\tvalid_1's auc: 0.835085\tvalid_1's binary_logloss: 0.131318\n",
            "[89]\ttraining's auc: 0.922923\ttraining's binary_logloss: 0.107974\tvalid_1's auc: 0.835137\tvalid_1's binary_logloss: 0.131324\n",
            "[90]\ttraining's auc: 0.923652\ttraining's binary_logloss: 0.10776\tvalid_1's auc: 0.83497\tvalid_1's binary_logloss: 0.131329\n",
            "[91]\ttraining's auc: 0.923884\ttraining's binary_logloss: 0.107622\tvalid_1's auc: 0.835038\tvalid_1's binary_logloss: 0.131335\n",
            "[92]\ttraining's auc: 0.924481\ttraining's binary_logloss: 0.107382\tvalid_1's auc: 0.834833\tvalid_1's binary_logloss: 0.131364\n",
            "[93]\ttraining's auc: 0.92502\ttraining's binary_logloss: 0.107208\tvalid_1's auc: 0.834654\tvalid_1's binary_logloss: 0.131376\n",
            "[94]\ttraining's auc: 0.925197\ttraining's binary_logloss: 0.107092\tvalid_1's auc: 0.834575\tvalid_1's binary_logloss: 0.131393\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 74%|███████▍  | 37/50 [18:41<05:45, 26.55s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.156511\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.162574\n",
            "[2]\ttraining's auc: 0.832574\ttraining's binary_logloss: 0.1518\tvalid_1's auc: 0.815421\tvalid_1's binary_logloss: 0.158312\n",
            "[3]\ttraining's auc: 0.837703\ttraining's binary_logloss: 0.148167\tvalid_1's auc: 0.817988\tvalid_1's binary_logloss: 0.155181\n",
            "[4]\ttraining's auc: 0.840804\ttraining's binary_logloss: 0.145236\tvalid_1's auc: 0.819551\tvalid_1's binary_logloss: 0.15267\n",
            "[5]\ttraining's auc: 0.845213\ttraining's binary_logloss: 0.142745\tvalid_1's auc: 0.822886\tvalid_1's binary_logloss: 0.15058\n",
            "[6]\ttraining's auc: 0.848553\ttraining's binary_logloss: 0.140523\tvalid_1's auc: 0.826\tvalid_1's binary_logloss: 0.148774\n",
            "[7]\ttraining's auc: 0.849967\ttraining's binary_logloss: 0.138602\tvalid_1's auc: 0.826999\tvalid_1's binary_logloss: 0.147235\n",
            "[8]\ttraining's auc: 0.852727\ttraining's binary_logloss: 0.136974\tvalid_1's auc: 0.828766\tvalid_1's binary_logloss: 0.146014\n",
            "[9]\ttraining's auc: 0.854913\ttraining's binary_logloss: 0.135481\tvalid_1's auc: 0.829167\tvalid_1's binary_logloss: 0.144896\n",
            "[10]\ttraining's auc: 0.856172\ttraining's binary_logloss: 0.134154\tvalid_1's auc: 0.829904\tvalid_1's binary_logloss: 0.143928\n",
            "[11]\ttraining's auc: 0.857986\ttraining's binary_logloss: 0.132947\tvalid_1's auc: 0.829711\tvalid_1's binary_logloss: 0.143101\n",
            "[12]\ttraining's auc: 0.859754\ttraining's binary_logloss: 0.13189\tvalid_1's auc: 0.830576\tvalid_1's binary_logloss: 0.142359\n",
            "[13]\ttraining's auc: 0.862127\ttraining's binary_logloss: 0.13091\tvalid_1's auc: 0.830739\tvalid_1's binary_logloss: 0.14172\n",
            "[14]\ttraining's auc: 0.864528\ttraining's binary_logloss: 0.129927\tvalid_1's auc: 0.830661\tvalid_1's binary_logloss: 0.141175\n",
            "[15]\ttraining's auc: 0.866119\ttraining's binary_logloss: 0.129081\tvalid_1's auc: 0.831048\tvalid_1's binary_logloss: 0.14068\n",
            "[16]\ttraining's auc: 0.867729\ttraining's binary_logloss: 0.128261\tvalid_1's auc: 0.830923\tvalid_1's binary_logloss: 0.140252\n",
            "[17]\ttraining's auc: 0.869621\ttraining's binary_logloss: 0.127495\tvalid_1's auc: 0.833113\tvalid_1's binary_logloss: 0.139861\n",
            "[18]\ttraining's auc: 0.871381\ttraining's binary_logloss: 0.126738\tvalid_1's auc: 0.83424\tvalid_1's binary_logloss: 0.139404\n",
            "[19]\ttraining's auc: 0.872641\ttraining's binary_logloss: 0.126057\tvalid_1's auc: 0.83469\tvalid_1's binary_logloss: 0.139084\n",
            "[20]\ttraining's auc: 0.873942\ttraining's binary_logloss: 0.125404\tvalid_1's auc: 0.834841\tvalid_1's binary_logloss: 0.138793\n",
            "[21]\ttraining's auc: 0.874448\ttraining's binary_logloss: 0.124801\tvalid_1's auc: 0.835207\tvalid_1's binary_logloss: 0.138543\n",
            "[22]\ttraining's auc: 0.876364\ttraining's binary_logloss: 0.124214\tvalid_1's auc: 0.835424\tvalid_1's binary_logloss: 0.138293\n",
            "[23]\ttraining's auc: 0.878502\ttraining's binary_logloss: 0.123621\tvalid_1's auc: 0.835429\tvalid_1's binary_logloss: 0.138121\n",
            "[24]\ttraining's auc: 0.879874\ttraining's binary_logloss: 0.123134\tvalid_1's auc: 0.835734\tvalid_1's binary_logloss: 0.137933\n",
            "[25]\ttraining's auc: 0.88086\ttraining's binary_logloss: 0.122638\tvalid_1's auc: 0.835719\tvalid_1's binary_logloss: 0.137753\n",
            "[26]\ttraining's auc: 0.883484\ttraining's binary_logloss: 0.12205\tvalid_1's auc: 0.835344\tvalid_1's binary_logloss: 0.137618\n",
            "[27]\ttraining's auc: 0.884918\ttraining's binary_logloss: 0.121563\tvalid_1's auc: 0.835764\tvalid_1's binary_logloss: 0.137453\n",
            "[28]\ttraining's auc: 0.886047\ttraining's binary_logloss: 0.121086\tvalid_1's auc: 0.836397\tvalid_1's binary_logloss: 0.137268\n",
            "[29]\ttraining's auc: 0.887585\ttraining's binary_logloss: 0.120655\tvalid_1's auc: 0.835909\tvalid_1's binary_logloss: 0.137201\n",
            "[30]\ttraining's auc: 0.888472\ttraining's binary_logloss: 0.120227\tvalid_1's auc: 0.836172\tvalid_1's binary_logloss: 0.137049\n",
            "[31]\ttraining's auc: 0.889755\ttraining's binary_logloss: 0.119817\tvalid_1's auc: 0.835911\tvalid_1's binary_logloss: 0.137008\n",
            "[32]\ttraining's auc: 0.89095\ttraining's binary_logloss: 0.119422\tvalid_1's auc: 0.835672\tvalid_1's binary_logloss: 0.136965\n",
            "[33]\ttraining's auc: 0.891937\ttraining's binary_logloss: 0.119035\tvalid_1's auc: 0.835547\tvalid_1's binary_logloss: 0.136879\n",
            "[34]\ttraining's auc: 0.893429\ttraining's binary_logloss: 0.118611\tvalid_1's auc: 0.83516\tvalid_1's binary_logloss: 0.136853\n",
            "[35]\ttraining's auc: 0.894707\ttraining's binary_logloss: 0.118235\tvalid_1's auc: 0.835047\tvalid_1's binary_logloss: 0.136833\n",
            "[36]\ttraining's auc: 0.895712\ttraining's binary_logloss: 0.117814\tvalid_1's auc: 0.835041\tvalid_1's binary_logloss: 0.136812\n",
            "[37]\ttraining's auc: 0.896374\ttraining's binary_logloss: 0.117498\tvalid_1's auc: 0.834782\tvalid_1's binary_logloss: 0.136786\n",
            "[38]\ttraining's auc: 0.897111\ttraining's binary_logloss: 0.117178\tvalid_1's auc: 0.834487\tvalid_1's binary_logloss: 0.136785\n",
            "[39]\ttraining's auc: 0.898054\ttraining's binary_logloss: 0.116786\tvalid_1's auc: 0.834613\tvalid_1's binary_logloss: 0.136745\n",
            "[40]\ttraining's auc: 0.89895\ttraining's binary_logloss: 0.116476\tvalid_1's auc: 0.83434\tvalid_1's binary_logloss: 0.136746\n",
            "[41]\ttraining's auc: 0.899705\ttraining's binary_logloss: 0.116183\tvalid_1's auc: 0.833969\tvalid_1's binary_logloss: 0.136757\n",
            "[42]\ttraining's auc: 0.900435\ttraining's binary_logloss: 0.115862\tvalid_1's auc: 0.834017\tvalid_1's binary_logloss: 0.13673\n",
            "[43]\ttraining's auc: 0.901354\ttraining's binary_logloss: 0.115533\tvalid_1's auc: 0.833859\tvalid_1's binary_logloss: 0.136709\n",
            "[44]\ttraining's auc: 0.90196\ttraining's binary_logloss: 0.115239\tvalid_1's auc: 0.833783\tvalid_1's binary_logloss: 0.136702\n",
            "[45]\ttraining's auc: 0.902913\ttraining's binary_logloss: 0.114889\tvalid_1's auc: 0.833866\tvalid_1's binary_logloss: 0.136615\n",
            "[46]\ttraining's auc: 0.903415\ttraining's binary_logloss: 0.114596\tvalid_1's auc: 0.83423\tvalid_1's binary_logloss: 0.136599\n",
            "[47]\ttraining's auc: 0.90396\ttraining's binary_logloss: 0.114345\tvalid_1's auc: 0.834337\tvalid_1's binary_logloss: 0.13658\n",
            "[48]\ttraining's auc: 0.904758\ttraining's binary_logloss: 0.11403\tvalid_1's auc: 0.834384\tvalid_1's binary_logloss: 0.136544\n",
            "[49]\ttraining's auc: 0.905479\ttraining's binary_logloss: 0.1138\tvalid_1's auc: 0.834502\tvalid_1's binary_logloss: 0.136529\n",
            "[50]\ttraining's auc: 0.906234\ttraining's binary_logloss: 0.113507\tvalid_1's auc: 0.834607\tvalid_1's binary_logloss: 0.136513\n",
            "[51]\ttraining's auc: 0.906755\ttraining's binary_logloss: 0.113244\tvalid_1's auc: 0.834609\tvalid_1's binary_logloss: 0.136502\n",
            "[52]\ttraining's auc: 0.907212\ttraining's binary_logloss: 0.112985\tvalid_1's auc: 0.834505\tvalid_1's binary_logloss: 0.136542\n",
            "[53]\ttraining's auc: 0.907705\ttraining's binary_logloss: 0.112778\tvalid_1's auc: 0.834456\tvalid_1's binary_logloss: 0.136554\n",
            "[54]\ttraining's auc: 0.908039\ttraining's binary_logloss: 0.112563\tvalid_1's auc: 0.834339\tvalid_1's binary_logloss: 0.136594\n",
            "[55]\ttraining's auc: 0.908786\ttraining's binary_logloss: 0.112253\tvalid_1's auc: 0.834454\tvalid_1's binary_logloss: 0.1366\n",
            "[56]\ttraining's auc: 0.909206\ttraining's binary_logloss: 0.111985\tvalid_1's auc: 0.834497\tvalid_1's binary_logloss: 0.136622\n",
            "[57]\ttraining's auc: 0.90985\ttraining's binary_logloss: 0.111746\tvalid_1's auc: 0.834384\tvalid_1's binary_logloss: 0.13668\n",
            "[58]\ttraining's auc: 0.910565\ttraining's binary_logloss: 0.111443\tvalid_1's auc: 0.834231\tvalid_1's binary_logloss: 0.136695\n",
            " 76%|███████▌  | 38/50 [18:51<05:44, 28.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.161392\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.162792\n",
            "[2]\ttraining's auc: 0.832234\ttraining's binary_logloss: 0.158703\tvalid_1's auc: 0.807016\tvalid_1's binary_logloss: 0.160677\n",
            "[3]\ttraining's auc: 0.834295\ttraining's binary_logloss: 0.15636\tvalid_1's auc: 0.807738\tvalid_1's binary_logloss: 0.158756\n",
            "[4]\ttraining's auc: 0.836713\ttraining's binary_logloss: 0.15432\tvalid_1's auc: 0.808908\tvalid_1's binary_logloss: 0.157135\n",
            "[5]\ttraining's auc: 0.837088\ttraining's binary_logloss: 0.152504\tvalid_1's auc: 0.808927\tvalid_1's binary_logloss: 0.155729\n",
            "[6]\ttraining's auc: 0.838181\ttraining's binary_logloss: 0.150864\tvalid_1's auc: 0.810166\tvalid_1's binary_logloss: 0.154415\n",
            "[7]\ttraining's auc: 0.842954\ttraining's binary_logloss: 0.149376\tvalid_1's auc: 0.815129\tvalid_1's binary_logloss: 0.153226\n",
            "[8]\ttraining's auc: 0.844506\ttraining's binary_logloss: 0.148003\tvalid_1's auc: 0.816253\tvalid_1's binary_logloss: 0.152178\n",
            "[9]\ttraining's auc: 0.846631\ttraining's binary_logloss: 0.146719\tvalid_1's auc: 0.816317\tvalid_1's binary_logloss: 0.151238\n",
            "[10]\ttraining's auc: 0.847658\ttraining's binary_logloss: 0.145579\tvalid_1's auc: 0.817569\tvalid_1's binary_logloss: 0.150353\n",
            "[11]\ttraining's auc: 0.848838\ttraining's binary_logloss: 0.144456\tvalid_1's auc: 0.817136\tvalid_1's binary_logloss: 0.149537\n",
            "[12]\ttraining's auc: 0.849601\ttraining's binary_logloss: 0.143374\tvalid_1's auc: 0.817949\tvalid_1's binary_logloss: 0.14874\n",
            "[13]\ttraining's auc: 0.850788\ttraining's binary_logloss: 0.14238\tvalid_1's auc: 0.819273\tvalid_1's binary_logloss: 0.148006\n",
            "[14]\ttraining's auc: 0.85147\ttraining's binary_logloss: 0.14147\tvalid_1's auc: 0.820255\tvalid_1's binary_logloss: 0.147316\n",
            "[15]\ttraining's auc: 0.853167\ttraining's binary_logloss: 0.140603\tvalid_1's auc: 0.821108\tvalid_1's binary_logloss: 0.146683\n",
            "[16]\ttraining's auc: 0.854116\ttraining's binary_logloss: 0.139761\tvalid_1's auc: 0.821821\tvalid_1's binary_logloss: 0.146099\n",
            "[17]\ttraining's auc: 0.854573\ttraining's binary_logloss: 0.139007\tvalid_1's auc: 0.821667\tvalid_1's binary_logloss: 0.145582\n",
            "[18]\ttraining's auc: 0.855062\ttraining's binary_logloss: 0.138279\tvalid_1's auc: 0.821141\tvalid_1's binary_logloss: 0.145117\n",
            "[19]\ttraining's auc: 0.855559\ttraining's binary_logloss: 0.137553\tvalid_1's auc: 0.821373\tvalid_1's binary_logloss: 0.144639\n",
            "[20]\ttraining's auc: 0.857811\ttraining's binary_logloss: 0.136867\tvalid_1's auc: 0.822495\tvalid_1's binary_logloss: 0.144164\n",
            "[21]\ttraining's auc: 0.858617\ttraining's binary_logloss: 0.136237\tvalid_1's auc: 0.822564\tvalid_1's binary_logloss: 0.143745\n",
            "[22]\ttraining's auc: 0.859496\ttraining's binary_logloss: 0.135607\tvalid_1's auc: 0.822809\tvalid_1's binary_logloss: 0.143354\n",
            "[23]\ttraining's auc: 0.860822\ttraining's binary_logloss: 0.135044\tvalid_1's auc: 0.823456\tvalid_1's binary_logloss: 0.14295\n",
            "[24]\ttraining's auc: 0.862362\ttraining's binary_logloss: 0.134468\tvalid_1's auc: 0.82396\tvalid_1's binary_logloss: 0.142583\n",
            "[25]\ttraining's auc: 0.862629\ttraining's binary_logloss: 0.133937\tvalid_1's auc: 0.824036\tvalid_1's binary_logloss: 0.142236\n",
            "[26]\ttraining's auc: 0.863539\ttraining's binary_logloss: 0.133427\tvalid_1's auc: 0.824528\tvalid_1's binary_logloss: 0.141892\n",
            "[27]\ttraining's auc: 0.864534\ttraining's binary_logloss: 0.132931\tvalid_1's auc: 0.825007\tvalid_1's binary_logloss: 0.141572\n",
            "[28]\ttraining's auc: 0.865136\ttraining's binary_logloss: 0.132463\tvalid_1's auc: 0.82539\tvalid_1's binary_logloss: 0.14127\n",
            "[29]\ttraining's auc: 0.866228\ttraining's binary_logloss: 0.132015\tvalid_1's auc: 0.825994\tvalid_1's binary_logloss: 0.140986\n",
            "[30]\ttraining's auc: 0.866125\ttraining's binary_logloss: 0.131577\tvalid_1's auc: 0.825944\tvalid_1's binary_logloss: 0.140778\n",
            "[31]\ttraining's auc: 0.866727\ttraining's binary_logloss: 0.131166\tvalid_1's auc: 0.825994\tvalid_1's binary_logloss: 0.140524\n",
            "[32]\ttraining's auc: 0.867157\ttraining's binary_logloss: 0.130732\tvalid_1's auc: 0.826335\tvalid_1's binary_logloss: 0.140284\n",
            "[33]\ttraining's auc: 0.868269\ttraining's binary_logloss: 0.130334\tvalid_1's auc: 0.826689\tvalid_1's binary_logloss: 0.140072\n",
            "[34]\ttraining's auc: 0.869056\ttraining's binary_logloss: 0.12995\tvalid_1's auc: 0.827225\tvalid_1's binary_logloss: 0.139863\n",
            "[35]\ttraining's auc: 0.869687\ttraining's binary_logloss: 0.12957\tvalid_1's auc: 0.827306\tvalid_1's binary_logloss: 0.139655\n",
            "[36]\ttraining's auc: 0.870378\ttraining's binary_logloss: 0.1292\tvalid_1's auc: 0.827536\tvalid_1's binary_logloss: 0.139492\n",
            "[37]\ttraining's auc: 0.870969\ttraining's binary_logloss: 0.128853\tvalid_1's auc: 0.827357\tvalid_1's binary_logloss: 0.139358\n",
            "[38]\ttraining's auc: 0.871607\ttraining's binary_logloss: 0.128513\tvalid_1's auc: 0.827339\tvalid_1's binary_logloss: 0.139188\n",
            "[39]\ttraining's auc: 0.872547\ttraining's binary_logloss: 0.128165\tvalid_1's auc: 0.827385\tvalid_1's binary_logloss: 0.139025\n",
            "[40]\ttraining's auc: 0.873214\ttraining's binary_logloss: 0.127809\tvalid_1's auc: 0.827772\tvalid_1's binary_logloss: 0.13884\n",
            "[41]\ttraining's auc: 0.873821\ttraining's binary_logloss: 0.127477\tvalid_1's auc: 0.827746\tvalid_1's binary_logloss: 0.13871\n",
            "[42]\ttraining's auc: 0.874439\ttraining's binary_logloss: 0.127145\tvalid_1's auc: 0.82803\tvalid_1's binary_logloss: 0.138553\n",
            "[43]\ttraining's auc: 0.875171\ttraining's binary_logloss: 0.126852\tvalid_1's auc: 0.827901\tvalid_1's binary_logloss: 0.138445\n",
            "[44]\ttraining's auc: 0.875675\ttraining's binary_logloss: 0.126544\tvalid_1's auc: 0.827938\tvalid_1's binary_logloss: 0.138323\n",
            "[45]\ttraining's auc: 0.876041\ttraining's binary_logloss: 0.126276\tvalid_1's auc: 0.827947\tvalid_1's binary_logloss: 0.138223\n",
            "[46]\ttraining's auc: 0.87646\ttraining's binary_logloss: 0.126\tvalid_1's auc: 0.827855\tvalid_1's binary_logloss: 0.138122\n",
            "[47]\ttraining's auc: 0.876933\ttraining's binary_logloss: 0.125731\tvalid_1's auc: 0.828015\tvalid_1's binary_logloss: 0.138016\n",
            "[48]\ttraining's auc: 0.878156\ttraining's binary_logloss: 0.125449\tvalid_1's auc: 0.827998\tvalid_1's binary_logloss: 0.137919\n",
            "[49]\ttraining's auc: 0.878596\ttraining's binary_logloss: 0.125196\tvalid_1's auc: 0.827748\tvalid_1's binary_logloss: 0.137829\n",
            "[50]\ttraining's auc: 0.879143\ttraining's binary_logloss: 0.124942\tvalid_1's auc: 0.82803\tvalid_1's binary_logloss: 0.137711\n",
            "[51]\ttraining's auc: 0.879917\ttraining's binary_logloss: 0.124681\tvalid_1's auc: 0.82803\tvalid_1's binary_logloss: 0.137656\n",
            "[52]\ttraining's auc: 0.880362\ttraining's binary_logloss: 0.12443\tvalid_1's auc: 0.828425\tvalid_1's binary_logloss: 0.137575\n",
            "[53]\ttraining's auc: 0.881491\ttraining's binary_logloss: 0.124154\tvalid_1's auc: 0.828512\tvalid_1's binary_logloss: 0.137459\n",
            "[54]\ttraining's auc: 0.882017\ttraining's binary_logloss: 0.123917\tvalid_1's auc: 0.828422\tvalid_1's binary_logloss: 0.137373\n",
            "[55]\ttraining's auc: 0.882661\ttraining's binary_logloss: 0.123685\tvalid_1's auc: 0.82852\tvalid_1's binary_logloss: 0.137306\n",
            "[56]\ttraining's auc: 0.88325\ttraining's binary_logloss: 0.123443\tvalid_1's auc: 0.828463\tvalid_1's binary_logloss: 0.137227\n",
            "[57]\ttraining's auc: 0.883803\ttraining's binary_logloss: 0.123215\tvalid_1's auc: 0.828354\tvalid_1's binary_logloss: 0.137162\n",
            "[58]\ttraining's auc: 0.884247\ttraining's binary_logloss: 0.123\tvalid_1's auc: 0.828282\tvalid_1's binary_logloss: 0.137114\n",
            "[59]\ttraining's auc: 0.884813\ttraining's binary_logloss: 0.122789\tvalid_1's auc: 0.828585\tvalid_1's binary_logloss: 0.137015\n",
            "[60]\ttraining's auc: 0.885597\ttraining's binary_logloss: 0.122552\tvalid_1's auc: 0.829207\tvalid_1's binary_logloss: 0.136921\n",
            "[61]\ttraining's auc: 0.886211\ttraining's binary_logloss: 0.122329\tvalid_1's auc: 0.829346\tvalid_1's binary_logloss: 0.136864\n",
            "[62]\ttraining's auc: 0.88665\ttraining's binary_logloss: 0.122129\tvalid_1's auc: 0.829279\tvalid_1's binary_logloss: 0.136836\n",
            "[63]\ttraining's auc: 0.887365\ttraining's binary_logloss: 0.12189\tvalid_1's auc: 0.829373\tvalid_1's binary_logloss: 0.136773\n",
            "[64]\ttraining's auc: 0.887674\ttraining's binary_logloss: 0.121706\tvalid_1's auc: 0.82937\tvalid_1's binary_logloss: 0.13673\n",
            "[65]\ttraining's auc: 0.888451\ttraining's binary_logloss: 0.121462\tvalid_1's auc: 0.829273\tvalid_1's binary_logloss: 0.136705\n",
            "[66]\ttraining's auc: 0.888895\ttraining's binary_logloss: 0.121274\tvalid_1's auc: 0.829693\tvalid_1's binary_logloss: 0.136617\n",
            "[67]\ttraining's auc: 0.889231\ttraining's binary_logloss: 0.121099\tvalid_1's auc: 0.829816\tvalid_1's binary_logloss: 0.136574\n",
            "[68]\ttraining's auc: 0.889683\ttraining's binary_logloss: 0.120894\tvalid_1's auc: 0.829808\tvalid_1's binary_logloss: 0.136548\n",
            "[69]\ttraining's auc: 0.890106\ttraining's binary_logloss: 0.120708\tvalid_1's auc: 0.829797\tvalid_1's binary_logloss: 0.1365\n",
            "[70]\ttraining's auc: 0.890347\ttraining's binary_logloss: 0.120533\tvalid_1's auc: 0.829741\tvalid_1's binary_logloss: 0.136464\n",
            "[71]\ttraining's auc: 0.890652\ttraining's binary_logloss: 0.120357\tvalid_1's auc: 0.829804\tvalid_1's binary_logloss: 0.136442\n",
            "[72]\ttraining's auc: 0.890937\ttraining's binary_logloss: 0.120195\tvalid_1's auc: 0.829663\tvalid_1's binary_logloss: 0.13642\n",
            "[73]\ttraining's auc: 0.891318\ttraining's binary_logloss: 0.120019\tvalid_1's auc: 0.829725\tvalid_1's binary_logloss: 0.1364\n",
            "[74]\ttraining's auc: 0.892212\ttraining's binary_logloss: 0.11979\tvalid_1's auc: 0.830136\tvalid_1's binary_logloss: 0.136315\n",
            "[75]\ttraining's auc: 0.892662\ttraining's binary_logloss: 0.11961\tvalid_1's auc: 0.830212\tvalid_1's binary_logloss: 0.136271\n",
            "[76]\ttraining's auc: 0.893051\ttraining's binary_logloss: 0.119457\tvalid_1's auc: 0.830165\tvalid_1's binary_logloss: 0.136265\n",
            "[77]\ttraining's auc: 0.893536\ttraining's binary_logloss: 0.11928\tvalid_1's auc: 0.83037\tvalid_1's binary_logloss: 0.136221\n",
            "[78]\ttraining's auc: 0.893874\ttraining's binary_logloss: 0.119128\tvalid_1's auc: 0.830374\tvalid_1's binary_logloss: 0.136213\n",
            "[79]\ttraining's auc: 0.894157\ttraining's binary_logloss: 0.118983\tvalid_1's auc: 0.830271\tvalid_1's binary_logloss: 0.136204\n",
            "[80]\ttraining's auc: 0.895009\ttraining's binary_logloss: 0.118791\tvalid_1's auc: 0.830399\tvalid_1's binary_logloss: 0.13612\n",
            "[81]\ttraining's auc: 0.89528\ttraining's binary_logloss: 0.118634\tvalid_1's auc: 0.83047\tvalid_1's binary_logloss: 0.136113\n",
            "[82]\ttraining's auc: 0.895783\ttraining's binary_logloss: 0.118463\tvalid_1's auc: 0.830468\tvalid_1's binary_logloss: 0.136102\n",
            "[83]\ttraining's auc: 0.896618\ttraining's binary_logloss: 0.118282\tvalid_1's auc: 0.830875\tvalid_1's binary_logloss: 0.136026\n",
            "[84]\ttraining's auc: 0.897058\ttraining's binary_logloss: 0.118129\tvalid_1's auc: 0.830978\tvalid_1's binary_logloss: 0.135976\n",
            "[85]\ttraining's auc: 0.897436\ttraining's binary_logloss: 0.11797\tvalid_1's auc: 0.831108\tvalid_1's binary_logloss: 0.135934\n",
            "[86]\ttraining's auc: 0.897748\ttraining's binary_logloss: 0.11781\tvalid_1's auc: 0.831179\tvalid_1's binary_logloss: 0.135907\n",
            "[87]\ttraining's auc: 0.898001\ttraining's binary_logloss: 0.117667\tvalid_1's auc: 0.831102\tvalid_1's binary_logloss: 0.135898\n",
            "[88]\ttraining's auc: 0.898275\ttraining's binary_logloss: 0.117523\tvalid_1's auc: 0.831134\tvalid_1's binary_logloss: 0.135873\n",
            "[89]\ttraining's auc: 0.898709\ttraining's binary_logloss: 0.117382\tvalid_1's auc: 0.831079\tvalid_1's binary_logloss: 0.135843\n",
            "[90]\ttraining's auc: 0.898882\ttraining's binary_logloss: 0.117254\tvalid_1's auc: 0.831102\tvalid_1's binary_logloss: 0.135835\n",
            "[91]\ttraining's auc: 0.899591\ttraining's binary_logloss: 0.1171\tvalid_1's auc: 0.831277\tvalid_1's binary_logloss: 0.135804\n",
            "[92]\ttraining's auc: 0.899897\ttraining's binary_logloss: 0.116962\tvalid_1's auc: 0.831313\tvalid_1's binary_logloss: 0.135792\n",
            "[93]\ttraining's auc: 0.90032\ttraining's binary_logloss: 0.116828\tvalid_1's auc: 0.831314\tvalid_1's binary_logloss: 0.135786\n",
            "[94]\ttraining's auc: 0.900832\ttraining's binary_logloss: 0.11669\tvalid_1's auc: 0.83145\tvalid_1's binary_logloss: 0.135749\n",
            "[95]\ttraining's auc: 0.901188\ttraining's binary_logloss: 0.116555\tvalid_1's auc: 0.831413\tvalid_1's binary_logloss: 0.135754\n",
            "[96]\ttraining's auc: 0.901738\ttraining's binary_logloss: 0.116413\tvalid_1's auc: 0.831389\tvalid_1's binary_logloss: 0.135754\n",
            "[97]\ttraining's auc: 0.902142\ttraining's binary_logloss: 0.116271\tvalid_1's auc: 0.831485\tvalid_1's binary_logloss: 0.135726\n",
            "[98]\ttraining's auc: 0.902466\ttraining's binary_logloss: 0.116145\tvalid_1's auc: 0.831544\tvalid_1's binary_logloss: 0.135694\n",
            "[99]\ttraining's auc: 0.902756\ttraining's binary_logloss: 0.116024\tvalid_1's auc: 0.831564\tvalid_1's binary_logloss: 0.135672\n",
            "[100]\ttraining's auc: 0.903049\ttraining's binary_logloss: 0.115887\tvalid_1's auc: 0.831678\tvalid_1's binary_logloss: 0.135666\n",
            "[101]\ttraining's auc: 0.903283\ttraining's binary_logloss: 0.11578\tvalid_1's auc: 0.831685\tvalid_1's binary_logloss: 0.135663\n",
            "[102]\ttraining's auc: 0.903494\ttraining's binary_logloss: 0.11564\tvalid_1's auc: 0.831797\tvalid_1's binary_logloss: 0.135643\n",
            "[103]\ttraining's auc: 0.903826\ttraining's binary_logloss: 0.115514\tvalid_1's auc: 0.831879\tvalid_1's binary_logloss: 0.135621\n",
            "[104]\ttraining's auc: 0.904088\ttraining's binary_logloss: 0.115384\tvalid_1's auc: 0.831817\tvalid_1's binary_logloss: 0.135635\n",
            "[105]\ttraining's auc: 0.904307\ttraining's binary_logloss: 0.115252\tvalid_1's auc: 0.831641\tvalid_1's binary_logloss: 0.135664\n",
            "[106]\ttraining's auc: 0.904812\ttraining's binary_logloss: 0.115125\tvalid_1's auc: 0.831675\tvalid_1's binary_logloss: 0.135648\n",
            "[107]\ttraining's auc: 0.905018\ttraining's binary_logloss: 0.115001\tvalid_1's auc: 0.831739\tvalid_1's binary_logloss: 0.135648\n",
            "[108]\ttraining's auc: 0.905342\ttraining's binary_logloss: 0.114862\tvalid_1's auc: 0.831717\tvalid_1's binary_logloss: 0.135636\n",
            "[109]\ttraining's auc: 0.905739\ttraining's binary_logloss: 0.114758\tvalid_1's auc: 0.831597\tvalid_1's binary_logloss: 0.135642\n",
            "[110]\ttraining's auc: 0.905941\ttraining's binary_logloss: 0.114638\tvalid_1's auc: 0.831593\tvalid_1's binary_logloss: 0.135651\n",
            "[111]\ttraining's auc: 0.906192\ttraining's binary_logloss: 0.114528\tvalid_1's auc: 0.831552\tvalid_1's binary_logloss: 0.135658\n",
            "[112]\ttraining's auc: 0.906406\ttraining's binary_logloss: 0.114397\tvalid_1's auc: 0.831662\tvalid_1's binary_logloss: 0.135647\n",
            "[113]\ttraining's auc: 0.906628\ttraining's binary_logloss: 0.114277\tvalid_1's auc: 0.831693\tvalid_1's binary_logloss: 0.135628\n",
            "[114]\ttraining's auc: 0.906799\ttraining's binary_logloss: 0.11417\tvalid_1's auc: 0.831669\tvalid_1's binary_logloss: 0.135633\n",
            "[115]\ttraining's auc: 0.907046\ttraining's binary_logloss: 0.114057\tvalid_1's auc: 0.83156\tvalid_1's binary_logloss: 0.135647\n",
            "[116]\ttraining's auc: 0.907266\ttraining's binary_logloss: 0.113937\tvalid_1's auc: 0.831521\tvalid_1's binary_logloss: 0.135656\n",
            "[117]\ttraining's auc: 0.907463\ttraining's binary_logloss: 0.113822\tvalid_1's auc: 0.831492\tvalid_1's binary_logloss: 0.135663\n",
            "[118]\ttraining's auc: 0.907771\ttraining's binary_logloss: 0.113693\tvalid_1's auc: 0.831436\tvalid_1's binary_logloss: 0.13567\n",
            "[119]\ttraining's auc: 0.907977\ttraining's binary_logloss: 0.113579\tvalid_1's auc: 0.831398\tvalid_1's binary_logloss: 0.135672\n",
            "[120]\ttraining's auc: 0.908302\ttraining's binary_logloss: 0.113437\tvalid_1's auc: 0.831402\tvalid_1's binary_logloss: 0.135667\n",
            "[121]\ttraining's auc: 0.908686\ttraining's binary_logloss: 0.113337\tvalid_1's auc: 0.831489\tvalid_1's binary_logloss: 0.135656\n",
            "[122]\ttraining's auc: 0.908913\ttraining's binary_logloss: 0.113235\tvalid_1's auc: 0.831348\tvalid_1's binary_logloss: 0.135685\n",
            "[123]\ttraining's auc: 0.909163\ttraining's binary_logloss: 0.113113\tvalid_1's auc: 0.831279\tvalid_1's binary_logloss: 0.135699\n",
            "[124]\ttraining's auc: 0.909435\ttraining's binary_logloss: 0.112983\tvalid_1's auc: 0.831224\tvalid_1's binary_logloss: 0.135697\n",
            "[125]\ttraining's auc: 0.909862\ttraining's binary_logloss: 0.112835\tvalid_1's auc: 0.831108\tvalid_1's binary_logloss: 0.135717\n",
            "[126]\ttraining's auc: 0.910081\ttraining's binary_logloss: 0.11274\tvalid_1's auc: 0.830926\tvalid_1's binary_logloss: 0.135758\n",
            "[127]\ttraining's auc: 0.910666\ttraining's binary_logloss: 0.11261\tvalid_1's auc: 0.830882\tvalid_1's binary_logloss: 0.135768\n",
            "[128]\ttraining's auc: 0.910909\ttraining's binary_logloss: 0.112493\tvalid_1's auc: 0.830859\tvalid_1's binary_logloss: 0.135771\n",
            "[129]\ttraining's auc: 0.911239\ttraining's binary_logloss: 0.112379\tvalid_1's auc: 0.830681\tvalid_1's binary_logloss: 0.135811\n",
            "[130]\ttraining's auc: 0.911514\ttraining's binary_logloss: 0.112283\tvalid_1's auc: 0.830641\tvalid_1's binary_logloss: 0.135827\n",
            "[131]\ttraining's auc: 0.91178\ttraining's binary_logloss: 0.112181\tvalid_1's auc: 0.830546\tvalid_1's binary_logloss: 0.135855\n",
            "[132]\ttraining's auc: 0.911964\ttraining's binary_logloss: 0.112089\tvalid_1's auc: 0.830624\tvalid_1's binary_logloss: 0.135839\n",
            "[133]\ttraining's auc: 0.912153\ttraining's binary_logloss: 0.111989\tvalid_1's auc: 0.830589\tvalid_1's binary_logloss: 0.135848\n",
            " 76%|███████▌  | 38/50 [19:08<05:44, 28.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.163776\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.158291\n",
            "[2]\ttraining's auc: 0.822332\ttraining's binary_logloss: 0.161127\tvalid_1's auc: 0.804484\tvalid_1's binary_logloss: 0.156102\n",
            "[3]\ttraining's auc: 0.828473\ttraining's binary_logloss: 0.158773\tvalid_1's auc: 0.816004\tvalid_1's binary_logloss: 0.154277\n",
            "[4]\ttraining's auc: 0.830855\ttraining's binary_logloss: 0.15671\tvalid_1's auc: 0.81808\tvalid_1's binary_logloss: 0.152616\n",
            "[5]\ttraining's auc: 0.833837\ttraining's binary_logloss: 0.154845\tvalid_1's auc: 0.819312\tvalid_1's binary_logloss: 0.151142\n",
            "[6]\ttraining's auc: 0.834737\ttraining's binary_logloss: 0.153162\tvalid_1's auc: 0.819247\tvalid_1's binary_logloss: 0.149877\n",
            "[7]\ttraining's auc: 0.835339\ttraining's binary_logloss: 0.151653\tvalid_1's auc: 0.819968\tvalid_1's binary_logloss: 0.148697\n",
            "[8]\ttraining's auc: 0.836907\ttraining's binary_logloss: 0.150277\tvalid_1's auc: 0.820154\tvalid_1's binary_logloss: 0.147629\n",
            "[9]\ttraining's auc: 0.840298\ttraining's binary_logloss: 0.148971\tvalid_1's auc: 0.823167\tvalid_1's binary_logloss: 0.146637\n",
            "[10]\ttraining's auc: 0.842539\ttraining's binary_logloss: 0.147769\tvalid_1's auc: 0.824223\tvalid_1's binary_logloss: 0.145742\n",
            "[11]\ttraining's auc: 0.844555\ttraining's binary_logloss: 0.146642\tvalid_1's auc: 0.825525\tvalid_1's binary_logloss: 0.144881\n",
            "[12]\ttraining's auc: 0.847591\ttraining's binary_logloss: 0.145582\tvalid_1's auc: 0.827505\tvalid_1's binary_logloss: 0.144105\n",
            "[13]\ttraining's auc: 0.849352\ttraining's binary_logloss: 0.144592\tvalid_1's auc: 0.828134\tvalid_1's binary_logloss: 0.143384\n",
            "[14]\ttraining's auc: 0.850337\ttraining's binary_logloss: 0.143658\tvalid_1's auc: 0.828665\tvalid_1's binary_logloss: 0.142706\n",
            "[15]\ttraining's auc: 0.851235\ttraining's binary_logloss: 0.142768\tvalid_1's auc: 0.828917\tvalid_1's binary_logloss: 0.142086\n",
            "[16]\ttraining's auc: 0.852366\ttraining's binary_logloss: 0.141949\tvalid_1's auc: 0.829731\tvalid_1's binary_logloss: 0.141496\n",
            "[17]\ttraining's auc: 0.853761\ttraining's binary_logloss: 0.141155\tvalid_1's auc: 0.8302\tvalid_1's binary_logloss: 0.140892\n",
            "[18]\ttraining's auc: 0.854558\ttraining's binary_logloss: 0.140395\tvalid_1's auc: 0.830367\tvalid_1's binary_logloss: 0.140328\n",
            "[19]\ttraining's auc: 0.855891\ttraining's binary_logloss: 0.139674\tvalid_1's auc: 0.831406\tvalid_1's binary_logloss: 0.139781\n",
            "[20]\ttraining's auc: 0.857371\ttraining's binary_logloss: 0.139009\tvalid_1's auc: 0.832409\tvalid_1's binary_logloss: 0.139325\n",
            "[21]\ttraining's auc: 0.85834\ttraining's binary_logloss: 0.13837\tvalid_1's auc: 0.833047\tvalid_1's binary_logloss: 0.138895\n",
            "[22]\ttraining's auc: 0.859214\ttraining's binary_logloss: 0.137759\tvalid_1's auc: 0.832869\tvalid_1's binary_logloss: 0.138467\n",
            "[23]\ttraining's auc: 0.859687\ttraining's binary_logloss: 0.137164\tvalid_1's auc: 0.832918\tvalid_1's binary_logloss: 0.138078\n",
            "[24]\ttraining's auc: 0.860408\ttraining's binary_logloss: 0.136566\tvalid_1's auc: 0.833032\tvalid_1's binary_logloss: 0.137724\n",
            "[25]\ttraining's auc: 0.860548\ttraining's binary_logloss: 0.136024\tvalid_1's auc: 0.832997\tvalid_1's binary_logloss: 0.137387\n",
            "[26]\ttraining's auc: 0.861069\ttraining's binary_logloss: 0.135507\tvalid_1's auc: 0.832922\tvalid_1's binary_logloss: 0.137045\n",
            "[27]\ttraining's auc: 0.862494\ttraining's binary_logloss: 0.135025\tvalid_1's auc: 0.83365\tvalid_1's binary_logloss: 0.136767\n",
            "[28]\ttraining's auc: 0.863111\ttraining's binary_logloss: 0.134535\tvalid_1's auc: 0.834108\tvalid_1's binary_logloss: 0.136437\n",
            "[29]\ttraining's auc: 0.864919\ttraining's binary_logloss: 0.134037\tvalid_1's auc: 0.834414\tvalid_1's binary_logloss: 0.136175\n",
            "[30]\ttraining's auc: 0.865647\ttraining's binary_logloss: 0.133582\tvalid_1's auc: 0.834391\tvalid_1's binary_logloss: 0.135907\n",
            "[31]\ttraining's auc: 0.86708\ttraining's binary_logloss: 0.133125\tvalid_1's auc: 0.835168\tvalid_1's binary_logloss: 0.135639\n",
            "[32]\ttraining's auc: 0.86782\ttraining's binary_logloss: 0.132702\tvalid_1's auc: 0.835151\tvalid_1's binary_logloss: 0.135405\n",
            "[33]\ttraining's auc: 0.868541\ttraining's binary_logloss: 0.132274\tvalid_1's auc: 0.835621\tvalid_1's binary_logloss: 0.135187\n",
            "[34]\ttraining's auc: 0.869635\ttraining's binary_logloss: 0.131884\tvalid_1's auc: 0.835554\tvalid_1's binary_logloss: 0.134987\n",
            "[35]\ttraining's auc: 0.870426\ttraining's binary_logloss: 0.131505\tvalid_1's auc: 0.835607\tvalid_1's binary_logloss: 0.1348\n",
            "[36]\ttraining's auc: 0.871116\ttraining's binary_logloss: 0.131126\tvalid_1's auc: 0.835443\tvalid_1's binary_logloss: 0.13463\n",
            "[37]\ttraining's auc: 0.871741\ttraining's binary_logloss: 0.130765\tvalid_1's auc: 0.835047\tvalid_1's binary_logloss: 0.134457\n",
            "[38]\ttraining's auc: 0.872266\ttraining's binary_logloss: 0.130417\tvalid_1's auc: 0.835141\tvalid_1's binary_logloss: 0.134264\n",
            "[39]\ttraining's auc: 0.872756\ttraining's binary_logloss: 0.130089\tvalid_1's auc: 0.835034\tvalid_1's binary_logloss: 0.134109\n",
            "[40]\ttraining's auc: 0.8732\ttraining's binary_logloss: 0.129771\tvalid_1's auc: 0.835143\tvalid_1's binary_logloss: 0.133949\n",
            "[41]\ttraining's auc: 0.873791\ttraining's binary_logloss: 0.129455\tvalid_1's auc: 0.834985\tvalid_1's binary_logloss: 0.133839\n",
            "[42]\ttraining's auc: 0.874237\ttraining's binary_logloss: 0.129135\tvalid_1's auc: 0.834629\tvalid_1's binary_logloss: 0.133732\n",
            "[43]\ttraining's auc: 0.874508\ttraining's binary_logloss: 0.128848\tvalid_1's auc: 0.834802\tvalid_1's binary_logloss: 0.133588\n",
            "[44]\ttraining's auc: 0.874891\ttraining's binary_logloss: 0.128553\tvalid_1's auc: 0.834857\tvalid_1's binary_logloss: 0.13346\n",
            "[45]\ttraining's auc: 0.875252\ttraining's binary_logloss: 0.128275\tvalid_1's auc: 0.834915\tvalid_1's binary_logloss: 0.133337\n",
            "[46]\ttraining's auc: 0.875519\ttraining's binary_logloss: 0.128004\tvalid_1's auc: 0.834811\tvalid_1's binary_logloss: 0.133235\n",
            "[47]\ttraining's auc: 0.875837\ttraining's binary_logloss: 0.127722\tvalid_1's auc: 0.8347\tvalid_1's binary_logloss: 0.133142\n",
            "[48]\ttraining's auc: 0.876528\ttraining's binary_logloss: 0.127438\tvalid_1's auc: 0.834467\tvalid_1's binary_logloss: 0.133056\n",
            "[49]\ttraining's auc: 0.876858\ttraining's binary_logloss: 0.127198\tvalid_1's auc: 0.834496\tvalid_1's binary_logloss: 0.132943\n",
            "[50]\ttraining's auc: 0.87768\ttraining's binary_logloss: 0.12691\tvalid_1's auc: 0.834622\tvalid_1's binary_logloss: 0.132842\n",
            "[51]\ttraining's auc: 0.878123\ttraining's binary_logloss: 0.126647\tvalid_1's auc: 0.834612\tvalid_1's binary_logloss: 0.132751\n",
            "[52]\ttraining's auc: 0.878526\ttraining's binary_logloss: 0.126407\tvalid_1's auc: 0.83456\tvalid_1's binary_logloss: 0.132671\n",
            "[53]\ttraining's auc: 0.878909\ttraining's binary_logloss: 0.126159\tvalid_1's auc: 0.834428\tvalid_1's binary_logloss: 0.132593\n",
            "[54]\ttraining's auc: 0.879323\ttraining's binary_logloss: 0.125906\tvalid_1's auc: 0.834465\tvalid_1's binary_logloss: 0.132511\n",
            "[55]\ttraining's auc: 0.879704\ttraining's binary_logloss: 0.125681\tvalid_1's auc: 0.83442\tvalid_1's binary_logloss: 0.132435\n",
            "[56]\ttraining's auc: 0.880033\ttraining's binary_logloss: 0.125458\tvalid_1's auc: 0.834582\tvalid_1's binary_logloss: 0.132361\n",
            "[57]\ttraining's auc: 0.880534\ttraining's binary_logloss: 0.125223\tvalid_1's auc: 0.834745\tvalid_1's binary_logloss: 0.132292\n",
            "[58]\ttraining's auc: 0.881391\ttraining's binary_logloss: 0.124986\tvalid_1's auc: 0.834761\tvalid_1's binary_logloss: 0.132217\n",
            "[59]\ttraining's auc: 0.881796\ttraining's binary_logloss: 0.124776\tvalid_1's auc: 0.834618\tvalid_1's binary_logloss: 0.132158\n",
            "[60]\ttraining's auc: 0.882327\ttraining's binary_logloss: 0.124556\tvalid_1's auc: 0.834622\tvalid_1's binary_logloss: 0.132099\n",
            "[61]\ttraining's auc: 0.883354\ttraining's binary_logloss: 0.124318\tvalid_1's auc: 0.834631\tvalid_1's binary_logloss: 0.132042\n",
            "[62]\ttraining's auc: 0.88405\ttraining's binary_logloss: 0.124097\tvalid_1's auc: 0.834734\tvalid_1's binary_logloss: 0.13198\n",
            "[63]\ttraining's auc: 0.884764\ttraining's binary_logloss: 0.123895\tvalid_1's auc: 0.834816\tvalid_1's binary_logloss: 0.131936\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 76%|███████▌  | 38/50 [19:19<05:44, 28.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.160107\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.165796\n",
            "[2]\ttraining's auc: 0.830943\ttraining's binary_logloss: 0.157537\tvalid_1's auc: 0.816301\tvalid_1's binary_logloss: 0.163445\n",
            "[3]\ttraining's auc: 0.832195\ttraining's binary_logloss: 0.155345\tvalid_1's auc: 0.814219\tvalid_1's binary_logloss: 0.161557\n",
            "[4]\ttraining's auc: 0.833813\ttraining's binary_logloss: 0.153368\tvalid_1's auc: 0.816404\tvalid_1's binary_logloss: 0.159708\n",
            "[5]\ttraining's auc: 0.835521\ttraining's binary_logloss: 0.151598\tvalid_1's auc: 0.817172\tvalid_1's binary_logloss: 0.15817\n",
            "[6]\ttraining's auc: 0.839001\ttraining's binary_logloss: 0.14996\tvalid_1's auc: 0.81964\tvalid_1's binary_logloss: 0.156703\n",
            "[7]\ttraining's auc: 0.839457\ttraining's binary_logloss: 0.148502\tvalid_1's auc: 0.819052\tvalid_1's binary_logloss: 0.155475\n",
            "[8]\ttraining's auc: 0.843224\ttraining's binary_logloss: 0.147121\tvalid_1's auc: 0.822739\tvalid_1's binary_logloss: 0.154283\n",
            "[9]\ttraining's auc: 0.84668\ttraining's binary_logloss: 0.145834\tvalid_1's auc: 0.825716\tvalid_1's binary_logloss: 0.153197\n",
            "[10]\ttraining's auc: 0.848248\ttraining's binary_logloss: 0.144644\tvalid_1's auc: 0.827223\tvalid_1's binary_logloss: 0.152163\n",
            "[11]\ttraining's auc: 0.85\ttraining's binary_logloss: 0.143567\tvalid_1's auc: 0.827707\tvalid_1's binary_logloss: 0.151244\n",
            "[12]\ttraining's auc: 0.850512\ttraining's binary_logloss: 0.142565\tvalid_1's auc: 0.827813\tvalid_1's binary_logloss: 0.150429\n",
            "[13]\ttraining's auc: 0.850593\ttraining's binary_logloss: 0.141625\tvalid_1's auc: 0.828506\tvalid_1's binary_logloss: 0.149618\n",
            "[14]\ttraining's auc: 0.851729\ttraining's binary_logloss: 0.140713\tvalid_1's auc: 0.828961\tvalid_1's binary_logloss: 0.14887\n",
            "[15]\ttraining's auc: 0.852836\ttraining's binary_logloss: 0.139844\tvalid_1's auc: 0.82911\tvalid_1's binary_logloss: 0.148178\n",
            "[16]\ttraining's auc: 0.853585\ttraining's binary_logloss: 0.139004\tvalid_1's auc: 0.829432\tvalid_1's binary_logloss: 0.147492\n",
            "[17]\ttraining's auc: 0.85428\ttraining's binary_logloss: 0.13825\tvalid_1's auc: 0.829748\tvalid_1's binary_logloss: 0.146893\n",
            "[18]\ttraining's auc: 0.854281\ttraining's binary_logloss: 0.1375\tvalid_1's auc: 0.830027\tvalid_1's binary_logloss: 0.14634\n",
            "[19]\ttraining's auc: 0.855211\ttraining's binary_logloss: 0.136808\tvalid_1's auc: 0.830389\tvalid_1's binary_logloss: 0.145816\n",
            "[20]\ttraining's auc: 0.856063\ttraining's binary_logloss: 0.136148\tvalid_1's auc: 0.830939\tvalid_1's binary_logloss: 0.145313\n",
            "[21]\ttraining's auc: 0.856758\ttraining's binary_logloss: 0.135498\tvalid_1's auc: 0.831224\tvalid_1's binary_logloss: 0.144826\n",
            "[22]\ttraining's auc: 0.85764\ttraining's binary_logloss: 0.134913\tvalid_1's auc: 0.83137\tvalid_1's binary_logloss: 0.144377\n",
            "[23]\ttraining's auc: 0.858277\ttraining's binary_logloss: 0.134337\tvalid_1's auc: 0.831558\tvalid_1's binary_logloss: 0.143954\n",
            "[24]\ttraining's auc: 0.858961\ttraining's binary_logloss: 0.13377\tvalid_1's auc: 0.83121\tvalid_1's binary_logloss: 0.143557\n",
            "[25]\ttraining's auc: 0.859767\ttraining's binary_logloss: 0.133241\tvalid_1's auc: 0.831597\tvalid_1's binary_logloss: 0.143175\n",
            "[26]\ttraining's auc: 0.860899\ttraining's binary_logloss: 0.132725\tvalid_1's auc: 0.831822\tvalid_1's binary_logloss: 0.142837\n",
            "[27]\ttraining's auc: 0.862213\ttraining's binary_logloss: 0.132241\tvalid_1's auc: 0.832028\tvalid_1's binary_logloss: 0.142499\n",
            "[28]\ttraining's auc: 0.86285\ttraining's binary_logloss: 0.131772\tvalid_1's auc: 0.832202\tvalid_1's binary_logloss: 0.142174\n",
            "[29]\ttraining's auc: 0.863602\ttraining's binary_logloss: 0.131331\tvalid_1's auc: 0.832146\tvalid_1's binary_logloss: 0.141892\n",
            "[30]\ttraining's auc: 0.865153\ttraining's binary_logloss: 0.130878\tvalid_1's auc: 0.832669\tvalid_1's binary_logloss: 0.141579\n",
            "[31]\ttraining's auc: 0.866009\ttraining's binary_logloss: 0.130463\tvalid_1's auc: 0.83267\tvalid_1's binary_logloss: 0.141321\n",
            "[32]\ttraining's auc: 0.866304\ttraining's binary_logloss: 0.130063\tvalid_1's auc: 0.832525\tvalid_1's binary_logloss: 0.141082\n",
            "[33]\ttraining's auc: 0.867393\ttraining's binary_logloss: 0.129671\tvalid_1's auc: 0.83269\tvalid_1's binary_logloss: 0.140839\n",
            "[34]\ttraining's auc: 0.868537\ttraining's binary_logloss: 0.129277\tvalid_1's auc: 0.832781\tvalid_1's binary_logloss: 0.140628\n",
            "[35]\ttraining's auc: 0.869302\ttraining's binary_logloss: 0.12891\tvalid_1's auc: 0.832908\tvalid_1's binary_logloss: 0.140428\n",
            "[36]\ttraining's auc: 0.869879\ttraining's binary_logloss: 0.128547\tvalid_1's auc: 0.832591\tvalid_1's binary_logloss: 0.140263\n",
            "[37]\ttraining's auc: 0.871516\ttraining's binary_logloss: 0.128162\tvalid_1's auc: 0.833908\tvalid_1's binary_logloss: 0.14008\n",
            "[38]\ttraining's auc: 0.871807\ttraining's binary_logloss: 0.127825\tvalid_1's auc: 0.834325\tvalid_1's binary_logloss: 0.139895\n",
            "[39]\ttraining's auc: 0.872673\ttraining's binary_logloss: 0.127506\tvalid_1's auc: 0.834792\tvalid_1's binary_logloss: 0.139693\n",
            "[40]\ttraining's auc: 0.873298\ttraining's binary_logloss: 0.127178\tvalid_1's auc: 0.834887\tvalid_1's binary_logloss: 0.139521\n",
            "[41]\ttraining's auc: 0.873995\ttraining's binary_logloss: 0.126854\tvalid_1's auc: 0.834848\tvalid_1's binary_logloss: 0.139364\n",
            "[42]\ttraining's auc: 0.87481\ttraining's binary_logloss: 0.126548\tvalid_1's auc: 0.835665\tvalid_1's binary_logloss: 0.139169\n",
            "[43]\ttraining's auc: 0.875165\ttraining's binary_logloss: 0.12625\tvalid_1's auc: 0.83595\tvalid_1's binary_logloss: 0.139002\n",
            "[44]\ttraining's auc: 0.87576\ttraining's binary_logloss: 0.125969\tvalid_1's auc: 0.83596\tvalid_1's binary_logloss: 0.138885\n",
            "[45]\ttraining's auc: 0.876161\ttraining's binary_logloss: 0.125677\tvalid_1's auc: 0.836082\tvalid_1's binary_logloss: 0.138765\n",
            "[46]\ttraining's auc: 0.876608\ttraining's binary_logloss: 0.125392\tvalid_1's auc: 0.836045\tvalid_1's binary_logloss: 0.138661\n",
            "[47]\ttraining's auc: 0.877093\ttraining's binary_logloss: 0.125128\tvalid_1's auc: 0.835927\tvalid_1's binary_logloss: 0.138546\n",
            "[48]\ttraining's auc: 0.878382\ttraining's binary_logloss: 0.124853\tvalid_1's auc: 0.835968\tvalid_1's binary_logloss: 0.138432\n",
            "[49]\ttraining's auc: 0.87968\ttraining's binary_logloss: 0.124574\tvalid_1's auc: 0.835861\tvalid_1's binary_logloss: 0.138309\n",
            "[50]\ttraining's auc: 0.88021\ttraining's binary_logloss: 0.124301\tvalid_1's auc: 0.836038\tvalid_1's binary_logloss: 0.138204\n",
            "[51]\ttraining's auc: 0.880587\ttraining's binary_logloss: 0.124064\tvalid_1's auc: 0.836406\tvalid_1's binary_logloss: 0.138064\n",
            "[52]\ttraining's auc: 0.881259\ttraining's binary_logloss: 0.123826\tvalid_1's auc: 0.836739\tvalid_1's binary_logloss: 0.137957\n",
            "[53]\ttraining's auc: 0.881563\ttraining's binary_logloss: 0.123594\tvalid_1's auc: 0.836962\tvalid_1's binary_logloss: 0.137875\n",
            "[54]\ttraining's auc: 0.882303\ttraining's binary_logloss: 0.123319\tvalid_1's auc: 0.836733\tvalid_1's binary_logloss: 0.137822\n",
            "[55]\ttraining's auc: 0.882503\ttraining's binary_logloss: 0.123111\tvalid_1's auc: 0.836837\tvalid_1's binary_logloss: 0.137724\n",
            "[56]\ttraining's auc: 0.88347\ttraining's binary_logloss: 0.122857\tvalid_1's auc: 0.836675\tvalid_1's binary_logloss: 0.137639\n",
            "[57]\ttraining's auc: 0.883843\ttraining's binary_logloss: 0.12266\tvalid_1's auc: 0.836724\tvalid_1's binary_logloss: 0.137556\n",
            "[58]\ttraining's auc: 0.88444\ttraining's binary_logloss: 0.122436\tvalid_1's auc: 0.83663\tvalid_1's binary_logloss: 0.137492\n",
            "[59]\ttraining's auc: 0.885031\ttraining's binary_logloss: 0.122193\tvalid_1's auc: 0.836412\tvalid_1's binary_logloss: 0.137458\n",
            "[60]\ttraining's auc: 0.885657\ttraining's binary_logloss: 0.121958\tvalid_1's auc: 0.836387\tvalid_1's binary_logloss: 0.137413\n",
            "[61]\ttraining's auc: 0.886487\ttraining's binary_logloss: 0.121729\tvalid_1's auc: 0.836374\tvalid_1's binary_logloss: 0.137361\n",
            "[62]\ttraining's auc: 0.886982\ttraining's binary_logloss: 0.121525\tvalid_1's auc: 0.836372\tvalid_1's binary_logloss: 0.137302\n",
            "[63]\ttraining's auc: 0.887519\ttraining's binary_logloss: 0.121326\tvalid_1's auc: 0.836583\tvalid_1's binary_logloss: 0.137238\n",
            "[64]\ttraining's auc: 0.888062\ttraining's binary_logloss: 0.121118\tvalid_1's auc: 0.836667\tvalid_1's binary_logloss: 0.137162\n",
            "[65]\ttraining's auc: 0.888567\ttraining's binary_logloss: 0.120923\tvalid_1's auc: 0.836751\tvalid_1's binary_logloss: 0.137124\n",
            "[66]\ttraining's auc: 0.889068\ttraining's binary_logloss: 0.120728\tvalid_1's auc: 0.836733\tvalid_1's binary_logloss: 0.137088\n",
            "[67]\ttraining's auc: 0.889445\ttraining's binary_logloss: 0.120543\tvalid_1's auc: 0.836889\tvalid_1's binary_logloss: 0.137021\n",
            "[68]\ttraining's auc: 0.890012\ttraining's binary_logloss: 0.120334\tvalid_1's auc: 0.836776\tvalid_1's binary_logloss: 0.137\n",
            "[69]\ttraining's auc: 0.890404\ttraining's binary_logloss: 0.120164\tvalid_1's auc: 0.836975\tvalid_1's binary_logloss: 0.136944\n",
            "[70]\ttraining's auc: 0.890753\ttraining's binary_logloss: 0.119993\tvalid_1's auc: 0.83687\tvalid_1's binary_logloss: 0.136918\n",
            "[71]\ttraining's auc: 0.891125\ttraining's binary_logloss: 0.119817\tvalid_1's auc: 0.836869\tvalid_1's binary_logloss: 0.13688\n",
            "[72]\ttraining's auc: 0.891454\ttraining's binary_logloss: 0.119667\tvalid_1's auc: 0.836768\tvalid_1's binary_logloss: 0.136852\n",
            "[73]\ttraining's auc: 0.891895\ttraining's binary_logloss: 0.119476\tvalid_1's auc: 0.836711\tvalid_1's binary_logloss: 0.136819\n",
            "[74]\ttraining's auc: 0.892548\ttraining's binary_logloss: 0.119271\tvalid_1's auc: 0.836664\tvalid_1's binary_logloss: 0.136792\n",
            "[75]\ttraining's auc: 0.892927\ttraining's binary_logloss: 0.119122\tvalid_1's auc: 0.836477\tvalid_1's binary_logloss: 0.136782\n",
            "[76]\ttraining's auc: 0.893182\ttraining's binary_logloss: 0.11898\tvalid_1's auc: 0.836542\tvalid_1's binary_logloss: 0.136745\n",
            "[77]\ttraining's auc: 0.893741\ttraining's binary_logloss: 0.118816\tvalid_1's auc: 0.836466\tvalid_1's binary_logloss: 0.136719\n",
            "[78]\ttraining's auc: 0.894383\ttraining's binary_logloss: 0.11864\tvalid_1's auc: 0.836412\tvalid_1's binary_logloss: 0.136698\n",
            "[79]\ttraining's auc: 0.894732\ttraining's binary_logloss: 0.118481\tvalid_1's auc: 0.836432\tvalid_1's binary_logloss: 0.136683\n",
            "[80]\ttraining's auc: 0.895148\ttraining's binary_logloss: 0.118302\tvalid_1's auc: 0.836484\tvalid_1's binary_logloss: 0.136658\n",
            "[81]\ttraining's auc: 0.895648\ttraining's binary_logloss: 0.118127\tvalid_1's auc: 0.836484\tvalid_1's binary_logloss: 0.136639\n",
            "[82]\ttraining's auc: 0.895908\ttraining's binary_logloss: 0.117987\tvalid_1's auc: 0.836497\tvalid_1's binary_logloss: 0.13662\n",
            "[83]\ttraining's auc: 0.896354\ttraining's binary_logloss: 0.117812\tvalid_1's auc: 0.836555\tvalid_1's binary_logloss: 0.136605\n",
            "[84]\ttraining's auc: 0.896746\ttraining's binary_logloss: 0.117664\tvalid_1's auc: 0.836514\tvalid_1's binary_logloss: 0.136572\n",
            "[85]\ttraining's auc: 0.897217\ttraining's binary_logloss: 0.117517\tvalid_1's auc: 0.836453\tvalid_1's binary_logloss: 0.136556\n",
            "[86]\ttraining's auc: 0.897584\ttraining's binary_logloss: 0.117382\tvalid_1's auc: 0.836437\tvalid_1's binary_logloss: 0.136547\n",
            "[87]\ttraining's auc: 0.897996\ttraining's binary_logloss: 0.117233\tvalid_1's auc: 0.836531\tvalid_1's binary_logloss: 0.136525\n",
            "[88]\ttraining's auc: 0.898311\ttraining's binary_logloss: 0.117085\tvalid_1's auc: 0.836582\tvalid_1's binary_logloss: 0.136494\n",
            "[89]\ttraining's auc: 0.898682\ttraining's binary_logloss: 0.11695\tvalid_1's auc: 0.836746\tvalid_1's binary_logloss: 0.13648\n",
            "[90]\ttraining's auc: 0.89892\ttraining's binary_logloss: 0.116817\tvalid_1's auc: 0.836574\tvalid_1's binary_logloss: 0.136487\n",
            "[91]\ttraining's auc: 0.899288\ttraining's binary_logloss: 0.11666\tvalid_1's auc: 0.836489\tvalid_1's binary_logloss: 0.13646\n",
            "[92]\ttraining's auc: 0.89949\ttraining's binary_logloss: 0.116527\tvalid_1's auc: 0.836354\tvalid_1's binary_logloss: 0.136451\n",
            "[93]\ttraining's auc: 0.899833\ttraining's binary_logloss: 0.116401\tvalid_1's auc: 0.836422\tvalid_1's binary_logloss: 0.136427\n",
            "[94]\ttraining's auc: 0.900165\ttraining's binary_logloss: 0.116265\tvalid_1's auc: 0.836415\tvalid_1's binary_logloss: 0.13641\n",
            "[95]\ttraining's auc: 0.900529\ttraining's binary_logloss: 0.116113\tvalid_1's auc: 0.836486\tvalid_1's binary_logloss: 0.136386\n",
            "[96]\ttraining's auc: 0.900975\ttraining's binary_logloss: 0.115969\tvalid_1's auc: 0.836614\tvalid_1's binary_logloss: 0.13636\n",
            "[97]\ttraining's auc: 0.901344\ttraining's binary_logloss: 0.115848\tvalid_1's auc: 0.836545\tvalid_1's binary_logloss: 0.136365\n",
            "[98]\ttraining's auc: 0.901618\ttraining's binary_logloss: 0.115723\tvalid_1's auc: 0.836407\tvalid_1's binary_logloss: 0.136374\n",
            "[99]\ttraining's auc: 0.902078\ttraining's binary_logloss: 0.115551\tvalid_1's auc: 0.83623\tvalid_1's binary_logloss: 0.136361\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 78%|███████▊  | 39/50 [19:33<05:59, 32.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.151656\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.154871\n",
            "[2]\ttraining's auc: 0.835699\ttraining's binary_logloss: 0.145296\tvalid_1's auc: 0.810608\tvalid_1's binary_logloss: 0.14988\n",
            "[3]\ttraining's auc: 0.844254\ttraining's binary_logloss: 0.140933\tvalid_1's auc: 0.815691\tvalid_1's binary_logloss: 0.146712\n",
            "[4]\ttraining's auc: 0.849754\ttraining's binary_logloss: 0.137508\tvalid_1's auc: 0.817009\tvalid_1's binary_logloss: 0.14452\n",
            "[5]\ttraining's auc: 0.853607\ttraining's binary_logloss: 0.134753\tvalid_1's auc: 0.819912\tvalid_1's binary_logloss: 0.142812\n",
            "[6]\ttraining's auc: 0.858997\ttraining's binary_logloss: 0.132506\tvalid_1's auc: 0.821354\tvalid_1's binary_logloss: 0.141589\n",
            "[7]\ttraining's auc: 0.863532\ttraining's binary_logloss: 0.130494\tvalid_1's auc: 0.824651\tvalid_1's binary_logloss: 0.140301\n",
            "[8]\ttraining's auc: 0.867277\ttraining's binary_logloss: 0.128883\tvalid_1's auc: 0.824643\tvalid_1's binary_logloss: 0.139569\n",
            "[9]\ttraining's auc: 0.869644\ttraining's binary_logloss: 0.127415\tvalid_1's auc: 0.825215\tvalid_1's binary_logloss: 0.138881\n",
            "[10]\ttraining's auc: 0.872441\ttraining's binary_logloss: 0.126193\tvalid_1's auc: 0.825002\tvalid_1's binary_logloss: 0.138482\n",
            "[11]\ttraining's auc: 0.875994\ttraining's binary_logloss: 0.124979\tvalid_1's auc: 0.824834\tvalid_1's binary_logloss: 0.138087\n",
            "[12]\ttraining's auc: 0.878686\ttraining's binary_logloss: 0.123941\tvalid_1's auc: 0.825275\tvalid_1's binary_logloss: 0.137827\n",
            "[13]\ttraining's auc: 0.882726\ttraining's binary_logloss: 0.122793\tvalid_1's auc: 0.825064\tvalid_1's binary_logloss: 0.137575\n",
            "[14]\ttraining's auc: 0.885407\ttraining's binary_logloss: 0.12184\tvalid_1's auc: 0.825444\tvalid_1's binary_logloss: 0.137331\n",
            "[15]\ttraining's auc: 0.887401\ttraining's binary_logloss: 0.120913\tvalid_1's auc: 0.825088\tvalid_1's binary_logloss: 0.137291\n",
            "[16]\ttraining's auc: 0.889806\ttraining's binary_logloss: 0.120023\tvalid_1's auc: 0.826013\tvalid_1's binary_logloss: 0.137036\n",
            "[17]\ttraining's auc: 0.891631\ttraining's binary_logloss: 0.119359\tvalid_1's auc: 0.825937\tvalid_1's binary_logloss: 0.136988\n",
            "[18]\ttraining's auc: 0.892939\ttraining's binary_logloss: 0.11862\tvalid_1's auc: 0.825623\tvalid_1's binary_logloss: 0.136978\n",
            "[19]\ttraining's auc: 0.896349\ttraining's binary_logloss: 0.11777\tvalid_1's auc: 0.827387\tvalid_1's binary_logloss: 0.13667\n",
            "[20]\ttraining's auc: 0.897842\ttraining's binary_logloss: 0.117157\tvalid_1's auc: 0.827728\tvalid_1's binary_logloss: 0.136581\n",
            "[21]\ttraining's auc: 0.900009\ttraining's binary_logloss: 0.116485\tvalid_1's auc: 0.827201\tvalid_1's binary_logloss: 0.136673\n",
            "[22]\ttraining's auc: 0.901161\ttraining's binary_logloss: 0.115874\tvalid_1's auc: 0.827356\tvalid_1's binary_logloss: 0.1366\n",
            "[23]\ttraining's auc: 0.902543\ttraining's binary_logloss: 0.115253\tvalid_1's auc: 0.826883\tvalid_1's binary_logloss: 0.136713\n",
            "[24]\ttraining's auc: 0.903882\ttraining's binary_logloss: 0.114765\tvalid_1's auc: 0.827281\tvalid_1's binary_logloss: 0.136661\n",
            "[25]\ttraining's auc: 0.905211\ttraining's binary_logloss: 0.114193\tvalid_1's auc: 0.827285\tvalid_1's binary_logloss: 0.136648\n",
            "[26]\ttraining's auc: 0.906635\ttraining's binary_logloss: 0.113672\tvalid_1's auc: 0.827373\tvalid_1's binary_logloss: 0.136664\n",
            "[27]\ttraining's auc: 0.907614\ttraining's binary_logloss: 0.113155\tvalid_1's auc: 0.826982\tvalid_1's binary_logloss: 0.136706\n",
            "[28]\ttraining's auc: 0.908711\ttraining's binary_logloss: 0.112676\tvalid_1's auc: 0.827452\tvalid_1's binary_logloss: 0.136618\n",
            "[29]\ttraining's auc: 0.910557\ttraining's binary_logloss: 0.112198\tvalid_1's auc: 0.827165\tvalid_1's binary_logloss: 0.136735\n",
            "[30]\ttraining's auc: 0.911257\ttraining's binary_logloss: 0.111792\tvalid_1's auc: 0.827375\tvalid_1's binary_logloss: 0.136698\n",
            "[31]\ttraining's auc: 0.91206\ttraining's binary_logloss: 0.111376\tvalid_1's auc: 0.827239\tvalid_1's binary_logloss: 0.136783\n",
            "[32]\ttraining's auc: 0.912697\ttraining's binary_logloss: 0.111019\tvalid_1's auc: 0.826869\tvalid_1's binary_logloss: 0.136846\n",
            "[33]\ttraining's auc: 0.913595\ttraining's binary_logloss: 0.11062\tvalid_1's auc: 0.826289\tvalid_1's binary_logloss: 0.136958\n",
            "[34]\ttraining's auc: 0.91431\ttraining's binary_logloss: 0.110304\tvalid_1's auc: 0.826006\tvalid_1's binary_logloss: 0.13703\n",
            "[35]\ttraining's auc: 0.914853\ttraining's binary_logloss: 0.109963\tvalid_1's auc: 0.825852\tvalid_1's binary_logloss: 0.137113\n",
            "[36]\ttraining's auc: 0.916022\ttraining's binary_logloss: 0.109512\tvalid_1's auc: 0.825578\tvalid_1's binary_logloss: 0.137156\n",
            "[37]\ttraining's auc: 0.916609\ttraining's binary_logloss: 0.10916\tvalid_1's auc: 0.825072\tvalid_1's binary_logloss: 0.137267\n",
            "[38]\ttraining's auc: 0.917191\ttraining's binary_logloss: 0.108823\tvalid_1's auc: 0.824694\tvalid_1's binary_logloss: 0.137333\n",
            "[39]\ttraining's auc: 0.917959\ttraining's binary_logloss: 0.108486\tvalid_1's auc: 0.824689\tvalid_1's binary_logloss: 0.137387\n",
            "[40]\ttraining's auc: 0.918558\ttraining's binary_logloss: 0.108143\tvalid_1's auc: 0.824506\tvalid_1's binary_logloss: 0.137482\n",
            "[41]\ttraining's auc: 0.919485\ttraining's binary_logloss: 0.107837\tvalid_1's auc: 0.824459\tvalid_1's binary_logloss: 0.137528\n",
            "[42]\ttraining's auc: 0.920433\ttraining's binary_logloss: 0.107364\tvalid_1's auc: 0.824466\tvalid_1's binary_logloss: 0.137509\n",
            "[43]\ttraining's auc: 0.921422\ttraining's binary_logloss: 0.106991\tvalid_1's auc: 0.824269\tvalid_1's binary_logloss: 0.137591\n",
            "[44]\ttraining's auc: 0.921803\ttraining's binary_logloss: 0.106711\tvalid_1's auc: 0.824425\tvalid_1's binary_logloss: 0.137607\n",
            "[45]\ttraining's auc: 0.922751\ttraining's binary_logloss: 0.106306\tvalid_1's auc: 0.824363\tvalid_1's binary_logloss: 0.137653\n",
            "[46]\ttraining's auc: 0.923071\ttraining's binary_logloss: 0.106085\tvalid_1's auc: 0.823985\tvalid_1's binary_logloss: 0.13773\n",
            "[47]\ttraining's auc: 0.923961\ttraining's binary_logloss: 0.105814\tvalid_1's auc: 0.823678\tvalid_1's binary_logloss: 0.137825\n",
            "[48]\ttraining's auc: 0.924421\ttraining's binary_logloss: 0.105543\tvalid_1's auc: 0.82328\tvalid_1's binary_logloss: 0.137957\n",
            "[49]\ttraining's auc: 0.925623\ttraining's binary_logloss: 0.104984\tvalid_1's auc: 0.823558\tvalid_1's binary_logloss: 0.137917\n",
            "[50]\ttraining's auc: 0.925973\ttraining's binary_logloss: 0.104702\tvalid_1's auc: 0.823357\tvalid_1's binary_logloss: 0.137963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.154106\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.151075\n",
            "[2]\ttraining's auc: 0.832215\ttraining's binary_logloss: 0.147514\tvalid_1's auc: 0.816865\tvalid_1's binary_logloss: 0.146042\n",
            "[3]\ttraining's auc: 0.840788\ttraining's binary_logloss: 0.14308\tvalid_1's auc: 0.820741\tvalid_1's binary_logloss: 0.14274\n",
            "[4]\ttraining's auc: 0.848938\ttraining's binary_logloss: 0.1397\tvalid_1's auc: 0.82699\tvalid_1's binary_logloss: 0.140372\n",
            "[5]\ttraining's auc: 0.852825\ttraining's binary_logloss: 0.136951\tvalid_1's auc: 0.828759\tvalid_1's binary_logloss: 0.138469\n",
            "[6]\ttraining's auc: 0.855155\ttraining's binary_logloss: 0.134727\tvalid_1's auc: 0.828506\tvalid_1's binary_logloss: 0.137279\n",
            "[7]\ttraining's auc: 0.86206\ttraining's binary_logloss: 0.132618\tvalid_1's auc: 0.8296\tvalid_1's binary_logloss: 0.136237\n",
            "[8]\ttraining's auc: 0.866474\ttraining's binary_logloss: 0.130904\tvalid_1's auc: 0.829591\tvalid_1's binary_logloss: 0.135456\n",
            "[9]\ttraining's auc: 0.869794\ttraining's binary_logloss: 0.129413\tvalid_1's auc: 0.830779\tvalid_1's binary_logloss: 0.134842\n",
            "[10]\ttraining's auc: 0.871863\ttraining's binary_logloss: 0.128122\tvalid_1's auc: 0.830571\tvalid_1's binary_logloss: 0.134326\n",
            "[11]\ttraining's auc: 0.873901\ttraining's binary_logloss: 0.126808\tvalid_1's auc: 0.830741\tvalid_1's binary_logloss: 0.133976\n",
            "[12]\ttraining's auc: 0.876788\ttraining's binary_logloss: 0.125649\tvalid_1's auc: 0.83109\tvalid_1's binary_logloss: 0.1336\n",
            "[13]\ttraining's auc: 0.878972\ttraining's binary_logloss: 0.124621\tvalid_1's auc: 0.830651\tvalid_1's binary_logloss: 0.133355\n",
            "[14]\ttraining's auc: 0.881149\ttraining's binary_logloss: 0.12371\tvalid_1's auc: 0.831447\tvalid_1's binary_logloss: 0.133089\n",
            "[15]\ttraining's auc: 0.883055\ttraining's binary_logloss: 0.122753\tvalid_1's auc: 0.831271\tvalid_1's binary_logloss: 0.132895\n",
            "[16]\ttraining's auc: 0.887386\ttraining's binary_logloss: 0.1216\tvalid_1's auc: 0.832138\tvalid_1's binary_logloss: 0.132711\n",
            "[17]\ttraining's auc: 0.889199\ttraining's binary_logloss: 0.120846\tvalid_1's auc: 0.83184\tvalid_1's binary_logloss: 0.132597\n",
            "[18]\ttraining's auc: 0.890961\ttraining's binary_logloss: 0.120169\tvalid_1's auc: 0.83147\tvalid_1's binary_logloss: 0.132548\n",
            "[19]\ttraining's auc: 0.893212\ttraining's binary_logloss: 0.119524\tvalid_1's auc: 0.83164\tvalid_1's binary_logloss: 0.132483\n",
            "[20]\ttraining's auc: 0.894593\ttraining's binary_logloss: 0.118853\tvalid_1's auc: 0.832133\tvalid_1's binary_logloss: 0.132364\n",
            "[21]\ttraining's auc: 0.895831\ttraining's binary_logloss: 0.118272\tvalid_1's auc: 0.832261\tvalid_1's binary_logloss: 0.132291\n",
            "[22]\ttraining's auc: 0.897078\ttraining's binary_logloss: 0.117749\tvalid_1's auc: 0.832183\tvalid_1's binary_logloss: 0.132258\n",
            "[23]\ttraining's auc: 0.898527\ttraining's binary_logloss: 0.117207\tvalid_1's auc: 0.831822\tvalid_1's binary_logloss: 0.132311\n",
            "[24]\ttraining's auc: 0.901123\ttraining's binary_logloss: 0.116593\tvalid_1's auc: 0.831282\tvalid_1's binary_logloss: 0.132338\n",
            "[25]\ttraining's auc: 0.902162\ttraining's binary_logloss: 0.116109\tvalid_1's auc: 0.830958\tvalid_1's binary_logloss: 0.132347\n",
            "[26]\ttraining's auc: 0.903857\ttraining's binary_logloss: 0.11541\tvalid_1's auc: 0.831381\tvalid_1's binary_logloss: 0.132355\n",
            "[27]\ttraining's auc: 0.905171\ttraining's binary_logloss: 0.114907\tvalid_1's auc: 0.831318\tvalid_1's binary_logloss: 0.132383\n",
            "[28]\ttraining's auc: 0.90631\ttraining's binary_logloss: 0.114475\tvalid_1's auc: 0.831043\tvalid_1's binary_logloss: 0.132411\n",
            "[29]\ttraining's auc: 0.907792\ttraining's binary_logloss: 0.11387\tvalid_1's auc: 0.831308\tvalid_1's binary_logloss: 0.132386\n",
            "[30]\ttraining's auc: 0.908998\ttraining's binary_logloss: 0.11341\tvalid_1's auc: 0.83105\tvalid_1's binary_logloss: 0.132444\n",
            "[31]\ttraining's auc: 0.909878\ttraining's binary_logloss: 0.112919\tvalid_1's auc: 0.830778\tvalid_1's binary_logloss: 0.13249\n",
            "[32]\ttraining's auc: 0.911507\ttraining's binary_logloss: 0.112327\tvalid_1's auc: 0.830503\tvalid_1's binary_logloss: 0.132545\n",
            "[33]\ttraining's auc: 0.912368\ttraining's binary_logloss: 0.111887\tvalid_1's auc: 0.830736\tvalid_1's binary_logloss: 0.132487\n",
            "[34]\ttraining's auc: 0.913306\ttraining's binary_logloss: 0.111406\tvalid_1's auc: 0.831254\tvalid_1's binary_logloss: 0.132434\n",
            "[35]\ttraining's auc: 0.91377\ttraining's binary_logloss: 0.111097\tvalid_1's auc: 0.831091\tvalid_1's binary_logloss: 0.132466\n",
            "[36]\ttraining's auc: 0.914786\ttraining's binary_logloss: 0.110624\tvalid_1's auc: 0.830882\tvalid_1's binary_logloss: 0.132525\n",
            "[37]\ttraining's auc: 0.916247\ttraining's binary_logloss: 0.110075\tvalid_1's auc: 0.830877\tvalid_1's binary_logloss: 0.132576\n",
            "[38]\ttraining's auc: 0.91695\ttraining's binary_logloss: 0.109675\tvalid_1's auc: 0.830221\tvalid_1's binary_logloss: 0.132708\n",
            "[39]\ttraining's auc: 0.917674\ttraining's binary_logloss: 0.109264\tvalid_1's auc: 0.830304\tvalid_1's binary_logloss: 0.132718\n",
            "[40]\ttraining's auc: 0.918538\ttraining's binary_logloss: 0.108862\tvalid_1's auc: 0.830131\tvalid_1's binary_logloss: 0.132767\n",
            "[41]\ttraining's auc: 0.919091\ttraining's binary_logloss: 0.108549\tvalid_1's auc: 0.830156\tvalid_1's binary_logloss: 0.132714\n",
            "[42]\ttraining's auc: 0.920124\ttraining's binary_logloss: 0.108146\tvalid_1's auc: 0.82987\tvalid_1's binary_logloss: 0.132733\n",
            "[43]\ttraining's auc: 0.920708\ttraining's binary_logloss: 0.107863\tvalid_1's auc: 0.829904\tvalid_1's binary_logloss: 0.132723\n",
            "[44]\ttraining's auc: 0.921283\ttraining's binary_logloss: 0.107574\tvalid_1's auc: 0.829528\tvalid_1's binary_logloss: 0.132801\n",
            "[45]\ttraining's auc: 0.921645\ttraining's binary_logloss: 0.10731\tvalid_1's auc: 0.82944\tvalid_1's binary_logloss: 0.132836\n",
            "[46]\ttraining's auc: 0.921924\ttraining's binary_logloss: 0.107085\tvalid_1's auc: 0.829254\tvalid_1's binary_logloss: 0.132871\n",
            "[47]\ttraining's auc: 0.92271\ttraining's binary_logloss: 0.106714\tvalid_1's auc: 0.82909\tvalid_1's binary_logloss: 0.132899\n",
            "[48]\ttraining's auc: 0.923349\ttraining's binary_logloss: 0.106395\tvalid_1's auc: 0.82878\tvalid_1's binary_logloss: 0.132977\n",
            "[49]\ttraining's auc: 0.923892\ttraining's binary_logloss: 0.10607\tvalid_1's auc: 0.828881\tvalid_1's binary_logloss: 0.132978\n",
            "[50]\ttraining's auc: 0.924213\ttraining's binary_logloss: 0.105856\tvalid_1's auc: 0.829329\tvalid_1's binary_logloss: 0.132886\n",
            "[51]\ttraining's auc: 0.925173\ttraining's binary_logloss: 0.105426\tvalid_1's auc: 0.829042\tvalid_1's binary_logloss: 0.132976\n",
            " 78%|███████▊  | 39/50 [19:47<05:59, 32.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.151\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.157703\n",
            "[2]\ttraining's auc: 0.835986\ttraining's binary_logloss: 0.144798\tvalid_1's auc: 0.817533\tvalid_1's binary_logloss: 0.152114\n",
            "[3]\ttraining's auc: 0.842562\ttraining's binary_logloss: 0.140505\tvalid_1's auc: 0.822013\tvalid_1's binary_logloss: 0.148587\n",
            "[4]\ttraining's auc: 0.848211\ttraining's binary_logloss: 0.136939\tvalid_1's auc: 0.825049\tvalid_1's binary_logloss: 0.146071\n",
            "[5]\ttraining's auc: 0.85213\ttraining's binary_logloss: 0.134219\tvalid_1's auc: 0.827154\tvalid_1's binary_logloss: 0.144238\n",
            "[6]\ttraining's auc: 0.856226\ttraining's binary_logloss: 0.132009\tvalid_1's auc: 0.82799\tvalid_1's binary_logloss: 0.142687\n",
            "[7]\ttraining's auc: 0.861542\ttraining's binary_logloss: 0.130089\tvalid_1's auc: 0.829261\tvalid_1's binary_logloss: 0.141439\n",
            "[8]\ttraining's auc: 0.865459\ttraining's binary_logloss: 0.12848\tvalid_1's auc: 0.829147\tvalid_1's binary_logloss: 0.140565\n",
            "[9]\ttraining's auc: 0.86931\ttraining's binary_logloss: 0.127095\tvalid_1's auc: 0.83214\tvalid_1's binary_logloss: 0.139762\n",
            "[10]\ttraining's auc: 0.872873\ttraining's binary_logloss: 0.125733\tvalid_1's auc: 0.833397\tvalid_1's binary_logloss: 0.139154\n",
            "[11]\ttraining's auc: 0.876688\ttraining's binary_logloss: 0.124425\tvalid_1's auc: 0.833715\tvalid_1's binary_logloss: 0.138608\n",
            "[12]\ttraining's auc: 0.879415\ttraining's binary_logloss: 0.123274\tvalid_1's auc: 0.833446\tvalid_1's binary_logloss: 0.138338\n",
            "[13]\ttraining's auc: 0.880546\ttraining's binary_logloss: 0.122328\tvalid_1's auc: 0.833549\tvalid_1's binary_logloss: 0.138068\n",
            "[14]\ttraining's auc: 0.883881\ttraining's binary_logloss: 0.121381\tvalid_1's auc: 0.832883\tvalid_1's binary_logloss: 0.137896\n",
            "[15]\ttraining's auc: 0.885221\ttraining's binary_logloss: 0.120557\tvalid_1's auc: 0.834005\tvalid_1's binary_logloss: 0.137558\n",
            "[16]\ttraining's auc: 0.886865\ttraining's binary_logloss: 0.119774\tvalid_1's auc: 0.83366\tvalid_1's binary_logloss: 0.137401\n",
            "[17]\ttraining's auc: 0.888237\ttraining's binary_logloss: 0.119105\tvalid_1's auc: 0.834196\tvalid_1's binary_logloss: 0.137234\n",
            "[18]\ttraining's auc: 0.889774\ttraining's binary_logloss: 0.118398\tvalid_1's auc: 0.833834\tvalid_1's binary_logloss: 0.137222\n",
            "[19]\ttraining's auc: 0.892014\ttraining's binary_logloss: 0.117769\tvalid_1's auc: 0.833681\tvalid_1's binary_logloss: 0.137217\n",
            "[20]\ttraining's auc: 0.89396\ttraining's binary_logloss: 0.117079\tvalid_1's auc: 0.833504\tvalid_1's binary_logloss: 0.137219\n",
            "[21]\ttraining's auc: 0.895969\ttraining's binary_logloss: 0.116382\tvalid_1's auc: 0.83358\tvalid_1's binary_logloss: 0.137172\n",
            "[22]\ttraining's auc: 0.897448\ttraining's binary_logloss: 0.115868\tvalid_1's auc: 0.833349\tvalid_1's binary_logloss: 0.137139\n",
            "[23]\ttraining's auc: 0.899187\ttraining's binary_logloss: 0.115269\tvalid_1's auc: 0.833544\tvalid_1's binary_logloss: 0.137082\n",
            "[24]\ttraining's auc: 0.900831\ttraining's binary_logloss: 0.114749\tvalid_1's auc: 0.833496\tvalid_1's binary_logloss: 0.137089\n",
            "[25]\ttraining's auc: 0.902779\ttraining's binary_logloss: 0.114106\tvalid_1's auc: 0.833072\tvalid_1's binary_logloss: 0.137132\n",
            "[26]\ttraining's auc: 0.904021\ttraining's binary_logloss: 0.113473\tvalid_1's auc: 0.833186\tvalid_1's binary_logloss: 0.137161\n",
            "[27]\ttraining's auc: 0.90524\ttraining's binary_logloss: 0.112908\tvalid_1's auc: 0.833332\tvalid_1's binary_logloss: 0.13716\n",
            "[28]\ttraining's auc: 0.906685\ttraining's binary_logloss: 0.112364\tvalid_1's auc: 0.833247\tvalid_1's binary_logloss: 0.137182\n",
            "[29]\ttraining's auc: 0.90785\ttraining's binary_logloss: 0.11185\tvalid_1's auc: 0.832952\tvalid_1's binary_logloss: 0.137247\n",
            "[30]\ttraining's auc: 0.908988\ttraining's binary_logloss: 0.111383\tvalid_1's auc: 0.83225\tvalid_1's binary_logloss: 0.137393\n",
            "[31]\ttraining's auc: 0.910422\ttraining's binary_logloss: 0.110906\tvalid_1's auc: 0.832834\tvalid_1's binary_logloss: 0.137319\n",
            "[32]\ttraining's auc: 0.91093\ttraining's binary_logloss: 0.110567\tvalid_1's auc: 0.832804\tvalid_1's binary_logloss: 0.13734\n",
            "[33]\ttraining's auc: 0.911548\ttraining's binary_logloss: 0.110188\tvalid_1's auc: 0.833064\tvalid_1's binary_logloss: 0.137322\n",
            "[34]\ttraining's auc: 0.912311\ttraining's binary_logloss: 0.109855\tvalid_1's auc: 0.833003\tvalid_1's binary_logloss: 0.137385\n",
            "[35]\ttraining's auc: 0.913675\ttraining's binary_logloss: 0.109333\tvalid_1's auc: 0.832582\tvalid_1's binary_logloss: 0.137526\n",
            "[36]\ttraining's auc: 0.914917\ttraining's binary_logloss: 0.108856\tvalid_1's auc: 0.832415\tvalid_1's binary_logloss: 0.137587\n",
            "[37]\ttraining's auc: 0.91562\ttraining's binary_logloss: 0.108495\tvalid_1's auc: 0.832356\tvalid_1's binary_logloss: 0.137589\n",
            "[38]\ttraining's auc: 0.916743\ttraining's binary_logloss: 0.108022\tvalid_1's auc: 0.832176\tvalid_1's binary_logloss: 0.137654\n",
            "[39]\ttraining's auc: 0.918136\ttraining's binary_logloss: 0.107527\tvalid_1's auc: 0.831654\tvalid_1's binary_logloss: 0.137851\n",
            "[40]\ttraining's auc: 0.91856\ttraining's binary_logloss: 0.107204\tvalid_1's auc: 0.831694\tvalid_1's binary_logloss: 0.137858\n",
            "[41]\ttraining's auc: 0.919225\ttraining's binary_logloss: 0.106812\tvalid_1's auc: 0.830996\tvalid_1's binary_logloss: 0.138051\n",
            "[42]\ttraining's auc: 0.919732\ttraining's binary_logloss: 0.106433\tvalid_1's auc: 0.830823\tvalid_1's binary_logloss: 0.138104\n",
            "[43]\ttraining's auc: 0.920301\ttraining's binary_logloss: 0.106125\tvalid_1's auc: 0.830982\tvalid_1's binary_logloss: 0.138119\n",
            "[44]\ttraining's auc: 0.921074\ttraining's binary_logloss: 0.105724\tvalid_1's auc: 0.830849\tvalid_1's binary_logloss: 0.138178\n",
            "[45]\ttraining's auc: 0.921485\ttraining's binary_logloss: 0.10547\tvalid_1's auc: 0.830587\tvalid_1's binary_logloss: 0.138232\n",
            "[46]\ttraining's auc: 0.922223\ttraining's binary_logloss: 0.10511\tvalid_1's auc: 0.830095\tvalid_1's binary_logloss: 0.138368\n",
            "[47]\ttraining's auc: 0.922666\ttraining's binary_logloss: 0.104827\tvalid_1's auc: 0.829827\tvalid_1's binary_logloss: 0.138446\n",
            " 80%|████████  | 40/50 [19:54<04:53, 29.37s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.159309\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.161066\n",
            "[2]\ttraining's auc: 0.832577\ttraining's binary_logloss: 0.155348\tvalid_1's auc: 0.805536\tvalid_1's binary_logloss: 0.158045\n",
            "[3]\ttraining's auc: 0.833816\ttraining's binary_logloss: 0.152173\tvalid_1's auc: 0.8068\tvalid_1's binary_logloss: 0.155558\n",
            "[4]\ttraining's auc: 0.839631\ttraining's binary_logloss: 0.149511\tvalid_1's auc: 0.813082\tvalid_1's binary_logloss: 0.153333\n",
            "[5]\ttraining's auc: 0.844463\ttraining's binary_logloss: 0.147216\tvalid_1's auc: 0.813937\tvalid_1's binary_logloss: 0.151592\n",
            "[6]\ttraining's auc: 0.847206\ttraining's binary_logloss: 0.145172\tvalid_1's auc: 0.816337\tvalid_1's binary_logloss: 0.150099\n",
            "[7]\ttraining's auc: 0.849649\ttraining's binary_logloss: 0.143333\tvalid_1's auc: 0.818186\tvalid_1's binary_logloss: 0.148708\n",
            "[8]\ttraining's auc: 0.851089\ttraining's binary_logloss: 0.141677\tvalid_1's auc: 0.819413\tvalid_1's binary_logloss: 0.147548\n",
            "[9]\ttraining's auc: 0.85214\ttraining's binary_logloss: 0.140215\tvalid_1's auc: 0.821015\tvalid_1's binary_logloss: 0.146435\n",
            "[10]\ttraining's auc: 0.853748\ttraining's binary_logloss: 0.138865\tvalid_1's auc: 0.821528\tvalid_1's binary_logloss: 0.145574\n",
            "[11]\ttraining's auc: 0.854964\ttraining's binary_logloss: 0.1376\tvalid_1's auc: 0.82173\tvalid_1's binary_logloss: 0.144684\n",
            "[12]\ttraining's auc: 0.857267\ttraining's binary_logloss: 0.136481\tvalid_1's auc: 0.823099\tvalid_1's binary_logloss: 0.143876\n",
            "[13]\ttraining's auc: 0.857997\ttraining's binary_logloss: 0.135429\tvalid_1's auc: 0.822858\tvalid_1's binary_logloss: 0.143261\n",
            "[14]\ttraining's auc: 0.860327\ttraining's binary_logloss: 0.134503\tvalid_1's auc: 0.823317\tvalid_1's binary_logloss: 0.142662\n",
            "[15]\ttraining's auc: 0.861518\ttraining's binary_logloss: 0.133552\tvalid_1's auc: 0.823607\tvalid_1's binary_logloss: 0.142049\n",
            "[16]\ttraining's auc: 0.863813\ttraining's binary_logloss: 0.132673\tvalid_1's auc: 0.824417\tvalid_1's binary_logloss: 0.14151\n",
            "[17]\ttraining's auc: 0.865698\ttraining's binary_logloss: 0.131894\tvalid_1's auc: 0.824974\tvalid_1's binary_logloss: 0.141034\n",
            "[18]\ttraining's auc: 0.866733\ttraining's binary_logloss: 0.131175\tvalid_1's auc: 0.825424\tvalid_1's binary_logloss: 0.140627\n",
            "[19]\ttraining's auc: 0.867782\ttraining's binary_logloss: 0.130511\tvalid_1's auc: 0.825347\tvalid_1's binary_logloss: 0.140272\n",
            "[20]\ttraining's auc: 0.868429\ttraining's binary_logloss: 0.129827\tvalid_1's auc: 0.826414\tvalid_1's binary_logloss: 0.139859\n",
            "[21]\ttraining's auc: 0.870042\ttraining's binary_logloss: 0.129208\tvalid_1's auc: 0.826721\tvalid_1's binary_logloss: 0.139525\n",
            "[22]\ttraining's auc: 0.870822\ttraining's binary_logloss: 0.128671\tvalid_1's auc: 0.826791\tvalid_1's binary_logloss: 0.139231\n",
            "[23]\ttraining's auc: 0.872138\ttraining's binary_logloss: 0.12806\tvalid_1's auc: 0.827175\tvalid_1's binary_logloss: 0.138934\n",
            "[24]\ttraining's auc: 0.873229\ttraining's binary_logloss: 0.127482\tvalid_1's auc: 0.827441\tvalid_1's binary_logloss: 0.138698\n",
            "[25]\ttraining's auc: 0.874214\ttraining's binary_logloss: 0.126985\tvalid_1's auc: 0.827216\tvalid_1's binary_logloss: 0.138523\n",
            "[26]\ttraining's auc: 0.874974\ttraining's binary_logloss: 0.126498\tvalid_1's auc: 0.827357\tvalid_1's binary_logloss: 0.138299\n",
            "[27]\ttraining's auc: 0.876028\ttraining's binary_logloss: 0.126022\tvalid_1's auc: 0.82773\tvalid_1's binary_logloss: 0.138101\n",
            "[28]\ttraining's auc: 0.876759\ttraining's binary_logloss: 0.125566\tvalid_1's auc: 0.827566\tvalid_1's binary_logloss: 0.137931\n",
            "[29]\ttraining's auc: 0.877276\ttraining's binary_logloss: 0.125162\tvalid_1's auc: 0.828028\tvalid_1's binary_logloss: 0.137777\n",
            "[30]\ttraining's auc: 0.879819\ttraining's binary_logloss: 0.124646\tvalid_1's auc: 0.828317\tvalid_1's binary_logloss: 0.137609\n",
            "[31]\ttraining's auc: 0.880641\ttraining's binary_logloss: 0.124242\tvalid_1's auc: 0.828182\tvalid_1's binary_logloss: 0.137476\n",
            "[32]\ttraining's auc: 0.881461\ttraining's binary_logloss: 0.123844\tvalid_1's auc: 0.828681\tvalid_1's binary_logloss: 0.137351\n",
            "[33]\ttraining's auc: 0.882216\ttraining's binary_logloss: 0.12345\tvalid_1's auc: 0.828851\tvalid_1's binary_logloss: 0.13723\n",
            "[34]\ttraining's auc: 0.883516\ttraining's binary_logloss: 0.123056\tvalid_1's auc: 0.828991\tvalid_1's binary_logloss: 0.137094\n",
            "[35]\ttraining's auc: 0.884735\ttraining's binary_logloss: 0.122671\tvalid_1's auc: 0.829394\tvalid_1's binary_logloss: 0.136953\n",
            "[36]\ttraining's auc: 0.885297\ttraining's binary_logloss: 0.12233\tvalid_1's auc: 0.829458\tvalid_1's binary_logloss: 0.136911\n",
            "[37]\ttraining's auc: 0.885713\ttraining's binary_logloss: 0.121987\tvalid_1's auc: 0.829695\tvalid_1's binary_logloss: 0.136812\n",
            "[38]\ttraining's auc: 0.886434\ttraining's binary_logloss: 0.121652\tvalid_1's auc: 0.829791\tvalid_1's binary_logloss: 0.136724\n",
            "[39]\ttraining's auc: 0.887435\ttraining's binary_logloss: 0.121265\tvalid_1's auc: 0.830314\tvalid_1's binary_logloss: 0.136619\n",
            "[40]\ttraining's auc: 0.888421\ttraining's binary_logloss: 0.120904\tvalid_1's auc: 0.830324\tvalid_1's binary_logloss: 0.136569\n",
            "[41]\ttraining's auc: 0.889126\ttraining's binary_logloss: 0.120592\tvalid_1's auc: 0.830284\tvalid_1's binary_logloss: 0.136534\n",
            "[42]\ttraining's auc: 0.889865\ttraining's binary_logloss: 0.120291\tvalid_1's auc: 0.83028\tvalid_1's binary_logloss: 0.136498\n",
            "[43]\ttraining's auc: 0.890541\ttraining's binary_logloss: 0.119994\tvalid_1's auc: 0.830102\tvalid_1's binary_logloss: 0.136479\n",
            "[44]\ttraining's auc: 0.891596\ttraining's binary_logloss: 0.119652\tvalid_1's auc: 0.830085\tvalid_1's binary_logloss: 0.13644\n",
            "[45]\ttraining's auc: 0.892069\ttraining's binary_logloss: 0.119356\tvalid_1's auc: 0.830235\tvalid_1's binary_logloss: 0.136366\n",
            "[46]\ttraining's auc: 0.892825\ttraining's binary_logloss: 0.119093\tvalid_1's auc: 0.83043\tvalid_1's binary_logloss: 0.136318\n",
            "[47]\ttraining's auc: 0.8938\ttraining's binary_logloss: 0.118784\tvalid_1's auc: 0.831139\tvalid_1's binary_logloss: 0.13622\n",
            "[48]\ttraining's auc: 0.89436\ttraining's binary_logloss: 0.118518\tvalid_1's auc: 0.831189\tvalid_1's binary_logloss: 0.136205\n",
            "[49]\ttraining's auc: 0.89494\ttraining's binary_logloss: 0.118242\tvalid_1's auc: 0.831104\tvalid_1's binary_logloss: 0.136208\n",
            "[50]\ttraining's auc: 0.895611\ttraining's binary_logloss: 0.118022\tvalid_1's auc: 0.831158\tvalid_1's binary_logloss: 0.136174\n",
            "[51]\ttraining's auc: 0.896894\ttraining's binary_logloss: 0.117712\tvalid_1's auc: 0.83156\tvalid_1's binary_logloss: 0.136075\n",
            "[52]\ttraining's auc: 0.897604\ttraining's binary_logloss: 0.117427\tvalid_1's auc: 0.831703\tvalid_1's binary_logloss: 0.136041\n",
            "[53]\ttraining's auc: 0.898502\ttraining's binary_logloss: 0.117143\tvalid_1's auc: 0.831585\tvalid_1's binary_logloss: 0.136029\n",
            "[54]\ttraining's auc: 0.899149\ttraining's binary_logloss: 0.116909\tvalid_1's auc: 0.831506\tvalid_1's binary_logloss: 0.136015\n",
            "[55]\ttraining's auc: 0.899539\ttraining's binary_logloss: 0.116676\tvalid_1's auc: 0.831473\tvalid_1's binary_logloss: 0.135979\n",
            "[56]\ttraining's auc: 0.900046\ttraining's binary_logloss: 0.116431\tvalid_1's auc: 0.831578\tvalid_1's binary_logloss: 0.135947\n",
            "[57]\ttraining's auc: 0.900538\ttraining's binary_logloss: 0.116212\tvalid_1's auc: 0.831554\tvalid_1's binary_logloss: 0.135954\n",
            "[58]\ttraining's auc: 0.901509\ttraining's binary_logloss: 0.115954\tvalid_1's auc: 0.83183\tvalid_1's binary_logloss: 0.135887\n",
            "[59]\ttraining's auc: 0.90254\ttraining's binary_logloss: 0.115725\tvalid_1's auc: 0.831905\tvalid_1's binary_logloss: 0.135856\n",
            "[60]\ttraining's auc: 0.903167\ttraining's binary_logloss: 0.115515\tvalid_1's auc: 0.831831\tvalid_1's binary_logloss: 0.135849\n",
            "[61]\ttraining's auc: 0.903546\ttraining's binary_logloss: 0.115314\tvalid_1's auc: 0.831735\tvalid_1's binary_logloss: 0.135857\n",
            "[62]\ttraining's auc: 0.904145\ttraining's binary_logloss: 0.115104\tvalid_1's auc: 0.831985\tvalid_1's binary_logloss: 0.135824\n",
            "[63]\ttraining's auc: 0.904519\ttraining's binary_logloss: 0.114922\tvalid_1's auc: 0.831836\tvalid_1's binary_logloss: 0.135877\n",
            "[64]\ttraining's auc: 0.905153\ttraining's binary_logloss: 0.114748\tvalid_1's auc: 0.831808\tvalid_1's binary_logloss: 0.135879\n",
            "[65]\ttraining's auc: 0.905643\ttraining's binary_logloss: 0.114515\tvalid_1's auc: 0.831559\tvalid_1's binary_logloss: 0.135915\n",
            "[66]\ttraining's auc: 0.906022\ttraining's binary_logloss: 0.114314\tvalid_1's auc: 0.831724\tvalid_1's binary_logloss: 0.135905\n",
            "[67]\ttraining's auc: 0.906438\ttraining's binary_logloss: 0.114102\tvalid_1's auc: 0.831717\tvalid_1's binary_logloss: 0.135907\n",
            "[68]\ttraining's auc: 0.906876\ttraining's binary_logloss: 0.113883\tvalid_1's auc: 0.831564\tvalid_1's binary_logloss: 0.135907\n",
            "[69]\ttraining's auc: 0.90744\ttraining's binary_logloss: 0.113672\tvalid_1's auc: 0.831466\tvalid_1's binary_logloss: 0.13593\n",
            "[70]\ttraining's auc: 0.907852\ttraining's binary_logloss: 0.113452\tvalid_1's auc: 0.831263\tvalid_1's binary_logloss: 0.136\n",
            "[71]\ttraining's auc: 0.908444\ttraining's binary_logloss: 0.113254\tvalid_1's auc: 0.831006\tvalid_1's binary_logloss: 0.136057\n",
            "[72]\ttraining's auc: 0.909114\ttraining's binary_logloss: 0.113079\tvalid_1's auc: 0.830754\tvalid_1's binary_logloss: 0.136086\n",
            "[73]\ttraining's auc: 0.909362\ttraining's binary_logloss: 0.112908\tvalid_1's auc: 0.830871\tvalid_1's binary_logloss: 0.136071\n",
            "[74]\ttraining's auc: 0.909714\ttraining's binary_logloss: 0.112711\tvalid_1's auc: 0.830751\tvalid_1's binary_logloss: 0.136109\n",
            "[75]\ttraining's auc: 0.910203\ttraining's binary_logloss: 0.112482\tvalid_1's auc: 0.830873\tvalid_1's binary_logloss: 0.136099\n",
            "[76]\ttraining's auc: 0.910706\ttraining's binary_logloss: 0.112308\tvalid_1's auc: 0.830793\tvalid_1's binary_logloss: 0.136115\n",
            "[77]\ttraining's auc: 0.911096\ttraining's binary_logloss: 0.112118\tvalid_1's auc: 0.830704\tvalid_1's binary_logloss: 0.13614\n",
            "[78]\ttraining's auc: 0.911732\ttraining's binary_logloss: 0.111941\tvalid_1's auc: 0.830686\tvalid_1's binary_logloss: 0.13615\n",
            "[79]\ttraining's auc: 0.91231\ttraining's binary_logloss: 0.111754\tvalid_1's auc: 0.830829\tvalid_1's binary_logloss: 0.136113\n",
            "[80]\ttraining's auc: 0.912538\ttraining's binary_logloss: 0.111614\tvalid_1's auc: 0.830821\tvalid_1's binary_logloss: 0.136127\n",
            "[81]\ttraining's auc: 0.912993\ttraining's binary_logloss: 0.111429\tvalid_1's auc: 0.830695\tvalid_1's binary_logloss: 0.136139\n",
            "[82]\ttraining's auc: 0.913315\ttraining's binary_logloss: 0.111268\tvalid_1's auc: 0.830583\tvalid_1's binary_logloss: 0.136169\n",
            "[83]\ttraining's auc: 0.913902\ttraining's binary_logloss: 0.111061\tvalid_1's auc: 0.83075\tvalid_1's binary_logloss: 0.136155\n",
            "[84]\ttraining's auc: 0.914218\ttraining's binary_logloss: 0.110916\tvalid_1's auc: 0.830663\tvalid_1's binary_logloss: 0.136179\n",
            "[85]\ttraining's auc: 0.914461\ttraining's binary_logloss: 0.110768\tvalid_1's auc: 0.830416\tvalid_1's binary_logloss: 0.136223\n",
            "[86]\ttraining's auc: 0.914851\ttraining's binary_logloss: 0.110585\tvalid_1's auc: 0.830334\tvalid_1's binary_logloss: 0.136221\n",
            "[87]\ttraining's auc: 0.915113\ttraining's binary_logloss: 0.110426\tvalid_1's auc: 0.830195\tvalid_1's binary_logloss: 0.136244\n",
            "[88]\ttraining's auc: 0.915624\ttraining's binary_logloss: 0.110267\tvalid_1's auc: 0.830343\tvalid_1's binary_logloss: 0.136229\n",
            "[89]\ttraining's auc: 0.915928\ttraining's binary_logloss: 0.110129\tvalid_1's auc: 0.830229\tvalid_1's binary_logloss: 0.136254\n",
            "[90]\ttraining's auc: 0.91635\ttraining's binary_logloss: 0.109988\tvalid_1's auc: 0.830417\tvalid_1's binary_logloss: 0.136223\n",
            "[91]\ttraining's auc: 0.916856\ttraining's binary_logloss: 0.109809\tvalid_1's auc: 0.830278\tvalid_1's binary_logloss: 0.136239\n",
            "[92]\ttraining's auc: 0.917471\ttraining's binary_logloss: 0.109672\tvalid_1's auc: 0.83039\tvalid_1's binary_logloss: 0.136238\n",
            " 80%|████████  | 40/50 [20:06<04:53, 29.37s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.161705\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156708\n",
            "[2]\ttraining's auc: 0.823429\ttraining's binary_logloss: 0.157792\tvalid_1's auc: 0.804273\tvalid_1's binary_logloss: 0.153583\n",
            "[3]\ttraining's auc: 0.831535\ttraining's binary_logloss: 0.154515\tvalid_1's auc: 0.815664\tvalid_1's binary_logloss: 0.150991\n",
            "[4]\ttraining's auc: 0.835094\ttraining's binary_logloss: 0.151751\tvalid_1's auc: 0.81746\tvalid_1's binary_logloss: 0.148973\n",
            "[5]\ttraining's auc: 0.837851\ttraining's binary_logloss: 0.149424\tvalid_1's auc: 0.818904\tvalid_1's binary_logloss: 0.147214\n",
            "[6]\ttraining's auc: 0.841694\ttraining's binary_logloss: 0.147429\tvalid_1's auc: 0.822338\tvalid_1's binary_logloss: 0.145708\n",
            "[7]\ttraining's auc: 0.844837\ttraining's binary_logloss: 0.145613\tvalid_1's auc: 0.823928\tvalid_1's binary_logloss: 0.144372\n",
            "[8]\ttraining's auc: 0.848701\ttraining's binary_logloss: 0.143977\tvalid_1's auc: 0.827278\tvalid_1's binary_logloss: 0.143178\n",
            "[9]\ttraining's auc: 0.851526\ttraining's binary_logloss: 0.142452\tvalid_1's auc: 0.827797\tvalid_1's binary_logloss: 0.142073\n",
            "[10]\ttraining's auc: 0.852935\ttraining's binary_logloss: 0.141105\tvalid_1's auc: 0.828831\tvalid_1's binary_logloss: 0.141057\n",
            "[11]\ttraining's auc: 0.854568\ttraining's binary_logloss: 0.139867\tvalid_1's auc: 0.828981\tvalid_1's binary_logloss: 0.140186\n",
            "[12]\ttraining's auc: 0.856209\ttraining's binary_logloss: 0.138758\tvalid_1's auc: 0.831427\tvalid_1's binary_logloss: 0.139335\n",
            "[13]\ttraining's auc: 0.857731\ttraining's binary_logloss: 0.137733\tvalid_1's auc: 0.831474\tvalid_1's binary_logloss: 0.138638\n",
            "[14]\ttraining's auc: 0.858918\ttraining's binary_logloss: 0.136734\tvalid_1's auc: 0.831288\tvalid_1's binary_logloss: 0.138063\n",
            "[15]\ttraining's auc: 0.859935\ttraining's binary_logloss: 0.135816\tvalid_1's auc: 0.831148\tvalid_1's binary_logloss: 0.137476\n",
            "[16]\ttraining's auc: 0.862144\ttraining's binary_logloss: 0.134979\tvalid_1's auc: 0.831885\tvalid_1's binary_logloss: 0.136923\n",
            "[17]\ttraining's auc: 0.864674\ttraining's binary_logloss: 0.134131\tvalid_1's auc: 0.832068\tvalid_1's binary_logloss: 0.136448\n",
            "[18]\ttraining's auc: 0.866242\ttraining's binary_logloss: 0.13335\tvalid_1's auc: 0.831941\tvalid_1's binary_logloss: 0.136015\n",
            "[19]\ttraining's auc: 0.867815\ttraining's binary_logloss: 0.132595\tvalid_1's auc: 0.83194\tvalid_1's binary_logloss: 0.13567\n",
            "[20]\ttraining's auc: 0.869809\ttraining's binary_logloss: 0.131879\tvalid_1's auc: 0.832474\tvalid_1's binary_logloss: 0.135324\n",
            "[21]\ttraining's auc: 0.870856\ttraining's binary_logloss: 0.13124\tvalid_1's auc: 0.83236\tvalid_1's binary_logloss: 0.135016\n",
            "[22]\ttraining's auc: 0.871649\ttraining's binary_logloss: 0.130633\tvalid_1's auc: 0.832621\tvalid_1's binary_logloss: 0.134713\n",
            "[23]\ttraining's auc: 0.872396\ttraining's binary_logloss: 0.130084\tvalid_1's auc: 0.832444\tvalid_1's binary_logloss: 0.134496\n",
            "[24]\ttraining's auc: 0.873163\ttraining's binary_logloss: 0.129548\tvalid_1's auc: 0.832222\tvalid_1's binary_logloss: 0.134252\n",
            "[25]\ttraining's auc: 0.873878\ttraining's binary_logloss: 0.128988\tvalid_1's auc: 0.832599\tvalid_1's binary_logloss: 0.134004\n",
            "[26]\ttraining's auc: 0.874438\ttraining's binary_logloss: 0.128478\tvalid_1's auc: 0.832487\tvalid_1's binary_logloss: 0.133812\n",
            "[27]\ttraining's auc: 0.875111\ttraining's binary_logloss: 0.128019\tvalid_1's auc: 0.832523\tvalid_1's binary_logloss: 0.133592\n",
            "[28]\ttraining's auc: 0.876642\ttraining's binary_logloss: 0.127514\tvalid_1's auc: 0.832831\tvalid_1's binary_logloss: 0.133416\n",
            "[29]\ttraining's auc: 0.877584\ttraining's binary_logloss: 0.127038\tvalid_1's auc: 0.832968\tvalid_1's binary_logloss: 0.133239\n",
            "[30]\ttraining's auc: 0.878573\ttraining's binary_logloss: 0.126591\tvalid_1's auc: 0.833047\tvalid_1's binary_logloss: 0.1331\n",
            "[31]\ttraining's auc: 0.879146\ttraining's binary_logloss: 0.126162\tvalid_1's auc: 0.832768\tvalid_1's binary_logloss: 0.132971\n",
            "[32]\ttraining's auc: 0.880062\ttraining's binary_logloss: 0.125715\tvalid_1's auc: 0.832544\tvalid_1's binary_logloss: 0.13285\n",
            "[33]\ttraining's auc: 0.880482\ttraining's binary_logloss: 0.125346\tvalid_1's auc: 0.832503\tvalid_1's binary_logloss: 0.132745\n",
            "[34]\ttraining's auc: 0.881528\ttraining's binary_logloss: 0.124968\tvalid_1's auc: 0.832368\tvalid_1's binary_logloss: 0.132652\n",
            "[35]\ttraining's auc: 0.882445\ttraining's binary_logloss: 0.124568\tvalid_1's auc: 0.832575\tvalid_1's binary_logloss: 0.132465\n",
            "[36]\ttraining's auc: 0.883761\ttraining's binary_logloss: 0.124181\tvalid_1's auc: 0.832624\tvalid_1's binary_logloss: 0.132378\n",
            "[37]\ttraining's auc: 0.884929\ttraining's binary_logloss: 0.123841\tvalid_1's auc: 0.832774\tvalid_1's binary_logloss: 0.132281\n",
            "[38]\ttraining's auc: 0.885679\ttraining's binary_logloss: 0.123474\tvalid_1's auc: 0.83266\tvalid_1's binary_logloss: 0.13222\n",
            "[39]\ttraining's auc: 0.886447\ttraining's binary_logloss: 0.123155\tvalid_1's auc: 0.832791\tvalid_1's binary_logloss: 0.132148\n",
            "[40]\ttraining's auc: 0.887411\ttraining's binary_logloss: 0.122807\tvalid_1's auc: 0.833048\tvalid_1's binary_logloss: 0.132049\n",
            "[41]\ttraining's auc: 0.888144\ttraining's binary_logloss: 0.12247\tvalid_1's auc: 0.832996\tvalid_1's binary_logloss: 0.132006\n",
            "[42]\ttraining's auc: 0.889525\ttraining's binary_logloss: 0.122083\tvalid_1's auc: 0.833193\tvalid_1's binary_logloss: 0.131925\n",
            "[43]\ttraining's auc: 0.890161\ttraining's binary_logloss: 0.121781\tvalid_1's auc: 0.833244\tvalid_1's binary_logloss: 0.131896\n",
            "[44]\ttraining's auc: 0.891022\ttraining's binary_logloss: 0.121482\tvalid_1's auc: 0.833426\tvalid_1's binary_logloss: 0.131833\n",
            "[45]\ttraining's auc: 0.891586\ttraining's binary_logloss: 0.12117\tvalid_1's auc: 0.833558\tvalid_1's binary_logloss: 0.131771\n",
            "[46]\ttraining's auc: 0.892102\ttraining's binary_logloss: 0.120902\tvalid_1's auc: 0.833745\tvalid_1's binary_logloss: 0.131702\n",
            "[47]\ttraining's auc: 0.893182\ttraining's binary_logloss: 0.120619\tvalid_1's auc: 0.833689\tvalid_1's binary_logloss: 0.13166\n",
            "[48]\ttraining's auc: 0.893657\ttraining's binary_logloss: 0.120376\tvalid_1's auc: 0.833588\tvalid_1's binary_logloss: 0.131627\n",
            "[49]\ttraining's auc: 0.894587\ttraining's binary_logloss: 0.120102\tvalid_1's auc: 0.833555\tvalid_1's binary_logloss: 0.131603\n",
            "[50]\ttraining's auc: 0.894967\ttraining's binary_logloss: 0.119874\tvalid_1's auc: 0.833389\tvalid_1's binary_logloss: 0.131592\n",
            "[51]\ttraining's auc: 0.89525\ttraining's binary_logloss: 0.119649\tvalid_1's auc: 0.833433\tvalid_1's binary_logloss: 0.131557\n",
            "[52]\ttraining's auc: 0.895885\ttraining's binary_logloss: 0.119404\tvalid_1's auc: 0.833612\tvalid_1's binary_logloss: 0.131504\n",
            "[53]\ttraining's auc: 0.896625\ttraining's binary_logloss: 0.119161\tvalid_1's auc: 0.833277\tvalid_1's binary_logloss: 0.131491\n",
            "[54]\ttraining's auc: 0.89732\ttraining's binary_logloss: 0.11894\tvalid_1's auc: 0.833272\tvalid_1's binary_logloss: 0.131475\n",
            "[55]\ttraining's auc: 0.897836\ttraining's binary_logloss: 0.118693\tvalid_1's auc: 0.833437\tvalid_1's binary_logloss: 0.131426\n",
            "[56]\ttraining's auc: 0.898324\ttraining's binary_logloss: 0.118467\tvalid_1's auc: 0.833568\tvalid_1's binary_logloss: 0.131376\n",
            "[57]\ttraining's auc: 0.899011\ttraining's binary_logloss: 0.118234\tvalid_1's auc: 0.833808\tvalid_1's binary_logloss: 0.131334\n",
            "[58]\ttraining's auc: 0.899272\ttraining's binary_logloss: 0.118038\tvalid_1's auc: 0.833816\tvalid_1's binary_logloss: 0.131328\n",
            "[59]\ttraining's auc: 0.900322\ttraining's binary_logloss: 0.117787\tvalid_1's auc: 0.833629\tvalid_1's binary_logloss: 0.131333\n",
            "[60]\ttraining's auc: 0.901556\ttraining's binary_logloss: 0.117523\tvalid_1's auc: 0.833402\tvalid_1's binary_logloss: 0.131341\n",
            "[61]\ttraining's auc: 0.901984\ttraining's binary_logloss: 0.117298\tvalid_1's auc: 0.833217\tvalid_1's binary_logloss: 0.131367\n",
            "[62]\ttraining's auc: 0.902614\ttraining's binary_logloss: 0.117067\tvalid_1's auc: 0.833352\tvalid_1's binary_logloss: 0.13134\n",
            "[63]\ttraining's auc: 0.902983\ttraining's binary_logloss: 0.116887\tvalid_1's auc: 0.833441\tvalid_1's binary_logloss: 0.13132\n",
            "[64]\ttraining's auc: 0.903473\ttraining's binary_logloss: 0.11665\tvalid_1's auc: 0.833402\tvalid_1's binary_logloss: 0.131318\n",
            "[65]\ttraining's auc: 0.903964\ttraining's binary_logloss: 0.116464\tvalid_1's auc: 0.833787\tvalid_1's binary_logloss: 0.131254\n",
            "[66]\ttraining's auc: 0.904395\ttraining's binary_logloss: 0.116286\tvalid_1's auc: 0.833754\tvalid_1's binary_logloss: 0.13125\n",
            "[67]\ttraining's auc: 0.904991\ttraining's binary_logloss: 0.116081\tvalid_1's auc: 0.833635\tvalid_1's binary_logloss: 0.131266\n",
            "[68]\ttraining's auc: 0.905546\ttraining's binary_logloss: 0.115843\tvalid_1's auc: 0.833647\tvalid_1's binary_logloss: 0.131266\n",
            "[69]\ttraining's auc: 0.905792\ttraining's binary_logloss: 0.11568\tvalid_1's auc: 0.833703\tvalid_1's binary_logloss: 0.131265\n",
            "[70]\ttraining's auc: 0.906485\ttraining's binary_logloss: 0.115482\tvalid_1's auc: 0.833545\tvalid_1's binary_logloss: 0.131275\n",
            "[71]\ttraining's auc: 0.907087\ttraining's binary_logloss: 0.11526\tvalid_1's auc: 0.833402\tvalid_1's binary_logloss: 0.131275\n",
            "[72]\ttraining's auc: 0.907522\ttraining's binary_logloss: 0.115035\tvalid_1's auc: 0.833537\tvalid_1's binary_logloss: 0.131266\n",
            "[73]\ttraining's auc: 0.908246\ttraining's binary_logloss: 0.11479\tvalid_1's auc: 0.833586\tvalid_1's binary_logloss: 0.131266\n",
            "[74]\ttraining's auc: 0.908525\ttraining's binary_logloss: 0.114652\tvalid_1's auc: 0.833556\tvalid_1's binary_logloss: 0.131262\n",
            "[75]\ttraining's auc: 0.909188\ttraining's binary_logloss: 0.114413\tvalid_1's auc: 0.833497\tvalid_1's binary_logloss: 0.131281\n",
            "[76]\ttraining's auc: 0.909588\ttraining's binary_logloss: 0.114214\tvalid_1's auc: 0.833499\tvalid_1's binary_logloss: 0.131266\n",
            "[77]\ttraining's auc: 0.90997\ttraining's binary_logloss: 0.114035\tvalid_1's auc: 0.833397\tvalid_1's binary_logloss: 0.131288\n",
            "[78]\ttraining's auc: 0.910237\ttraining's binary_logloss: 0.113871\tvalid_1's auc: 0.833472\tvalid_1's binary_logloss: 0.131286\n",
            "[79]\ttraining's auc: 0.910624\ttraining's binary_logloss: 0.11367\tvalid_1's auc: 0.833543\tvalid_1's binary_logloss: 0.13128\n",
            "[80]\ttraining's auc: 0.911669\ttraining's binary_logloss: 0.113408\tvalid_1's auc: 0.833563\tvalid_1's binary_logloss: 0.131285\n",
            "[81]\ttraining's auc: 0.911909\ttraining's binary_logloss: 0.113297\tvalid_1's auc: 0.833491\tvalid_1's binary_logloss: 0.131292\n",
            "[82]\ttraining's auc: 0.912209\ttraining's binary_logloss: 0.113129\tvalid_1's auc: 0.833642\tvalid_1's binary_logloss: 0.131278\n",
            "[83]\ttraining's auc: 0.912763\ttraining's binary_logloss: 0.112916\tvalid_1's auc: 0.833936\tvalid_1's binary_logloss: 0.131256\n",
            "[84]\ttraining's auc: 0.913252\ttraining's binary_logloss: 0.112745\tvalid_1's auc: 0.833942\tvalid_1's binary_logloss: 0.131233\n",
            "[85]\ttraining's auc: 0.913619\ttraining's binary_logloss: 0.112618\tvalid_1's auc: 0.833981\tvalid_1's binary_logloss: 0.13122\n",
            "[86]\ttraining's auc: 0.913931\ttraining's binary_logloss: 0.112458\tvalid_1's auc: 0.834028\tvalid_1's binary_logloss: 0.131226\n",
            "[87]\ttraining's auc: 0.914205\ttraining's binary_logloss: 0.112335\tvalid_1's auc: 0.83408\tvalid_1's binary_logloss: 0.13121\n",
            "[88]\ttraining's auc: 0.914697\ttraining's binary_logloss: 0.112134\tvalid_1's auc: 0.834151\tvalid_1's binary_logloss: 0.131204\n",
            "[89]\ttraining's auc: 0.915082\ttraining's binary_logloss: 0.111983\tvalid_1's auc: 0.834183\tvalid_1's binary_logloss: 0.131207\n",
            "[90]\ttraining's auc: 0.915518\ttraining's binary_logloss: 0.111854\tvalid_1's auc: 0.834031\tvalid_1's binary_logloss: 0.131224\n",
            "[91]\ttraining's auc: 0.915738\ttraining's binary_logloss: 0.111697\tvalid_1's auc: 0.83409\tvalid_1's binary_logloss: 0.131209\n",
            "[92]\ttraining's auc: 0.915956\ttraining's binary_logloss: 0.11154\tvalid_1's auc: 0.834124\tvalid_1's binary_logloss: 0.131199\n",
            "[93]\ttraining's auc: 0.916286\ttraining's binary_logloss: 0.11138\tvalid_1's auc: 0.834191\tvalid_1's binary_logloss: 0.131171\n",
            "[94]\ttraining's auc: 0.916867\ttraining's binary_logloss: 0.111208\tvalid_1's auc: 0.834057\tvalid_1's binary_logloss: 0.131194\n",
            "[95]\ttraining's auc: 0.917141\ttraining's binary_logloss: 0.111073\tvalid_1's auc: 0.83396\tvalid_1's binary_logloss: 0.131203\n",
            "[96]\ttraining's auc: 0.917361\ttraining's binary_logloss: 0.110936\tvalid_1's auc: 0.833798\tvalid_1's binary_logloss: 0.131239\n",
            "[97]\ttraining's auc: 0.917932\ttraining's binary_logloss: 0.110697\tvalid_1's auc: 0.83376\tvalid_1's binary_logloss: 0.131251\n",
            "[98]\ttraining's auc: 0.918067\ttraining's binary_logloss: 0.1106\tvalid_1's auc: 0.8337\tvalid_1's binary_logloss: 0.131263\n",
            "[99]\ttraining's auc: 0.918461\ttraining's binary_logloss: 0.110487\tvalid_1's auc: 0.833708\tvalid_1's binary_logloss: 0.131263\n",
            "[100]\ttraining's auc: 0.918679\ttraining's binary_logloss: 0.110355\tvalid_1's auc: 0.833593\tvalid_1's binary_logloss: 0.131265\n",
            "[101]\ttraining's auc: 0.919083\ttraining's binary_logloss: 0.110165\tvalid_1's auc: 0.833561\tvalid_1's binary_logloss: 0.131265\n",
            "[102]\ttraining's auc: 0.919291\ttraining's binary_logloss: 0.110043\tvalid_1's auc: 0.833624\tvalid_1's binary_logloss: 0.131272\n",
            "[103]\ttraining's auc: 0.919532\ttraining's binary_logloss: 0.109915\tvalid_1's auc: 0.833744\tvalid_1's binary_logloss: 0.131255\n",
            "[104]\ttraining's auc: 0.919862\ttraining's binary_logloss: 0.109805\tvalid_1's auc: 0.833676\tvalid_1's binary_logloss: 0.131271\n",
            "[105]\ttraining's auc: 0.92001\ttraining's binary_logloss: 0.109681\tvalid_1's auc: 0.833621\tvalid_1's binary_logloss: 0.131275\n",
            "[106]\ttraining's auc: 0.920429\ttraining's binary_logloss: 0.109502\tvalid_1's auc: 0.833749\tvalid_1's binary_logloss: 0.131265\n",
            "[107]\ttraining's auc: 0.92069\ttraining's binary_logloss: 0.109384\tvalid_1's auc: 0.833671\tvalid_1's binary_logloss: 0.131271\n",
            "[108]\ttraining's auc: 0.921112\ttraining's binary_logloss: 0.109241\tvalid_1's auc: 0.833586\tvalid_1's binary_logloss: 0.131272\n",
            "[109]\ttraining's auc: 0.921377\ttraining's binary_logloss: 0.109092\tvalid_1's auc: 0.833407\tvalid_1's binary_logloss: 0.131284\n",
            "[110]\ttraining's auc: 0.921561\ttraining's binary_logloss: 0.108987\tvalid_1's auc: 0.833374\tvalid_1's binary_logloss: 0.13129\n",
            "[111]\ttraining's auc: 0.92207\ttraining's binary_logloss: 0.108797\tvalid_1's auc: 0.833276\tvalid_1's binary_logloss: 0.131289\n",
            "[112]\ttraining's auc: 0.922304\ttraining's binary_logloss: 0.108648\tvalid_1's auc: 0.833244\tvalid_1's binary_logloss: 0.131297\n",
            "[113]\ttraining's auc: 0.922437\ttraining's binary_logloss: 0.108538\tvalid_1's auc: 0.833305\tvalid_1's binary_logloss: 0.131283\n",
            "[114]\ttraining's auc: 0.922767\ttraining's binary_logloss: 0.108384\tvalid_1's auc: 0.833141\tvalid_1's binary_logloss: 0.131321\n",
            "[115]\ttraining's auc: 0.923075\ttraining's binary_logloss: 0.108278\tvalid_1's auc: 0.833234\tvalid_1's binary_logloss: 0.131305\n",
            "[116]\ttraining's auc: 0.923297\ttraining's binary_logloss: 0.108134\tvalid_1's auc: 0.833274\tvalid_1's binary_logloss: 0.131299\n",
            "[117]\ttraining's auc: 0.923427\ttraining's binary_logloss: 0.108038\tvalid_1's auc: 0.833308\tvalid_1's binary_logloss: 0.131277\n",
            "[118]\ttraining's auc: 0.923623\ttraining's binary_logloss: 0.107913\tvalid_1's auc: 0.833198\tvalid_1's binary_logloss: 0.131287\n",
            "[119]\ttraining's auc: 0.923994\ttraining's binary_logloss: 0.107744\tvalid_1's auc: 0.83312\tvalid_1's binary_logloss: 0.131312\n",
            "[120]\ttraining's auc: 0.924137\ttraining's binary_logloss: 0.107642\tvalid_1's auc: 0.833298\tvalid_1's binary_logloss: 0.131308\n",
            "[121]\ttraining's auc: 0.924262\ttraining's binary_logloss: 0.107541\tvalid_1's auc: 0.833047\tvalid_1's binary_logloss: 0.131352\n",
            "[122]\ttraining's auc: 0.924424\ttraining's binary_logloss: 0.107435\tvalid_1's auc: 0.832922\tvalid_1's binary_logloss: 0.131382\n",
            "[123]\ttraining's auc: 0.924591\ttraining's binary_logloss: 0.107338\tvalid_1's auc: 0.832868\tvalid_1's binary_logloss: 0.131391\n",
            " 80%|████████  | 40/50 [20:24<04:53, 29.37s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.158166\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.164053\n",
            "[2]\ttraining's auc: 0.831482\ttraining's binary_logloss: 0.154337\tvalid_1's auc: 0.814485\tvalid_1's binary_logloss: 0.160612\n",
            "[3]\ttraining's auc: 0.834122\ttraining's binary_logloss: 0.151297\tvalid_1's auc: 0.816294\tvalid_1's binary_logloss: 0.15791\n",
            "[4]\ttraining's auc: 0.838283\ttraining's binary_logloss: 0.14865\tvalid_1's auc: 0.818454\tvalid_1's binary_logloss: 0.155626\n",
            "[5]\ttraining's auc: 0.842073\ttraining's binary_logloss: 0.146395\tvalid_1's auc: 0.821366\tvalid_1's binary_logloss: 0.153645\n",
            "[6]\ttraining's auc: 0.846348\ttraining's binary_logloss: 0.144326\tvalid_1's auc: 0.824764\tvalid_1's binary_logloss: 0.151958\n",
            "[7]\ttraining's auc: 0.848731\ttraining's binary_logloss: 0.142586\tvalid_1's auc: 0.826247\tvalid_1's binary_logloss: 0.150448\n",
            "[8]\ttraining's auc: 0.849263\ttraining's binary_logloss: 0.14102\tvalid_1's auc: 0.827053\tvalid_1's binary_logloss: 0.14914\n",
            "[9]\ttraining's auc: 0.851117\ttraining's binary_logloss: 0.139544\tvalid_1's auc: 0.828202\tvalid_1's binary_logloss: 0.147924\n",
            "[10]\ttraining's auc: 0.851917\ttraining's binary_logloss: 0.138237\tvalid_1's auc: 0.828548\tvalid_1's binary_logloss: 0.146895\n",
            "[11]\ttraining's auc: 0.854728\ttraining's binary_logloss: 0.137003\tvalid_1's auc: 0.829413\tvalid_1's binary_logloss: 0.145957\n",
            "[12]\ttraining's auc: 0.85553\ttraining's binary_logloss: 0.135919\tvalid_1's auc: 0.829654\tvalid_1's binary_logloss: 0.14512\n",
            "[13]\ttraining's auc: 0.856019\ttraining's binary_logloss: 0.134911\tvalid_1's auc: 0.830226\tvalid_1's binary_logloss: 0.144376\n",
            "[14]\ttraining's auc: 0.857731\ttraining's binary_logloss: 0.133957\tvalid_1's auc: 0.830912\tvalid_1's binary_logloss: 0.143653\n",
            "[15]\ttraining's auc: 0.859373\ttraining's binary_logloss: 0.133086\tvalid_1's auc: 0.831207\tvalid_1's binary_logloss: 0.14303\n",
            "[16]\ttraining's auc: 0.861168\ttraining's binary_logloss: 0.132293\tvalid_1's auc: 0.831702\tvalid_1's binary_logloss: 0.14244\n",
            "[17]\ttraining's auc: 0.862423\ttraining's binary_logloss: 0.131527\tvalid_1's auc: 0.831952\tvalid_1's binary_logloss: 0.141937\n",
            "[18]\ttraining's auc: 0.863408\ttraining's binary_logloss: 0.13081\tvalid_1's auc: 0.832094\tvalid_1's binary_logloss: 0.141465\n",
            "[19]\ttraining's auc: 0.864242\ttraining's binary_logloss: 0.130141\tvalid_1's auc: 0.832161\tvalid_1's binary_logloss: 0.141053\n",
            "[20]\ttraining's auc: 0.866341\ttraining's binary_logloss: 0.129459\tvalid_1's auc: 0.832561\tvalid_1's binary_logloss: 0.140642\n",
            "[21]\ttraining's auc: 0.868412\ttraining's binary_logloss: 0.128835\tvalid_1's auc: 0.833083\tvalid_1's binary_logloss: 0.14033\n",
            "[22]\ttraining's auc: 0.869803\ttraining's binary_logloss: 0.128247\tvalid_1's auc: 0.834321\tvalid_1's binary_logloss: 0.140026\n",
            "[23]\ttraining's auc: 0.870814\ttraining's binary_logloss: 0.127697\tvalid_1's auc: 0.834084\tvalid_1's binary_logloss: 0.139754\n",
            "[24]\ttraining's auc: 0.871817\ttraining's binary_logloss: 0.12716\tvalid_1's auc: 0.834668\tvalid_1's binary_logloss: 0.139438\n",
            "[25]\ttraining's auc: 0.872906\ttraining's binary_logloss: 0.126637\tvalid_1's auc: 0.835165\tvalid_1's binary_logloss: 0.139181\n",
            "[26]\ttraining's auc: 0.874396\ttraining's binary_logloss: 0.126127\tvalid_1's auc: 0.836033\tvalid_1's binary_logloss: 0.138937\n",
            "[27]\ttraining's auc: 0.875158\ttraining's binary_logloss: 0.125646\tvalid_1's auc: 0.836262\tvalid_1's binary_logloss: 0.138663\n",
            "[28]\ttraining's auc: 0.875618\ttraining's binary_logloss: 0.125214\tvalid_1's auc: 0.83594\tvalid_1's binary_logloss: 0.138492\n",
            "[29]\ttraining's auc: 0.876746\ttraining's binary_logloss: 0.124753\tvalid_1's auc: 0.836256\tvalid_1's binary_logloss: 0.138288\n",
            "[30]\ttraining's auc: 0.878159\ttraining's binary_logloss: 0.124328\tvalid_1's auc: 0.836218\tvalid_1's binary_logloss: 0.13813\n",
            "[31]\ttraining's auc: 0.879529\ttraining's binary_logloss: 0.123864\tvalid_1's auc: 0.836607\tvalid_1's binary_logloss: 0.137954\n",
            "[32]\ttraining's auc: 0.88128\ttraining's binary_logloss: 0.123418\tvalid_1's auc: 0.836879\tvalid_1's binary_logloss: 0.137802\n",
            "[33]\ttraining's auc: 0.882661\ttraining's binary_logloss: 0.123042\tvalid_1's auc: 0.83662\tvalid_1's binary_logloss: 0.137667\n",
            "[34]\ttraining's auc: 0.883782\ttraining's binary_logloss: 0.12263\tvalid_1's auc: 0.836275\tvalid_1's binary_logloss: 0.137571\n",
            "[35]\ttraining's auc: 0.884571\ttraining's binary_logloss: 0.122257\tvalid_1's auc: 0.836027\tvalid_1's binary_logloss: 0.137485\n",
            "[36]\ttraining's auc: 0.885537\ttraining's binary_logloss: 0.121908\tvalid_1's auc: 0.836177\tvalid_1's binary_logloss: 0.137362\n",
            "[37]\ttraining's auc: 0.886711\ttraining's binary_logloss: 0.121531\tvalid_1's auc: 0.83591\tvalid_1's binary_logloss: 0.137265\n",
            "[38]\ttraining's auc: 0.887836\ttraining's binary_logloss: 0.121182\tvalid_1's auc: 0.836675\tvalid_1's binary_logloss: 0.137124\n",
            "[39]\ttraining's auc: 0.888657\ttraining's binary_logloss: 0.120801\tvalid_1's auc: 0.836992\tvalid_1's binary_logloss: 0.137034\n",
            "[40]\ttraining's auc: 0.88941\ttraining's binary_logloss: 0.12046\tvalid_1's auc: 0.836951\tvalid_1's binary_logloss: 0.136997\n",
            "[41]\ttraining's auc: 0.890261\ttraining's binary_logloss: 0.120133\tvalid_1's auc: 0.836746\tvalid_1's binary_logloss: 0.136956\n",
            "[42]\ttraining's auc: 0.890985\ttraining's binary_logloss: 0.11982\tvalid_1's auc: 0.836801\tvalid_1's binary_logloss: 0.136902\n",
            "[43]\ttraining's auc: 0.891706\ttraining's binary_logloss: 0.119509\tvalid_1's auc: 0.836564\tvalid_1's binary_logloss: 0.136871\n",
            "[44]\ttraining's auc: 0.892146\ttraining's binary_logloss: 0.119235\tvalid_1's auc: 0.836742\tvalid_1's binary_logloss: 0.136789\n",
            "[45]\ttraining's auc: 0.893301\ttraining's binary_logloss: 0.118907\tvalid_1's auc: 0.836808\tvalid_1's binary_logloss: 0.136731\n",
            "[46]\ttraining's auc: 0.893713\ttraining's binary_logloss: 0.118651\tvalid_1's auc: 0.836794\tvalid_1's binary_logloss: 0.136678\n",
            "[47]\ttraining's auc: 0.894245\ttraining's binary_logloss: 0.118399\tvalid_1's auc: 0.836885\tvalid_1's binary_logloss: 0.136648\n",
            "[48]\ttraining's auc: 0.894881\ttraining's binary_logloss: 0.11812\tvalid_1's auc: 0.836969\tvalid_1's binary_logloss: 0.13661\n",
            "[49]\ttraining's auc: 0.895527\ttraining's binary_logloss: 0.117876\tvalid_1's auc: 0.836831\tvalid_1's binary_logloss: 0.136583\n",
            "[50]\ttraining's auc: 0.896237\ttraining's binary_logloss: 0.117606\tvalid_1's auc: 0.836626\tvalid_1's binary_logloss: 0.136589\n",
            "[51]\ttraining's auc: 0.897119\ttraining's binary_logloss: 0.117331\tvalid_1's auc: 0.836513\tvalid_1's binary_logloss: 0.13657\n",
            "[52]\ttraining's auc: 0.897737\ttraining's binary_logloss: 0.11708\tvalid_1's auc: 0.836363\tvalid_1's binary_logloss: 0.136554\n",
            "[53]\ttraining's auc: 0.8982\ttraining's binary_logloss: 0.116832\tvalid_1's auc: 0.836011\tvalid_1's binary_logloss: 0.136566\n",
            "[54]\ttraining's auc: 0.898827\ttraining's binary_logloss: 0.116569\tvalid_1's auc: 0.836227\tvalid_1's binary_logloss: 0.136504\n",
            "[55]\ttraining's auc: 0.899326\ttraining's binary_logloss: 0.116359\tvalid_1's auc: 0.836229\tvalid_1's binary_logloss: 0.136496\n",
            "[56]\ttraining's auc: 0.899729\ttraining's binary_logloss: 0.11618\tvalid_1's auc: 0.835998\tvalid_1's binary_logloss: 0.136489\n",
            "[57]\ttraining's auc: 0.900324\ttraining's binary_logloss: 0.115972\tvalid_1's auc: 0.83591\tvalid_1's binary_logloss: 0.136485\n",
            "[58]\ttraining's auc: 0.900779\ttraining's binary_logloss: 0.115781\tvalid_1's auc: 0.835985\tvalid_1's binary_logloss: 0.136466\n",
            "[59]\ttraining's auc: 0.901315\ttraining's binary_logloss: 0.115555\tvalid_1's auc: 0.835837\tvalid_1's binary_logloss: 0.136461\n",
            "[60]\ttraining's auc: 0.901945\ttraining's binary_logloss: 0.115321\tvalid_1's auc: 0.835627\tvalid_1's binary_logloss: 0.136486\n",
            "[61]\ttraining's auc: 0.902552\ttraining's binary_logloss: 0.115105\tvalid_1's auc: 0.83559\tvalid_1's binary_logloss: 0.136481\n",
            "[62]\ttraining's auc: 0.903351\ttraining's binary_logloss: 0.114803\tvalid_1's auc: 0.835468\tvalid_1's binary_logloss: 0.136494\n",
            "[63]\ttraining's auc: 0.903797\ttraining's binary_logloss: 0.114635\tvalid_1's auc: 0.835518\tvalid_1's binary_logloss: 0.136506\n",
            "[64]\ttraining's auc: 0.90484\ttraining's binary_logloss: 0.114349\tvalid_1's auc: 0.835284\tvalid_1's binary_logloss: 0.136531\n",
            "[65]\ttraining's auc: 0.905413\ttraining's binary_logloss: 0.114116\tvalid_1's auc: 0.835439\tvalid_1's binary_logloss: 0.136496\n",
            "[66]\ttraining's auc: 0.906028\ttraining's binary_logloss: 0.113902\tvalid_1's auc: 0.835317\tvalid_1's binary_logloss: 0.136512\n",
            "[67]\ttraining's auc: 0.906615\ttraining's binary_logloss: 0.113665\tvalid_1's auc: 0.83538\tvalid_1's binary_logloss: 0.136519\n",
            "[68]\ttraining's auc: 0.907276\ttraining's binary_logloss: 0.113423\tvalid_1's auc: 0.835359\tvalid_1's binary_logloss: 0.136518\n",
            "[69]\ttraining's auc: 0.907703\ttraining's binary_logloss: 0.113268\tvalid_1's auc: 0.835378\tvalid_1's binary_logloss: 0.136518\n",
            " 82%|████████▏ | 41/50 [20:37<05:00, 33.36s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.158181\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.160137\n",
            "[2]\ttraining's auc: 0.832841\ttraining's binary_logloss: 0.153669\tvalid_1's auc: 0.806025\tvalid_1's binary_logloss: 0.156591\n",
            "[3]\ttraining's auc: 0.834224\ttraining's binary_logloss: 0.150134\tvalid_1's auc: 0.806804\tvalid_1's binary_logloss: 0.153928\n",
            "[4]\ttraining's auc: 0.842025\ttraining's binary_logloss: 0.147254\tvalid_1's auc: 0.814198\tvalid_1's binary_logloss: 0.151654\n",
            "[5]\ttraining's auc: 0.845371\ttraining's binary_logloss: 0.144864\tvalid_1's auc: 0.816458\tvalid_1's binary_logloss: 0.14982\n",
            "[6]\ttraining's auc: 0.84754\ttraining's binary_logloss: 0.142708\tvalid_1's auc: 0.81682\tvalid_1's binary_logloss: 0.148294\n",
            "[7]\ttraining's auc: 0.849585\ttraining's binary_logloss: 0.140785\tvalid_1's auc: 0.818383\tvalid_1's binary_logloss: 0.146906\n",
            "[8]\ttraining's auc: 0.851424\ttraining's binary_logloss: 0.139113\tvalid_1's auc: 0.819468\tvalid_1's binary_logloss: 0.145722\n",
            "[9]\ttraining's auc: 0.852507\ttraining's binary_logloss: 0.137653\tvalid_1's auc: 0.820253\tvalid_1's binary_logloss: 0.144721\n",
            "[10]\ttraining's auc: 0.854094\ttraining's binary_logloss: 0.136274\tvalid_1's auc: 0.820933\tvalid_1's binary_logloss: 0.143814\n",
            "[11]\ttraining's auc: 0.856878\ttraining's binary_logloss: 0.135013\tvalid_1's auc: 0.82225\tvalid_1's binary_logloss: 0.14291\n",
            "[12]\ttraining's auc: 0.859495\ttraining's binary_logloss: 0.13385\tvalid_1's auc: 0.822889\tvalid_1's binary_logloss: 0.142162\n",
            "[13]\ttraining's auc: 0.861095\ttraining's binary_logloss: 0.132826\tvalid_1's auc: 0.822891\tvalid_1's binary_logloss: 0.141554\n",
            "[14]\ttraining's auc: 0.862532\ttraining's binary_logloss: 0.131858\tvalid_1's auc: 0.824033\tvalid_1's binary_logloss: 0.141048\n",
            "[15]\ttraining's auc: 0.864053\ttraining's binary_logloss: 0.131028\tvalid_1's auc: 0.824584\tvalid_1's binary_logloss: 0.14048\n",
            "[16]\ttraining's auc: 0.865937\ttraining's binary_logloss: 0.130218\tvalid_1's auc: 0.825614\tvalid_1's binary_logloss: 0.140036\n",
            "[17]\ttraining's auc: 0.867973\ttraining's binary_logloss: 0.1294\tvalid_1's auc: 0.826418\tvalid_1's binary_logloss: 0.139633\n",
            "[18]\ttraining's auc: 0.869261\ttraining's binary_logloss: 0.12869\tvalid_1's auc: 0.826373\tvalid_1's binary_logloss: 0.139344\n",
            "[19]\ttraining's auc: 0.870167\ttraining's binary_logloss: 0.128074\tvalid_1's auc: 0.826609\tvalid_1's binary_logloss: 0.139012\n",
            "[20]\ttraining's auc: 0.871867\ttraining's binary_logloss: 0.127389\tvalid_1's auc: 0.826983\tvalid_1's binary_logloss: 0.138683\n",
            "[21]\ttraining's auc: 0.872663\ttraining's binary_logloss: 0.126781\tvalid_1's auc: 0.827015\tvalid_1's binary_logloss: 0.138431\n",
            "[22]\ttraining's auc: 0.873544\ttraining's binary_logloss: 0.12619\tvalid_1's auc: 0.826975\tvalid_1's binary_logloss: 0.13821\n",
            "[23]\ttraining's auc: 0.874537\ttraining's binary_logloss: 0.125633\tvalid_1's auc: 0.826896\tvalid_1's binary_logloss: 0.138041\n",
            "[24]\ttraining's auc: 0.875516\ttraining's binary_logloss: 0.12514\tvalid_1's auc: 0.826938\tvalid_1's binary_logloss: 0.137885\n",
            "[25]\ttraining's auc: 0.876849\ttraining's binary_logloss: 0.124659\tvalid_1's auc: 0.827832\tvalid_1's binary_logloss: 0.13769\n",
            "[26]\ttraining's auc: 0.877865\ttraining's binary_logloss: 0.124136\tvalid_1's auc: 0.828343\tvalid_1's binary_logloss: 0.137525\n",
            "[27]\ttraining's auc: 0.880419\ttraining's binary_logloss: 0.123584\tvalid_1's auc: 0.827805\tvalid_1's binary_logloss: 0.137399\n",
            "[28]\ttraining's auc: 0.881615\ttraining's binary_logloss: 0.123132\tvalid_1's auc: 0.8279\tvalid_1's binary_logloss: 0.137281\n",
            "[29]\ttraining's auc: 0.883107\ttraining's binary_logloss: 0.122648\tvalid_1's auc: 0.82776\tvalid_1's binary_logloss: 0.137185\n",
            "[30]\ttraining's auc: 0.884158\ttraining's binary_logloss: 0.122216\tvalid_1's auc: 0.828036\tvalid_1's binary_logloss: 0.137062\n",
            "[31]\ttraining's auc: 0.884926\ttraining's binary_logloss: 0.121837\tvalid_1's auc: 0.82837\tvalid_1's binary_logloss: 0.13693\n",
            "[32]\ttraining's auc: 0.885692\ttraining's binary_logloss: 0.121448\tvalid_1's auc: 0.828158\tvalid_1's binary_logloss: 0.1369\n",
            "[33]\ttraining's auc: 0.887744\ttraining's binary_logloss: 0.120992\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.136724\n",
            "[34]\ttraining's auc: 0.888942\ttraining's binary_logloss: 0.12055\tvalid_1's auc: 0.829153\tvalid_1's binary_logloss: 0.136704\n",
            "[35]\ttraining's auc: 0.889779\ttraining's binary_logloss: 0.120175\tvalid_1's auc: 0.829211\tvalid_1's binary_logloss: 0.136656\n",
            "[36]\ttraining's auc: 0.890547\ttraining's binary_logloss: 0.119821\tvalid_1's auc: 0.829265\tvalid_1's binary_logloss: 0.136634\n",
            "[37]\ttraining's auc: 0.891426\ttraining's binary_logloss: 0.119469\tvalid_1's auc: 0.829044\tvalid_1's binary_logloss: 0.136596\n",
            "[38]\ttraining's auc: 0.892184\ttraining's binary_logloss: 0.119152\tvalid_1's auc: 0.828856\tvalid_1's binary_logloss: 0.136558\n",
            "[39]\ttraining's auc: 0.89328\ttraining's binary_logloss: 0.118846\tvalid_1's auc: 0.82872\tvalid_1's binary_logloss: 0.136546\n",
            "[40]\ttraining's auc: 0.894519\ttraining's binary_logloss: 0.118535\tvalid_1's auc: 0.829181\tvalid_1's binary_logloss: 0.136459\n",
            "[41]\ttraining's auc: 0.895291\ttraining's binary_logloss: 0.118202\tvalid_1's auc: 0.829256\tvalid_1's binary_logloss: 0.13644\n",
            "[42]\ttraining's auc: 0.896233\ttraining's binary_logloss: 0.117906\tvalid_1's auc: 0.829074\tvalid_1's binary_logloss: 0.136447\n",
            "[43]\ttraining's auc: 0.897008\ttraining's binary_logloss: 0.11759\tvalid_1's auc: 0.829764\tvalid_1's binary_logloss: 0.136335\n",
            "[44]\ttraining's auc: 0.898067\ttraining's binary_logloss: 0.117274\tvalid_1's auc: 0.829567\tvalid_1's binary_logloss: 0.136347\n",
            "[45]\ttraining's auc: 0.898721\ttraining's binary_logloss: 0.116969\tvalid_1's auc: 0.829446\tvalid_1's binary_logloss: 0.136353\n",
            "[46]\ttraining's auc: 0.899257\ttraining's binary_logloss: 0.116702\tvalid_1's auc: 0.829638\tvalid_1's binary_logloss: 0.136322\n",
            "[47]\ttraining's auc: 0.900761\ttraining's binary_logloss: 0.11634\tvalid_1's auc: 0.829921\tvalid_1's binary_logloss: 0.136234\n",
            "[48]\ttraining's auc: 0.901568\ttraining's binary_logloss: 0.116049\tvalid_1's auc: 0.829953\tvalid_1's binary_logloss: 0.136201\n",
            "[49]\ttraining's auc: 0.902339\ttraining's binary_logloss: 0.115788\tvalid_1's auc: 0.829811\tvalid_1's binary_logloss: 0.136242\n",
            "[50]\ttraining's auc: 0.903056\ttraining's binary_logloss: 0.115559\tvalid_1's auc: 0.829848\tvalid_1's binary_logloss: 0.136219\n",
            "[51]\ttraining's auc: 0.903977\ttraining's binary_logloss: 0.115282\tvalid_1's auc: 0.830143\tvalid_1's binary_logloss: 0.136157\n",
            "[52]\ttraining's auc: 0.904471\ttraining's binary_logloss: 0.11502\tvalid_1's auc: 0.830172\tvalid_1's binary_logloss: 0.136159\n",
            "[53]\ttraining's auc: 0.905567\ttraining's binary_logloss: 0.114768\tvalid_1's auc: 0.83029\tvalid_1's binary_logloss: 0.136124\n",
            "[54]\ttraining's auc: 0.906189\ttraining's binary_logloss: 0.114525\tvalid_1's auc: 0.83057\tvalid_1's binary_logloss: 0.136096\n",
            "[55]\ttraining's auc: 0.906742\ttraining's binary_logloss: 0.11426\tvalid_1's auc: 0.830507\tvalid_1's binary_logloss: 0.136113\n",
            "[56]\ttraining's auc: 0.907276\ttraining's binary_logloss: 0.114009\tvalid_1's auc: 0.830358\tvalid_1's binary_logloss: 0.136129\n",
            "[57]\ttraining's auc: 0.907752\ttraining's binary_logloss: 0.113772\tvalid_1's auc: 0.830309\tvalid_1's binary_logloss: 0.136137\n",
            "[58]\ttraining's auc: 0.908315\ttraining's binary_logloss: 0.113503\tvalid_1's auc: 0.830175\tvalid_1's binary_logloss: 0.136137\n",
            "[59]\ttraining's auc: 0.908909\ttraining's binary_logloss: 0.113241\tvalid_1's auc: 0.830124\tvalid_1's binary_logloss: 0.136152\n",
            "[60]\ttraining's auc: 0.909298\ttraining's binary_logloss: 0.11304\tvalid_1's auc: 0.829955\tvalid_1's binary_logloss: 0.136178\n",
            "[61]\ttraining's auc: 0.909747\ttraining's binary_logloss: 0.112806\tvalid_1's auc: 0.829687\tvalid_1's binary_logloss: 0.136219\n",
            "[62]\ttraining's auc: 0.910294\ttraining's binary_logloss: 0.112605\tvalid_1's auc: 0.829611\tvalid_1's binary_logloss: 0.136231\n",
            "[63]\ttraining's auc: 0.911068\ttraining's binary_logloss: 0.112328\tvalid_1's auc: 0.829479\tvalid_1's binary_logloss: 0.136271\n",
            "[64]\ttraining's auc: 0.911637\ttraining's binary_logloss: 0.112058\tvalid_1's auc: 0.829545\tvalid_1's binary_logloss: 0.136236\n",
            "[65]\ttraining's auc: 0.911934\ttraining's binary_logloss: 0.111894\tvalid_1's auc: 0.829147\tvalid_1's binary_logloss: 0.136292\n",
            "[66]\ttraining's auc: 0.912982\ttraining's binary_logloss: 0.11157\tvalid_1's auc: 0.828913\tvalid_1's binary_logloss: 0.13634\n",
            "[67]\ttraining's auc: 0.91337\ttraining's binary_logloss: 0.111352\tvalid_1's auc: 0.828923\tvalid_1's binary_logloss: 0.136346\n",
            "[68]\ttraining's auc: 0.914025\ttraining's binary_logloss: 0.111165\tvalid_1's auc: 0.828986\tvalid_1's binary_logloss: 0.136329\n",
            "[69]\ttraining's auc: 0.914231\ttraining's binary_logloss: 0.111021\tvalid_1's auc: 0.828838\tvalid_1's binary_logloss: 0.136358\n",
            "[70]\ttraining's auc: 0.914586\ttraining's binary_logloss: 0.110838\tvalid_1's auc: 0.828704\tvalid_1's binary_logloss: 0.136385\n",
            "[71]\ttraining's auc: 0.914938\ttraining's binary_logloss: 0.110653\tvalid_1's auc: 0.828564\tvalid_1's binary_logloss: 0.136431\n",
            "[72]\ttraining's auc: 0.915365\ttraining's binary_logloss: 0.110453\tvalid_1's auc: 0.828652\tvalid_1's binary_logloss: 0.136418\n",
            "[73]\ttraining's auc: 0.915707\ttraining's binary_logloss: 0.110283\tvalid_1's auc: 0.828707\tvalid_1's binary_logloss: 0.136407\n",
            "[74]\ttraining's auc: 0.916108\ttraining's binary_logloss: 0.110086\tvalid_1's auc: 0.828516\tvalid_1's binary_logloss: 0.13644\n",
            "[75]\ttraining's auc: 0.916438\ttraining's binary_logloss: 0.10992\tvalid_1's auc: 0.828286\tvalid_1's binary_logloss: 0.136493\n",
            "[76]\ttraining's auc: 0.916602\ttraining's binary_logloss: 0.109791\tvalid_1's auc: 0.828097\tvalid_1's binary_logloss: 0.136556\n",
            "[77]\ttraining's auc: 0.916958\ttraining's binary_logloss: 0.109616\tvalid_1's auc: 0.827586\tvalid_1's binary_logloss: 0.136627\n",
            "[78]\ttraining's auc: 0.917577\ttraining's binary_logloss: 0.10942\tvalid_1's auc: 0.827815\tvalid_1's binary_logloss: 0.136599\n",
            "[79]\ttraining's auc: 0.917889\ttraining's binary_logloss: 0.109262\tvalid_1's auc: 0.827722\tvalid_1's binary_logloss: 0.136629\n",
            "[80]\ttraining's auc: 0.918384\ttraining's binary_logloss: 0.109061\tvalid_1's auc: 0.827782\tvalid_1's binary_logloss: 0.136643\n",
            "[81]\ttraining's auc: 0.918517\ttraining's binary_logloss: 0.108947\tvalid_1's auc: 0.827569\tvalid_1's binary_logloss: 0.136707\n",
            "[82]\ttraining's auc: 0.918703\ttraining's binary_logloss: 0.10884\tvalid_1's auc: 0.827592\tvalid_1's binary_logloss: 0.136724\n",
            "[83]\ttraining's auc: 0.920017\ttraining's binary_logloss: 0.108568\tvalid_1's auc: 0.827287\tvalid_1's binary_logloss: 0.136777\n",
            "[84]\ttraining's auc: 0.920763\ttraining's binary_logloss: 0.108404\tvalid_1's auc: 0.827097\tvalid_1's binary_logloss: 0.13682\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 82%|████████▏ | 41/50 [20:50<05:00, 33.36s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.160584\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.155858\n",
            "[2]\ttraining's auc: 0.826338\ttraining's binary_logloss: 0.15601\tvalid_1's auc: 0.81573\tvalid_1's binary_logloss: 0.152353\n",
            "[3]\ttraining's auc: 0.83263\ttraining's binary_logloss: 0.152347\tvalid_1's auc: 0.817808\tvalid_1's binary_logloss: 0.149533\n",
            "[4]\ttraining's auc: 0.834842\ttraining's binary_logloss: 0.149443\tvalid_1's auc: 0.81992\tvalid_1's binary_logloss: 0.147215\n",
            "[5]\ttraining's auc: 0.841414\ttraining's binary_logloss: 0.146985\tvalid_1's auc: 0.823578\tvalid_1's binary_logloss: 0.145335\n",
            "[6]\ttraining's auc: 0.844084\ttraining's binary_logloss: 0.144829\tvalid_1's auc: 0.824781\tvalid_1's binary_logloss: 0.143759\n",
            "[7]\ttraining's auc: 0.848872\ttraining's binary_logloss: 0.142884\tvalid_1's auc: 0.828075\tvalid_1's binary_logloss: 0.142323\n",
            "[8]\ttraining's auc: 0.851452\ttraining's binary_logloss: 0.141221\tvalid_1's auc: 0.828993\tvalid_1's binary_logloss: 0.141158\n",
            "[9]\ttraining's auc: 0.853131\ttraining's binary_logloss: 0.139738\tvalid_1's auc: 0.829315\tvalid_1's binary_logloss: 0.140061\n",
            "[10]\ttraining's auc: 0.856264\ttraining's binary_logloss: 0.138375\tvalid_1's auc: 0.831975\tvalid_1's binary_logloss: 0.139106\n",
            "[11]\ttraining's auc: 0.857768\ttraining's binary_logloss: 0.137088\tvalid_1's auc: 0.831365\tvalid_1's binary_logloss: 0.138363\n",
            "[12]\ttraining's auc: 0.858863\ttraining's binary_logloss: 0.135962\tvalid_1's auc: 0.831395\tvalid_1's binary_logloss: 0.137657\n",
            "[13]\ttraining's auc: 0.861016\ttraining's binary_logloss: 0.134901\tvalid_1's auc: 0.832647\tvalid_1's binary_logloss: 0.136978\n",
            "[14]\ttraining's auc: 0.862642\ttraining's binary_logloss: 0.133936\tvalid_1's auc: 0.832508\tvalid_1's binary_logloss: 0.136392\n",
            "[15]\ttraining's auc: 0.865369\ttraining's binary_logloss: 0.132974\tvalid_1's auc: 0.833538\tvalid_1's binary_logloss: 0.135861\n",
            "[16]\ttraining's auc: 0.8672\ttraining's binary_logloss: 0.132101\tvalid_1's auc: 0.833395\tvalid_1's binary_logloss: 0.13538\n",
            "[17]\ttraining's auc: 0.868509\ttraining's binary_logloss: 0.131313\tvalid_1's auc: 0.833499\tvalid_1's binary_logloss: 0.134965\n",
            "[18]\ttraining's auc: 0.870672\ttraining's binary_logloss: 0.130484\tvalid_1's auc: 0.83395\tvalid_1's binary_logloss: 0.134571\n",
            "[19]\ttraining's auc: 0.872322\ttraining's binary_logloss: 0.129779\tvalid_1's auc: 0.833739\tvalid_1's binary_logloss: 0.134299\n",
            "[20]\ttraining's auc: 0.872952\ttraining's binary_logloss: 0.129147\tvalid_1's auc: 0.833899\tvalid_1's binary_logloss: 0.133976\n",
            "[21]\ttraining's auc: 0.873816\ttraining's binary_logloss: 0.128537\tvalid_1's auc: 0.833822\tvalid_1's binary_logloss: 0.133685\n",
            "[22]\ttraining's auc: 0.874746\ttraining's binary_logloss: 0.127938\tvalid_1's auc: 0.834512\tvalid_1's binary_logloss: 0.133383\n",
            "[23]\ttraining's auc: 0.875619\ttraining's binary_logloss: 0.127345\tvalid_1's auc: 0.834274\tvalid_1's binary_logloss: 0.13317\n",
            "[24]\ttraining's auc: 0.877535\ttraining's binary_logloss: 0.126757\tvalid_1's auc: 0.83477\tvalid_1's binary_logloss: 0.132981\n",
            "[25]\ttraining's auc: 0.878768\ttraining's binary_logloss: 0.126214\tvalid_1's auc: 0.834922\tvalid_1's binary_logloss: 0.132759\n",
            "[26]\ttraining's auc: 0.879764\ttraining's binary_logloss: 0.125666\tvalid_1's auc: 0.835061\tvalid_1's binary_logloss: 0.132613\n",
            "[27]\ttraining's auc: 0.880644\ttraining's binary_logloss: 0.125213\tvalid_1's auc: 0.834945\tvalid_1's binary_logloss: 0.132469\n",
            "[28]\ttraining's auc: 0.881186\ttraining's binary_logloss: 0.124768\tvalid_1's auc: 0.834945\tvalid_1's binary_logloss: 0.132338\n",
            "[29]\ttraining's auc: 0.882038\ttraining's binary_logloss: 0.124335\tvalid_1's auc: 0.834435\tvalid_1's binary_logloss: 0.132246\n",
            "[30]\ttraining's auc: 0.883397\ttraining's binary_logloss: 0.123911\tvalid_1's auc: 0.834635\tvalid_1's binary_logloss: 0.132134\n",
            "[31]\ttraining's auc: 0.884314\ttraining's binary_logloss: 0.123497\tvalid_1's auc: 0.835008\tvalid_1's binary_logloss: 0.132\n",
            "[32]\ttraining's auc: 0.886041\ttraining's binary_logloss: 0.12302\tvalid_1's auc: 0.835183\tvalid_1's binary_logloss: 0.131934\n",
            "[33]\ttraining's auc: 0.88686\ttraining's binary_logloss: 0.12262\tvalid_1's auc: 0.835544\tvalid_1's binary_logloss: 0.131828\n",
            "[34]\ttraining's auc: 0.887523\ttraining's binary_logloss: 0.122288\tvalid_1's auc: 0.835304\tvalid_1's binary_logloss: 0.131787\n",
            "[35]\ttraining's auc: 0.888302\ttraining's binary_logloss: 0.121928\tvalid_1's auc: 0.835572\tvalid_1's binary_logloss: 0.131701\n",
            "[36]\ttraining's auc: 0.889178\ttraining's binary_logloss: 0.121564\tvalid_1's auc: 0.835638\tvalid_1's binary_logloss: 0.131629\n",
            "[37]\ttraining's auc: 0.89007\ttraining's binary_logloss: 0.121211\tvalid_1's auc: 0.835351\tvalid_1's binary_logloss: 0.131585\n",
            "[38]\ttraining's auc: 0.890945\ttraining's binary_logloss: 0.120864\tvalid_1's auc: 0.835774\tvalid_1's binary_logloss: 0.131494\n",
            "[39]\ttraining's auc: 0.891646\ttraining's binary_logloss: 0.120544\tvalid_1's auc: 0.835896\tvalid_1's binary_logloss: 0.131466\n",
            "[40]\ttraining's auc: 0.892799\ttraining's binary_logloss: 0.1202\tvalid_1's auc: 0.83567\tvalid_1's binary_logloss: 0.131455\n",
            "[41]\ttraining's auc: 0.893446\ttraining's binary_logloss: 0.11991\tvalid_1's auc: 0.835756\tvalid_1's binary_logloss: 0.131397\n",
            "[42]\ttraining's auc: 0.894131\ttraining's binary_logloss: 0.119608\tvalid_1's auc: 0.83544\tvalid_1's binary_logloss: 0.131408\n",
            "[43]\ttraining's auc: 0.895081\ttraining's binary_logloss: 0.119312\tvalid_1's auc: 0.83544\tvalid_1's binary_logloss: 0.131374\n",
            "[44]\ttraining's auc: 0.895728\ttraining's binary_logloss: 0.119031\tvalid_1's auc: 0.835278\tvalid_1's binary_logloss: 0.131351\n",
            "[45]\ttraining's auc: 0.896362\ttraining's binary_logloss: 0.118741\tvalid_1's auc: 0.835413\tvalid_1's binary_logloss: 0.131334\n",
            "[46]\ttraining's auc: 0.897452\ttraining's binary_logloss: 0.118426\tvalid_1's auc: 0.835497\tvalid_1's binary_logloss: 0.131283\n",
            "[47]\ttraining's auc: 0.899038\ttraining's binary_logloss: 0.118112\tvalid_1's auc: 0.835424\tvalid_1's binary_logloss: 0.131264\n",
            "[48]\ttraining's auc: 0.899516\ttraining's binary_logloss: 0.117862\tvalid_1's auc: 0.835494\tvalid_1's binary_logloss: 0.131228\n",
            "[49]\ttraining's auc: 0.900691\ttraining's binary_logloss: 0.11757\tvalid_1's auc: 0.835481\tvalid_1's binary_logloss: 0.131212\n",
            "[50]\ttraining's auc: 0.901449\ttraining's binary_logloss: 0.117265\tvalid_1's auc: 0.835165\tvalid_1's binary_logloss: 0.131241\n",
            "[51]\ttraining's auc: 0.902554\ttraining's binary_logloss: 0.116975\tvalid_1's auc: 0.835212\tvalid_1's binary_logloss: 0.131224\n",
            "[52]\ttraining's auc: 0.903707\ttraining's binary_logloss: 0.116631\tvalid_1's auc: 0.835429\tvalid_1's binary_logloss: 0.131176\n",
            "[53]\ttraining's auc: 0.904148\ttraining's binary_logloss: 0.116416\tvalid_1's auc: 0.835471\tvalid_1's binary_logloss: 0.13116\n",
            "[54]\ttraining's auc: 0.904868\ttraining's binary_logloss: 0.116133\tvalid_1's auc: 0.835347\tvalid_1's binary_logloss: 0.131177\n",
            "[55]\ttraining's auc: 0.905442\ttraining's binary_logloss: 0.115906\tvalid_1's auc: 0.835256\tvalid_1's binary_logloss: 0.131188\n",
            "[56]\ttraining's auc: 0.905955\ttraining's binary_logloss: 0.115644\tvalid_1's auc: 0.835299\tvalid_1's binary_logloss: 0.131179\n",
            "[57]\ttraining's auc: 0.906432\ttraining's binary_logloss: 0.115407\tvalid_1's auc: 0.835217\tvalid_1's binary_logloss: 0.131211\n",
            "[58]\ttraining's auc: 0.906753\ttraining's binary_logloss: 0.115216\tvalid_1's auc: 0.835132\tvalid_1's binary_logloss: 0.131218\n",
            "[59]\ttraining's auc: 0.907112\ttraining's binary_logloss: 0.115044\tvalid_1's auc: 0.835207\tvalid_1's binary_logloss: 0.131199\n",
            "[60]\ttraining's auc: 0.907879\ttraining's binary_logloss: 0.114764\tvalid_1's auc: 0.834865\tvalid_1's binary_logloss: 0.131258\n",
            "[61]\ttraining's auc: 0.908604\ttraining's binary_logloss: 0.114463\tvalid_1's auc: 0.834793\tvalid_1's binary_logloss: 0.131257\n",
            "[62]\ttraining's auc: 0.908971\ttraining's binary_logloss: 0.114307\tvalid_1's auc: 0.834718\tvalid_1's binary_logloss: 0.131261\n",
            "[63]\ttraining's auc: 0.909366\ttraining's binary_logloss: 0.114079\tvalid_1's auc: 0.8348\tvalid_1's binary_logloss: 0.131249\n",
            "[64]\ttraining's auc: 0.909782\ttraining's binary_logloss: 0.113856\tvalid_1's auc: 0.834955\tvalid_1's binary_logloss: 0.13118\n",
            "[65]\ttraining's auc: 0.910264\ttraining's binary_logloss: 0.113658\tvalid_1's auc: 0.834822\tvalid_1's binary_logloss: 0.131191\n",
            "[66]\ttraining's auc: 0.910856\ttraining's binary_logloss: 0.1134\tvalid_1's auc: 0.834466\tvalid_1's binary_logloss: 0.131271\n",
            "[67]\ttraining's auc: 0.911153\ttraining's binary_logloss: 0.113186\tvalid_1's auc: 0.834504\tvalid_1's binary_logloss: 0.13126\n",
            "[68]\ttraining's auc: 0.911499\ttraining's binary_logloss: 0.112979\tvalid_1's auc: 0.834397\tvalid_1's binary_logloss: 0.1313\n",
            "[69]\ttraining's auc: 0.91195\ttraining's binary_logloss: 0.112778\tvalid_1's auc: 0.834371\tvalid_1's binary_logloss: 0.131318\n",
            " 82%|████████▏ | 41/50 [20:59<05:00, 33.36s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.157114\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.163112\n",
            "[2]\ttraining's auc: 0.833005\ttraining's binary_logloss: 0.152664\tvalid_1's auc: 0.815241\tvalid_1's binary_logloss: 0.15911\n",
            "[3]\ttraining's auc: 0.836909\ttraining's binary_logloss: 0.149213\tvalid_1's auc: 0.817546\tvalid_1's binary_logloss: 0.156113\n",
            "[4]\ttraining's auc: 0.839679\ttraining's binary_logloss: 0.146393\tvalid_1's auc: 0.818419\tvalid_1's binary_logloss: 0.15376\n",
            "[5]\ttraining's auc: 0.845352\ttraining's binary_logloss: 0.143802\tvalid_1's auc: 0.822915\tvalid_1's binary_logloss: 0.151678\n",
            "[6]\ttraining's auc: 0.84956\ttraining's binary_logloss: 0.141665\tvalid_1's auc: 0.825715\tvalid_1's binary_logloss: 0.149964\n",
            "[7]\ttraining's auc: 0.851143\ttraining's binary_logloss: 0.139808\tvalid_1's auc: 0.827322\tvalid_1's binary_logloss: 0.148387\n",
            "[8]\ttraining's auc: 0.853128\ttraining's binary_logloss: 0.1382\tvalid_1's auc: 0.827722\tvalid_1's binary_logloss: 0.14714\n",
            "[9]\ttraining's auc: 0.854764\ttraining's binary_logloss: 0.13667\tvalid_1's auc: 0.828726\tvalid_1's binary_logloss: 0.14597\n",
            "[10]\ttraining's auc: 0.855987\ttraining's binary_logloss: 0.135343\tvalid_1's auc: 0.828948\tvalid_1's binary_logloss: 0.144979\n",
            "[11]\ttraining's auc: 0.857359\ttraining's binary_logloss: 0.134129\tvalid_1's auc: 0.82964\tvalid_1's binary_logloss: 0.144041\n",
            "[12]\ttraining's auc: 0.859178\ttraining's binary_logloss: 0.133013\tvalid_1's auc: 0.830638\tvalid_1's binary_logloss: 0.14317\n",
            "[13]\ttraining's auc: 0.860521\ttraining's binary_logloss: 0.131986\tvalid_1's auc: 0.83066\tvalid_1's binary_logloss: 0.142475\n",
            "[14]\ttraining's auc: 0.86193\ttraining's binary_logloss: 0.131042\tvalid_1's auc: 0.830498\tvalid_1's binary_logloss: 0.141924\n",
            "[15]\ttraining's auc: 0.863904\ttraining's binary_logloss: 0.130164\tvalid_1's auc: 0.830753\tvalid_1's binary_logloss: 0.141355\n",
            "[16]\ttraining's auc: 0.865352\ttraining's binary_logloss: 0.129392\tvalid_1's auc: 0.831176\tvalid_1's binary_logloss: 0.140823\n",
            "[17]\ttraining's auc: 0.868194\ttraining's binary_logloss: 0.128577\tvalid_1's auc: 0.831277\tvalid_1's binary_logloss: 0.140412\n",
            "[18]\ttraining's auc: 0.870396\ttraining's binary_logloss: 0.12781\tvalid_1's auc: 0.833111\tvalid_1's binary_logloss: 0.140015\n",
            "[19]\ttraining's auc: 0.871383\ttraining's binary_logloss: 0.127182\tvalid_1's auc: 0.833547\tvalid_1's binary_logloss: 0.139608\n",
            "[20]\ttraining's auc: 0.873804\ttraining's binary_logloss: 0.126524\tvalid_1's auc: 0.834103\tvalid_1's binary_logloss: 0.13929\n",
            "[21]\ttraining's auc: 0.874548\ttraining's binary_logloss: 0.125944\tvalid_1's auc: 0.834122\tvalid_1's binary_logloss: 0.139005\n",
            "[22]\ttraining's auc: 0.875161\ttraining's binary_logloss: 0.125399\tvalid_1's auc: 0.834495\tvalid_1's binary_logloss: 0.138724\n",
            "[23]\ttraining's auc: 0.876667\ttraining's binary_logloss: 0.124825\tvalid_1's auc: 0.835537\tvalid_1's binary_logloss: 0.138437\n",
            "[24]\ttraining's auc: 0.878509\ttraining's binary_logloss: 0.124261\tvalid_1's auc: 0.83525\tvalid_1's binary_logloss: 0.138257\n",
            "[25]\ttraining's auc: 0.879261\ttraining's binary_logloss: 0.123762\tvalid_1's auc: 0.835194\tvalid_1's binary_logloss: 0.138049\n",
            "[26]\ttraining's auc: 0.880948\ttraining's binary_logloss: 0.123248\tvalid_1's auc: 0.835613\tvalid_1's binary_logloss: 0.137877\n",
            "[27]\ttraining's auc: 0.882169\ttraining's binary_logloss: 0.122746\tvalid_1's auc: 0.835802\tvalid_1's binary_logloss: 0.137713\n",
            "[28]\ttraining's auc: 0.883626\ttraining's binary_logloss: 0.122241\tvalid_1's auc: 0.83539\tvalid_1's binary_logloss: 0.137628\n",
            "[29]\ttraining's auc: 0.884756\ttraining's binary_logloss: 0.121795\tvalid_1's auc: 0.835255\tvalid_1's binary_logloss: 0.137479\n",
            "[30]\ttraining's auc: 0.885697\ttraining's binary_logloss: 0.121361\tvalid_1's auc: 0.835848\tvalid_1's binary_logloss: 0.137298\n",
            "[31]\ttraining's auc: 0.886652\ttraining's binary_logloss: 0.120952\tvalid_1's auc: 0.836034\tvalid_1's binary_logloss: 0.13716\n",
            "[32]\ttraining's auc: 0.887594\ttraining's binary_logloss: 0.120547\tvalid_1's auc: 0.836208\tvalid_1's binary_logloss: 0.137045\n",
            "[33]\ttraining's auc: 0.888763\ttraining's binary_logloss: 0.120135\tvalid_1's auc: 0.836597\tvalid_1's binary_logloss: 0.13692\n",
            "[34]\ttraining's auc: 0.88993\ttraining's binary_logloss: 0.119721\tvalid_1's auc: 0.835992\tvalid_1's binary_logloss: 0.136893\n",
            "[35]\ttraining's auc: 0.890959\ttraining's binary_logloss: 0.119377\tvalid_1's auc: 0.83611\tvalid_1's binary_logloss: 0.136817\n",
            "[36]\ttraining's auc: 0.891711\ttraining's binary_logloss: 0.119026\tvalid_1's auc: 0.835682\tvalid_1's binary_logloss: 0.136821\n",
            "[37]\ttraining's auc: 0.892345\ttraining's binary_logloss: 0.118707\tvalid_1's auc: 0.835628\tvalid_1's binary_logloss: 0.136778\n",
            "[38]\ttraining's auc: 0.892908\ttraining's binary_logloss: 0.118386\tvalid_1's auc: 0.835891\tvalid_1's binary_logloss: 0.136674\n",
            "[39]\ttraining's auc: 0.893652\ttraining's binary_logloss: 0.118039\tvalid_1's auc: 0.836022\tvalid_1's binary_logloss: 0.136628\n",
            "[40]\ttraining's auc: 0.894786\ttraining's binary_logloss: 0.117666\tvalid_1's auc: 0.836171\tvalid_1's binary_logloss: 0.136586\n",
            "[41]\ttraining's auc: 0.895825\ttraining's binary_logloss: 0.117363\tvalid_1's auc: 0.83609\tvalid_1's binary_logloss: 0.136562\n",
            "[42]\ttraining's auc: 0.896836\ttraining's binary_logloss: 0.117055\tvalid_1's auc: 0.835871\tvalid_1's binary_logloss: 0.136548\n",
            "[43]\ttraining's auc: 0.897873\ttraining's binary_logloss: 0.116737\tvalid_1's auc: 0.836181\tvalid_1's binary_logloss: 0.136444\n",
            "[44]\ttraining's auc: 0.898587\ttraining's binary_logloss: 0.116456\tvalid_1's auc: 0.835822\tvalid_1's binary_logloss: 0.136455\n",
            "[45]\ttraining's auc: 0.899168\ttraining's binary_logloss: 0.116201\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.136454\n",
            "[46]\ttraining's auc: 0.899831\ttraining's binary_logloss: 0.11594\tvalid_1's auc: 0.835678\tvalid_1's binary_logloss: 0.136449\n",
            "[47]\ttraining's auc: 0.900312\ttraining's binary_logloss: 0.115711\tvalid_1's auc: 0.835829\tvalid_1's binary_logloss: 0.136398\n",
            "[48]\ttraining's auc: 0.901045\ttraining's binary_logloss: 0.115428\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.136386\n",
            "[49]\ttraining's auc: 0.901555\ttraining's binary_logloss: 0.115223\tvalid_1's auc: 0.835708\tvalid_1's binary_logloss: 0.136378\n",
            "[50]\ttraining's auc: 0.901973\ttraining's binary_logloss: 0.114997\tvalid_1's auc: 0.835882\tvalid_1's binary_logloss: 0.136303\n",
            "[51]\ttraining's auc: 0.902773\ttraining's binary_logloss: 0.114769\tvalid_1's auc: 0.835833\tvalid_1's binary_logloss: 0.136306\n",
            "[52]\ttraining's auc: 0.903515\ttraining's binary_logloss: 0.114425\tvalid_1's auc: 0.835947\tvalid_1's binary_logloss: 0.13631\n",
            "[53]\ttraining's auc: 0.904178\ttraining's binary_logloss: 0.1142\tvalid_1's auc: 0.835944\tvalid_1's binary_logloss: 0.136326\n",
            "[54]\ttraining's auc: 0.905029\ttraining's binary_logloss: 0.113889\tvalid_1's auc: 0.835773\tvalid_1's binary_logloss: 0.13629\n",
            "[55]\ttraining's auc: 0.905898\ttraining's binary_logloss: 0.113529\tvalid_1's auc: 0.83579\tvalid_1's binary_logloss: 0.136263\n",
            "[56]\ttraining's auc: 0.906276\ttraining's binary_logloss: 0.113338\tvalid_1's auc: 0.83587\tvalid_1's binary_logloss: 0.136247\n",
            "[57]\ttraining's auc: 0.907026\ttraining's binary_logloss: 0.113063\tvalid_1's auc: 0.835795\tvalid_1's binary_logloss: 0.136244\n",
            "[58]\ttraining's auc: 0.907313\ttraining's binary_logloss: 0.112883\tvalid_1's auc: 0.835865\tvalid_1's binary_logloss: 0.13624\n",
            "[59]\ttraining's auc: 0.907747\ttraining's binary_logloss: 0.112705\tvalid_1's auc: 0.836105\tvalid_1's binary_logloss: 0.136216\n",
            "[60]\ttraining's auc: 0.908376\ttraining's binary_logloss: 0.112458\tvalid_1's auc: 0.835874\tvalid_1's binary_logloss: 0.136275\n",
            "[61]\ttraining's auc: 0.908876\ttraining's binary_logloss: 0.112213\tvalid_1's auc: 0.835859\tvalid_1's binary_logloss: 0.136282\n",
            "[62]\ttraining's auc: 0.90922\ttraining's binary_logloss: 0.112065\tvalid_1's auc: 0.835911\tvalid_1's binary_logloss: 0.136267\n",
            "[63]\ttraining's auc: 0.909893\ttraining's binary_logloss: 0.111799\tvalid_1's auc: 0.835771\tvalid_1's binary_logloss: 0.136294\n",
            " 84%|████████▍ | 42/50 [21:08<04:22, 32.80s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.149478\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.15318\n",
            "[2]\ttraining's auc: 0.838093\ttraining's binary_logloss: 0.142888\tvalid_1's auc: 0.81002\tvalid_1's binary_logloss: 0.14828\n",
            "[3]\ttraining's auc: 0.848449\ttraining's binary_logloss: 0.138385\tvalid_1's auc: 0.816775\tvalid_1's binary_logloss: 0.145141\n",
            "[4]\ttraining's auc: 0.852483\ttraining's binary_logloss: 0.135005\tvalid_1's auc: 0.817723\tvalid_1's binary_logloss: 0.143108\n",
            "[5]\ttraining's auc: 0.856901\ttraining's binary_logloss: 0.13222\tvalid_1's auc: 0.818523\tvalid_1's binary_logloss: 0.141684\n",
            "[6]\ttraining's auc: 0.863962\ttraining's binary_logloss: 0.130096\tvalid_1's auc: 0.823179\tvalid_1's binary_logloss: 0.140289\n",
            "[7]\ttraining's auc: 0.868399\ttraining's binary_logloss: 0.128306\tvalid_1's auc: 0.824643\tvalid_1's binary_logloss: 0.139288\n",
            "[8]\ttraining's auc: 0.871388\ttraining's binary_logloss: 0.126581\tvalid_1's auc: 0.826086\tvalid_1's binary_logloss: 0.138439\n",
            "[9]\ttraining's auc: 0.87331\ttraining's binary_logloss: 0.125275\tvalid_1's auc: 0.8256\tvalid_1's binary_logloss: 0.137948\n",
            "[10]\ttraining's auc: 0.876366\ttraining's binary_logloss: 0.124055\tvalid_1's auc: 0.825019\tvalid_1's binary_logloss: 0.13775\n",
            "[11]\ttraining's auc: 0.879828\ttraining's binary_logloss: 0.122807\tvalid_1's auc: 0.825038\tvalid_1's binary_logloss: 0.137573\n",
            "[12]\ttraining's auc: 0.882413\ttraining's binary_logloss: 0.121789\tvalid_1's auc: 0.825185\tvalid_1's binary_logloss: 0.137365\n",
            "[13]\ttraining's auc: 0.885984\ttraining's binary_logloss: 0.120638\tvalid_1's auc: 0.824545\tvalid_1's binary_logloss: 0.13731\n",
            "[14]\ttraining's auc: 0.887865\ttraining's binary_logloss: 0.119684\tvalid_1's auc: 0.824144\tvalid_1's binary_logloss: 0.137425\n",
            "[15]\ttraining's auc: 0.891259\ttraining's binary_logloss: 0.118684\tvalid_1's auc: 0.825776\tvalid_1's binary_logloss: 0.137138\n",
            "[16]\ttraining's auc: 0.893903\ttraining's binary_logloss: 0.117846\tvalid_1's auc: 0.825574\tvalid_1's binary_logloss: 0.13716\n",
            "[17]\ttraining's auc: 0.896832\ttraining's binary_logloss: 0.116966\tvalid_1's auc: 0.826598\tvalid_1's binary_logloss: 0.136932\n",
            "[18]\ttraining's auc: 0.89935\ttraining's binary_logloss: 0.116213\tvalid_1's auc: 0.82561\tvalid_1's binary_logloss: 0.137035\n",
            "[19]\ttraining's auc: 0.900732\ttraining's binary_logloss: 0.115568\tvalid_1's auc: 0.825295\tvalid_1's binary_logloss: 0.137116\n",
            "[20]\ttraining's auc: 0.902272\ttraining's binary_logloss: 0.114902\tvalid_1's auc: 0.82568\tvalid_1's binary_logloss: 0.137165\n",
            "[21]\ttraining's auc: 0.903491\ttraining's binary_logloss: 0.114259\tvalid_1's auc: 0.82537\tvalid_1's binary_logloss: 0.137227\n",
            "[22]\ttraining's auc: 0.904641\ttraining's binary_logloss: 0.113718\tvalid_1's auc: 0.8253\tvalid_1's binary_logloss: 0.137239\n",
            "[23]\ttraining's auc: 0.906071\ttraining's binary_logloss: 0.113205\tvalid_1's auc: 0.82486\tvalid_1's binary_logloss: 0.137364\n",
            "[24]\ttraining's auc: 0.907658\ttraining's binary_logloss: 0.112581\tvalid_1's auc: 0.824308\tvalid_1's binary_logloss: 0.13748\n",
            "[25]\ttraining's auc: 0.908831\ttraining's binary_logloss: 0.112041\tvalid_1's auc: 0.82385\tvalid_1's binary_logloss: 0.137642\n",
            "[26]\ttraining's auc: 0.909795\ttraining's binary_logloss: 0.111533\tvalid_1's auc: 0.823682\tvalid_1's binary_logloss: 0.13772\n",
            "[27]\ttraining's auc: 0.911098\ttraining's binary_logloss: 0.110972\tvalid_1's auc: 0.823602\tvalid_1's binary_logloss: 0.137711\n",
            "[28]\ttraining's auc: 0.912258\ttraining's binary_logloss: 0.110436\tvalid_1's auc: 0.823964\tvalid_1's binary_logloss: 0.137678\n",
            "[29]\ttraining's auc: 0.914086\ttraining's binary_logloss: 0.109999\tvalid_1's auc: 0.823598\tvalid_1's binary_logloss: 0.137802\n",
            "[30]\ttraining's auc: 0.915131\ttraining's binary_logloss: 0.109533\tvalid_1's auc: 0.823118\tvalid_1's binary_logloss: 0.137909\n",
            "[31]\ttraining's auc: 0.9159\ttraining's binary_logloss: 0.109187\tvalid_1's auc: 0.822814\tvalid_1's binary_logloss: 0.138011\n",
            "[32]\ttraining's auc: 0.916495\ttraining's binary_logloss: 0.108815\tvalid_1's auc: 0.822508\tvalid_1's binary_logloss: 0.138106\n",
            "[33]\ttraining's auc: 0.917619\ttraining's binary_logloss: 0.108464\tvalid_1's auc: 0.822339\tvalid_1's binary_logloss: 0.138175\n",
            "[34]\ttraining's auc: 0.918927\ttraining's binary_logloss: 0.107874\tvalid_1's auc: 0.822241\tvalid_1's binary_logloss: 0.138266\n",
            "[35]\ttraining's auc: 0.919747\ttraining's binary_logloss: 0.107461\tvalid_1's auc: 0.822043\tvalid_1's binary_logloss: 0.138296\n",
            "[36]\ttraining's auc: 0.920626\ttraining's binary_logloss: 0.107096\tvalid_1's auc: 0.821455\tvalid_1's binary_logloss: 0.138636\n",
            "[37]\ttraining's auc: 0.922134\ttraining's binary_logloss: 0.106531\tvalid_1's auc: 0.821402\tvalid_1's binary_logloss: 0.13872\n",
            "[38]\ttraining's auc: 0.924319\ttraining's binary_logloss: 0.105918\tvalid_1's auc: 0.82086\tvalid_1's binary_logloss: 0.138867\n",
            "[39]\ttraining's auc: 0.92473\ttraining's binary_logloss: 0.105591\tvalid_1's auc: 0.820366\tvalid_1's binary_logloss: 0.138979\n",
            "[40]\ttraining's auc: 0.926067\ttraining's binary_logloss: 0.105026\tvalid_1's auc: 0.820029\tvalid_1's binary_logloss: 0.139075\n",
            "[41]\ttraining's auc: 0.926684\ttraining's binary_logloss: 0.104704\tvalid_1's auc: 0.81983\tvalid_1's binary_logloss: 0.139182\n",
            "[42]\ttraining's auc: 0.926989\ttraining's binary_logloss: 0.104456\tvalid_1's auc: 0.819938\tvalid_1's binary_logloss: 0.139192\n",
            "[43]\ttraining's auc: 0.927453\ttraining's binary_logloss: 0.104192\tvalid_1's auc: 0.8195\tvalid_1's binary_logloss: 0.13931\n",
            "[44]\ttraining's auc: 0.928133\ttraining's binary_logloss: 0.103786\tvalid_1's auc: 0.818918\tvalid_1's binary_logloss: 0.139449\n",
            "[45]\ttraining's auc: 0.929098\ttraining's binary_logloss: 0.103431\tvalid_1's auc: 0.818706\tvalid_1's binary_logloss: 0.13955\n",
            "[46]\ttraining's auc: 0.930063\ttraining's binary_logloss: 0.102921\tvalid_1's auc: 0.819739\tvalid_1's binary_logloss: 0.139343\n",
            "[47]\ttraining's auc: 0.930512\ttraining's binary_logloss: 0.102696\tvalid_1's auc: 0.819419\tvalid_1's binary_logloss: 0.139446\n",
            " 84%|████████▍ | 42/50 [21:15<04:22, 32.80s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.15195\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.149563\n",
            "[2]\ttraining's auc: 0.836114\ttraining's binary_logloss: 0.145133\tvalid_1's auc: 0.818462\tvalid_1's binary_logloss: 0.144492\n",
            "[3]\ttraining's auc: 0.847196\ttraining's binary_logloss: 0.140406\tvalid_1's auc: 0.823945\tvalid_1's binary_logloss: 0.141482\n",
            "[4]\ttraining's auc: 0.852609\ttraining's binary_logloss: 0.137038\tvalid_1's auc: 0.828755\tvalid_1's binary_logloss: 0.13918\n",
            "[5]\ttraining's auc: 0.855818\ttraining's binary_logloss: 0.134445\tvalid_1's auc: 0.828393\tvalid_1's binary_logloss: 0.137719\n",
            "[6]\ttraining's auc: 0.859102\ttraining's binary_logloss: 0.132228\tvalid_1's auc: 0.8276\tvalid_1's binary_logloss: 0.136703\n",
            "[7]\ttraining's auc: 0.865254\ttraining's binary_logloss: 0.130268\tvalid_1's auc: 0.828979\tvalid_1's binary_logloss: 0.135622\n",
            "[8]\ttraining's auc: 0.869075\ttraining's binary_logloss: 0.128659\tvalid_1's auc: 0.829592\tvalid_1's binary_logloss: 0.134984\n",
            "[9]\ttraining's auc: 0.872367\ttraining's binary_logloss: 0.12723\tvalid_1's auc: 0.829266\tvalid_1's binary_logloss: 0.134442\n",
            "[10]\ttraining's auc: 0.876055\ttraining's binary_logloss: 0.125867\tvalid_1's auc: 0.829546\tvalid_1's binary_logloss: 0.134157\n",
            "[11]\ttraining's auc: 0.877731\ttraining's binary_logloss: 0.124714\tvalid_1's auc: 0.829661\tvalid_1's binary_logloss: 0.13387\n",
            "[12]\ttraining's auc: 0.88171\ttraining's binary_logloss: 0.123602\tvalid_1's auc: 0.829418\tvalid_1's binary_logloss: 0.13367\n",
            "[13]\ttraining's auc: 0.885185\ttraining's binary_logloss: 0.122422\tvalid_1's auc: 0.829118\tvalid_1's binary_logloss: 0.133516\n",
            "[14]\ttraining's auc: 0.886977\ttraining's binary_logloss: 0.121597\tvalid_1's auc: 0.830026\tvalid_1's binary_logloss: 0.13325\n",
            "[15]\ttraining's auc: 0.888978\ttraining's binary_logloss: 0.120731\tvalid_1's auc: 0.830079\tvalid_1's binary_logloss: 0.133124\n",
            "[16]\ttraining's auc: 0.891218\ttraining's binary_logloss: 0.119789\tvalid_1's auc: 0.830812\tvalid_1's binary_logloss: 0.133003\n",
            "[17]\ttraining's auc: 0.892638\ttraining's binary_logloss: 0.118967\tvalid_1's auc: 0.830408\tvalid_1's binary_logloss: 0.133012\n",
            "[18]\ttraining's auc: 0.89449\ttraining's binary_logloss: 0.118259\tvalid_1's auc: 0.829915\tvalid_1's binary_logloss: 0.13301\n",
            "[19]\ttraining's auc: 0.897099\ttraining's binary_logloss: 0.117525\tvalid_1's auc: 0.828853\tvalid_1's binary_logloss: 0.133189\n",
            "[20]\ttraining's auc: 0.899692\ttraining's binary_logloss: 0.11692\tvalid_1's auc: 0.828973\tvalid_1's binary_logloss: 0.133155\n",
            "[21]\ttraining's auc: 0.901333\ttraining's binary_logloss: 0.116286\tvalid_1's auc: 0.829101\tvalid_1's binary_logloss: 0.133152\n",
            "[22]\ttraining's auc: 0.902446\ttraining's binary_logloss: 0.115714\tvalid_1's auc: 0.829568\tvalid_1's binary_logloss: 0.133116\n",
            "[23]\ttraining's auc: 0.904153\ttraining's binary_logloss: 0.115006\tvalid_1's auc: 0.829912\tvalid_1's binary_logloss: 0.133121\n",
            "[24]\ttraining's auc: 0.905296\ttraining's binary_logloss: 0.114418\tvalid_1's auc: 0.829434\tvalid_1's binary_logloss: 0.133212\n",
            "[25]\ttraining's auc: 0.906648\ttraining's binary_logloss: 0.113746\tvalid_1's auc: 0.829484\tvalid_1's binary_logloss: 0.133263\n",
            "[26]\ttraining's auc: 0.908149\ttraining's binary_logloss: 0.113296\tvalid_1's auc: 0.829974\tvalid_1's binary_logloss: 0.133205\n",
            "[27]\ttraining's auc: 0.90934\ttraining's binary_logloss: 0.112693\tvalid_1's auc: 0.830031\tvalid_1's binary_logloss: 0.133205\n",
            "[28]\ttraining's auc: 0.910034\ttraining's binary_logloss: 0.112299\tvalid_1's auc: 0.830309\tvalid_1's binary_logloss: 0.133144\n",
            "[29]\ttraining's auc: 0.91097\ttraining's binary_logloss: 0.111798\tvalid_1's auc: 0.830126\tvalid_1's binary_logloss: 0.133156\n",
            "[30]\ttraining's auc: 0.912201\ttraining's binary_logloss: 0.11121\tvalid_1's auc: 0.829555\tvalid_1's binary_logloss: 0.133277\n",
            "[31]\ttraining's auc: 0.913059\ttraining's binary_logloss: 0.110727\tvalid_1's auc: 0.830325\tvalid_1's binary_logloss: 0.133152\n",
            "[32]\ttraining's auc: 0.914038\ttraining's binary_logloss: 0.110277\tvalid_1's auc: 0.830318\tvalid_1's binary_logloss: 0.133222\n",
            "[33]\ttraining's auc: 0.915339\ttraining's binary_logloss: 0.109736\tvalid_1's auc: 0.829542\tvalid_1's binary_logloss: 0.133415\n",
            "[34]\ttraining's auc: 0.915853\ttraining's binary_logloss: 0.109399\tvalid_1's auc: 0.829397\tvalid_1's binary_logloss: 0.133408\n",
            "[35]\ttraining's auc: 0.917139\ttraining's binary_logloss: 0.109001\tvalid_1's auc: 0.828837\tvalid_1's binary_logloss: 0.133464\n",
            "[36]\ttraining's auc: 0.918318\ttraining's binary_logloss: 0.108564\tvalid_1's auc: 0.82894\tvalid_1's binary_logloss: 0.133552\n",
            "[37]\ttraining's auc: 0.920059\ttraining's binary_logloss: 0.107991\tvalid_1's auc: 0.828539\tvalid_1's binary_logloss: 0.133668\n",
            "[38]\ttraining's auc: 0.921026\ttraining's binary_logloss: 0.10748\tvalid_1's auc: 0.828851\tvalid_1's binary_logloss: 0.133636\n",
            "[39]\ttraining's auc: 0.922284\ttraining's binary_logloss: 0.106892\tvalid_1's auc: 0.828706\tvalid_1's binary_logloss: 0.133693\n",
            "[40]\ttraining's auc: 0.923052\ttraining's binary_logloss: 0.106509\tvalid_1's auc: 0.827889\tvalid_1's binary_logloss: 0.133852\n",
            "[41]\ttraining's auc: 0.923387\ttraining's binary_logloss: 0.10625\tvalid_1's auc: 0.827893\tvalid_1's binary_logloss: 0.133889\n",
            "[42]\ttraining's auc: 0.924245\ttraining's binary_logloss: 0.105763\tvalid_1's auc: 0.827852\tvalid_1's binary_logloss: 0.133964\n",
            "[43]\ttraining's auc: 0.924642\ttraining's binary_logloss: 0.105471\tvalid_1's auc: 0.827718\tvalid_1's binary_logloss: 0.133952\n",
            "[44]\ttraining's auc: 0.925334\ttraining's binary_logloss: 0.105136\tvalid_1's auc: 0.827805\tvalid_1's binary_logloss: 0.13398\n",
            "[45]\ttraining's auc: 0.925624\ttraining's binary_logloss: 0.104897\tvalid_1's auc: 0.827955\tvalid_1's binary_logloss: 0.13395\n",
            "[46]\ttraining's auc: 0.926283\ttraining's binary_logloss: 0.104559\tvalid_1's auc: 0.827404\tvalid_1's binary_logloss: 0.134097\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 84%|████████▍ | 42/50 [21:23<04:22, 32.80s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.148933\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.155911\n",
            "[2]\ttraining's auc: 0.838357\ttraining's binary_logloss: 0.14238\tvalid_1's auc: 0.821608\tvalid_1's binary_logloss: 0.150484\n",
            "[3]\ttraining's auc: 0.846168\ttraining's binary_logloss: 0.137816\tvalid_1's auc: 0.824569\tvalid_1's binary_logloss: 0.147244\n",
            "[4]\ttraining's auc: 0.851421\ttraining's binary_logloss: 0.134551\tvalid_1's auc: 0.828031\tvalid_1's binary_logloss: 0.144659\n",
            "[5]\ttraining's auc: 0.854178\ttraining's binary_logloss: 0.131949\tvalid_1's auc: 0.828389\tvalid_1's binary_logloss: 0.142828\n",
            "[6]\ttraining's auc: 0.861679\ttraining's binary_logloss: 0.129696\tvalid_1's auc: 0.830141\tvalid_1's binary_logloss: 0.141378\n",
            "[7]\ttraining's auc: 0.865485\ttraining's binary_logloss: 0.127832\tvalid_1's auc: 0.829661\tvalid_1's binary_logloss: 0.14047\n",
            "[8]\ttraining's auc: 0.869042\ttraining's binary_logloss: 0.126299\tvalid_1's auc: 0.832477\tvalid_1's binary_logloss: 0.139702\n",
            "[9]\ttraining's auc: 0.871667\ttraining's binary_logloss: 0.124973\tvalid_1's auc: 0.832836\tvalid_1's binary_logloss: 0.13916\n",
            "[10]\ttraining's auc: 0.873873\ttraining's binary_logloss: 0.12378\tvalid_1's auc: 0.833049\tvalid_1's binary_logloss: 0.138717\n",
            "[11]\ttraining's auc: 0.876144\ttraining's binary_logloss: 0.122739\tvalid_1's auc: 0.83317\tvalid_1's binary_logloss: 0.138314\n",
            "[12]\ttraining's auc: 0.878683\ttraining's binary_logloss: 0.121717\tvalid_1's auc: 0.833362\tvalid_1's binary_logloss: 0.137983\n",
            "[13]\ttraining's auc: 0.882354\ttraining's binary_logloss: 0.120636\tvalid_1's auc: 0.834\tvalid_1's binary_logloss: 0.137745\n",
            "[14]\ttraining's auc: 0.885006\ttraining's binary_logloss: 0.119649\tvalid_1's auc: 0.834019\tvalid_1's binary_logloss: 0.137642\n",
            "[15]\ttraining's auc: 0.887877\ttraining's binary_logloss: 0.118662\tvalid_1's auc: 0.83367\tvalid_1's binary_logloss: 0.137604\n",
            "[16]\ttraining's auc: 0.890702\ttraining's binary_logloss: 0.117776\tvalid_1's auc: 0.833082\tvalid_1's binary_logloss: 0.137688\n",
            "[17]\ttraining's auc: 0.892443\ttraining's binary_logloss: 0.11699\tvalid_1's auc: 0.833097\tvalid_1's binary_logloss: 0.137658\n",
            "[18]\ttraining's auc: 0.894421\ttraining's binary_logloss: 0.116268\tvalid_1's auc: 0.832203\tvalid_1's binary_logloss: 0.13778\n",
            "[19]\ttraining's auc: 0.896448\ttraining's binary_logloss: 0.115501\tvalid_1's auc: 0.831738\tvalid_1's binary_logloss: 0.137827\n",
            "[20]\ttraining's auc: 0.898936\ttraining's binary_logloss: 0.114814\tvalid_1's auc: 0.831391\tvalid_1's binary_logloss: 0.137881\n",
            "[21]\ttraining's auc: 0.900366\ttraining's binary_logloss: 0.114288\tvalid_1's auc: 0.831463\tvalid_1's binary_logloss: 0.137914\n",
            "[22]\ttraining's auc: 0.902452\ttraining's binary_logloss: 0.113542\tvalid_1's auc: 0.830574\tvalid_1's binary_logloss: 0.138118\n",
            "[23]\ttraining's auc: 0.904128\ttraining's binary_logloss: 0.112905\tvalid_1's auc: 0.830162\tvalid_1's binary_logloss: 0.138185\n",
            "[24]\ttraining's auc: 0.905045\ttraining's binary_logloss: 0.112347\tvalid_1's auc: 0.830072\tvalid_1's binary_logloss: 0.138228\n",
            "[25]\ttraining's auc: 0.906232\ttraining's binary_logloss: 0.111833\tvalid_1's auc: 0.829844\tvalid_1's binary_logloss: 0.138312\n",
            "[26]\ttraining's auc: 0.90736\ttraining's binary_logloss: 0.111334\tvalid_1's auc: 0.829382\tvalid_1's binary_logloss: 0.138402\n",
            "[27]\ttraining's auc: 0.90855\ttraining's binary_logloss: 0.110844\tvalid_1's auc: 0.82899\tvalid_1's binary_logloss: 0.138478\n",
            "[28]\ttraining's auc: 0.91076\ttraining's binary_logloss: 0.110198\tvalid_1's auc: 0.828456\tvalid_1's binary_logloss: 0.13864\n",
            "[29]\ttraining's auc: 0.912559\ttraining's binary_logloss: 0.109599\tvalid_1's auc: 0.828556\tvalid_1's binary_logloss: 0.138656\n",
            "[30]\ttraining's auc: 0.913499\ttraining's binary_logloss: 0.109127\tvalid_1's auc: 0.828471\tvalid_1's binary_logloss: 0.138679\n",
            "[31]\ttraining's auc: 0.914624\ttraining's binary_logloss: 0.108571\tvalid_1's auc: 0.828173\tvalid_1's binary_logloss: 0.138778\n",
            "[32]\ttraining's auc: 0.915634\ttraining's binary_logloss: 0.108028\tvalid_1's auc: 0.828067\tvalid_1's binary_logloss: 0.138807\n",
            "[33]\ttraining's auc: 0.9161\ttraining's binary_logloss: 0.107711\tvalid_1's auc: 0.828121\tvalid_1's binary_logloss: 0.138872\n",
            "[34]\ttraining's auc: 0.917685\ttraining's binary_logloss: 0.107129\tvalid_1's auc: 0.827978\tvalid_1's binary_logloss: 0.138865\n",
            "[35]\ttraining's auc: 0.918966\ttraining's binary_logloss: 0.106764\tvalid_1's auc: 0.82809\tvalid_1's binary_logloss: 0.13887\n",
            "[36]\ttraining's auc: 0.919953\ttraining's binary_logloss: 0.10628\tvalid_1's auc: 0.828394\tvalid_1's binary_logloss: 0.138779\n",
            "[37]\ttraining's auc: 0.920539\ttraining's binary_logloss: 0.105908\tvalid_1's auc: 0.827727\tvalid_1's binary_logloss: 0.138954\n",
            "[38]\ttraining's auc: 0.920967\ttraining's binary_logloss: 0.105567\tvalid_1's auc: 0.827978\tvalid_1's binary_logloss: 0.138935\n",
            "[39]\ttraining's auc: 0.921812\ttraining's binary_logloss: 0.105141\tvalid_1's auc: 0.827401\tvalid_1's binary_logloss: 0.13911\n",
            "[40]\ttraining's auc: 0.922313\ttraining's binary_logloss: 0.104813\tvalid_1's auc: 0.826644\tvalid_1's binary_logloss: 0.139227\n",
            "[41]\ttraining's auc: 0.923183\ttraining's binary_logloss: 0.10443\tvalid_1's auc: 0.826799\tvalid_1's binary_logloss: 0.139258\n",
            "[42]\ttraining's auc: 0.924159\ttraining's binary_logloss: 0.103985\tvalid_1's auc: 0.82695\tvalid_1's binary_logloss: 0.13925\n",
            "[43]\ttraining's auc: 0.924665\ttraining's binary_logloss: 0.103709\tvalid_1's auc: 0.826426\tvalid_1's binary_logloss: 0.139385\n",
            "[44]\ttraining's auc: 0.925251\ttraining's binary_logloss: 0.103383\tvalid_1's auc: 0.826203\tvalid_1's binary_logloss: 0.139463\n",
            " 86%|████████▌ | 43/50 [21:29<03:23, 29.04s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.16126\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.162681\n",
            "[2]\ttraining's auc: 0.832253\ttraining's binary_logloss: 0.158479\tvalid_1's auc: 0.807015\tvalid_1's binary_logloss: 0.160496\n",
            "[3]\ttraining's auc: 0.834365\ttraining's binary_logloss: 0.156068\tvalid_1's auc: 0.807762\tvalid_1's binary_logloss: 0.15852\n",
            "[4]\ttraining's auc: 0.836729\ttraining's binary_logloss: 0.153978\tvalid_1's auc: 0.808891\tvalid_1's binary_logloss: 0.15686\n",
            "[5]\ttraining's auc: 0.837086\ttraining's binary_logloss: 0.152129\tvalid_1's auc: 0.808654\tvalid_1's binary_logloss: 0.155447\n",
            "[6]\ttraining's auc: 0.838642\ttraining's binary_logloss: 0.15046\tvalid_1's auc: 0.810605\tvalid_1's binary_logloss: 0.154101\n",
            "[7]\ttraining's auc: 0.844506\ttraining's binary_logloss: 0.14891\tvalid_1's auc: 0.814932\tvalid_1's binary_logloss: 0.152933\n",
            "[8]\ttraining's auc: 0.844703\ttraining's binary_logloss: 0.147524\tvalid_1's auc: 0.815041\tvalid_1's binary_logloss: 0.151862\n",
            "[9]\ttraining's auc: 0.847104\ttraining's binary_logloss: 0.146246\tvalid_1's auc: 0.816886\tvalid_1's binary_logloss: 0.150849\n",
            "[10]\ttraining's auc: 0.848834\ttraining's binary_logloss: 0.145034\tvalid_1's auc: 0.818863\tvalid_1's binary_logloss: 0.149903\n",
            "[11]\ttraining's auc: 0.84977\ttraining's binary_logloss: 0.143863\tvalid_1's auc: 0.819538\tvalid_1's binary_logloss: 0.149072\n",
            "[12]\ttraining's auc: 0.850729\ttraining's binary_logloss: 0.142801\tvalid_1's auc: 0.820097\tvalid_1's binary_logloss: 0.148313\n",
            "[13]\ttraining's auc: 0.851531\ttraining's binary_logloss: 0.141813\tvalid_1's auc: 0.820937\tvalid_1's binary_logloss: 0.147573\n",
            "[14]\ttraining's auc: 0.852417\ttraining's binary_logloss: 0.140882\tvalid_1's auc: 0.821126\tvalid_1's binary_logloss: 0.146904\n",
            "[15]\ttraining's auc: 0.853822\ttraining's binary_logloss: 0.139998\tvalid_1's auc: 0.821749\tvalid_1's binary_logloss: 0.146259\n",
            "[16]\ttraining's auc: 0.854291\ttraining's binary_logloss: 0.139198\tvalid_1's auc: 0.821643\tvalid_1's binary_logloss: 0.145677\n",
            "[17]\ttraining's auc: 0.854746\ttraining's binary_logloss: 0.138433\tvalid_1's auc: 0.821766\tvalid_1's binary_logloss: 0.14517\n",
            "[18]\ttraining's auc: 0.855272\ttraining's binary_logloss: 0.137661\tvalid_1's auc: 0.821595\tvalid_1's binary_logloss: 0.144665\n",
            "[19]\ttraining's auc: 0.857853\ttraining's binary_logloss: 0.136963\tvalid_1's auc: 0.821964\tvalid_1's binary_logloss: 0.144171\n",
            "[20]\ttraining's auc: 0.858301\ttraining's binary_logloss: 0.136301\tvalid_1's auc: 0.822975\tvalid_1's binary_logloss: 0.143718\n",
            "[21]\ttraining's auc: 0.85912\ttraining's binary_logloss: 0.135647\tvalid_1's auc: 0.823135\tvalid_1's binary_logloss: 0.143307\n",
            "[22]\ttraining's auc: 0.85941\ttraining's binary_logloss: 0.135052\tvalid_1's auc: 0.823217\tvalid_1's binary_logloss: 0.142929\n",
            "[23]\ttraining's auc: 0.861434\ttraining's binary_logloss: 0.134448\tvalid_1's auc: 0.823789\tvalid_1's binary_logloss: 0.14253\n",
            "[24]\ttraining's auc: 0.861742\ttraining's binary_logloss: 0.133906\tvalid_1's auc: 0.823991\tvalid_1's binary_logloss: 0.142188\n",
            "[25]\ttraining's auc: 0.86228\ttraining's binary_logloss: 0.133368\tvalid_1's auc: 0.824262\tvalid_1's binary_logloss: 0.141854\n",
            "[26]\ttraining's auc: 0.863502\ttraining's binary_logloss: 0.132876\tvalid_1's auc: 0.824397\tvalid_1's binary_logloss: 0.141514\n",
            "[27]\ttraining's auc: 0.864571\ttraining's binary_logloss: 0.132396\tvalid_1's auc: 0.825797\tvalid_1's binary_logloss: 0.141199\n",
            "[28]\ttraining's auc: 0.864925\ttraining's binary_logloss: 0.131912\tvalid_1's auc: 0.825895\tvalid_1's binary_logloss: 0.140953\n",
            "[29]\ttraining's auc: 0.866014\ttraining's binary_logloss: 0.131463\tvalid_1's auc: 0.82628\tvalid_1's binary_logloss: 0.140655\n",
            "[30]\ttraining's auc: 0.866395\ttraining's binary_logloss: 0.131012\tvalid_1's auc: 0.826356\tvalid_1's binary_logloss: 0.140391\n",
            "[31]\ttraining's auc: 0.867219\ttraining's binary_logloss: 0.130582\tvalid_1's auc: 0.82673\tvalid_1's binary_logloss: 0.140152\n",
            "[32]\ttraining's auc: 0.8683\ttraining's binary_logloss: 0.130177\tvalid_1's auc: 0.827067\tvalid_1's binary_logloss: 0.139928\n",
            "[33]\ttraining's auc: 0.869234\ttraining's binary_logloss: 0.129787\tvalid_1's auc: 0.827468\tvalid_1's binary_logloss: 0.13974\n",
            "[34]\ttraining's auc: 0.869585\ttraining's binary_logloss: 0.129406\tvalid_1's auc: 0.827461\tvalid_1's binary_logloss: 0.139534\n",
            "[35]\ttraining's auc: 0.870108\ttraining's binary_logloss: 0.129048\tvalid_1's auc: 0.827462\tvalid_1's binary_logloss: 0.139376\n",
            "[36]\ttraining's auc: 0.870556\ttraining's binary_logloss: 0.128698\tvalid_1's auc: 0.827544\tvalid_1's binary_logloss: 0.139199\n",
            "[37]\ttraining's auc: 0.871007\ttraining's binary_logloss: 0.128357\tvalid_1's auc: 0.827442\tvalid_1's binary_logloss: 0.139051\n",
            "[38]\ttraining's auc: 0.871762\ttraining's binary_logloss: 0.127994\tvalid_1's auc: 0.827933\tvalid_1's binary_logloss: 0.138865\n",
            "[39]\ttraining's auc: 0.872622\ttraining's binary_logloss: 0.127662\tvalid_1's auc: 0.827775\tvalid_1's binary_logloss: 0.138737\n",
            "[40]\ttraining's auc: 0.873144\ttraining's binary_logloss: 0.127352\tvalid_1's auc: 0.827835\tvalid_1's binary_logloss: 0.138618\n",
            "[41]\ttraining's auc: 0.873904\ttraining's binary_logloss: 0.127014\tvalid_1's auc: 0.827868\tvalid_1's binary_logloss: 0.138478\n",
            "[42]\ttraining's auc: 0.874421\ttraining's binary_logloss: 0.126706\tvalid_1's auc: 0.827834\tvalid_1's binary_logloss: 0.138349\n",
            "[43]\ttraining's auc: 0.874924\ttraining's binary_logloss: 0.126402\tvalid_1's auc: 0.828012\tvalid_1's binary_logloss: 0.138209\n",
            "[44]\ttraining's auc: 0.87542\ttraining's binary_logloss: 0.126124\tvalid_1's auc: 0.828047\tvalid_1's binary_logloss: 0.138103\n",
            "[45]\ttraining's auc: 0.875871\ttraining's binary_logloss: 0.125845\tvalid_1's auc: 0.828109\tvalid_1's binary_logloss: 0.137971\n",
            "[46]\ttraining's auc: 0.876128\ttraining's binary_logloss: 0.125583\tvalid_1's auc: 0.828074\tvalid_1's binary_logloss: 0.137871\n",
            "[47]\ttraining's auc: 0.877441\ttraining's binary_logloss: 0.125297\tvalid_1's auc: 0.82837\tvalid_1's binary_logloss: 0.137769\n",
            "[48]\ttraining's auc: 0.878743\ttraining's binary_logloss: 0.124988\tvalid_1's auc: 0.828596\tvalid_1's binary_logloss: 0.137634\n",
            "[49]\ttraining's auc: 0.87917\ttraining's binary_logloss: 0.124742\tvalid_1's auc: 0.828873\tvalid_1's binary_logloss: 0.137522\n",
            "[50]\ttraining's auc: 0.879491\ttraining's binary_logloss: 0.124502\tvalid_1's auc: 0.828984\tvalid_1's binary_logloss: 0.137432\n",
            "[51]\ttraining's auc: 0.88035\ttraining's binary_logloss: 0.124233\tvalid_1's auc: 0.828864\tvalid_1's binary_logloss: 0.137366\n",
            "[52]\ttraining's auc: 0.880736\ttraining's binary_logloss: 0.124007\tvalid_1's auc: 0.82868\tvalid_1's binary_logloss: 0.137304\n",
            "[53]\ttraining's auc: 0.881593\ttraining's binary_logloss: 0.123752\tvalid_1's auc: 0.828885\tvalid_1's binary_logloss: 0.137199\n",
            "[54]\ttraining's auc: 0.881961\ttraining's binary_logloss: 0.123514\tvalid_1's auc: 0.829056\tvalid_1's binary_logloss: 0.137112\n",
            "[55]\ttraining's auc: 0.882618\ttraining's binary_logloss: 0.123285\tvalid_1's auc: 0.828987\tvalid_1's binary_logloss: 0.137053\n",
            "[56]\ttraining's auc: 0.883359\ttraining's binary_logloss: 0.12304\tvalid_1's auc: 0.828992\tvalid_1's binary_logloss: 0.136994\n",
            "[57]\ttraining's auc: 0.883974\ttraining's binary_logloss: 0.12281\tvalid_1's auc: 0.828949\tvalid_1's binary_logloss: 0.136928\n",
            "[58]\ttraining's auc: 0.884443\ttraining's binary_logloss: 0.1226\tvalid_1's auc: 0.828911\tvalid_1's binary_logloss: 0.13687\n",
            "[59]\ttraining's auc: 0.885341\ttraining's binary_logloss: 0.122365\tvalid_1's auc: 0.8291\tvalid_1's binary_logloss: 0.136806\n",
            "[60]\ttraining's auc: 0.885777\ttraining's binary_logloss: 0.122135\tvalid_1's auc: 0.829713\tvalid_1's binary_logloss: 0.136719\n",
            "[61]\ttraining's auc: 0.886407\ttraining's binary_logloss: 0.121887\tvalid_1's auc: 0.82988\tvalid_1's binary_logloss: 0.136656\n",
            "[62]\ttraining's auc: 0.887135\ttraining's binary_logloss: 0.121637\tvalid_1's auc: 0.829854\tvalid_1's binary_logloss: 0.136619\n",
            "[63]\ttraining's auc: 0.887628\ttraining's binary_logloss: 0.121442\tvalid_1's auc: 0.829934\tvalid_1's binary_logloss: 0.136566\n",
            "[64]\ttraining's auc: 0.888217\ttraining's binary_logloss: 0.121226\tvalid_1's auc: 0.829983\tvalid_1's binary_logloss: 0.136546\n",
            "[65]\ttraining's auc: 0.889178\ttraining's binary_logloss: 0.121004\tvalid_1's auc: 0.830096\tvalid_1's binary_logloss: 0.136467\n",
            "[66]\ttraining's auc: 0.889426\ttraining's binary_logloss: 0.120825\tvalid_1's auc: 0.829967\tvalid_1's binary_logloss: 0.136455\n",
            "[67]\ttraining's auc: 0.889761\ttraining's binary_logloss: 0.12064\tvalid_1's auc: 0.829849\tvalid_1's binary_logloss: 0.136433\n",
            "[68]\ttraining's auc: 0.890691\ttraining's binary_logloss: 0.120406\tvalid_1's auc: 0.830255\tvalid_1's binary_logloss: 0.136347\n",
            "[69]\ttraining's auc: 0.891097\ttraining's binary_logloss: 0.120222\tvalid_1's auc: 0.830338\tvalid_1's binary_logloss: 0.136329\n",
            "[70]\ttraining's auc: 0.891372\ttraining's binary_logloss: 0.120057\tvalid_1's auc: 0.830258\tvalid_1's binary_logloss: 0.136292\n",
            "[71]\ttraining's auc: 0.892005\ttraining's binary_logloss: 0.11987\tvalid_1's auc: 0.830265\tvalid_1's binary_logloss: 0.136261\n",
            "[72]\ttraining's auc: 0.892405\ttraining's binary_logloss: 0.119702\tvalid_1's auc: 0.830554\tvalid_1's binary_logloss: 0.136226\n",
            "[73]\ttraining's auc: 0.892654\ttraining's binary_logloss: 0.119545\tvalid_1's auc: 0.830564\tvalid_1's binary_logloss: 0.136205\n",
            "[74]\ttraining's auc: 0.893155\ttraining's binary_logloss: 0.119369\tvalid_1's auc: 0.830848\tvalid_1's binary_logloss: 0.136153\n",
            "[75]\ttraining's auc: 0.89345\ttraining's binary_logloss: 0.119204\tvalid_1's auc: 0.830994\tvalid_1's binary_logloss: 0.136129\n",
            "[76]\ttraining's auc: 0.893863\ttraining's binary_logloss: 0.119037\tvalid_1's auc: 0.830973\tvalid_1's binary_logloss: 0.136115\n",
            "[77]\ttraining's auc: 0.894411\ttraining's binary_logloss: 0.118864\tvalid_1's auc: 0.831242\tvalid_1's binary_logloss: 0.136057\n",
            "[78]\ttraining's auc: 0.894934\ttraining's binary_logloss: 0.118692\tvalid_1's auc: 0.831138\tvalid_1's binary_logloss: 0.136046\n",
            "[79]\ttraining's auc: 0.895173\ttraining's binary_logloss: 0.118547\tvalid_1's auc: 0.831297\tvalid_1's binary_logloss: 0.13602\n",
            "[80]\ttraining's auc: 0.896012\ttraining's binary_logloss: 0.118366\tvalid_1's auc: 0.831573\tvalid_1's binary_logloss: 0.135964\n",
            "[81]\ttraining's auc: 0.896395\ttraining's binary_logloss: 0.118207\tvalid_1's auc: 0.831408\tvalid_1's binary_logloss: 0.135969\n",
            "[82]\ttraining's auc: 0.8967\ttraining's binary_logloss: 0.118046\tvalid_1's auc: 0.831595\tvalid_1's binary_logloss: 0.135942\n",
            "[83]\ttraining's auc: 0.896991\ttraining's binary_logloss: 0.117878\tvalid_1's auc: 0.831545\tvalid_1's binary_logloss: 0.135936\n",
            "[84]\ttraining's auc: 0.897321\ttraining's binary_logloss: 0.117738\tvalid_1's auc: 0.831352\tvalid_1's binary_logloss: 0.135948\n",
            "[85]\ttraining's auc: 0.897945\ttraining's binary_logloss: 0.117579\tvalid_1's auc: 0.831545\tvalid_1's binary_logloss: 0.135904\n",
            "[86]\ttraining's auc: 0.898335\ttraining's binary_logloss: 0.117426\tvalid_1's auc: 0.831629\tvalid_1's binary_logloss: 0.135886\n",
            "[87]\ttraining's auc: 0.898845\ttraining's binary_logloss: 0.117242\tvalid_1's auc: 0.831583\tvalid_1's binary_logloss: 0.135895\n",
            "[88]\ttraining's auc: 0.899167\ttraining's binary_logloss: 0.117108\tvalid_1's auc: 0.831491\tvalid_1's binary_logloss: 0.135893\n",
            "[89]\ttraining's auc: 0.899511\ttraining's binary_logloss: 0.11696\tvalid_1's auc: 0.831541\tvalid_1's binary_logloss: 0.135879\n",
            "[90]\ttraining's auc: 0.900046\ttraining's binary_logloss: 0.116815\tvalid_1's auc: 0.831709\tvalid_1's binary_logloss: 0.135841\n",
            "[91]\ttraining's auc: 0.900322\ttraining's binary_logloss: 0.116683\tvalid_1's auc: 0.831677\tvalid_1's binary_logloss: 0.135839\n",
            "[92]\ttraining's auc: 0.900692\ttraining's binary_logloss: 0.116548\tvalid_1's auc: 0.831747\tvalid_1's binary_logloss: 0.135833\n",
            "[93]\ttraining's auc: 0.901037\ttraining's binary_logloss: 0.116419\tvalid_1's auc: 0.831906\tvalid_1's binary_logloss: 0.135799\n",
            "[94]\ttraining's auc: 0.901349\ttraining's binary_logloss: 0.116284\tvalid_1's auc: 0.831868\tvalid_1's binary_logloss: 0.135802\n",
            "[95]\ttraining's auc: 0.901657\ttraining's binary_logloss: 0.11616\tvalid_1's auc: 0.83183\tvalid_1's binary_logloss: 0.135784\n",
            "[96]\ttraining's auc: 0.901952\ttraining's binary_logloss: 0.11603\tvalid_1's auc: 0.831773\tvalid_1's binary_logloss: 0.135798\n",
            "[97]\ttraining's auc: 0.90226\ttraining's binary_logloss: 0.115881\tvalid_1's auc: 0.831683\tvalid_1's binary_logloss: 0.135808\n",
            "[98]\ttraining's auc: 0.90249\ttraining's binary_logloss: 0.115769\tvalid_1's auc: 0.831649\tvalid_1's binary_logloss: 0.135815\n",
            "[99]\ttraining's auc: 0.903199\ttraining's binary_logloss: 0.115623\tvalid_1's auc: 0.831747\tvalid_1's binary_logloss: 0.135784\n",
            "[100]\ttraining's auc: 0.903521\ttraining's binary_logloss: 0.115491\tvalid_1's auc: 0.831549\tvalid_1's binary_logloss: 0.135803\n",
            "[101]\ttraining's auc: 0.903777\ttraining's binary_logloss: 0.115344\tvalid_1's auc: 0.831576\tvalid_1's binary_logloss: 0.135814\n",
            "[102]\ttraining's auc: 0.904076\ttraining's binary_logloss: 0.115225\tvalid_1's auc: 0.831666\tvalid_1's binary_logloss: 0.135801\n",
            "[103]\ttraining's auc: 0.904381\ttraining's binary_logloss: 0.115085\tvalid_1's auc: 0.831558\tvalid_1's binary_logloss: 0.135802\n",
            "[104]\ttraining's auc: 0.904886\ttraining's binary_logloss: 0.114959\tvalid_1's auc: 0.831619\tvalid_1's binary_logloss: 0.135797\n",
            "[105]\ttraining's auc: 0.905121\ttraining's binary_logloss: 0.114826\tvalid_1's auc: 0.831572\tvalid_1's binary_logloss: 0.13581\n",
            "[106]\ttraining's auc: 0.905652\ttraining's binary_logloss: 0.114703\tvalid_1's auc: 0.831495\tvalid_1's binary_logloss: 0.135807\n",
            "[107]\ttraining's auc: 0.906075\ttraining's binary_logloss: 0.114585\tvalid_1's auc: 0.831738\tvalid_1's binary_logloss: 0.135763\n",
            "[108]\ttraining's auc: 0.906241\ttraining's binary_logloss: 0.114457\tvalid_1's auc: 0.831692\tvalid_1's binary_logloss: 0.135778\n",
            "[109]\ttraining's auc: 0.906462\ttraining's binary_logloss: 0.114341\tvalid_1's auc: 0.831581\tvalid_1's binary_logloss: 0.135788\n",
            "[110]\ttraining's auc: 0.906704\ttraining's binary_logloss: 0.11422\tvalid_1's auc: 0.831672\tvalid_1's binary_logloss: 0.135771\n",
            "[111]\ttraining's auc: 0.906905\ttraining's binary_logloss: 0.114113\tvalid_1's auc: 0.831649\tvalid_1's binary_logloss: 0.135776\n",
            "[112]\ttraining's auc: 0.907216\ttraining's binary_logloss: 0.113974\tvalid_1's auc: 0.831592\tvalid_1's binary_logloss: 0.13578\n",
            "[113]\ttraining's auc: 0.90749\ttraining's binary_logloss: 0.113846\tvalid_1's auc: 0.831576\tvalid_1's binary_logloss: 0.135774\n",
            "[114]\ttraining's auc: 0.907687\ttraining's binary_logloss: 0.11374\tvalid_1's auc: 0.831633\tvalid_1's binary_logloss: 0.135773\n",
            "[115]\ttraining's auc: 0.908118\ttraining's binary_logloss: 0.113602\tvalid_1's auc: 0.831714\tvalid_1's binary_logloss: 0.135762\n",
            "[116]\ttraining's auc: 0.90834\ttraining's binary_logloss: 0.113478\tvalid_1's auc: 0.831731\tvalid_1's binary_logloss: 0.135755\n",
            "[117]\ttraining's auc: 0.908508\ttraining's binary_logloss: 0.113374\tvalid_1's auc: 0.831721\tvalid_1's binary_logloss: 0.135762\n",
            "[118]\ttraining's auc: 0.909187\ttraining's binary_logloss: 0.113203\tvalid_1's auc: 0.831656\tvalid_1's binary_logloss: 0.135775\n",
            "[119]\ttraining's auc: 0.909445\ttraining's binary_logloss: 0.11309\tvalid_1's auc: 0.831504\tvalid_1's binary_logloss: 0.13581\n",
            "[120]\ttraining's auc: 0.909695\ttraining's binary_logloss: 0.112972\tvalid_1's auc: 0.831469\tvalid_1's binary_logloss: 0.135816\n",
            "[121]\ttraining's auc: 0.910059\ttraining's binary_logloss: 0.112856\tvalid_1's auc: 0.83155\tvalid_1's binary_logloss: 0.135806\n",
            "[122]\ttraining's auc: 0.910332\ttraining's binary_logloss: 0.112729\tvalid_1's auc: 0.831617\tvalid_1's binary_logloss: 0.13579\n",
            "[123]\ttraining's auc: 0.91055\ttraining's binary_logloss: 0.112617\tvalid_1's auc: 0.831478\tvalid_1's binary_logloss: 0.135824\n",
            " 86%|████████▌ | 43/50 [21:48<03:23, 29.04s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.163644\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.158189\n",
            "[2]\ttraining's auc: 0.82234\ttraining's binary_logloss: 0.160906\tvalid_1's auc: 0.804481\tvalid_1's binary_logloss: 0.155926\n",
            "[3]\ttraining's auc: 0.828438\ttraining's binary_logloss: 0.158491\tvalid_1's auc: 0.815997\tvalid_1's binary_logloss: 0.154052\n",
            "[4]\ttraining's auc: 0.832671\ttraining's binary_logloss: 0.156329\tvalid_1's auc: 0.818515\tvalid_1's binary_logloss: 0.152371\n",
            "[5]\ttraining's auc: 0.833642\ttraining's binary_logloss: 0.154464\tvalid_1's auc: 0.819097\tvalid_1's binary_logloss: 0.150872\n",
            "[6]\ttraining's auc: 0.834932\ttraining's binary_logloss: 0.152758\tvalid_1's auc: 0.820054\tvalid_1's binary_logloss: 0.149549\n",
            "[7]\ttraining's auc: 0.836991\ttraining's binary_logloss: 0.151221\tvalid_1's auc: 0.820972\tvalid_1's binary_logloss: 0.148333\n",
            "[8]\ttraining's auc: 0.840226\ttraining's binary_logloss: 0.149788\tvalid_1's auc: 0.823345\tvalid_1's binary_logloss: 0.147271\n",
            "[9]\ttraining's auc: 0.840977\ttraining's binary_logloss: 0.148482\tvalid_1's auc: 0.823115\tvalid_1's binary_logloss: 0.146312\n",
            "[10]\ttraining's auc: 0.844979\ttraining's binary_logloss: 0.14726\tvalid_1's auc: 0.824903\tvalid_1's binary_logloss: 0.145407\n",
            "[11]\ttraining's auc: 0.848061\ttraining's binary_logloss: 0.14609\tvalid_1's auc: 0.827773\tvalid_1's binary_logloss: 0.144563\n",
            "[12]\ttraining's auc: 0.84903\ttraining's binary_logloss: 0.145044\tvalid_1's auc: 0.82812\tvalid_1's binary_logloss: 0.143774\n",
            "[13]\ttraining's auc: 0.849809\ttraining's binary_logloss: 0.144054\tvalid_1's auc: 0.828743\tvalid_1's binary_logloss: 0.14305\n",
            "[14]\ttraining's auc: 0.851318\ttraining's binary_logloss: 0.143093\tvalid_1's auc: 0.828522\tvalid_1's binary_logloss: 0.142404\n",
            "[15]\ttraining's auc: 0.852768\ttraining's binary_logloss: 0.142228\tvalid_1's auc: 0.828567\tvalid_1's binary_logloss: 0.141765\n",
            "[16]\ttraining's auc: 0.853049\ttraining's binary_logloss: 0.141424\tvalid_1's auc: 0.828722\tvalid_1's binary_logloss: 0.141155\n",
            "[17]\ttraining's auc: 0.854077\ttraining's binary_logloss: 0.140629\tvalid_1's auc: 0.829621\tvalid_1's binary_logloss: 0.140554\n",
            "[18]\ttraining's auc: 0.855593\ttraining's binary_logloss: 0.139871\tvalid_1's auc: 0.830752\tvalid_1's binary_logloss: 0.13997\n",
            "[19]\ttraining's auc: 0.856621\ttraining's binary_logloss: 0.13917\tvalid_1's auc: 0.833178\tvalid_1's binary_logloss: 0.139434\n",
            "[20]\ttraining's auc: 0.857717\ttraining's binary_logloss: 0.138492\tvalid_1's auc: 0.832631\tvalid_1's binary_logloss: 0.139018\n",
            "[21]\ttraining's auc: 0.85851\ttraining's binary_logloss: 0.137837\tvalid_1's auc: 0.83264\tvalid_1's binary_logloss: 0.138589\n",
            "[22]\ttraining's auc: 0.859032\ttraining's binary_logloss: 0.137227\tvalid_1's auc: 0.832629\tvalid_1's binary_logloss: 0.13819\n",
            "[23]\ttraining's auc: 0.859977\ttraining's binary_logloss: 0.136634\tvalid_1's auc: 0.832604\tvalid_1's binary_logloss: 0.137797\n",
            "[24]\ttraining's auc: 0.860522\ttraining's binary_logloss: 0.136071\tvalid_1's auc: 0.832134\tvalid_1's binary_logloss: 0.137465\n",
            "[25]\ttraining's auc: 0.861732\ttraining's binary_logloss: 0.135536\tvalid_1's auc: 0.832667\tvalid_1's binary_logloss: 0.137094\n",
            "[26]\ttraining's auc: 0.862269\ttraining's binary_logloss: 0.135014\tvalid_1's auc: 0.832579\tvalid_1's binary_logloss: 0.136799\n",
            "[27]\ttraining's auc: 0.862754\ttraining's binary_logloss: 0.1345\tvalid_1's auc: 0.83239\tvalid_1's binary_logloss: 0.136501\n",
            "[28]\ttraining's auc: 0.864726\ttraining's binary_logloss: 0.133978\tvalid_1's auc: 0.832392\tvalid_1's binary_logloss: 0.136233\n",
            "[29]\ttraining's auc: 0.865736\ttraining's binary_logloss: 0.133501\tvalid_1's auc: 0.832339\tvalid_1's binary_logloss: 0.135979\n",
            "[30]\ttraining's auc: 0.8667\ttraining's binary_logloss: 0.133016\tvalid_1's auc: 0.832483\tvalid_1's binary_logloss: 0.135735\n",
            "[31]\ttraining's auc: 0.867576\ttraining's binary_logloss: 0.132563\tvalid_1's auc: 0.832429\tvalid_1's binary_logloss: 0.135517\n",
            "[32]\ttraining's auc: 0.868825\ttraining's binary_logloss: 0.132119\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.135248\n",
            "[33]\ttraining's auc: 0.869677\ttraining's binary_logloss: 0.131706\tvalid_1's auc: 0.83367\tvalid_1's binary_logloss: 0.13505\n",
            "[34]\ttraining's auc: 0.870699\ttraining's binary_logloss: 0.131305\tvalid_1's auc: 0.833597\tvalid_1's binary_logloss: 0.134842\n",
            "[35]\ttraining's auc: 0.871523\ttraining's binary_logloss: 0.130899\tvalid_1's auc: 0.83356\tvalid_1's binary_logloss: 0.134632\n",
            "[36]\ttraining's auc: 0.872207\ttraining's binary_logloss: 0.13054\tvalid_1's auc: 0.833545\tvalid_1's binary_logloss: 0.134469\n",
            "[37]\ttraining's auc: 0.872714\ttraining's binary_logloss: 0.130194\tvalid_1's auc: 0.833492\tvalid_1's binary_logloss: 0.134286\n",
            "[38]\ttraining's auc: 0.87305\ttraining's binary_logloss: 0.129846\tvalid_1's auc: 0.833709\tvalid_1's binary_logloss: 0.13411\n",
            "[39]\ttraining's auc: 0.873478\ttraining's binary_logloss: 0.129526\tvalid_1's auc: 0.833719\tvalid_1's binary_logloss: 0.133945\n",
            "[40]\ttraining's auc: 0.873808\ttraining's binary_logloss: 0.12922\tvalid_1's auc: 0.833637\tvalid_1's binary_logloss: 0.133804\n",
            "[41]\ttraining's auc: 0.874267\ttraining's binary_logloss: 0.128901\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.133672\n",
            "[42]\ttraining's auc: 0.874669\ttraining's binary_logloss: 0.128587\tvalid_1's auc: 0.833384\tvalid_1's binary_logloss: 0.133539\n",
            "[43]\ttraining's auc: 0.875077\ttraining's binary_logloss: 0.128274\tvalid_1's auc: 0.83342\tvalid_1's binary_logloss: 0.133414\n",
            "[44]\ttraining's auc: 0.875595\ttraining's binary_logloss: 0.127976\tvalid_1's auc: 0.833355\tvalid_1's binary_logloss: 0.133311\n",
            "[45]\ttraining's auc: 0.87588\ttraining's binary_logloss: 0.127687\tvalid_1's auc: 0.833421\tvalid_1's binary_logloss: 0.133193\n",
            "[46]\ttraining's auc: 0.877524\ttraining's binary_logloss: 0.127373\tvalid_1's auc: 0.834146\tvalid_1's binary_logloss: 0.133085\n",
            "[47]\ttraining's auc: 0.878032\ttraining's binary_logloss: 0.127078\tvalid_1's auc: 0.834166\tvalid_1's binary_logloss: 0.132993\n",
            "[48]\ttraining's auc: 0.878653\ttraining's binary_logloss: 0.126789\tvalid_1's auc: 0.833803\tvalid_1's binary_logloss: 0.132913\n",
            "[49]\ttraining's auc: 0.879209\ttraining's binary_logloss: 0.12651\tvalid_1's auc: 0.833951\tvalid_1's binary_logloss: 0.132803\n",
            "[50]\ttraining's auc: 0.87992\ttraining's binary_logloss: 0.126194\tvalid_1's auc: 0.834034\tvalid_1's binary_logloss: 0.132706\n",
            "[51]\ttraining's auc: 0.88019\ttraining's binary_logloss: 0.125941\tvalid_1's auc: 0.83396\tvalid_1's binary_logloss: 0.132633\n",
            "[52]\ttraining's auc: 0.880494\ttraining's binary_logloss: 0.125693\tvalid_1's auc: 0.833935\tvalid_1's binary_logloss: 0.132536\n",
            "[53]\ttraining's auc: 0.88089\ttraining's binary_logloss: 0.125439\tvalid_1's auc: 0.833773\tvalid_1's binary_logloss: 0.132473\n",
            "[54]\ttraining's auc: 0.881202\ttraining's binary_logloss: 0.125211\tvalid_1's auc: 0.833952\tvalid_1's binary_logloss: 0.1324\n",
            "[55]\ttraining's auc: 0.881631\ttraining's binary_logloss: 0.124975\tvalid_1's auc: 0.83391\tvalid_1's binary_logloss: 0.13234\n",
            "[56]\ttraining's auc: 0.881873\ttraining's binary_logloss: 0.12475\tvalid_1's auc: 0.833816\tvalid_1's binary_logloss: 0.132271\n",
            "[57]\ttraining's auc: 0.882821\ttraining's binary_logloss: 0.124491\tvalid_1's auc: 0.83407\tvalid_1's binary_logloss: 0.132164\n",
            "[58]\ttraining's auc: 0.883075\ttraining's binary_logloss: 0.124287\tvalid_1's auc: 0.834041\tvalid_1's binary_logloss: 0.132101\n",
            "[59]\ttraining's auc: 0.883823\ttraining's binary_logloss: 0.124044\tvalid_1's auc: 0.834\tvalid_1's binary_logloss: 0.132047\n",
            "[60]\ttraining's auc: 0.884559\ttraining's binary_logloss: 0.123819\tvalid_1's auc: 0.834015\tvalid_1's binary_logloss: 0.132003\n",
            "[61]\ttraining's auc: 0.885131\ttraining's binary_logloss: 0.12362\tvalid_1's auc: 0.83416\tvalid_1's binary_logloss: 0.131935\n",
            "[62]\ttraining's auc: 0.885733\ttraining's binary_logloss: 0.123429\tvalid_1's auc: 0.83462\tvalid_1's binary_logloss: 0.131885\n",
            "[63]\ttraining's auc: 0.885969\ttraining's binary_logloss: 0.123238\tvalid_1's auc: 0.834757\tvalid_1's binary_logloss: 0.131836\n",
            "[64]\ttraining's auc: 0.886516\ttraining's binary_logloss: 0.123036\tvalid_1's auc: 0.834805\tvalid_1's binary_logloss: 0.131779\n",
            "[65]\ttraining's auc: 0.887126\ttraining's binary_logloss: 0.122844\tvalid_1's auc: 0.834494\tvalid_1's binary_logloss: 0.131758\n",
            "[66]\ttraining's auc: 0.887572\ttraining's binary_logloss: 0.122656\tvalid_1's auc: 0.83455\tvalid_1's binary_logloss: 0.13174\n",
            "[67]\ttraining's auc: 0.887891\ttraining's binary_logloss: 0.122454\tvalid_1's auc: 0.834841\tvalid_1's binary_logloss: 0.13169\n",
            "[68]\ttraining's auc: 0.88811\ttraining's binary_logloss: 0.122284\tvalid_1's auc: 0.834636\tvalid_1's binary_logloss: 0.131674\n",
            "[69]\ttraining's auc: 0.888881\ttraining's binary_logloss: 0.122068\tvalid_1's auc: 0.834773\tvalid_1's binary_logloss: 0.13163\n",
            "[70]\ttraining's auc: 0.889595\ttraining's binary_logloss: 0.121854\tvalid_1's auc: 0.834775\tvalid_1's binary_logloss: 0.131597\n",
            "[71]\ttraining's auc: 0.890145\ttraining's binary_logloss: 0.121656\tvalid_1's auc: 0.834867\tvalid_1's binary_logloss: 0.131548\n",
            "[72]\ttraining's auc: 0.890605\ttraining's binary_logloss: 0.121476\tvalid_1's auc: 0.834919\tvalid_1's binary_logloss: 0.131511\n",
            "[73]\ttraining's auc: 0.890994\ttraining's binary_logloss: 0.1213\tvalid_1's auc: 0.834822\tvalid_1's binary_logloss: 0.131498\n",
            "[74]\ttraining's auc: 0.89154\ttraining's binary_logloss: 0.121111\tvalid_1's auc: 0.834972\tvalid_1's binary_logloss: 0.131453\n",
            "[75]\ttraining's auc: 0.891753\ttraining's binary_logloss: 0.120958\tvalid_1's auc: 0.834857\tvalid_1's binary_logloss: 0.131444\n",
            "[76]\ttraining's auc: 0.892277\ttraining's binary_logloss: 0.120783\tvalid_1's auc: 0.834744\tvalid_1's binary_logloss: 0.131427\n",
            "[77]\ttraining's auc: 0.892565\ttraining's binary_logloss: 0.120628\tvalid_1's auc: 0.834664\tvalid_1's binary_logloss: 0.131418\n",
            "[78]\ttraining's auc: 0.892955\ttraining's binary_logloss: 0.120463\tvalid_1's auc: 0.834796\tvalid_1's binary_logloss: 0.131369\n",
            "[79]\ttraining's auc: 0.893336\ttraining's binary_logloss: 0.120287\tvalid_1's auc: 0.834838\tvalid_1's binary_logloss: 0.131338\n",
            "[80]\ttraining's auc: 0.893942\ttraining's binary_logloss: 0.120129\tvalid_1's auc: 0.834778\tvalid_1's binary_logloss: 0.131325\n",
            "[81]\ttraining's auc: 0.894307\ttraining's binary_logloss: 0.11996\tvalid_1's auc: 0.834841\tvalid_1's binary_logloss: 0.131298\n",
            "[82]\ttraining's auc: 0.894546\ttraining's binary_logloss: 0.119814\tvalid_1's auc: 0.83482\tvalid_1's binary_logloss: 0.131254\n",
            "[83]\ttraining's auc: 0.894972\ttraining's binary_logloss: 0.119661\tvalid_1's auc: 0.835112\tvalid_1's binary_logloss: 0.131212\n",
            "[84]\ttraining's auc: 0.895429\ttraining's binary_logloss: 0.119517\tvalid_1's auc: 0.834946\tvalid_1's binary_logloss: 0.131208\n",
            "[85]\ttraining's auc: 0.895839\ttraining's binary_logloss: 0.119364\tvalid_1's auc: 0.835087\tvalid_1's binary_logloss: 0.131172\n",
            "[86]\ttraining's auc: 0.896523\ttraining's binary_logloss: 0.119206\tvalid_1's auc: 0.835167\tvalid_1's binary_logloss: 0.131145\n",
            "[87]\ttraining's auc: 0.896835\ttraining's binary_logloss: 0.119056\tvalid_1's auc: 0.83534\tvalid_1's binary_logloss: 0.131109\n",
            "[88]\ttraining's auc: 0.89712\ttraining's binary_logloss: 0.118908\tvalid_1's auc: 0.835419\tvalid_1's binary_logloss: 0.13109\n",
            "[89]\ttraining's auc: 0.897523\ttraining's binary_logloss: 0.118755\tvalid_1's auc: 0.83556\tvalid_1's binary_logloss: 0.131054\n",
            "[90]\ttraining's auc: 0.897908\ttraining's binary_logloss: 0.118597\tvalid_1's auc: 0.835634\tvalid_1's binary_logloss: 0.131024\n",
            "[91]\ttraining's auc: 0.898187\ttraining's binary_logloss: 0.118461\tvalid_1's auc: 0.835605\tvalid_1's binary_logloss: 0.131009\n",
            "[92]\ttraining's auc: 0.898528\ttraining's binary_logloss: 0.118326\tvalid_1's auc: 0.835572\tvalid_1's binary_logloss: 0.130997\n",
            "[93]\ttraining's auc: 0.898842\ttraining's binary_logloss: 0.118211\tvalid_1's auc: 0.835706\tvalid_1's binary_logloss: 0.130979\n",
            "[94]\ttraining's auc: 0.899361\ttraining's binary_logloss: 0.118069\tvalid_1's auc: 0.835734\tvalid_1's binary_logloss: 0.130966\n",
            "[95]\ttraining's auc: 0.899627\ttraining's binary_logloss: 0.117947\tvalid_1's auc: 0.835681\tvalid_1's binary_logloss: 0.130959\n",
            "[96]\ttraining's auc: 0.900082\ttraining's binary_logloss: 0.117783\tvalid_1's auc: 0.835687\tvalid_1's binary_logloss: 0.13095\n",
            "[97]\ttraining's auc: 0.900488\ttraining's binary_logloss: 0.117649\tvalid_1's auc: 0.83556\tvalid_1's binary_logloss: 0.130942\n",
            "[98]\ttraining's auc: 0.901057\ttraining's binary_logloss: 0.117511\tvalid_1's auc: 0.835613\tvalid_1's binary_logloss: 0.130929\n",
            "[99]\ttraining's auc: 0.901443\ttraining's binary_logloss: 0.117388\tvalid_1's auc: 0.835618\tvalid_1's binary_logloss: 0.130921\n",
            "[100]\ttraining's auc: 0.901853\ttraining's binary_logloss: 0.117263\tvalid_1's auc: 0.835651\tvalid_1's binary_logloss: 0.130915\n",
            "[101]\ttraining's auc: 0.902294\ttraining's binary_logloss: 0.117122\tvalid_1's auc: 0.835663\tvalid_1's binary_logloss: 0.130911\n",
            "[102]\ttraining's auc: 0.9028\ttraining's binary_logloss: 0.116982\tvalid_1's auc: 0.835765\tvalid_1's binary_logloss: 0.130893\n",
            "[103]\ttraining's auc: 0.903152\ttraining's binary_logloss: 0.116858\tvalid_1's auc: 0.835737\tvalid_1's binary_logloss: 0.130879\n",
            "[104]\ttraining's auc: 0.903537\ttraining's binary_logloss: 0.116734\tvalid_1's auc: 0.835836\tvalid_1's binary_logloss: 0.130854\n",
            "[105]\ttraining's auc: 0.903899\ttraining's binary_logloss: 0.116613\tvalid_1's auc: 0.835893\tvalid_1's binary_logloss: 0.130839\n",
            "[106]\ttraining's auc: 0.90432\ttraining's binary_logloss: 0.116462\tvalid_1's auc: 0.835899\tvalid_1's binary_logloss: 0.130834\n",
            "[107]\ttraining's auc: 0.904824\ttraining's binary_logloss: 0.116335\tvalid_1's auc: 0.835815\tvalid_1's binary_logloss: 0.130839\n",
            "[108]\ttraining's auc: 0.905109\ttraining's binary_logloss: 0.116233\tvalid_1's auc: 0.835756\tvalid_1's binary_logloss: 0.130858\n",
            "[109]\ttraining's auc: 0.905474\ttraining's binary_logloss: 0.116109\tvalid_1's auc: 0.835752\tvalid_1's binary_logloss: 0.130851\n",
            "[110]\ttraining's auc: 0.905797\ttraining's binary_logloss: 0.115986\tvalid_1's auc: 0.835759\tvalid_1's binary_logloss: 0.13085\n",
            "[111]\ttraining's auc: 0.906067\ttraining's binary_logloss: 0.115854\tvalid_1's auc: 0.835789\tvalid_1's binary_logloss: 0.130844\n",
            "[112]\ttraining's auc: 0.906257\ttraining's binary_logloss: 0.115762\tvalid_1's auc: 0.835787\tvalid_1's binary_logloss: 0.13085\n",
            "[113]\ttraining's auc: 0.90651\ttraining's binary_logloss: 0.115627\tvalid_1's auc: 0.835869\tvalid_1's binary_logloss: 0.13083\n",
            "[114]\ttraining's auc: 0.906747\ttraining's binary_logloss: 0.115518\tvalid_1's auc: 0.835993\tvalid_1's binary_logloss: 0.130812\n",
            "[115]\ttraining's auc: 0.906988\ttraining's binary_logloss: 0.115387\tvalid_1's auc: 0.835889\tvalid_1's binary_logloss: 0.130829\n",
            "[116]\ttraining's auc: 0.90758\ttraining's binary_logloss: 0.115207\tvalid_1's auc: 0.835746\tvalid_1's binary_logloss: 0.130863\n",
            "[117]\ttraining's auc: 0.90812\ttraining's binary_logloss: 0.115046\tvalid_1's auc: 0.835693\tvalid_1's binary_logloss: 0.130868\n",
            "[118]\ttraining's auc: 0.908375\ttraining's binary_logloss: 0.11496\tvalid_1's auc: 0.835713\tvalid_1's binary_logloss: 0.130859\n",
            "[119]\ttraining's auc: 0.908861\ttraining's binary_logloss: 0.114834\tvalid_1's auc: 0.835772\tvalid_1's binary_logloss: 0.130847\n",
            "[120]\ttraining's auc: 0.909363\ttraining's binary_logloss: 0.114674\tvalid_1's auc: 0.835699\tvalid_1's binary_logloss: 0.13086\n",
            "[121]\ttraining's auc: 0.909726\ttraining's binary_logloss: 0.114517\tvalid_1's auc: 0.835643\tvalid_1's binary_logloss: 0.130883\n",
            "[122]\ttraining's auc: 0.910027\ttraining's binary_logloss: 0.114393\tvalid_1's auc: 0.835651\tvalid_1's binary_logloss: 0.130877\n",
            "[123]\ttraining's auc: 0.910215\ttraining's binary_logloss: 0.114287\tvalid_1's auc: 0.835567\tvalid_1's binary_logloss: 0.130893\n",
            "[124]\ttraining's auc: 0.910415\ttraining's binary_logloss: 0.114169\tvalid_1's auc: 0.835611\tvalid_1's binary_logloss: 0.130888\n",
            "[125]\ttraining's auc: 0.910588\ttraining's binary_logloss: 0.114072\tvalid_1's auc: 0.835733\tvalid_1's binary_logloss: 0.130876\n",
            "[126]\ttraining's auc: 0.910853\ttraining's binary_logloss: 0.11396\tvalid_1's auc: 0.835832\tvalid_1's binary_logloss: 0.130861\n",
            "[127]\ttraining's auc: 0.911037\ttraining's binary_logloss: 0.113883\tvalid_1's auc: 0.835745\tvalid_1's binary_logloss: 0.130868\n",
            "[128]\ttraining's auc: 0.911251\ttraining's binary_logloss: 0.113784\tvalid_1's auc: 0.835724\tvalid_1's binary_logloss: 0.130871\n",
            "[129]\ttraining's auc: 0.911564\ttraining's binary_logloss: 0.113657\tvalid_1's auc: 0.835744\tvalid_1's binary_logloss: 0.13087\n",
            "[130]\ttraining's auc: 0.911847\ttraining's binary_logloss: 0.113536\tvalid_1's auc: 0.835826\tvalid_1's binary_logloss: 0.130855\n",
            "[131]\ttraining's auc: 0.912\ttraining's binary_logloss: 0.11345\tvalid_1's auc: 0.835798\tvalid_1's binary_logloss: 0.130853\n",
            "[132]\ttraining's auc: 0.912499\ttraining's binary_logloss: 0.113338\tvalid_1's auc: 0.835687\tvalid_1's binary_logloss: 0.130857\n",
            "[133]\ttraining's auc: 0.912727\ttraining's binary_logloss: 0.113221\tvalid_1's auc: 0.835584\tvalid_1's binary_logloss: 0.13087\n",
            "[134]\ttraining's auc: 0.912841\ttraining's binary_logloss: 0.113142\tvalid_1's auc: 0.835558\tvalid_1's binary_logloss: 0.130876\n",
            "[135]\ttraining's auc: 0.913207\ttraining's binary_logloss: 0.113\tvalid_1's auc: 0.835528\tvalid_1's binary_logloss: 0.13088\n",
            "[136]\ttraining's auc: 0.913341\ttraining's binary_logloss: 0.112913\tvalid_1's auc: 0.835551\tvalid_1's binary_logloss: 0.130876\n",
            "[137]\ttraining's auc: 0.913525\ttraining's binary_logloss: 0.112801\tvalid_1's auc: 0.835575\tvalid_1's binary_logloss: 0.130879\n",
            "[138]\ttraining's auc: 0.913654\ttraining's binary_logloss: 0.112707\tvalid_1's auc: 0.835537\tvalid_1's binary_logloss: 0.130891\n",
            "[139]\ttraining's auc: 0.913779\ttraining's binary_logloss: 0.112638\tvalid_1's auc: 0.835483\tvalid_1's binary_logloss: 0.130901\n",
            "[140]\ttraining's auc: 0.914138\ttraining's binary_logloss: 0.112526\tvalid_1's auc: 0.835435\tvalid_1's binary_logloss: 0.130907\n",
            "[141]\ttraining's auc: 0.914384\ttraining's binary_logloss: 0.112414\tvalid_1's auc: 0.835376\tvalid_1's binary_logloss: 0.130914\n",
            "[142]\ttraining's auc: 0.914649\ttraining's binary_logloss: 0.112313\tvalid_1's auc: 0.835426\tvalid_1's binary_logloss: 0.130903\n",
            "[143]\ttraining's auc: 0.914868\ttraining's binary_logloss: 0.112222\tvalid_1's auc: 0.835391\tvalid_1's binary_logloss: 0.130906\n",
            "[144]\ttraining's auc: 0.915016\ttraining's binary_logloss: 0.112139\tvalid_1's auc: 0.83522\tvalid_1's binary_logloss: 0.13092\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 86%|████████▌ | 43/50 [22:08<03:23, 29.04s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.159984\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.165685\n",
            "[2]\ttraining's auc: 0.830948\ttraining's binary_logloss: 0.157324\tvalid_1's auc: 0.81629\tvalid_1's binary_logloss: 0.163253\n",
            "[3]\ttraining's auc: 0.832191\ttraining's binary_logloss: 0.155067\tvalid_1's auc: 0.814216\tvalid_1's binary_logloss: 0.16131\n",
            "[4]\ttraining's auc: 0.833822\ttraining's binary_logloss: 0.153039\tvalid_1's auc: 0.816399\tvalid_1's binary_logloss: 0.159415\n",
            "[5]\ttraining's auc: 0.836374\ttraining's binary_logloss: 0.151238\tvalid_1's auc: 0.818567\tvalid_1's binary_logloss: 0.157805\n",
            "[6]\ttraining's auc: 0.838079\ttraining's binary_logloss: 0.149531\tvalid_1's auc: 0.818939\tvalid_1's binary_logloss: 0.156329\n",
            "[7]\ttraining's auc: 0.839223\ttraining's binary_logloss: 0.148069\tvalid_1's auc: 0.818933\tvalid_1's binary_logloss: 0.155082\n",
            "[8]\ttraining's auc: 0.841206\ttraining's binary_logloss: 0.146701\tvalid_1's auc: 0.820124\tvalid_1's binary_logloss: 0.15389\n",
            "[9]\ttraining's auc: 0.844933\ttraining's binary_logloss: 0.145347\tvalid_1's auc: 0.823372\tvalid_1's binary_logloss: 0.152811\n",
            "[10]\ttraining's auc: 0.847178\ttraining's binary_logloss: 0.144157\tvalid_1's auc: 0.82474\tvalid_1's binary_logloss: 0.151838\n",
            "[11]\ttraining's auc: 0.848846\ttraining's binary_logloss: 0.143074\tvalid_1's auc: 0.82609\tvalid_1's binary_logloss: 0.150896\n",
            "[12]\ttraining's auc: 0.849589\ttraining's binary_logloss: 0.142069\tvalid_1's auc: 0.826643\tvalid_1's binary_logloss: 0.150042\n",
            "[13]\ttraining's auc: 0.850292\ttraining's binary_logloss: 0.141095\tvalid_1's auc: 0.827216\tvalid_1's binary_logloss: 0.149227\n",
            "[14]\ttraining's auc: 0.851657\ttraining's binary_logloss: 0.14019\tvalid_1's auc: 0.82818\tvalid_1's binary_logloss: 0.148472\n",
            "[15]\ttraining's auc: 0.852548\ttraining's binary_logloss: 0.139318\tvalid_1's auc: 0.828378\tvalid_1's binary_logloss: 0.147808\n",
            "[16]\ttraining's auc: 0.852745\ttraining's binary_logloss: 0.138467\tvalid_1's auc: 0.828456\tvalid_1's binary_logloss: 0.14716\n",
            "[17]\ttraining's auc: 0.854128\ttraining's binary_logloss: 0.137679\tvalid_1's auc: 0.829436\tvalid_1's binary_logloss: 0.146536\n",
            "[18]\ttraining's auc: 0.855167\ttraining's binary_logloss: 0.136953\tvalid_1's auc: 0.829664\tvalid_1's binary_logloss: 0.145963\n",
            "[19]\ttraining's auc: 0.855578\ttraining's binary_logloss: 0.136253\tvalid_1's auc: 0.829863\tvalid_1's binary_logloss: 0.145424\n",
            "[20]\ttraining's auc: 0.856348\ttraining's binary_logloss: 0.135604\tvalid_1's auc: 0.830032\tvalid_1's binary_logloss: 0.144938\n",
            "[21]\ttraining's auc: 0.857162\ttraining's binary_logloss: 0.134959\tvalid_1's auc: 0.830317\tvalid_1's binary_logloss: 0.144455\n",
            "[22]\ttraining's auc: 0.85831\ttraining's binary_logloss: 0.134337\tvalid_1's auc: 0.830732\tvalid_1's binary_logloss: 0.144006\n",
            "[23]\ttraining's auc: 0.859418\ttraining's binary_logloss: 0.13376\tvalid_1's auc: 0.830463\tvalid_1's binary_logloss: 0.143615\n",
            "[24]\ttraining's auc: 0.860187\ttraining's binary_logloss: 0.133229\tvalid_1's auc: 0.830428\tvalid_1's binary_logloss: 0.14323\n",
            "[25]\ttraining's auc: 0.86148\ttraining's binary_logloss: 0.132688\tvalid_1's auc: 0.831064\tvalid_1's binary_logloss: 0.142865\n",
            "[26]\ttraining's auc: 0.86265\ttraining's binary_logloss: 0.132202\tvalid_1's auc: 0.831298\tvalid_1's binary_logloss: 0.142512\n",
            "[27]\ttraining's auc: 0.86342\ttraining's binary_logloss: 0.131711\tvalid_1's auc: 0.831095\tvalid_1's binary_logloss: 0.142219\n",
            "[28]\ttraining's auc: 0.864574\ttraining's binary_logloss: 0.131254\tvalid_1's auc: 0.831664\tvalid_1's binary_logloss: 0.1419\n",
            "[29]\ttraining's auc: 0.865145\ttraining's binary_logloss: 0.13081\tvalid_1's auc: 0.831804\tvalid_1's binary_logloss: 0.141638\n",
            "[30]\ttraining's auc: 0.865667\ttraining's binary_logloss: 0.130381\tvalid_1's auc: 0.83182\tvalid_1's binary_logloss: 0.141392\n",
            "[31]\ttraining's auc: 0.866315\ttraining's binary_logloss: 0.129979\tvalid_1's auc: 0.831817\tvalid_1's binary_logloss: 0.141142\n",
            "[32]\ttraining's auc: 0.867782\ttraining's binary_logloss: 0.129549\tvalid_1's auc: 0.832022\tvalid_1's binary_logloss: 0.140868\n",
            "[33]\ttraining's auc: 0.868343\ttraining's binary_logloss: 0.129167\tvalid_1's auc: 0.832035\tvalid_1's binary_logloss: 0.140656\n",
            "[34]\ttraining's auc: 0.868638\ttraining's binary_logloss: 0.128789\tvalid_1's auc: 0.832025\tvalid_1's binary_logloss: 0.14043\n",
            "[35]\ttraining's auc: 0.870087\ttraining's binary_logloss: 0.128405\tvalid_1's auc: 0.832161\tvalid_1's binary_logloss: 0.140235\n",
            "[36]\ttraining's auc: 0.871051\ttraining's binary_logloss: 0.128031\tvalid_1's auc: 0.831946\tvalid_1's binary_logloss: 0.140055\n",
            "[37]\ttraining's auc: 0.871927\ttraining's binary_logloss: 0.1277\tvalid_1's auc: 0.833657\tvalid_1's binary_logloss: 0.139844\n",
            "[38]\ttraining's auc: 0.872791\ttraining's binary_logloss: 0.127363\tvalid_1's auc: 0.834134\tvalid_1's binary_logloss: 0.139635\n",
            "[39]\ttraining's auc: 0.873392\ttraining's binary_logloss: 0.127045\tvalid_1's auc: 0.834453\tvalid_1's binary_logloss: 0.139451\n",
            "[40]\ttraining's auc: 0.87405\ttraining's binary_logloss: 0.12673\tvalid_1's auc: 0.83483\tvalid_1's binary_logloss: 0.1393\n",
            "[41]\ttraining's auc: 0.874542\ttraining's binary_logloss: 0.126403\tvalid_1's auc: 0.834971\tvalid_1's binary_logloss: 0.139146\n",
            "[42]\ttraining's auc: 0.875235\ttraining's binary_logloss: 0.126079\tvalid_1's auc: 0.835214\tvalid_1's binary_logloss: 0.138985\n",
            "[43]\ttraining's auc: 0.875516\ttraining's binary_logloss: 0.125784\tvalid_1's auc: 0.83537\tvalid_1's binary_logloss: 0.138845\n",
            "[44]\ttraining's auc: 0.876179\ttraining's binary_logloss: 0.125491\tvalid_1's auc: 0.835314\tvalid_1's binary_logloss: 0.138716\n",
            "[45]\ttraining's auc: 0.87704\ttraining's binary_logloss: 0.125198\tvalid_1's auc: 0.835569\tvalid_1's binary_logloss: 0.138579\n",
            "[46]\ttraining's auc: 0.878096\ttraining's binary_logloss: 0.124907\tvalid_1's auc: 0.835405\tvalid_1's binary_logloss: 0.138475\n",
            "[47]\ttraining's auc: 0.879178\ttraining's binary_logloss: 0.124615\tvalid_1's auc: 0.835593\tvalid_1's binary_logloss: 0.138322\n",
            "[48]\ttraining's auc: 0.87964\ttraining's binary_logloss: 0.124363\tvalid_1's auc: 0.835559\tvalid_1's binary_logloss: 0.138204\n",
            "[49]\ttraining's auc: 0.880397\ttraining's binary_logloss: 0.12407\tvalid_1's auc: 0.835344\tvalid_1's binary_logloss: 0.138119\n",
            "[50]\ttraining's auc: 0.880836\ttraining's binary_logloss: 0.123824\tvalid_1's auc: 0.835614\tvalid_1's binary_logloss: 0.138023\n",
            "[51]\ttraining's auc: 0.881196\ttraining's binary_logloss: 0.123577\tvalid_1's auc: 0.83556\tvalid_1's binary_logloss: 0.137944\n",
            "[52]\ttraining's auc: 0.881751\ttraining's binary_logloss: 0.123328\tvalid_1's auc: 0.835631\tvalid_1's binary_logloss: 0.137871\n",
            "[53]\ttraining's auc: 0.882305\ttraining's binary_logloss: 0.123093\tvalid_1's auc: 0.835636\tvalid_1's binary_logloss: 0.137753\n",
            "[54]\ttraining's auc: 0.883182\ttraining's binary_logloss: 0.122815\tvalid_1's auc: 0.835603\tvalid_1's binary_logloss: 0.137686\n",
            "[55]\ttraining's auc: 0.884483\ttraining's binary_logloss: 0.12255\tvalid_1's auc: 0.835431\tvalid_1's binary_logloss: 0.1376\n",
            "[56]\ttraining's auc: 0.885054\ttraining's binary_logloss: 0.122302\tvalid_1's auc: 0.835665\tvalid_1's binary_logloss: 0.1375\n",
            "[57]\ttraining's auc: 0.885755\ttraining's binary_logloss: 0.122053\tvalid_1's auc: 0.835872\tvalid_1's binary_logloss: 0.137417\n",
            "[58]\ttraining's auc: 0.886384\ttraining's binary_logloss: 0.121838\tvalid_1's auc: 0.835868\tvalid_1's binary_logloss: 0.13736\n",
            "[59]\ttraining's auc: 0.886938\ttraining's binary_logloss: 0.121619\tvalid_1's auc: 0.836215\tvalid_1's binary_logloss: 0.137282\n",
            "[60]\ttraining's auc: 0.887396\ttraining's binary_logloss: 0.121397\tvalid_1's auc: 0.836348\tvalid_1's binary_logloss: 0.137218\n",
            "[61]\ttraining's auc: 0.887901\ttraining's binary_logloss: 0.121185\tvalid_1's auc: 0.836164\tvalid_1's binary_logloss: 0.137184\n",
            "[62]\ttraining's auc: 0.888447\ttraining's binary_logloss: 0.120983\tvalid_1's auc: 0.836148\tvalid_1's binary_logloss: 0.137134\n",
            "[63]\ttraining's auc: 0.888904\ttraining's binary_logloss: 0.120787\tvalid_1's auc: 0.836133\tvalid_1's binary_logloss: 0.137099\n",
            "[64]\ttraining's auc: 0.889328\ttraining's binary_logloss: 0.120567\tvalid_1's auc: 0.83635\tvalid_1's binary_logloss: 0.137024\n",
            "[65]\ttraining's auc: 0.889732\ttraining's binary_logloss: 0.12037\tvalid_1's auc: 0.836271\tvalid_1's binary_logloss: 0.136997\n",
            "[66]\ttraining's auc: 0.890054\ttraining's binary_logloss: 0.120183\tvalid_1's auc: 0.83637\tvalid_1's binary_logloss: 0.136941\n",
            "[67]\ttraining's auc: 0.890472\ttraining's binary_logloss: 0.120016\tvalid_1's auc: 0.836274\tvalid_1's binary_logloss: 0.136906\n",
            "[68]\ttraining's auc: 0.890762\ttraining's binary_logloss: 0.119833\tvalid_1's auc: 0.836166\tvalid_1's binary_logloss: 0.136889\n",
            "[69]\ttraining's auc: 0.891251\ttraining's binary_logloss: 0.119654\tvalid_1's auc: 0.836154\tvalid_1's binary_logloss: 0.136863\n",
            "[70]\ttraining's auc: 0.891631\ttraining's binary_logloss: 0.119497\tvalid_1's auc: 0.836239\tvalid_1's binary_logloss: 0.136811\n",
            "[71]\ttraining's auc: 0.892057\ttraining's binary_logloss: 0.119334\tvalid_1's auc: 0.836055\tvalid_1's binary_logloss: 0.136799\n",
            "[72]\ttraining's auc: 0.892328\ttraining's binary_logloss: 0.119181\tvalid_1's auc: 0.835982\tvalid_1's binary_logloss: 0.136772\n",
            "[73]\ttraining's auc: 0.892694\ttraining's binary_logloss: 0.119001\tvalid_1's auc: 0.836188\tvalid_1's binary_logloss: 0.136729\n",
            "[74]\ttraining's auc: 0.89346\ttraining's binary_logloss: 0.118787\tvalid_1's auc: 0.83622\tvalid_1's binary_logloss: 0.136706\n",
            "[75]\ttraining's auc: 0.894045\ttraining's binary_logloss: 0.118621\tvalid_1's auc: 0.836022\tvalid_1's binary_logloss: 0.136706\n",
            "[76]\ttraining's auc: 0.894454\ttraining's binary_logloss: 0.118467\tvalid_1's auc: 0.836129\tvalid_1's binary_logloss: 0.136678\n",
            "[77]\ttraining's auc: 0.894824\ttraining's binary_logloss: 0.118307\tvalid_1's auc: 0.836098\tvalid_1's binary_logloss: 0.136667\n",
            "[78]\ttraining's auc: 0.895245\ttraining's binary_logloss: 0.118139\tvalid_1's auc: 0.836052\tvalid_1's binary_logloss: 0.136654\n",
            "[79]\ttraining's auc: 0.895621\ttraining's binary_logloss: 0.117989\tvalid_1's auc: 0.836\tvalid_1's binary_logloss: 0.136644\n",
            "[80]\ttraining's auc: 0.896109\ttraining's binary_logloss: 0.117812\tvalid_1's auc: 0.836097\tvalid_1's binary_logloss: 0.136595\n",
            "[81]\ttraining's auc: 0.896684\ttraining's binary_logloss: 0.117642\tvalid_1's auc: 0.836135\tvalid_1's binary_logloss: 0.136565\n",
            "[82]\ttraining's auc: 0.897018\ttraining's binary_logloss: 0.117498\tvalid_1's auc: 0.835912\tvalid_1's binary_logloss: 0.136572\n",
            "[83]\ttraining's auc: 0.897431\ttraining's binary_logloss: 0.117338\tvalid_1's auc: 0.836023\tvalid_1's binary_logloss: 0.136537\n",
            "[84]\ttraining's auc: 0.89773\ttraining's binary_logloss: 0.117212\tvalid_1's auc: 0.835939\tvalid_1's binary_logloss: 0.13654\n",
            "[85]\ttraining's auc: 0.897993\ttraining's binary_logloss: 0.117076\tvalid_1's auc: 0.835996\tvalid_1's binary_logloss: 0.136508\n",
            "[86]\ttraining's auc: 0.898542\ttraining's binary_logloss: 0.116903\tvalid_1's auc: 0.835837\tvalid_1's binary_logloss: 0.13651\n",
            "[87]\ttraining's auc: 0.899057\ttraining's binary_logloss: 0.116731\tvalid_1's auc: 0.835607\tvalid_1's binary_logloss: 0.136511\n",
            "[88]\ttraining's auc: 0.899507\ttraining's binary_logloss: 0.116578\tvalid_1's auc: 0.835559\tvalid_1's binary_logloss: 0.1365\n",
            "[89]\ttraining's auc: 0.899929\ttraining's binary_logloss: 0.116431\tvalid_1's auc: 0.83562\tvalid_1's binary_logloss: 0.136482\n",
            "[90]\ttraining's auc: 0.90031\ttraining's binary_logloss: 0.116274\tvalid_1's auc: 0.835638\tvalid_1's binary_logloss: 0.136457\n",
            "[91]\ttraining's auc: 0.900807\ttraining's binary_logloss: 0.116107\tvalid_1's auc: 0.835653\tvalid_1's binary_logloss: 0.136454\n",
            "[92]\ttraining's auc: 0.901273\ttraining's binary_logloss: 0.115961\tvalid_1's auc: 0.835811\tvalid_1's binary_logloss: 0.136419\n",
            "[93]\ttraining's auc: 0.901581\ttraining's binary_logloss: 0.115832\tvalid_1's auc: 0.835718\tvalid_1's binary_logloss: 0.136413\n",
            "[94]\ttraining's auc: 0.902219\ttraining's binary_logloss: 0.115636\tvalid_1's auc: 0.835693\tvalid_1's binary_logloss: 0.136396\n",
            "[95]\ttraining's auc: 0.902495\ttraining's binary_logloss: 0.115522\tvalid_1's auc: 0.835735\tvalid_1's binary_logloss: 0.136383\n",
            "[96]\ttraining's auc: 0.903001\ttraining's binary_logloss: 0.115327\tvalid_1's auc: 0.835607\tvalid_1's binary_logloss: 0.136358\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 88%|████████▊ | 44/50 [22:23<03:38, 36.45s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.16287\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.164021\n",
            "[2]\ttraining's auc: 0.827212\ttraining's binary_logloss: 0.161317\tvalid_1's auc: 0.805077\tvalid_1's binary_logloss: 0.162723\n",
            "[3]\ttraining's auc: 0.833072\ttraining's binary_logloss: 0.159879\tvalid_1's auc: 0.807826\tvalid_1's binary_logloss: 0.161592\n",
            "[4]\ttraining's auc: 0.833453\ttraining's binary_logloss: 0.158564\tvalid_1's auc: 0.807831\tvalid_1's binary_logloss: 0.160519\n",
            "[5]\ttraining's auc: 0.834188\ttraining's binary_logloss: 0.157345\tvalid_1's auc: 0.807862\tvalid_1's binary_logloss: 0.159542\n",
            "[6]\ttraining's auc: 0.836294\ttraining's binary_logloss: 0.156193\tvalid_1's auc: 0.808665\tvalid_1's binary_logloss: 0.158634\n",
            "[7]\ttraining's auc: 0.836469\ttraining's binary_logloss: 0.155112\tvalid_1's auc: 0.808893\tvalid_1's binary_logloss: 0.1578\n",
            "[8]\ttraining's auc: 0.836434\ttraining's binary_logloss: 0.154096\tvalid_1's auc: 0.808545\tvalid_1's binary_logloss: 0.157017\n",
            "[9]\ttraining's auc: 0.83679\ttraining's binary_logloss: 0.153141\tvalid_1's auc: 0.808474\tvalid_1's binary_logloss: 0.156282\n",
            "[10]\ttraining's auc: 0.838939\ttraining's binary_logloss: 0.152207\tvalid_1's auc: 0.810064\tvalid_1's binary_logloss: 0.155559\n",
            "[11]\ttraining's auc: 0.839023\ttraining's binary_logloss: 0.151345\tvalid_1's auc: 0.810648\tvalid_1's binary_logloss: 0.154871\n",
            "[12]\ttraining's auc: 0.841906\ttraining's binary_logloss: 0.150521\tvalid_1's auc: 0.812164\tvalid_1's binary_logloss: 0.154209\n",
            "[13]\ttraining's auc: 0.843846\ttraining's binary_logloss: 0.149725\tvalid_1's auc: 0.81504\tvalid_1's binary_logloss: 0.153573\n",
            "[14]\ttraining's auc: 0.843914\ttraining's binary_logloss: 0.148978\tvalid_1's auc: 0.814853\tvalid_1's binary_logloss: 0.153022\n",
            "[15]\ttraining's auc: 0.845096\ttraining's binary_logloss: 0.148262\tvalid_1's auc: 0.815241\tvalid_1's binary_logloss: 0.152474\n",
            "[16]\ttraining's auc: 0.845672\ttraining's binary_logloss: 0.147585\tvalid_1's auc: 0.815926\tvalid_1's binary_logloss: 0.151936\n",
            "[17]\ttraining's auc: 0.847006\ttraining's binary_logloss: 0.146932\tvalid_1's auc: 0.817544\tvalid_1's binary_logloss: 0.151402\n",
            "[18]\ttraining's auc: 0.847869\ttraining's binary_logloss: 0.146285\tvalid_1's auc: 0.817826\tvalid_1's binary_logloss: 0.150916\n",
            "[19]\ttraining's auc: 0.848971\ttraining's binary_logloss: 0.145646\tvalid_1's auc: 0.818731\tvalid_1's binary_logloss: 0.150434\n",
            "[20]\ttraining's auc: 0.849207\ttraining's binary_logloss: 0.145055\tvalid_1's auc: 0.818818\tvalid_1's binary_logloss: 0.149982\n",
            "[21]\ttraining's auc: 0.849765\ttraining's binary_logloss: 0.144459\tvalid_1's auc: 0.819322\tvalid_1's binary_logloss: 0.14955\n",
            "[22]\ttraining's auc: 0.850457\ttraining's binary_logloss: 0.143884\tvalid_1's auc: 0.819998\tvalid_1's binary_logloss: 0.149117\n",
            "[23]\ttraining's auc: 0.851099\ttraining's binary_logloss: 0.143333\tvalid_1's auc: 0.820419\tvalid_1's binary_logloss: 0.148712\n",
            "[24]\ttraining's auc: 0.852004\ttraining's binary_logloss: 0.142802\tvalid_1's auc: 0.82068\tvalid_1's binary_logloss: 0.148322\n",
            "[25]\ttraining's auc: 0.852599\ttraining's binary_logloss: 0.142294\tvalid_1's auc: 0.821353\tvalid_1's binary_logloss: 0.14795\n",
            "[26]\ttraining's auc: 0.853111\ttraining's binary_logloss: 0.141812\tvalid_1's auc: 0.821644\tvalid_1's binary_logloss: 0.147585\n",
            "[27]\ttraining's auc: 0.853417\ttraining's binary_logloss: 0.141335\tvalid_1's auc: 0.821898\tvalid_1's binary_logloss: 0.147245\n",
            "[28]\ttraining's auc: 0.853864\ttraining's binary_logloss: 0.140883\tvalid_1's auc: 0.822216\tvalid_1's binary_logloss: 0.146897\n",
            "[29]\ttraining's auc: 0.855097\ttraining's binary_logloss: 0.140437\tvalid_1's auc: 0.823209\tvalid_1's binary_logloss: 0.14657\n",
            "[30]\ttraining's auc: 0.855315\ttraining's binary_logloss: 0.140013\tvalid_1's auc: 0.82332\tvalid_1's binary_logloss: 0.146258\n",
            "[31]\ttraining's auc: 0.855563\ttraining's binary_logloss: 0.139596\tvalid_1's auc: 0.823188\tvalid_1's binary_logloss: 0.145969\n",
            "[32]\ttraining's auc: 0.855824\ttraining's binary_logloss: 0.13919\tvalid_1's auc: 0.823247\tvalid_1's binary_logloss: 0.145677\n",
            "[33]\ttraining's auc: 0.855762\ttraining's binary_logloss: 0.138804\tvalid_1's auc: 0.823424\tvalid_1's binary_logloss: 0.14539\n",
            "[34]\ttraining's auc: 0.856189\ttraining's binary_logloss: 0.138418\tvalid_1's auc: 0.823147\tvalid_1's binary_logloss: 0.145132\n",
            "[35]\ttraining's auc: 0.856294\ttraining's binary_logloss: 0.138026\tvalid_1's auc: 0.822901\tvalid_1's binary_logloss: 0.144863\n",
            "[36]\ttraining's auc: 0.858293\ttraining's binary_logloss: 0.137655\tvalid_1's auc: 0.823437\tvalid_1's binary_logloss: 0.144599\n",
            "[37]\ttraining's auc: 0.858652\ttraining's binary_logloss: 0.137298\tvalid_1's auc: 0.82356\tvalid_1's binary_logloss: 0.144349\n",
            "[38]\ttraining's auc: 0.858949\ttraining's binary_logloss: 0.136949\tvalid_1's auc: 0.823541\tvalid_1's binary_logloss: 0.144098\n",
            "[39]\ttraining's auc: 0.859217\ttraining's binary_logloss: 0.136613\tvalid_1's auc: 0.823445\tvalid_1's binary_logloss: 0.143872\n",
            "[40]\ttraining's auc: 0.859399\ttraining's binary_logloss: 0.136284\tvalid_1's auc: 0.824174\tvalid_1's binary_logloss: 0.143653\n",
            "[41]\ttraining's auc: 0.859757\ttraining's binary_logloss: 0.13595\tvalid_1's auc: 0.824287\tvalid_1's binary_logloss: 0.143442\n",
            "[42]\ttraining's auc: 0.859979\ttraining's binary_logloss: 0.135649\tvalid_1's auc: 0.824351\tvalid_1's binary_logloss: 0.14322\n",
            "[43]\ttraining's auc: 0.860676\ttraining's binary_logloss: 0.135314\tvalid_1's auc: 0.824795\tvalid_1's binary_logloss: 0.143016\n",
            "[44]\ttraining's auc: 0.860835\ttraining's binary_logloss: 0.135029\tvalid_1's auc: 0.824883\tvalid_1's binary_logloss: 0.142814\n",
            "[45]\ttraining's auc: 0.861631\ttraining's binary_logloss: 0.134726\tvalid_1's auc: 0.825055\tvalid_1's binary_logloss: 0.142612\n",
            "[46]\ttraining's auc: 0.862136\ttraining's binary_logloss: 0.134428\tvalid_1's auc: 0.825142\tvalid_1's binary_logloss: 0.142424\n",
            "[47]\ttraining's auc: 0.862653\ttraining's binary_logloss: 0.134136\tvalid_1's auc: 0.82514\tvalid_1's binary_logloss: 0.142244\n",
            "[48]\ttraining's auc: 0.863021\ttraining's binary_logloss: 0.133855\tvalid_1's auc: 0.825212\tvalid_1's binary_logloss: 0.142083\n",
            "[49]\ttraining's auc: 0.86324\ttraining's binary_logloss: 0.133595\tvalid_1's auc: 0.82537\tvalid_1's binary_logloss: 0.141917\n",
            "[50]\ttraining's auc: 0.863878\ttraining's binary_logloss: 0.133332\tvalid_1's auc: 0.825891\tvalid_1's binary_logloss: 0.141727\n",
            "[51]\ttraining's auc: 0.864514\ttraining's binary_logloss: 0.133068\tvalid_1's auc: 0.826218\tvalid_1's binary_logloss: 0.141559\n",
            "[52]\ttraining's auc: 0.864955\ttraining's binary_logloss: 0.132812\tvalid_1's auc: 0.826229\tvalid_1's binary_logloss: 0.141406\n",
            "[53]\ttraining's auc: 0.865201\ttraining's binary_logloss: 0.132575\tvalid_1's auc: 0.82638\tvalid_1's binary_logloss: 0.141258\n",
            "[54]\ttraining's auc: 0.865585\ttraining's binary_logloss: 0.132332\tvalid_1's auc: 0.826521\tvalid_1's binary_logloss: 0.141101\n",
            "[55]\ttraining's auc: 0.866015\ttraining's binary_logloss: 0.132071\tvalid_1's auc: 0.826606\tvalid_1's binary_logloss: 0.140931\n",
            "[56]\ttraining's auc: 0.866326\ttraining's binary_logloss: 0.131836\tvalid_1's auc: 0.826881\tvalid_1's binary_logloss: 0.14079\n",
            "[57]\ttraining's auc: 0.866594\ttraining's binary_logloss: 0.131603\tvalid_1's auc: 0.827061\tvalid_1's binary_logloss: 0.140674\n",
            "[58]\ttraining's auc: 0.866779\ttraining's binary_logloss: 0.131364\tvalid_1's auc: 0.827176\tvalid_1's binary_logloss: 0.140539\n",
            "[59]\ttraining's auc: 0.867149\ttraining's binary_logloss: 0.131138\tvalid_1's auc: 0.827297\tvalid_1's binary_logloss: 0.140391\n",
            "[60]\ttraining's auc: 0.867603\ttraining's binary_logloss: 0.130911\tvalid_1's auc: 0.82741\tvalid_1's binary_logloss: 0.140271\n",
            "[61]\ttraining's auc: 0.868131\ttraining's binary_logloss: 0.130703\tvalid_1's auc: 0.827326\tvalid_1's binary_logloss: 0.140163\n",
            "[62]\ttraining's auc: 0.868635\ttraining's binary_logloss: 0.130495\tvalid_1's auc: 0.827541\tvalid_1's binary_logloss: 0.140049\n",
            "[63]\ttraining's auc: 0.86887\ttraining's binary_logloss: 0.130296\tvalid_1's auc: 0.827695\tvalid_1's binary_logloss: 0.139926\n",
            "[64]\ttraining's auc: 0.869274\ttraining's binary_logloss: 0.130087\tvalid_1's auc: 0.82804\tvalid_1's binary_logloss: 0.139809\n",
            "[65]\ttraining's auc: 0.86962\ttraining's binary_logloss: 0.129884\tvalid_1's auc: 0.828071\tvalid_1's binary_logloss: 0.139717\n",
            "[66]\ttraining's auc: 0.869778\ttraining's binary_logloss: 0.129692\tvalid_1's auc: 0.828182\tvalid_1's binary_logloss: 0.139617\n",
            "[67]\ttraining's auc: 0.870089\ttraining's binary_logloss: 0.129494\tvalid_1's auc: 0.82816\tvalid_1's binary_logloss: 0.139517\n",
            "[68]\ttraining's auc: 0.870334\ttraining's binary_logloss: 0.129308\tvalid_1's auc: 0.828084\tvalid_1's binary_logloss: 0.139436\n",
            "[69]\ttraining's auc: 0.870593\ttraining's binary_logloss: 0.129121\tvalid_1's auc: 0.828083\tvalid_1's binary_logloss: 0.139335\n",
            "[70]\ttraining's auc: 0.870871\ttraining's binary_logloss: 0.12894\tvalid_1's auc: 0.827975\tvalid_1's binary_logloss: 0.13925\n",
            "[71]\ttraining's auc: 0.871068\ttraining's binary_logloss: 0.128766\tvalid_1's auc: 0.828074\tvalid_1's binary_logloss: 0.139155\n",
            "[72]\ttraining's auc: 0.871244\ttraining's binary_logloss: 0.128602\tvalid_1's auc: 0.82808\tvalid_1's binary_logloss: 0.139075\n",
            "[73]\ttraining's auc: 0.871537\ttraining's binary_logloss: 0.128426\tvalid_1's auc: 0.828202\tvalid_1's binary_logloss: 0.138989\n",
            "[74]\ttraining's auc: 0.871683\ttraining's binary_logloss: 0.128263\tvalid_1's auc: 0.828408\tvalid_1's binary_logloss: 0.138905\n",
            "[75]\ttraining's auc: 0.872145\ttraining's binary_logloss: 0.128075\tvalid_1's auc: 0.828293\tvalid_1's binary_logloss: 0.138825\n",
            "[76]\ttraining's auc: 0.872306\ttraining's binary_logloss: 0.127923\tvalid_1's auc: 0.828255\tvalid_1's binary_logloss: 0.138745\n",
            "[77]\ttraining's auc: 0.872846\ttraining's binary_logloss: 0.127751\tvalid_1's auc: 0.828285\tvalid_1's binary_logloss: 0.13868\n",
            "[78]\ttraining's auc: 0.873135\ttraining's binary_logloss: 0.127594\tvalid_1's auc: 0.828239\tvalid_1's binary_logloss: 0.138613\n",
            "[79]\ttraining's auc: 0.873437\ttraining's binary_logloss: 0.127422\tvalid_1's auc: 0.828338\tvalid_1's binary_logloss: 0.13853\n",
            "[80]\ttraining's auc: 0.873761\ttraining's binary_logloss: 0.127267\tvalid_1's auc: 0.828108\tvalid_1's binary_logloss: 0.138474\n",
            "[81]\ttraining's auc: 0.874142\ttraining's binary_logloss: 0.127111\tvalid_1's auc: 0.828069\tvalid_1's binary_logloss: 0.138422\n",
            "[82]\ttraining's auc: 0.874458\ttraining's binary_logloss: 0.126952\tvalid_1's auc: 0.827967\tvalid_1's binary_logloss: 0.138367\n",
            "[83]\ttraining's auc: 0.874804\ttraining's binary_logloss: 0.126788\tvalid_1's auc: 0.828148\tvalid_1's binary_logloss: 0.138291\n",
            "[84]\ttraining's auc: 0.875115\ttraining's binary_logloss: 0.126633\tvalid_1's auc: 0.828214\tvalid_1's binary_logloss: 0.138235\n",
            "[85]\ttraining's auc: 0.875375\ttraining's binary_logloss: 0.126488\tvalid_1's auc: 0.828161\tvalid_1's binary_logloss: 0.138179\n",
            "[86]\ttraining's auc: 0.87562\ttraining's binary_logloss: 0.126335\tvalid_1's auc: 0.828229\tvalid_1's binary_logloss: 0.138113\n",
            "[87]\ttraining's auc: 0.876314\ttraining's binary_logloss: 0.126179\tvalid_1's auc: 0.828211\tvalid_1's binary_logloss: 0.138054\n",
            "[88]\ttraining's auc: 0.876525\ttraining's binary_logloss: 0.126034\tvalid_1's auc: 0.828209\tvalid_1's binary_logloss: 0.137994\n",
            "[89]\ttraining's auc: 0.876672\ttraining's binary_logloss: 0.125895\tvalid_1's auc: 0.828237\tvalid_1's binary_logloss: 0.13794\n",
            "[90]\ttraining's auc: 0.876969\ttraining's binary_logloss: 0.125748\tvalid_1's auc: 0.828397\tvalid_1's binary_logloss: 0.137876\n",
            "[91]\ttraining's auc: 0.877758\ttraining's binary_logloss: 0.125594\tvalid_1's auc: 0.828376\tvalid_1's binary_logloss: 0.137815\n",
            "[92]\ttraining's auc: 0.87797\ttraining's binary_logloss: 0.125458\tvalid_1's auc: 0.828278\tvalid_1's binary_logloss: 0.137769\n",
            "[93]\ttraining's auc: 0.878465\ttraining's binary_logloss: 0.125321\tvalid_1's auc: 0.828214\tvalid_1's binary_logloss: 0.137726\n",
            "[94]\ttraining's auc: 0.878518\ttraining's binary_logloss: 0.125193\tvalid_1's auc: 0.828178\tvalid_1's binary_logloss: 0.137681\n",
            "[95]\ttraining's auc: 0.878754\ttraining's binary_logloss: 0.125063\tvalid_1's auc: 0.828264\tvalid_1's binary_logloss: 0.137636\n",
            "[96]\ttraining's auc: 0.878996\ttraining's binary_logloss: 0.124932\tvalid_1's auc: 0.828456\tvalid_1's binary_logloss: 0.137579\n",
            "[97]\ttraining's auc: 0.879239\ttraining's binary_logloss: 0.124804\tvalid_1's auc: 0.828401\tvalid_1's binary_logloss: 0.13753\n",
            "[98]\ttraining's auc: 0.879386\ttraining's binary_logloss: 0.124681\tvalid_1's auc: 0.828293\tvalid_1's binary_logloss: 0.137493\n",
            "[99]\ttraining's auc: 0.879763\ttraining's binary_logloss: 0.124555\tvalid_1's auc: 0.82857\tvalid_1's binary_logloss: 0.137428\n",
            "[100]\ttraining's auc: 0.880033\ttraining's binary_logloss: 0.124437\tvalid_1's auc: 0.828514\tvalid_1's binary_logloss: 0.137385\n",
            "[101]\ttraining's auc: 0.880226\ttraining's binary_logloss: 0.124314\tvalid_1's auc: 0.82863\tvalid_1's binary_logloss: 0.137327\n",
            "[102]\ttraining's auc: 0.880506\ttraining's binary_logloss: 0.124185\tvalid_1's auc: 0.828832\tvalid_1's binary_logloss: 0.137284\n",
            "[103]\ttraining's auc: 0.880879\ttraining's binary_logloss: 0.124056\tvalid_1's auc: 0.828892\tvalid_1's binary_logloss: 0.137234\n",
            "[104]\ttraining's auc: 0.881095\ttraining's binary_logloss: 0.123942\tvalid_1's auc: 0.828934\tvalid_1's binary_logloss: 0.137195\n",
            "[105]\ttraining's auc: 0.881439\ttraining's binary_logloss: 0.123817\tvalid_1's auc: 0.828812\tvalid_1's binary_logloss: 0.137155\n",
            "[106]\ttraining's auc: 0.881789\ttraining's binary_logloss: 0.123689\tvalid_1's auc: 0.828923\tvalid_1's binary_logloss: 0.137121\n",
            "[107]\ttraining's auc: 0.88205\ttraining's binary_logloss: 0.123566\tvalid_1's auc: 0.828956\tvalid_1's binary_logloss: 0.1371\n",
            "[108]\ttraining's auc: 0.882552\ttraining's binary_logloss: 0.123428\tvalid_1's auc: 0.82892\tvalid_1's binary_logloss: 0.137068\n",
            "[109]\ttraining's auc: 0.882687\ttraining's binary_logloss: 0.123316\tvalid_1's auc: 0.828994\tvalid_1's binary_logloss: 0.137039\n",
            "[110]\ttraining's auc: 0.883139\ttraining's binary_logloss: 0.12319\tvalid_1's auc: 0.829007\tvalid_1's binary_logloss: 0.137\n",
            "[111]\ttraining's auc: 0.883685\ttraining's binary_logloss: 0.123058\tvalid_1's auc: 0.829238\tvalid_1's binary_logloss: 0.13696\n",
            "[112]\ttraining's auc: 0.884025\ttraining's binary_logloss: 0.122943\tvalid_1's auc: 0.829216\tvalid_1's binary_logloss: 0.136933\n",
            "[113]\ttraining's auc: 0.884207\ttraining's binary_logloss: 0.122831\tvalid_1's auc: 0.829229\tvalid_1's binary_logloss: 0.136894\n",
            "[114]\ttraining's auc: 0.884527\ttraining's binary_logloss: 0.122712\tvalid_1's auc: 0.82938\tvalid_1's binary_logloss: 0.13685\n",
            "[115]\ttraining's auc: 0.884824\ttraining's binary_logloss: 0.122602\tvalid_1's auc: 0.829383\tvalid_1's binary_logloss: 0.136831\n",
            "[116]\ttraining's auc: 0.885\ttraining's binary_logloss: 0.122496\tvalid_1's auc: 0.829419\tvalid_1's binary_logloss: 0.136804\n",
            "[117]\ttraining's auc: 0.885199\ttraining's binary_logloss: 0.122393\tvalid_1's auc: 0.82932\tvalid_1's binary_logloss: 0.136788\n",
            "[118]\ttraining's auc: 0.885619\ttraining's binary_logloss: 0.122255\tvalid_1's auc: 0.829349\tvalid_1's binary_logloss: 0.136768\n",
            "[119]\ttraining's auc: 0.885952\ttraining's binary_logloss: 0.12214\tvalid_1's auc: 0.829523\tvalid_1's binary_logloss: 0.136737\n",
            "[120]\ttraining's auc: 0.886398\ttraining's binary_logloss: 0.122012\tvalid_1's auc: 0.829514\tvalid_1's binary_logloss: 0.136718\n",
            "[121]\ttraining's auc: 0.886692\ttraining's binary_logloss: 0.1219\tvalid_1's auc: 0.829491\tvalid_1's binary_logloss: 0.136704\n",
            "[122]\ttraining's auc: 0.886933\ttraining's binary_logloss: 0.121794\tvalid_1's auc: 0.829635\tvalid_1's binary_logloss: 0.136665\n",
            "[123]\ttraining's auc: 0.887214\ttraining's binary_logloss: 0.121674\tvalid_1's auc: 0.829632\tvalid_1's binary_logloss: 0.13665\n",
            "[124]\ttraining's auc: 0.887454\ttraining's binary_logloss: 0.121568\tvalid_1's auc: 0.82969\tvalid_1's binary_logloss: 0.136627\n",
            "[125]\ttraining's auc: 0.887642\ttraining's binary_logloss: 0.121462\tvalid_1's auc: 0.829703\tvalid_1's binary_logloss: 0.136617\n",
            "[126]\ttraining's auc: 0.887831\ttraining's binary_logloss: 0.121363\tvalid_1's auc: 0.8297\tvalid_1's binary_logloss: 0.136589\n",
            "[127]\ttraining's auc: 0.888305\ttraining's binary_logloss: 0.121244\tvalid_1's auc: 0.82974\tvalid_1's binary_logloss: 0.136562\n",
            "[128]\ttraining's auc: 0.888418\ttraining's binary_logloss: 0.121152\tvalid_1's auc: 0.829784\tvalid_1's binary_logloss: 0.13654\n",
            "[129]\ttraining's auc: 0.888656\ttraining's binary_logloss: 0.121053\tvalid_1's auc: 0.829845\tvalid_1's binary_logloss: 0.136526\n",
            "[130]\ttraining's auc: 0.888827\ttraining's binary_logloss: 0.120959\tvalid_1's auc: 0.829868\tvalid_1's binary_logloss: 0.136507\n",
            "[131]\ttraining's auc: 0.888943\ttraining's binary_logloss: 0.120875\tvalid_1's auc: 0.82978\tvalid_1's binary_logloss: 0.136497\n",
            "[132]\ttraining's auc: 0.889247\ttraining's binary_logloss: 0.120771\tvalid_1's auc: 0.82998\tvalid_1's binary_logloss: 0.136461\n",
            "[133]\ttraining's auc: 0.889435\ttraining's binary_logloss: 0.120678\tvalid_1's auc: 0.830074\tvalid_1's binary_logloss: 0.136447\n",
            "[134]\ttraining's auc: 0.889578\ttraining's binary_logloss: 0.120591\tvalid_1's auc: 0.829994\tvalid_1's binary_logloss: 0.13644\n",
            "[135]\ttraining's auc: 0.890071\ttraining's binary_logloss: 0.120471\tvalid_1's auc: 0.830012\tvalid_1's binary_logloss: 0.136405\n",
            "[136]\ttraining's auc: 0.89019\ttraining's binary_logloss: 0.120393\tvalid_1's auc: 0.830072\tvalid_1's binary_logloss: 0.13638\n",
            "[137]\ttraining's auc: 0.890329\ttraining's binary_logloss: 0.120302\tvalid_1's auc: 0.830249\tvalid_1's binary_logloss: 0.136354\n",
            "[138]\ttraining's auc: 0.890515\ttraining's binary_logloss: 0.120213\tvalid_1's auc: 0.830155\tvalid_1's binary_logloss: 0.136349\n",
            "[139]\ttraining's auc: 0.890994\ttraining's binary_logloss: 0.120107\tvalid_1's auc: 0.830148\tvalid_1's binary_logloss: 0.136319\n",
            "[140]\ttraining's auc: 0.8912\ttraining's binary_logloss: 0.120013\tvalid_1's auc: 0.830103\tvalid_1's binary_logloss: 0.136299\n",
            "[141]\ttraining's auc: 0.891355\ttraining's binary_logloss: 0.119934\tvalid_1's auc: 0.830279\tvalid_1's binary_logloss: 0.136279\n",
            "[142]\ttraining's auc: 0.891724\ttraining's binary_logloss: 0.119832\tvalid_1's auc: 0.830367\tvalid_1's binary_logloss: 0.136253\n",
            "[143]\ttraining's auc: 0.891854\ttraining's binary_logloss: 0.119748\tvalid_1's auc: 0.830226\tvalid_1's binary_logloss: 0.136242\n",
            "[144]\ttraining's auc: 0.892103\ttraining's binary_logloss: 0.119666\tvalid_1's auc: 0.830203\tvalid_1's binary_logloss: 0.136237\n",
            "[145]\ttraining's auc: 0.892286\ttraining's binary_logloss: 0.119582\tvalid_1's auc: 0.830289\tvalid_1's binary_logloss: 0.136232\n",
            "[146]\ttraining's auc: 0.892646\ttraining's binary_logloss: 0.119483\tvalid_1's auc: 0.830684\tvalid_1's binary_logloss: 0.136191\n",
            "[147]\ttraining's auc: 0.892821\ttraining's binary_logloss: 0.1194\tvalid_1's auc: 0.830684\tvalid_1's binary_logloss: 0.136185\n",
            "[148]\ttraining's auc: 0.893155\ttraining's binary_logloss: 0.119299\tvalid_1's auc: 0.83078\tvalid_1's binary_logloss: 0.136154\n",
            "[149]\ttraining's auc: 0.893383\ttraining's binary_logloss: 0.119219\tvalid_1's auc: 0.830795\tvalid_1's binary_logloss: 0.136143\n",
            "[150]\ttraining's auc: 0.893543\ttraining's binary_logloss: 0.119136\tvalid_1's auc: 0.830753\tvalid_1's binary_logloss: 0.136142\n",
            "[151]\ttraining's auc: 0.893807\ttraining's binary_logloss: 0.119045\tvalid_1's auc: 0.830861\tvalid_1's binary_logloss: 0.136121\n",
            "[152]\ttraining's auc: 0.894104\ttraining's binary_logloss: 0.118959\tvalid_1's auc: 0.830908\tvalid_1's binary_logloss: 0.136113\n",
            "[153]\ttraining's auc: 0.89425\ttraining's binary_logloss: 0.118878\tvalid_1's auc: 0.830784\tvalid_1's binary_logloss: 0.136123\n",
            "[154]\ttraining's auc: 0.894475\ttraining's binary_logloss: 0.118794\tvalid_1's auc: 0.83079\tvalid_1's binary_logloss: 0.136107\n",
            "[155]\ttraining's auc: 0.894757\ttraining's binary_logloss: 0.118709\tvalid_1's auc: 0.830804\tvalid_1's binary_logloss: 0.136093\n",
            "[156]\ttraining's auc: 0.894967\ttraining's binary_logloss: 0.11863\tvalid_1's auc: 0.830845\tvalid_1's binary_logloss: 0.136068\n",
            "[157]\ttraining's auc: 0.895061\ttraining's binary_logloss: 0.118556\tvalid_1's auc: 0.830785\tvalid_1's binary_logloss: 0.136077\n",
            "[158]\ttraining's auc: 0.895268\ttraining's binary_logloss: 0.118476\tvalid_1's auc: 0.830773\tvalid_1's binary_logloss: 0.136075\n",
            "[159]\ttraining's auc: 0.895451\ttraining's binary_logloss: 0.118398\tvalid_1's auc: 0.830858\tvalid_1's binary_logloss: 0.136049\n",
            "[160]\ttraining's auc: 0.895569\ttraining's binary_logloss: 0.118321\tvalid_1's auc: 0.830792\tvalid_1's binary_logloss: 0.136053\n",
            "[161]\ttraining's auc: 0.895761\ttraining's binary_logloss: 0.118243\tvalid_1's auc: 0.830876\tvalid_1's binary_logloss: 0.136029\n",
            "[162]\ttraining's auc: 0.896031\ttraining's binary_logloss: 0.118156\tvalid_1's auc: 0.830967\tvalid_1's binary_logloss: 0.136006\n",
            "[163]\ttraining's auc: 0.896522\ttraining's binary_logloss: 0.118066\tvalid_1's auc: 0.831087\tvalid_1's binary_logloss: 0.135985\n",
            "[164]\ttraining's auc: 0.896679\ttraining's binary_logloss: 0.117982\tvalid_1's auc: 0.831053\tvalid_1's binary_logloss: 0.135982\n",
            "[165]\ttraining's auc: 0.896789\ttraining's binary_logloss: 0.117914\tvalid_1's auc: 0.831009\tvalid_1's binary_logloss: 0.135984\n",
            "[166]\ttraining's auc: 0.896947\ttraining's binary_logloss: 0.117836\tvalid_1's auc: 0.831011\tvalid_1's binary_logloss: 0.135982\n",
            "[167]\ttraining's auc: 0.897085\ttraining's binary_logloss: 0.117763\tvalid_1's auc: 0.830888\tvalid_1's binary_logloss: 0.13598\n",
            "[168]\ttraining's auc: 0.897205\ttraining's binary_logloss: 0.117694\tvalid_1's auc: 0.830827\tvalid_1's binary_logloss: 0.135985\n",
            "[169]\ttraining's auc: 0.897372\ttraining's binary_logloss: 0.11763\tvalid_1's auc: 0.830752\tvalid_1's binary_logloss: 0.135989\n",
            "[170]\ttraining's auc: 0.897603\ttraining's binary_logloss: 0.11755\tvalid_1's auc: 0.830775\tvalid_1's binary_logloss: 0.135987\n",
            "[171]\ttraining's auc: 0.897746\ttraining's binary_logloss: 0.117477\tvalid_1's auc: 0.830696\tvalid_1's binary_logloss: 0.135993\n",
            "[172]\ttraining's auc: 0.897879\ttraining's binary_logloss: 0.117401\tvalid_1's auc: 0.830735\tvalid_1's binary_logloss: 0.135984\n",
            "[173]\ttraining's auc: 0.898052\ttraining's binary_logloss: 0.117328\tvalid_1's auc: 0.830739\tvalid_1's binary_logloss: 0.135982\n",
            "[174]\ttraining's auc: 0.898297\ttraining's binary_logloss: 0.117256\tvalid_1's auc: 0.830754\tvalid_1's binary_logloss: 0.135978\n",
            "[175]\ttraining's auc: 0.898644\ttraining's binary_logloss: 0.117171\tvalid_1's auc: 0.8309\tvalid_1's binary_logloss: 0.135947\n",
            "[176]\ttraining's auc: 0.898806\ttraining's binary_logloss: 0.117101\tvalid_1's auc: 0.830872\tvalid_1's binary_logloss: 0.13595\n",
            "[177]\ttraining's auc: 0.898995\ttraining's binary_logloss: 0.117032\tvalid_1's auc: 0.830881\tvalid_1's binary_logloss: 0.135941\n",
            "[178]\ttraining's auc: 0.899295\ttraining's binary_logloss: 0.116941\tvalid_1's auc: 0.83092\tvalid_1's binary_logloss: 0.135929\n",
            "[179]\ttraining's auc: 0.89947\ttraining's binary_logloss: 0.116871\tvalid_1's auc: 0.830903\tvalid_1's binary_logloss: 0.135929\n",
            "[180]\ttraining's auc: 0.899935\ttraining's binary_logloss: 0.116782\tvalid_1's auc: 0.831007\tvalid_1's binary_logloss: 0.13591\n",
            "[181]\ttraining's auc: 0.900081\ttraining's binary_logloss: 0.116708\tvalid_1's auc: 0.831033\tvalid_1's binary_logloss: 0.135899\n",
            "[182]\ttraining's auc: 0.90032\ttraining's binary_logloss: 0.116629\tvalid_1's auc: 0.831065\tvalid_1's binary_logloss: 0.135881\n",
            "[183]\ttraining's auc: 0.900569\ttraining's binary_logloss: 0.116554\tvalid_1's auc: 0.831188\tvalid_1's binary_logloss: 0.135859\n",
            "[184]\ttraining's auc: 0.900721\ttraining's binary_logloss: 0.116495\tvalid_1's auc: 0.831237\tvalid_1's binary_logloss: 0.135858\n",
            "[185]\ttraining's auc: 0.901012\ttraining's binary_logloss: 0.11642\tvalid_1's auc: 0.831359\tvalid_1's binary_logloss: 0.135838\n",
            "[186]\ttraining's auc: 0.901144\ttraining's binary_logloss: 0.116361\tvalid_1's auc: 0.831359\tvalid_1's binary_logloss: 0.135836\n",
            "[187]\ttraining's auc: 0.901369\ttraining's binary_logloss: 0.11629\tvalid_1's auc: 0.831351\tvalid_1's binary_logloss: 0.135839\n",
            "[188]\ttraining's auc: 0.90157\ttraining's binary_logloss: 0.116218\tvalid_1's auc: 0.831347\tvalid_1's binary_logloss: 0.13584\n",
            "[189]\ttraining's auc: 0.901799\ttraining's binary_logloss: 0.116155\tvalid_1's auc: 0.831367\tvalid_1's binary_logloss: 0.135832\n",
            "[190]\ttraining's auc: 0.902038\ttraining's binary_logloss: 0.116091\tvalid_1's auc: 0.831318\tvalid_1's binary_logloss: 0.13583\n",
            "[191]\ttraining's auc: 0.902194\ttraining's binary_logloss: 0.116027\tvalid_1's auc: 0.83142\tvalid_1's binary_logloss: 0.135813\n",
            "[192]\ttraining's auc: 0.902319\ttraining's binary_logloss: 0.115968\tvalid_1's auc: 0.831388\tvalid_1's binary_logloss: 0.135812\n",
            "[193]\ttraining's auc: 0.902513\ttraining's binary_logloss: 0.115904\tvalid_1's auc: 0.831448\tvalid_1's binary_logloss: 0.135799\n",
            "[194]\ttraining's auc: 0.902778\ttraining's binary_logloss: 0.115824\tvalid_1's auc: 0.831512\tvalid_1's binary_logloss: 0.13579\n",
            "[195]\ttraining's auc: 0.902897\ttraining's binary_logloss: 0.115759\tvalid_1's auc: 0.831467\tvalid_1's binary_logloss: 0.1358\n",
            "[196]\ttraining's auc: 0.903046\ttraining's binary_logloss: 0.115691\tvalid_1's auc: 0.831404\tvalid_1's binary_logloss: 0.135807\n",
            "[197]\ttraining's auc: 0.903245\ttraining's binary_logloss: 0.115612\tvalid_1's auc: 0.831315\tvalid_1's binary_logloss: 0.135827\n",
            "[198]\ttraining's auc: 0.903383\ttraining's binary_logloss: 0.115546\tvalid_1's auc: 0.831259\tvalid_1's binary_logloss: 0.135835\n",
            "[199]\ttraining's auc: 0.903534\ttraining's binary_logloss: 0.115483\tvalid_1's auc: 0.831204\tvalid_1's binary_logloss: 0.135843\n",
            "[200]\ttraining's auc: 0.903647\ttraining's binary_logloss: 0.115417\tvalid_1's auc: 0.831065\tvalid_1's binary_logloss: 0.135862\n",
            "[201]\ttraining's auc: 0.903838\ttraining's binary_logloss: 0.115359\tvalid_1's auc: 0.831055\tvalid_1's binary_logloss: 0.135864\n",
            "[202]\ttraining's auc: 0.904032\ttraining's binary_logloss: 0.115291\tvalid_1's auc: 0.831067\tvalid_1's binary_logloss: 0.135865\n",
            "[203]\ttraining's auc: 0.90434\ttraining's binary_logloss: 0.115225\tvalid_1's auc: 0.831071\tvalid_1's binary_logloss: 0.135861\n",
            "[204]\ttraining's auc: 0.904475\ttraining's binary_logloss: 0.11516\tvalid_1's auc: 0.831102\tvalid_1's binary_logloss: 0.135858\n",
            "[205]\ttraining's auc: 0.904614\ttraining's binary_logloss: 0.115099\tvalid_1's auc: 0.831054\tvalid_1's binary_logloss: 0.135868\n",
            "[206]\ttraining's auc: 0.904904\ttraining's binary_logloss: 0.115036\tvalid_1's auc: 0.83106\tvalid_1's binary_logloss: 0.135863\n",
            "[207]\ttraining's auc: 0.905043\ttraining's binary_logloss: 0.114971\tvalid_1's auc: 0.831076\tvalid_1's binary_logloss: 0.135867\n",
            "[208]\ttraining's auc: 0.905225\ttraining's binary_logloss: 0.114916\tvalid_1's auc: 0.831088\tvalid_1's binary_logloss: 0.135863\n",
            "[209]\ttraining's auc: 0.905401\ttraining's binary_logloss: 0.114854\tvalid_1's auc: 0.831094\tvalid_1's binary_logloss: 0.135866\n",
            "[210]\ttraining's auc: 0.905532\ttraining's binary_logloss: 0.114792\tvalid_1's auc: 0.831053\tvalid_1's binary_logloss: 0.135879\n",
            "[211]\ttraining's auc: 0.905742\ttraining's binary_logloss: 0.114726\tvalid_1's auc: 0.831072\tvalid_1's binary_logloss: 0.135876\n",
            "[212]\ttraining's auc: 0.905907\ttraining's binary_logloss: 0.11465\tvalid_1's auc: 0.831012\tvalid_1's binary_logloss: 0.135889\n",
            "[213]\ttraining's auc: 0.906012\ttraining's binary_logloss: 0.114591\tvalid_1's auc: 0.830988\tvalid_1's binary_logloss: 0.135893\n",
            "[214]\ttraining's auc: 0.906173\ttraining's binary_logloss: 0.114519\tvalid_1's auc: 0.831001\tvalid_1's binary_logloss: 0.135898\n",
            "[215]\ttraining's auc: 0.906431\ttraining's binary_logloss: 0.114454\tvalid_1's auc: 0.830985\tvalid_1's binary_logloss: 0.1359\n",
            "[216]\ttraining's auc: 0.906642\ttraining's binary_logloss: 0.114393\tvalid_1's auc: 0.830985\tvalid_1's binary_logloss: 0.135903\n",
            "[217]\ttraining's auc: 0.906741\ttraining's binary_logloss: 0.114338\tvalid_1's auc: 0.830997\tvalid_1's binary_logloss: 0.135906\n",
            "[218]\ttraining's auc: 0.906901\ttraining's binary_logloss: 0.114269\tvalid_1's auc: 0.831007\tvalid_1's binary_logloss: 0.135901\n",
            "[219]\ttraining's auc: 0.906974\ttraining's binary_logloss: 0.114214\tvalid_1's auc: 0.830968\tvalid_1's binary_logloss: 0.13591\n",
            "[220]\ttraining's auc: 0.907079\ttraining's binary_logloss: 0.114156\tvalid_1's auc: 0.83103\tvalid_1's binary_logloss: 0.135904\n",
            "[221]\ttraining's auc: 0.907214\ttraining's binary_logloss: 0.11409\tvalid_1's auc: 0.831029\tvalid_1's binary_logloss: 0.1359\n",
            "[222]\ttraining's auc: 0.90735\ttraining's binary_logloss: 0.114027\tvalid_1's auc: 0.831039\tvalid_1's binary_logloss: 0.1359\n",
            "[223]\ttraining's auc: 0.907477\ttraining's binary_logloss: 0.113967\tvalid_1's auc: 0.831006\tvalid_1's binary_logloss: 0.135905\n",
            "[224]\ttraining's auc: 0.907589\ttraining's binary_logloss: 0.113913\tvalid_1's auc: 0.830988\tvalid_1's binary_logloss: 0.135909\n",
            " 88%|████████▊ | 44/50 [22:54<03:38, 36.45s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.165245\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.159421\n",
            "[2]\ttraining's auc: 0.819299\ttraining's binary_logloss: 0.163723\tvalid_1's auc: 0.802595\tvalid_1's binary_logloss: 0.1582\n",
            "[3]\ttraining's auc: 0.822267\ttraining's binary_logloss: 0.162319\tvalid_1's auc: 0.804784\tvalid_1's binary_logloss: 0.157046\n",
            "[4]\ttraining's auc: 0.823637\ttraining's binary_logloss: 0.16101\tvalid_1's auc: 0.805451\tvalid_1's binary_logloss: 0.155995\n",
            "[5]\ttraining's auc: 0.829238\ttraining's binary_logloss: 0.159751\tvalid_1's auc: 0.815959\tvalid_1's binary_logloss: 0.155012\n",
            "[6]\ttraining's auc: 0.830809\ttraining's binary_logloss: 0.158576\tvalid_1's auc: 0.816961\tvalid_1's binary_logloss: 0.154074\n",
            "[7]\ttraining's auc: 0.833611\ttraining's binary_logloss: 0.157469\tvalid_1's auc: 0.818951\tvalid_1's binary_logloss: 0.153209\n",
            "[8]\ttraining's auc: 0.834195\ttraining's binary_logloss: 0.156436\tvalid_1's auc: 0.818991\tvalid_1's binary_logloss: 0.152379\n",
            "[9]\ttraining's auc: 0.834747\ttraining's binary_logloss: 0.155479\tvalid_1's auc: 0.819174\tvalid_1's binary_logloss: 0.151609\n",
            "[10]\ttraining's auc: 0.834668\ttraining's binary_logloss: 0.15456\tvalid_1's auc: 0.819212\tvalid_1's binary_logloss: 0.150877\n",
            "[11]\ttraining's auc: 0.835148\ttraining's binary_logloss: 0.153699\tvalid_1's auc: 0.819315\tvalid_1's binary_logloss: 0.150192\n",
            "[12]\ttraining's auc: 0.835569\ttraining's binary_logloss: 0.152845\tvalid_1's auc: 0.819367\tvalid_1's binary_logloss: 0.149522\n",
            "[13]\ttraining's auc: 0.836679\ttraining's binary_logloss: 0.152053\tvalid_1's auc: 0.820754\tvalid_1's binary_logloss: 0.148885\n",
            "[14]\ttraining's auc: 0.837508\ttraining's binary_logloss: 0.151293\tvalid_1's auc: 0.820959\tvalid_1's binary_logloss: 0.148293\n",
            "[15]\ttraining's auc: 0.837626\ttraining's binary_logloss: 0.150566\tvalid_1's auc: 0.821162\tvalid_1's binary_logloss: 0.147738\n",
            "[16]\ttraining's auc: 0.840404\ttraining's binary_logloss: 0.149854\tvalid_1's auc: 0.823446\tvalid_1's binary_logloss: 0.147224\n",
            "[17]\ttraining's auc: 0.840938\ttraining's binary_logloss: 0.149181\tvalid_1's auc: 0.823451\tvalid_1's binary_logloss: 0.146725\n",
            "[18]\ttraining's auc: 0.841503\ttraining's binary_logloss: 0.148527\tvalid_1's auc: 0.823599\tvalid_1's binary_logloss: 0.146243\n",
            "[19]\ttraining's auc: 0.843055\ttraining's binary_logloss: 0.147919\tvalid_1's auc: 0.823728\tvalid_1's binary_logloss: 0.145784\n",
            "[20]\ttraining's auc: 0.844282\ttraining's binary_logloss: 0.147307\tvalid_1's auc: 0.824228\tvalid_1's binary_logloss: 0.145315\n",
            "[21]\ttraining's auc: 0.844567\ttraining's binary_logloss: 0.146731\tvalid_1's auc: 0.824588\tvalid_1's binary_logloss: 0.144879\n",
            "[22]\ttraining's auc: 0.84677\ttraining's binary_logloss: 0.146153\tvalid_1's auc: 0.827162\tvalid_1's binary_logloss: 0.144467\n",
            "[23]\ttraining's auc: 0.848404\ttraining's binary_logloss: 0.1456\tvalid_1's auc: 0.827814\tvalid_1's binary_logloss: 0.144067\n",
            "[24]\ttraining's auc: 0.848824\ttraining's binary_logloss: 0.145073\tvalid_1's auc: 0.828206\tvalid_1's binary_logloss: 0.143676\n",
            "[25]\ttraining's auc: 0.849233\ttraining's binary_logloss: 0.144563\tvalid_1's auc: 0.828649\tvalid_1's binary_logloss: 0.143301\n",
            "[26]\ttraining's auc: 0.849948\ttraining's binary_logloss: 0.144072\tvalid_1's auc: 0.828666\tvalid_1's binary_logloss: 0.142945\n",
            "[27]\ttraining's auc: 0.850308\ttraining's binary_logloss: 0.143597\tvalid_1's auc: 0.829048\tvalid_1's binary_logloss: 0.142602\n",
            "[28]\ttraining's auc: 0.851178\ttraining's binary_logloss: 0.143134\tvalid_1's auc: 0.829249\tvalid_1's binary_logloss: 0.14227\n",
            "[29]\ttraining's auc: 0.851509\ttraining's binary_logloss: 0.142693\tvalid_1's auc: 0.829093\tvalid_1's binary_logloss: 0.141947\n",
            "[30]\ttraining's auc: 0.852589\ttraining's binary_logloss: 0.142263\tvalid_1's auc: 0.829147\tvalid_1's binary_logloss: 0.141624\n",
            "[31]\ttraining's auc: 0.853437\ttraining's binary_logloss: 0.141815\tvalid_1's auc: 0.82968\tvalid_1's binary_logloss: 0.141293\n",
            "[32]\ttraining's auc: 0.853849\ttraining's binary_logloss: 0.141396\tvalid_1's auc: 0.830089\tvalid_1's binary_logloss: 0.140958\n",
            "[33]\ttraining's auc: 0.854431\ttraining's binary_logloss: 0.14099\tvalid_1's auc: 0.83062\tvalid_1's binary_logloss: 0.140673\n",
            "[34]\ttraining's auc: 0.855274\ttraining's binary_logloss: 0.140595\tvalid_1's auc: 0.830687\tvalid_1's binary_logloss: 0.140383\n",
            "[35]\ttraining's auc: 0.855864\ttraining's binary_logloss: 0.140208\tvalid_1's auc: 0.831239\tvalid_1's binary_logloss: 0.140084\n",
            "[36]\ttraining's auc: 0.857081\ttraining's binary_logloss: 0.139823\tvalid_1's auc: 0.833035\tvalid_1's binary_logloss: 0.139791\n",
            "[37]\ttraining's auc: 0.857419\ttraining's binary_logloss: 0.139471\tvalid_1's auc: 0.833028\tvalid_1's binary_logloss: 0.139543\n",
            "[38]\ttraining's auc: 0.85794\ttraining's binary_logloss: 0.139118\tvalid_1's auc: 0.833127\tvalid_1's binary_logloss: 0.139296\n",
            "[39]\ttraining's auc: 0.85828\ttraining's binary_logloss: 0.138785\tvalid_1's auc: 0.833112\tvalid_1's binary_logloss: 0.139063\n",
            "[40]\ttraining's auc: 0.858612\ttraining's binary_logloss: 0.138448\tvalid_1's auc: 0.833077\tvalid_1's binary_logloss: 0.138827\n",
            "[41]\ttraining's auc: 0.85913\ttraining's binary_logloss: 0.138114\tvalid_1's auc: 0.833483\tvalid_1's binary_logloss: 0.138593\n",
            "[42]\ttraining's auc: 0.859556\ttraining's binary_logloss: 0.137782\tvalid_1's auc: 0.833388\tvalid_1's binary_logloss: 0.138376\n",
            "[43]\ttraining's auc: 0.859881\ttraining's binary_logloss: 0.137463\tvalid_1's auc: 0.833231\tvalid_1's binary_logloss: 0.138171\n",
            "[44]\ttraining's auc: 0.861203\ttraining's binary_logloss: 0.137162\tvalid_1's auc: 0.833816\tvalid_1's binary_logloss: 0.137968\n",
            "[45]\ttraining's auc: 0.861505\ttraining's binary_logloss: 0.136863\tvalid_1's auc: 0.834046\tvalid_1's binary_logloss: 0.137776\n",
            "[46]\ttraining's auc: 0.861694\ttraining's binary_logloss: 0.136575\tvalid_1's auc: 0.83396\tvalid_1's binary_logloss: 0.137566\n",
            "[47]\ttraining's auc: 0.862035\ttraining's binary_logloss: 0.136299\tvalid_1's auc: 0.834169\tvalid_1's binary_logloss: 0.137387\n",
            "[48]\ttraining's auc: 0.862354\ttraining's binary_logloss: 0.135997\tvalid_1's auc: 0.833943\tvalid_1's binary_logloss: 0.137209\n",
            "[49]\ttraining's auc: 0.862531\ttraining's binary_logloss: 0.135723\tvalid_1's auc: 0.834083\tvalid_1's binary_logloss: 0.137021\n",
            "[50]\ttraining's auc: 0.862845\ttraining's binary_logloss: 0.135464\tvalid_1's auc: 0.834254\tvalid_1's binary_logloss: 0.136842\n",
            "[51]\ttraining's auc: 0.862911\ttraining's binary_logloss: 0.135203\tvalid_1's auc: 0.834116\tvalid_1's binary_logloss: 0.136689\n",
            "[52]\ttraining's auc: 0.863377\ttraining's binary_logloss: 0.134939\tvalid_1's auc: 0.834398\tvalid_1's binary_logloss: 0.136506\n",
            "[53]\ttraining's auc: 0.863619\ttraining's binary_logloss: 0.134698\tvalid_1's auc: 0.834336\tvalid_1's binary_logloss: 0.136368\n",
            "[54]\ttraining's auc: 0.864728\ttraining's binary_logloss: 0.134432\tvalid_1's auc: 0.834674\tvalid_1's binary_logloss: 0.136218\n",
            "[55]\ttraining's auc: 0.865582\ttraining's binary_logloss: 0.134167\tvalid_1's auc: 0.834773\tvalid_1's binary_logloss: 0.136066\n",
            "[56]\ttraining's auc: 0.866507\ttraining's binary_logloss: 0.133918\tvalid_1's auc: 0.83498\tvalid_1's binary_logloss: 0.135926\n",
            "[57]\ttraining's auc: 0.867121\ttraining's binary_logloss: 0.133675\tvalid_1's auc: 0.835258\tvalid_1's binary_logloss: 0.135781\n",
            "[58]\ttraining's auc: 0.867584\ttraining's binary_logloss: 0.133444\tvalid_1's auc: 0.835311\tvalid_1's binary_logloss: 0.135654\n",
            "[59]\ttraining's auc: 0.86817\ttraining's binary_logloss: 0.133205\tvalid_1's auc: 0.83572\tvalid_1's binary_logloss: 0.135521\n",
            "[60]\ttraining's auc: 0.868598\ttraining's binary_logloss: 0.132981\tvalid_1's auc: 0.836073\tvalid_1's binary_logloss: 0.135394\n",
            "[61]\ttraining's auc: 0.868881\ttraining's binary_logloss: 0.13276\tvalid_1's auc: 0.836205\tvalid_1's binary_logloss: 0.135274\n",
            "[62]\ttraining's auc: 0.869548\ttraining's binary_logloss: 0.132534\tvalid_1's auc: 0.836189\tvalid_1's binary_logloss: 0.135151\n",
            "[63]\ttraining's auc: 0.870115\ttraining's binary_logloss: 0.13231\tvalid_1's auc: 0.835968\tvalid_1's binary_logloss: 0.135033\n",
            "[64]\ttraining's auc: 0.870392\ttraining's binary_logloss: 0.132097\tvalid_1's auc: 0.835914\tvalid_1's binary_logloss: 0.134918\n",
            "[65]\ttraining's auc: 0.871033\ttraining's binary_logloss: 0.131894\tvalid_1's auc: 0.835866\tvalid_1's binary_logloss: 0.134805\n",
            "[66]\ttraining's auc: 0.871273\ttraining's binary_logloss: 0.13169\tvalid_1's auc: 0.835768\tvalid_1's binary_logloss: 0.134707\n",
            "[67]\ttraining's auc: 0.871538\ttraining's binary_logloss: 0.131493\tvalid_1's auc: 0.835657\tvalid_1's binary_logloss: 0.134618\n",
            "[68]\ttraining's auc: 0.871872\ttraining's binary_logloss: 0.131301\tvalid_1's auc: 0.83561\tvalid_1's binary_logloss: 0.134508\n",
            "[69]\ttraining's auc: 0.87202\ttraining's binary_logloss: 0.131113\tvalid_1's auc: 0.835498\tvalid_1's binary_logloss: 0.134423\n",
            "[70]\ttraining's auc: 0.872271\ttraining's binary_logloss: 0.130924\tvalid_1's auc: 0.83532\tvalid_1's binary_logloss: 0.134341\n",
            "[71]\ttraining's auc: 0.872476\ttraining's binary_logloss: 0.130738\tvalid_1's auc: 0.83548\tvalid_1's binary_logloss: 0.134246\n",
            "[72]\ttraining's auc: 0.87278\ttraining's binary_logloss: 0.130555\tvalid_1's auc: 0.835432\tvalid_1's binary_logloss: 0.134173\n",
            "[73]\ttraining's auc: 0.873172\ttraining's binary_logloss: 0.13036\tvalid_1's auc: 0.835215\tvalid_1's binary_logloss: 0.1341\n",
            "[74]\ttraining's auc: 0.87325\ttraining's binary_logloss: 0.130185\tvalid_1's auc: 0.835396\tvalid_1's binary_logloss: 0.134\n",
            "[75]\ttraining's auc: 0.873474\ttraining's binary_logloss: 0.130019\tvalid_1's auc: 0.83531\tvalid_1's binary_logloss: 0.133927\n",
            "[76]\ttraining's auc: 0.873699\ttraining's binary_logloss: 0.129842\tvalid_1's auc: 0.835195\tvalid_1's binary_logloss: 0.133865\n",
            "[77]\ttraining's auc: 0.873848\ttraining's binary_logloss: 0.129676\tvalid_1's auc: 0.835021\tvalid_1's binary_logloss: 0.133804\n",
            "[78]\ttraining's auc: 0.874278\ttraining's binary_logloss: 0.129499\tvalid_1's auc: 0.835117\tvalid_1's binary_logloss: 0.133723\n",
            "[79]\ttraining's auc: 0.874499\ttraining's binary_logloss: 0.129323\tvalid_1's auc: 0.83522\tvalid_1's binary_logloss: 0.133646\n",
            "[80]\ttraining's auc: 0.874725\ttraining's binary_logloss: 0.129161\tvalid_1's auc: 0.835145\tvalid_1's binary_logloss: 0.133574\n",
            "[81]\ttraining's auc: 0.874935\ttraining's binary_logloss: 0.128991\tvalid_1's auc: 0.835079\tvalid_1's binary_logloss: 0.13351\n",
            "[82]\ttraining's auc: 0.875043\ttraining's binary_logloss: 0.128837\tvalid_1's auc: 0.835026\tvalid_1's binary_logloss: 0.13345\n",
            "[83]\ttraining's auc: 0.875266\ttraining's binary_logloss: 0.12868\tvalid_1's auc: 0.835039\tvalid_1's binary_logloss: 0.133383\n",
            "[84]\ttraining's auc: 0.875309\ttraining's binary_logloss: 0.128532\tvalid_1's auc: 0.835128\tvalid_1's binary_logloss: 0.133323\n",
            "[85]\ttraining's auc: 0.875514\ttraining's binary_logloss: 0.128378\tvalid_1's auc: 0.835148\tvalid_1's binary_logloss: 0.133249\n",
            "[86]\ttraining's auc: 0.875772\ttraining's binary_logloss: 0.128235\tvalid_1's auc: 0.835219\tvalid_1's binary_logloss: 0.133181\n",
            "[87]\ttraining's auc: 0.875955\ttraining's binary_logloss: 0.128089\tvalid_1's auc: 0.835175\tvalid_1's binary_logloss: 0.133123\n",
            "[88]\ttraining's auc: 0.876056\ttraining's binary_logloss: 0.127954\tvalid_1's auc: 0.835051\tvalid_1's binary_logloss: 0.133065\n",
            "[89]\ttraining's auc: 0.876243\ttraining's binary_logloss: 0.127816\tvalid_1's auc: 0.83495\tvalid_1's binary_logloss: 0.133021\n",
            "[90]\ttraining's auc: 0.876399\ttraining's binary_logloss: 0.127685\tvalid_1's auc: 0.834931\tvalid_1's binary_logloss: 0.132963\n",
            "[91]\ttraining's auc: 0.876743\ttraining's binary_logloss: 0.127547\tvalid_1's auc: 0.835056\tvalid_1's binary_logloss: 0.132904\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 88%|████████▊ | 44/50 [23:10<03:38, 36.45s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.161483\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.167035\n",
            "[2]\ttraining's auc: 0.827205\ttraining's binary_logloss: 0.160027\tvalid_1's auc: 0.812039\tvalid_1's binary_logloss: 0.165641\n",
            "[3]\ttraining's auc: 0.83013\ttraining's binary_logloss: 0.158672\tvalid_1's auc: 0.814888\tvalid_1's binary_logloss: 0.164404\n",
            "[4]\ttraining's auc: 0.83122\ttraining's binary_logloss: 0.157425\tvalid_1's auc: 0.815989\tvalid_1's binary_logloss: 0.163255\n",
            "[5]\ttraining's auc: 0.831937\ttraining's binary_logloss: 0.156259\tvalid_1's auc: 0.815402\tvalid_1's binary_logloss: 0.162234\n",
            "[6]\ttraining's auc: 0.833728\ttraining's binary_logloss: 0.155129\tvalid_1's auc: 0.816175\tvalid_1's binary_logloss: 0.161191\n",
            "[7]\ttraining's auc: 0.834714\ttraining's binary_logloss: 0.15407\tvalid_1's auc: 0.816214\tvalid_1's binary_logloss: 0.160274\n",
            "[8]\ttraining's auc: 0.835383\ttraining's binary_logloss: 0.1531\tvalid_1's auc: 0.816452\tvalid_1's binary_logloss: 0.15941\n",
            "[9]\ttraining's auc: 0.837797\ttraining's binary_logloss: 0.152159\tvalid_1's auc: 0.817977\tvalid_1's binary_logloss: 0.15859\n",
            "[10]\ttraining's auc: 0.838358\ttraining's binary_logloss: 0.151276\tvalid_1's auc: 0.81787\tvalid_1's binary_logloss: 0.157803\n",
            "[11]\ttraining's auc: 0.838618\ttraining's binary_logloss: 0.150442\tvalid_1's auc: 0.818169\tvalid_1's binary_logloss: 0.157094\n",
            "[12]\ttraining's auc: 0.839753\ttraining's binary_logloss: 0.149627\tvalid_1's auc: 0.81892\tvalid_1's binary_logloss: 0.156374\n",
            "[13]\ttraining's auc: 0.841589\ttraining's binary_logloss: 0.148856\tvalid_1's auc: 0.819901\tvalid_1's binary_logloss: 0.15569\n",
            "[14]\ttraining's auc: 0.842156\ttraining's binary_logloss: 0.1481\tvalid_1's auc: 0.82023\tvalid_1's binary_logloss: 0.155044\n",
            "[15]\ttraining's auc: 0.842751\ttraining's binary_logloss: 0.147409\tvalid_1's auc: 0.820668\tvalid_1's binary_logloss: 0.154445\n",
            "[16]\ttraining's auc: 0.843323\ttraining's binary_logloss: 0.146727\tvalid_1's auc: 0.821326\tvalid_1's binary_logloss: 0.153854\n",
            "[17]\ttraining's auc: 0.846387\ttraining's binary_logloss: 0.146042\tvalid_1's auc: 0.823764\tvalid_1's binary_logloss: 0.153272\n",
            "[18]\ttraining's auc: 0.846953\ttraining's binary_logloss: 0.145393\tvalid_1's auc: 0.82475\tvalid_1's binary_logloss: 0.1527\n",
            "[19]\ttraining's auc: 0.847037\ttraining's binary_logloss: 0.144753\tvalid_1's auc: 0.824886\tvalid_1's binary_logloss: 0.152187\n",
            "[20]\ttraining's auc: 0.848622\ttraining's binary_logloss: 0.144162\tvalid_1's auc: 0.826498\tvalid_1's binary_logloss: 0.151693\n",
            "[21]\ttraining's auc: 0.849291\ttraining's binary_logloss: 0.143598\tvalid_1's auc: 0.827048\tvalid_1's binary_logloss: 0.151213\n",
            "[22]\ttraining's auc: 0.84964\ttraining's binary_logloss: 0.14306\tvalid_1's auc: 0.827083\tvalid_1's binary_logloss: 0.150751\n",
            "[23]\ttraining's auc: 0.849719\ttraining's binary_logloss: 0.142532\tvalid_1's auc: 0.827013\tvalid_1's binary_logloss: 0.150322\n",
            "[24]\ttraining's auc: 0.849969\ttraining's binary_logloss: 0.142021\tvalid_1's auc: 0.827055\tvalid_1's binary_logloss: 0.149919\n",
            "[25]\ttraining's auc: 0.850591\ttraining's binary_logloss: 0.141514\tvalid_1's auc: 0.827924\tvalid_1's binary_logloss: 0.149484\n",
            "[26]\ttraining's auc: 0.851129\ttraining's binary_logloss: 0.141036\tvalid_1's auc: 0.828397\tvalid_1's binary_logloss: 0.149088\n",
            "[27]\ttraining's auc: 0.851997\ttraining's binary_logloss: 0.140562\tvalid_1's auc: 0.828858\tvalid_1's binary_logloss: 0.148684\n",
            "[28]\ttraining's auc: 0.85238\ttraining's binary_logloss: 0.140078\tvalid_1's auc: 0.828631\tvalid_1's binary_logloss: 0.148325\n",
            "[29]\ttraining's auc: 0.852678\ttraining's binary_logloss: 0.139628\tvalid_1's auc: 0.828557\tvalid_1's binary_logloss: 0.147969\n",
            "[30]\ttraining's auc: 0.853037\ttraining's binary_logloss: 0.13919\tvalid_1's auc: 0.828849\tvalid_1's binary_logloss: 0.14761\n",
            "[31]\ttraining's auc: 0.853307\ttraining's binary_logloss: 0.138773\tvalid_1's auc: 0.829132\tvalid_1's binary_logloss: 0.147283\n",
            "[32]\ttraining's auc: 0.853249\ttraining's binary_logloss: 0.13836\tvalid_1's auc: 0.829118\tvalid_1's binary_logloss: 0.146955\n",
            "[33]\ttraining's auc: 0.854349\ttraining's binary_logloss: 0.137955\tvalid_1's auc: 0.829578\tvalid_1's binary_logloss: 0.146644\n",
            "[34]\ttraining's auc: 0.855058\ttraining's binary_logloss: 0.137567\tvalid_1's auc: 0.829684\tvalid_1's binary_logloss: 0.146354\n",
            "[35]\ttraining's auc: 0.855247\ttraining's binary_logloss: 0.137189\tvalid_1's auc: 0.829654\tvalid_1's binary_logloss: 0.146077\n",
            "[36]\ttraining's auc: 0.856047\ttraining's binary_logloss: 0.136818\tvalid_1's auc: 0.829857\tvalid_1's binary_logloss: 0.145797\n",
            "[37]\ttraining's auc: 0.856274\ttraining's binary_logloss: 0.136456\tvalid_1's auc: 0.830068\tvalid_1's binary_logloss: 0.14553\n",
            "[38]\ttraining's auc: 0.85648\ttraining's binary_logloss: 0.136115\tvalid_1's auc: 0.830196\tvalid_1's binary_logloss: 0.145262\n",
            "[39]\ttraining's auc: 0.856827\ttraining's binary_logloss: 0.135778\tvalid_1's auc: 0.830365\tvalid_1's binary_logloss: 0.145001\n",
            "[40]\ttraining's auc: 0.857163\ttraining's binary_logloss: 0.135456\tvalid_1's auc: 0.830558\tvalid_1's binary_logloss: 0.144752\n",
            "[41]\ttraining's auc: 0.857453\ttraining's binary_logloss: 0.135146\tvalid_1's auc: 0.830688\tvalid_1's binary_logloss: 0.144502\n",
            "[42]\ttraining's auc: 0.85794\ttraining's binary_logloss: 0.134833\tvalid_1's auc: 0.830735\tvalid_1's binary_logloss: 0.144285\n",
            "[43]\ttraining's auc: 0.8583\ttraining's binary_logloss: 0.134517\tvalid_1's auc: 0.830995\tvalid_1's binary_logloss: 0.144054\n",
            "[44]\ttraining's auc: 0.858795\ttraining's binary_logloss: 0.134227\tvalid_1's auc: 0.830924\tvalid_1's binary_logloss: 0.143841\n",
            "[45]\ttraining's auc: 0.859243\ttraining's binary_logloss: 0.133938\tvalid_1's auc: 0.831045\tvalid_1's binary_logloss: 0.143616\n",
            "[46]\ttraining's auc: 0.85937\ttraining's binary_logloss: 0.133656\tvalid_1's auc: 0.831159\tvalid_1's binary_logloss: 0.143411\n",
            "[47]\ttraining's auc: 0.859646\ttraining's binary_logloss: 0.133381\tvalid_1's auc: 0.831222\tvalid_1's binary_logloss: 0.143209\n",
            "[48]\ttraining's auc: 0.8609\ttraining's binary_logloss: 0.133112\tvalid_1's auc: 0.831172\tvalid_1's binary_logloss: 0.143014\n",
            "[49]\ttraining's auc: 0.861098\ttraining's binary_logloss: 0.132849\tvalid_1's auc: 0.831252\tvalid_1's binary_logloss: 0.142831\n",
            "[50]\ttraining's auc: 0.861789\ttraining's binary_logloss: 0.132583\tvalid_1's auc: 0.831328\tvalid_1's binary_logloss: 0.142657\n",
            "[51]\ttraining's auc: 0.86229\ttraining's binary_logloss: 0.132332\tvalid_1's auc: 0.831446\tvalid_1's binary_logloss: 0.142479\n",
            "[52]\ttraining's auc: 0.862654\ttraining's binary_logloss: 0.132079\tvalid_1's auc: 0.831322\tvalid_1's binary_logloss: 0.142323\n",
            "[53]\ttraining's auc: 0.862917\ttraining's binary_logloss: 0.131838\tvalid_1's auc: 0.831492\tvalid_1's binary_logloss: 0.142153\n",
            "[54]\ttraining's auc: 0.86341\ttraining's binary_logloss: 0.131602\tvalid_1's auc: 0.831513\tvalid_1's binary_logloss: 0.142\n",
            "[55]\ttraining's auc: 0.86374\ttraining's binary_logloss: 0.131365\tvalid_1's auc: 0.831346\tvalid_1's binary_logloss: 0.141856\n",
            "[56]\ttraining's auc: 0.864058\ttraining's binary_logloss: 0.131129\tvalid_1's auc: 0.831543\tvalid_1's binary_logloss: 0.141707\n",
            "[57]\ttraining's auc: 0.864423\ttraining's binary_logloss: 0.130903\tvalid_1's auc: 0.831619\tvalid_1's binary_logloss: 0.141568\n",
            "[58]\ttraining's auc: 0.864748\ttraining's binary_logloss: 0.130684\tvalid_1's auc: 0.831704\tvalid_1's binary_logloss: 0.141424\n",
            "[59]\ttraining's auc: 0.864945\ttraining's binary_logloss: 0.130472\tvalid_1's auc: 0.831726\tvalid_1's binary_logloss: 0.141297\n",
            "[60]\ttraining's auc: 0.865233\ttraining's binary_logloss: 0.130263\tvalid_1's auc: 0.831648\tvalid_1's binary_logloss: 0.141175\n",
            "[61]\ttraining's auc: 0.866383\ttraining's binary_logloss: 0.130043\tvalid_1's auc: 0.831851\tvalid_1's binary_logloss: 0.141046\n",
            "[62]\ttraining's auc: 0.867138\ttraining's binary_logloss: 0.12982\tvalid_1's auc: 0.832111\tvalid_1's binary_logloss: 0.14092\n",
            "[63]\ttraining's auc: 0.867527\ttraining's binary_logloss: 0.129605\tvalid_1's auc: 0.832185\tvalid_1's binary_logloss: 0.140785\n",
            "[64]\ttraining's auc: 0.868193\ttraining's binary_logloss: 0.129397\tvalid_1's auc: 0.832355\tvalid_1's binary_logloss: 0.140648\n",
            "[65]\ttraining's auc: 0.868681\ttraining's binary_logloss: 0.129193\tvalid_1's auc: 0.832332\tvalid_1's binary_logloss: 0.140538\n",
            "[66]\ttraining's auc: 0.869018\ttraining's binary_logloss: 0.129006\tvalid_1's auc: 0.832199\tvalid_1's binary_logloss: 0.140433\n",
            "[67]\ttraining's auc: 0.869577\ttraining's binary_logloss: 0.128796\tvalid_1's auc: 0.832067\tvalid_1's binary_logloss: 0.140337\n",
            "[68]\ttraining's auc: 0.870818\ttraining's binary_logloss: 0.128592\tvalid_1's auc: 0.832729\tvalid_1's binary_logloss: 0.140231\n",
            "[69]\ttraining's auc: 0.871558\ttraining's binary_logloss: 0.128407\tvalid_1's auc: 0.834225\tvalid_1's binary_logloss: 0.14012\n",
            "[70]\ttraining's auc: 0.872068\ttraining's binary_logloss: 0.128211\tvalid_1's auc: 0.834183\tvalid_1's binary_logloss: 0.140017\n",
            "[71]\ttraining's auc: 0.872277\ttraining's binary_logloss: 0.128029\tvalid_1's auc: 0.834216\tvalid_1's binary_logloss: 0.139919\n",
            "[72]\ttraining's auc: 0.872585\ttraining's binary_logloss: 0.127854\tvalid_1's auc: 0.834347\tvalid_1's binary_logloss: 0.139819\n",
            "[73]\ttraining's auc: 0.872781\ttraining's binary_logloss: 0.127674\tvalid_1's auc: 0.834448\tvalid_1's binary_logloss: 0.139712\n",
            "[74]\ttraining's auc: 0.872973\ttraining's binary_logloss: 0.127514\tvalid_1's auc: 0.834444\tvalid_1's binary_logloss: 0.139613\n",
            "[75]\ttraining's auc: 0.873361\ttraining's binary_logloss: 0.127335\tvalid_1's auc: 0.834468\tvalid_1's binary_logloss: 0.139523\n",
            "[76]\ttraining's auc: 0.873719\ttraining's binary_logloss: 0.127166\tvalid_1's auc: 0.834474\tvalid_1's binary_logloss: 0.139428\n",
            "[77]\ttraining's auc: 0.874073\ttraining's binary_logloss: 0.127001\tvalid_1's auc: 0.834773\tvalid_1's binary_logloss: 0.139342\n",
            "[78]\ttraining's auc: 0.874313\ttraining's binary_logloss: 0.126841\tvalid_1's auc: 0.83503\tvalid_1's binary_logloss: 0.139256\n",
            "[79]\ttraining's auc: 0.874704\ttraining's binary_logloss: 0.126671\tvalid_1's auc: 0.835142\tvalid_1's binary_logloss: 0.13917\n",
            "[80]\ttraining's auc: 0.875026\ttraining's binary_logloss: 0.126511\tvalid_1's auc: 0.83531\tvalid_1's binary_logloss: 0.13909\n",
            "[81]\ttraining's auc: 0.875287\ttraining's binary_logloss: 0.126354\tvalid_1's auc: 0.835173\tvalid_1's binary_logloss: 0.139019\n",
            "[82]\ttraining's auc: 0.875841\ttraining's binary_logloss: 0.126199\tvalid_1's auc: 0.835599\tvalid_1's binary_logloss: 0.138939\n",
            "[83]\ttraining's auc: 0.876119\ttraining's binary_logloss: 0.12605\tvalid_1's auc: 0.835528\tvalid_1's binary_logloss: 0.138864\n",
            "[84]\ttraining's auc: 0.876384\ttraining's binary_logloss: 0.125898\tvalid_1's auc: 0.835679\tvalid_1's binary_logloss: 0.138777\n",
            "[85]\ttraining's auc: 0.876456\ttraining's binary_logloss: 0.125751\tvalid_1's auc: 0.835612\tvalid_1's binary_logloss: 0.138722\n",
            "[86]\ttraining's auc: 0.876942\ttraining's binary_logloss: 0.125585\tvalid_1's auc: 0.835616\tvalid_1's binary_logloss: 0.138658\n",
            "[87]\ttraining's auc: 0.877227\ttraining's binary_logloss: 0.125436\tvalid_1's auc: 0.835785\tvalid_1's binary_logloss: 0.138581\n",
            "[88]\ttraining's auc: 0.877935\ttraining's binary_logloss: 0.125281\tvalid_1's auc: 0.835713\tvalid_1's binary_logloss: 0.138506\n",
            "[89]\ttraining's auc: 0.878309\ttraining's binary_logloss: 0.125126\tvalid_1's auc: 0.835728\tvalid_1's binary_logloss: 0.138444\n",
            "[90]\ttraining's auc: 0.878583\ttraining's binary_logloss: 0.124972\tvalid_1's auc: 0.83571\tvalid_1's binary_logloss: 0.138387\n",
            "[91]\ttraining's auc: 0.879235\ttraining's binary_logloss: 0.124817\tvalid_1's auc: 0.835744\tvalid_1's binary_logloss: 0.138328\n",
            "[92]\ttraining's auc: 0.879669\ttraining's binary_logloss: 0.124678\tvalid_1's auc: 0.835808\tvalid_1's binary_logloss: 0.138256\n",
            "[93]\ttraining's auc: 0.879955\ttraining's binary_logloss: 0.124536\tvalid_1's auc: 0.835803\tvalid_1's binary_logloss: 0.138205\n",
            "[94]\ttraining's auc: 0.880175\ttraining's binary_logloss: 0.124409\tvalid_1's auc: 0.835845\tvalid_1's binary_logloss: 0.138152\n",
            "[95]\ttraining's auc: 0.880453\ttraining's binary_logloss: 0.124275\tvalid_1's auc: 0.835903\tvalid_1's binary_logloss: 0.138092\n",
            "[96]\ttraining's auc: 0.880699\ttraining's binary_logloss: 0.124141\tvalid_1's auc: 0.836176\tvalid_1's binary_logloss: 0.138035\n",
            "[97]\ttraining's auc: 0.881019\ttraining's binary_logloss: 0.12401\tvalid_1's auc: 0.836196\tvalid_1's binary_logloss: 0.137984\n",
            "[98]\ttraining's auc: 0.881547\ttraining's binary_logloss: 0.123857\tvalid_1's auc: 0.836143\tvalid_1's binary_logloss: 0.137934\n",
            "[99]\ttraining's auc: 0.881688\ttraining's binary_logloss: 0.123732\tvalid_1's auc: 0.836115\tvalid_1's binary_logloss: 0.137892\n",
            "[100]\ttraining's auc: 0.881866\ttraining's binary_logloss: 0.123612\tvalid_1's auc: 0.836117\tvalid_1's binary_logloss: 0.137845\n",
            "[101]\ttraining's auc: 0.882278\ttraining's binary_logloss: 0.123479\tvalid_1's auc: 0.836414\tvalid_1's binary_logloss: 0.1378\n",
            "[102]\ttraining's auc: 0.882385\ttraining's binary_logloss: 0.12336\tvalid_1's auc: 0.836428\tvalid_1's binary_logloss: 0.137754\n",
            "[103]\ttraining's auc: 0.88252\ttraining's binary_logloss: 0.123239\tvalid_1's auc: 0.836433\tvalid_1's binary_logloss: 0.137715\n",
            "[104]\ttraining's auc: 0.88282\ttraining's binary_logloss: 0.123118\tvalid_1's auc: 0.83655\tvalid_1's binary_logloss: 0.137662\n",
            "[105]\ttraining's auc: 0.8831\ttraining's binary_logloss: 0.122994\tvalid_1's auc: 0.836536\tvalid_1's binary_logloss: 0.137616\n",
            "[106]\ttraining's auc: 0.883436\ttraining's binary_logloss: 0.122867\tvalid_1's auc: 0.836486\tvalid_1's binary_logloss: 0.137581\n",
            "[107]\ttraining's auc: 0.883853\ttraining's binary_logloss: 0.122747\tvalid_1's auc: 0.83646\tvalid_1's binary_logloss: 0.137529\n",
            "[108]\ttraining's auc: 0.884271\ttraining's binary_logloss: 0.122629\tvalid_1's auc: 0.83626\tvalid_1's binary_logloss: 0.137501\n",
            "[109]\ttraining's auc: 0.884724\ttraining's binary_logloss: 0.122498\tvalid_1's auc: 0.83609\tvalid_1's binary_logloss: 0.137453\n",
            "[110]\ttraining's auc: 0.884953\ttraining's binary_logloss: 0.122388\tvalid_1's auc: 0.836112\tvalid_1's binary_logloss: 0.137416\n",
            "[111]\ttraining's auc: 0.885271\ttraining's binary_logloss: 0.122262\tvalid_1's auc: 0.836302\tvalid_1's binary_logloss: 0.137368\n",
            "[112]\ttraining's auc: 0.885668\ttraining's binary_logloss: 0.122141\tvalid_1's auc: 0.836326\tvalid_1's binary_logloss: 0.137322\n",
            "[113]\ttraining's auc: 0.885971\ttraining's binary_logloss: 0.122018\tvalid_1's auc: 0.836326\tvalid_1's binary_logloss: 0.137287\n",
            "[114]\ttraining's auc: 0.886298\ttraining's binary_logloss: 0.121902\tvalid_1's auc: 0.836284\tvalid_1's binary_logloss: 0.13726\n",
            "[115]\ttraining's auc: 0.886602\ttraining's binary_logloss: 0.121784\tvalid_1's auc: 0.836336\tvalid_1's binary_logloss: 0.137218\n",
            "[116]\ttraining's auc: 0.886947\ttraining's binary_logloss: 0.121666\tvalid_1's auc: 0.8367\tvalid_1's binary_logloss: 0.137179\n",
            "[117]\ttraining's auc: 0.887203\ttraining's binary_logloss: 0.121555\tvalid_1's auc: 0.836845\tvalid_1's binary_logloss: 0.137136\n",
            "[118]\ttraining's auc: 0.887458\ttraining's binary_logloss: 0.121445\tvalid_1's auc: 0.836929\tvalid_1's binary_logloss: 0.137084\n",
            "[119]\ttraining's auc: 0.887807\ttraining's binary_logloss: 0.121331\tvalid_1's auc: 0.83689\tvalid_1's binary_logloss: 0.137052\n",
            "[120]\ttraining's auc: 0.8881\ttraining's binary_logloss: 0.121229\tvalid_1's auc: 0.836826\tvalid_1's binary_logloss: 0.137018\n",
            "[121]\ttraining's auc: 0.888359\ttraining's binary_logloss: 0.121117\tvalid_1's auc: 0.836785\tvalid_1's binary_logloss: 0.136989\n",
            "[122]\ttraining's auc: 0.888542\ttraining's binary_logloss: 0.121018\tvalid_1's auc: 0.836848\tvalid_1's binary_logloss: 0.136955\n",
            "[123]\ttraining's auc: 0.888798\ttraining's binary_logloss: 0.120906\tvalid_1's auc: 0.836973\tvalid_1's binary_logloss: 0.136915\n",
            "[124]\ttraining's auc: 0.889033\ttraining's binary_logloss: 0.120806\tvalid_1's auc: 0.836858\tvalid_1's binary_logloss: 0.136896\n",
            "[125]\ttraining's auc: 0.889355\ttraining's binary_logloss: 0.120697\tvalid_1's auc: 0.836824\tvalid_1's binary_logloss: 0.136867\n",
            "[126]\ttraining's auc: 0.889584\ttraining's binary_logloss: 0.120584\tvalid_1's auc: 0.836831\tvalid_1's binary_logloss: 0.136838\n",
            "[127]\ttraining's auc: 0.889811\ttraining's binary_logloss: 0.120484\tvalid_1's auc: 0.836729\tvalid_1's binary_logloss: 0.136816\n",
            "[128]\ttraining's auc: 0.889983\ttraining's binary_logloss: 0.120394\tvalid_1's auc: 0.836777\tvalid_1's binary_logloss: 0.136804\n",
            "[129]\ttraining's auc: 0.890148\ttraining's binary_logloss: 0.120303\tvalid_1's auc: 0.836696\tvalid_1's binary_logloss: 0.136791\n",
            "[130]\ttraining's auc: 0.890366\ttraining's binary_logloss: 0.120211\tvalid_1's auc: 0.83678\tvalid_1's binary_logloss: 0.136759\n",
            "[131]\ttraining's auc: 0.89054\ttraining's binary_logloss: 0.120116\tvalid_1's auc: 0.836691\tvalid_1's binary_logloss: 0.136743\n",
            "[132]\ttraining's auc: 0.89077\ttraining's binary_logloss: 0.120025\tvalid_1's auc: 0.836691\tvalid_1's binary_logloss: 0.136718\n",
            "[133]\ttraining's auc: 0.891039\ttraining's binary_logloss: 0.119929\tvalid_1's auc: 0.836764\tvalid_1's binary_logloss: 0.136697\n",
            "[134]\ttraining's auc: 0.891282\ttraining's binary_logloss: 0.119844\tvalid_1's auc: 0.83672\tvalid_1's binary_logloss: 0.136683\n",
            "[135]\ttraining's auc: 0.891458\ttraining's binary_logloss: 0.119762\tvalid_1's auc: 0.836689\tvalid_1's binary_logloss: 0.136674\n",
            "[136]\ttraining's auc: 0.891771\ttraining's binary_logloss: 0.11966\tvalid_1's auc: 0.836839\tvalid_1's binary_logloss: 0.136647\n",
            "[137]\ttraining's auc: 0.892042\ttraining's binary_logloss: 0.119566\tvalid_1's auc: 0.836919\tvalid_1's binary_logloss: 0.13662\n",
            "[138]\ttraining's auc: 0.892228\ttraining's binary_logloss: 0.119486\tvalid_1's auc: 0.836897\tvalid_1's binary_logloss: 0.136598\n",
            "[139]\ttraining's auc: 0.892457\ttraining's binary_logloss: 0.1194\tvalid_1's auc: 0.836865\tvalid_1's binary_logloss: 0.136575\n",
            "[140]\ttraining's auc: 0.892636\ttraining's binary_logloss: 0.119314\tvalid_1's auc: 0.836781\tvalid_1's binary_logloss: 0.136569\n",
            "[141]\ttraining's auc: 0.892832\ttraining's binary_logloss: 0.119227\tvalid_1's auc: 0.836872\tvalid_1's binary_logloss: 0.136544\n",
            "[142]\ttraining's auc: 0.893082\ttraining's binary_logloss: 0.119137\tvalid_1's auc: 0.836856\tvalid_1's binary_logloss: 0.136528\n",
            "[143]\ttraining's auc: 0.893298\ttraining's binary_logloss: 0.119057\tvalid_1's auc: 0.836917\tvalid_1's binary_logloss: 0.136501\n",
            "[144]\ttraining's auc: 0.893556\ttraining's binary_logloss: 0.118957\tvalid_1's auc: 0.836854\tvalid_1's binary_logloss: 0.136489\n",
            "[145]\ttraining's auc: 0.893812\ttraining's binary_logloss: 0.118857\tvalid_1's auc: 0.836838\tvalid_1's binary_logloss: 0.136476\n",
            "[146]\ttraining's auc: 0.893934\ttraining's binary_logloss: 0.11878\tvalid_1's auc: 0.836868\tvalid_1's binary_logloss: 0.136454\n",
            "[147]\ttraining's auc: 0.894213\ttraining's binary_logloss: 0.118699\tvalid_1's auc: 0.836889\tvalid_1's binary_logloss: 0.136444\n",
            "[148]\ttraining's auc: 0.89436\ttraining's binary_logloss: 0.118627\tvalid_1's auc: 0.836876\tvalid_1's binary_logloss: 0.136428\n",
            "[149]\ttraining's auc: 0.894555\ttraining's binary_logloss: 0.118544\tvalid_1's auc: 0.83678\tvalid_1's binary_logloss: 0.136427\n",
            "[150]\ttraining's auc: 0.89478\ttraining's binary_logloss: 0.11846\tvalid_1's auc: 0.836845\tvalid_1's binary_logloss: 0.136406\n",
            "[151]\ttraining's auc: 0.894991\ttraining's binary_logloss: 0.11837\tvalid_1's auc: 0.836818\tvalid_1's binary_logloss: 0.136398\n",
            "[152]\ttraining's auc: 0.895322\ttraining's binary_logloss: 0.118267\tvalid_1's auc: 0.836816\tvalid_1's binary_logloss: 0.136388\n",
            "[153]\ttraining's auc: 0.895546\ttraining's binary_logloss: 0.118185\tvalid_1's auc: 0.836905\tvalid_1's binary_logloss: 0.136371\n",
            " 90%|█████████ | 45/50 [23:34<03:55, 47.14s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.151021\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.154374\n",
            "[2]\ttraining's auc: 0.836045\ttraining's binary_logloss: 0.144587\tvalid_1's auc: 0.809199\tvalid_1's binary_logloss: 0.149194\n",
            "[3]\ttraining's auc: 0.844801\ttraining's binary_logloss: 0.140226\tvalid_1's auc: 0.81434\tvalid_1's binary_logloss: 0.146134\n",
            "[4]\ttraining's auc: 0.84983\ttraining's binary_logloss: 0.136674\tvalid_1's auc: 0.817815\tvalid_1's binary_logloss: 0.143864\n",
            "[5]\ttraining's auc: 0.853285\ttraining's binary_logloss: 0.134001\tvalid_1's auc: 0.8206\tvalid_1's binary_logloss: 0.142275\n",
            "[6]\ttraining's auc: 0.856193\ttraining's binary_logloss: 0.131647\tvalid_1's auc: 0.822159\tvalid_1's binary_logloss: 0.14071\n",
            "[7]\ttraining's auc: 0.861666\ttraining's binary_logloss: 0.129678\tvalid_1's auc: 0.823548\tvalid_1's binary_logloss: 0.139751\n",
            "[8]\ttraining's auc: 0.865806\ttraining's binary_logloss: 0.127964\tvalid_1's auc: 0.824711\tvalid_1's binary_logloss: 0.138933\n",
            "[9]\ttraining's auc: 0.869972\ttraining's binary_logloss: 0.126586\tvalid_1's auc: 0.824546\tvalid_1's binary_logloss: 0.138445\n",
            "[10]\ttraining's auc: 0.8728\ttraining's binary_logloss: 0.12534\tvalid_1's auc: 0.824654\tvalid_1's binary_logloss: 0.13805\n",
            "[11]\ttraining's auc: 0.875442\ttraining's binary_logloss: 0.124181\tvalid_1's auc: 0.825266\tvalid_1's binary_logloss: 0.137736\n",
            "[12]\ttraining's auc: 0.881149\ttraining's binary_logloss: 0.122832\tvalid_1's auc: 0.825712\tvalid_1's binary_logloss: 0.137455\n",
            "[13]\ttraining's auc: 0.883435\ttraining's binary_logloss: 0.121855\tvalid_1's auc: 0.825806\tvalid_1's binary_logloss: 0.137236\n",
            "[14]\ttraining's auc: 0.885064\ttraining's binary_logloss: 0.120988\tvalid_1's auc: 0.825116\tvalid_1's binary_logloss: 0.137241\n",
            "[15]\ttraining's auc: 0.886444\ttraining's binary_logloss: 0.120211\tvalid_1's auc: 0.824744\tvalid_1's binary_logloss: 0.137219\n",
            "[16]\ttraining's auc: 0.888603\ttraining's binary_logloss: 0.119342\tvalid_1's auc: 0.825326\tvalid_1's binary_logloss: 0.13699\n",
            "[17]\ttraining's auc: 0.890353\ttraining's binary_logloss: 0.11857\tvalid_1's auc: 0.825863\tvalid_1's binary_logloss: 0.136782\n",
            "[18]\ttraining's auc: 0.892569\ttraining's binary_logloss: 0.117847\tvalid_1's auc: 0.82574\tvalid_1's binary_logloss: 0.136763\n",
            "[19]\ttraining's auc: 0.895386\ttraining's binary_logloss: 0.117074\tvalid_1's auc: 0.82689\tvalid_1's binary_logloss: 0.136625\n",
            "[20]\ttraining's auc: 0.897372\ttraining's binary_logloss: 0.116405\tvalid_1's auc: 0.826475\tvalid_1's binary_logloss: 0.136694\n",
            "[21]\ttraining's auc: 0.899675\ttraining's binary_logloss: 0.115737\tvalid_1's auc: 0.826136\tvalid_1's binary_logloss: 0.136728\n",
            "[22]\ttraining's auc: 0.902299\ttraining's binary_logloss: 0.115037\tvalid_1's auc: 0.826885\tvalid_1's binary_logloss: 0.136626\n",
            "[23]\ttraining's auc: 0.903574\ttraining's binary_logloss: 0.114505\tvalid_1's auc: 0.827497\tvalid_1's binary_logloss: 0.136582\n",
            "[24]\ttraining's auc: 0.904677\ttraining's binary_logloss: 0.113961\tvalid_1's auc: 0.827964\tvalid_1's binary_logloss: 0.136486\n",
            "[25]\ttraining's auc: 0.906351\ttraining's binary_logloss: 0.11334\tvalid_1's auc: 0.827613\tvalid_1's binary_logloss: 0.136625\n",
            "[26]\ttraining's auc: 0.907711\ttraining's binary_logloss: 0.112835\tvalid_1's auc: 0.82784\tvalid_1's binary_logloss: 0.136586\n",
            "[27]\ttraining's auc: 0.909169\ttraining's binary_logloss: 0.112251\tvalid_1's auc: 0.82756\tvalid_1's binary_logloss: 0.13659\n",
            "[28]\ttraining's auc: 0.910152\ttraining's binary_logloss: 0.111805\tvalid_1's auc: 0.828045\tvalid_1's binary_logloss: 0.136547\n",
            "[29]\ttraining's auc: 0.910778\ttraining's binary_logloss: 0.111413\tvalid_1's auc: 0.827903\tvalid_1's binary_logloss: 0.136585\n",
            "[30]\ttraining's auc: 0.912396\ttraining's binary_logloss: 0.110763\tvalid_1's auc: 0.827557\tvalid_1's binary_logloss: 0.136725\n",
            "[31]\ttraining's auc: 0.913487\ttraining's binary_logloss: 0.110266\tvalid_1's auc: 0.827133\tvalid_1's binary_logloss: 0.136892\n",
            "[32]\ttraining's auc: 0.914191\ttraining's binary_logloss: 0.109845\tvalid_1's auc: 0.827049\tvalid_1's binary_logloss: 0.136891\n",
            "[33]\ttraining's auc: 0.914937\ttraining's binary_logloss: 0.109441\tvalid_1's auc: 0.826915\tvalid_1's binary_logloss: 0.136938\n",
            "[34]\ttraining's auc: 0.915713\ttraining's binary_logloss: 0.109102\tvalid_1's auc: 0.827068\tvalid_1's binary_logloss: 0.136942\n",
            "[35]\ttraining's auc: 0.916748\ttraining's binary_logloss: 0.108641\tvalid_1's auc: 0.826352\tvalid_1's binary_logloss: 0.137109\n",
            "[36]\ttraining's auc: 0.917451\ttraining's binary_logloss: 0.108265\tvalid_1's auc: 0.826037\tvalid_1's binary_logloss: 0.13714\n",
            "[37]\ttraining's auc: 0.917886\ttraining's binary_logloss: 0.107995\tvalid_1's auc: 0.825538\tvalid_1's binary_logloss: 0.137302\n",
            "[38]\ttraining's auc: 0.91926\ttraining's binary_logloss: 0.107459\tvalid_1's auc: 0.82505\tvalid_1's binary_logloss: 0.137403\n",
            "[39]\ttraining's auc: 0.920225\ttraining's binary_logloss: 0.107043\tvalid_1's auc: 0.825081\tvalid_1's binary_logloss: 0.137451\n",
            "[40]\ttraining's auc: 0.920746\ttraining's binary_logloss: 0.106716\tvalid_1's auc: 0.82455\tvalid_1's binary_logloss: 0.137613\n",
            "[41]\ttraining's auc: 0.92113\ttraining's binary_logloss: 0.106473\tvalid_1's auc: 0.823985\tvalid_1's binary_logloss: 0.137798\n",
            "[42]\ttraining's auc: 0.921713\ttraining's binary_logloss: 0.10616\tvalid_1's auc: 0.823378\tvalid_1's binary_logloss: 0.137959\n",
            "[43]\ttraining's auc: 0.921947\ttraining's binary_logloss: 0.105943\tvalid_1's auc: 0.822871\tvalid_1's binary_logloss: 0.1381\n",
            "[44]\ttraining's auc: 0.923808\ttraining's binary_logloss: 0.105494\tvalid_1's auc: 0.822549\tvalid_1's binary_logloss: 0.13819\n",
            "[45]\ttraining's auc: 0.92498\ttraining's binary_logloss: 0.105161\tvalid_1's auc: 0.822186\tvalid_1's binary_logloss: 0.138284\n",
            "[46]\ttraining's auc: 0.926181\ttraining's binary_logloss: 0.104859\tvalid_1's auc: 0.821966\tvalid_1's binary_logloss: 0.138347\n",
            "[47]\ttraining's auc: 0.926672\ttraining's binary_logloss: 0.104555\tvalid_1's auc: 0.821856\tvalid_1's binary_logloss: 0.138413\n",
            "[48]\ttraining's auc: 0.927682\ttraining's binary_logloss: 0.104248\tvalid_1's auc: 0.82211\tvalid_1's binary_logloss: 0.138394\n",
            "[49]\ttraining's auc: 0.928812\ttraining's binary_logloss: 0.103751\tvalid_1's auc: 0.82179\tvalid_1's binary_logloss: 0.138475\n",
            "[50]\ttraining's auc: 0.929311\ttraining's binary_logloss: 0.103459\tvalid_1's auc: 0.821482\tvalid_1's binary_logloss: 0.138595\n",
            "[51]\ttraining's auc: 0.929965\ttraining's binary_logloss: 0.10308\tvalid_1's auc: 0.821481\tvalid_1's binary_logloss: 0.138667\n",
            "[52]\ttraining's auc: 0.930532\ttraining's binary_logloss: 0.102734\tvalid_1's auc: 0.821063\tvalid_1's binary_logloss: 0.138815\n",
            "[53]\ttraining's auc: 0.931003\ttraining's binary_logloss: 0.102427\tvalid_1's auc: 0.82055\tvalid_1's binary_logloss: 0.13897\n",
            "[54]\ttraining's auc: 0.931255\ttraining's binary_logloss: 0.102223\tvalid_1's auc: 0.820405\tvalid_1's binary_logloss: 0.139067\n",
            " 90%|█████████ | 45/50 [23:40<03:55, 47.14s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.153478\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.150629\n",
            "[2]\ttraining's auc: 0.832247\ttraining's binary_logloss: 0.146813\tvalid_1's auc: 0.817444\tvalid_1's binary_logloss: 0.145451\n",
            "[3]\ttraining's auc: 0.840493\ttraining's binary_logloss: 0.142205\tvalid_1's auc: 0.821737\tvalid_1's binary_logloss: 0.142264\n",
            "[4]\ttraining's auc: 0.84851\ttraining's binary_logloss: 0.138724\tvalid_1's auc: 0.827232\tvalid_1's binary_logloss: 0.139962\n",
            "[5]\ttraining's auc: 0.853841\ttraining's binary_logloss: 0.135937\tvalid_1's auc: 0.829041\tvalid_1's binary_logloss: 0.138301\n",
            "[6]\ttraining's auc: 0.857785\ttraining's binary_logloss: 0.133676\tvalid_1's auc: 0.829799\tvalid_1's binary_logloss: 0.136983\n",
            "[7]\ttraining's auc: 0.863698\ttraining's binary_logloss: 0.131746\tvalid_1's auc: 0.830113\tvalid_1's binary_logloss: 0.135922\n",
            "[8]\ttraining's auc: 0.867631\ttraining's binary_logloss: 0.129976\tvalid_1's auc: 0.830323\tvalid_1's binary_logloss: 0.135288\n",
            "[9]\ttraining's auc: 0.870475\ttraining's binary_logloss: 0.128463\tvalid_1's auc: 0.830026\tvalid_1's binary_logloss: 0.134699\n",
            "[10]\ttraining's auc: 0.873055\ttraining's binary_logloss: 0.127207\tvalid_1's auc: 0.830537\tvalid_1's binary_logloss: 0.13418\n",
            "[11]\ttraining's auc: 0.875709\ttraining's binary_logloss: 0.126091\tvalid_1's auc: 0.831359\tvalid_1's binary_logloss: 0.133682\n",
            "[12]\ttraining's auc: 0.877518\ttraining's binary_logloss: 0.125014\tvalid_1's auc: 0.831426\tvalid_1's binary_logloss: 0.133373\n",
            "[13]\ttraining's auc: 0.879452\ttraining's binary_logloss: 0.12405\tvalid_1's auc: 0.831933\tvalid_1's binary_logloss: 0.133097\n",
            "[14]\ttraining's auc: 0.881522\ttraining's binary_logloss: 0.123194\tvalid_1's auc: 0.832342\tvalid_1's binary_logloss: 0.132867\n",
            "[15]\ttraining's auc: 0.884983\ttraining's binary_logloss: 0.122201\tvalid_1's auc: 0.833409\tvalid_1's binary_logloss: 0.132578\n",
            "[16]\ttraining's auc: 0.887089\ttraining's binary_logloss: 0.121369\tvalid_1's auc: 0.832668\tvalid_1's binary_logloss: 0.132602\n",
            "[17]\ttraining's auc: 0.889537\ttraining's binary_logloss: 0.120533\tvalid_1's auc: 0.83301\tvalid_1's binary_logloss: 0.132471\n",
            "[18]\ttraining's auc: 0.891367\ttraining's binary_logloss: 0.119841\tvalid_1's auc: 0.833376\tvalid_1's binary_logloss: 0.13235\n",
            "[19]\ttraining's auc: 0.89382\ttraining's binary_logloss: 0.119148\tvalid_1's auc: 0.833094\tvalid_1's binary_logloss: 0.132275\n",
            "[20]\ttraining's auc: 0.895218\ttraining's binary_logloss: 0.118519\tvalid_1's auc: 0.833221\tvalid_1's binary_logloss: 0.132206\n",
            "[21]\ttraining's auc: 0.896197\ttraining's binary_logloss: 0.118014\tvalid_1's auc: 0.833449\tvalid_1's binary_logloss: 0.132144\n",
            "[22]\ttraining's auc: 0.897389\ttraining's binary_logloss: 0.117378\tvalid_1's auc: 0.832838\tvalid_1's binary_logloss: 0.13219\n",
            "[23]\ttraining's auc: 0.899088\ttraining's binary_logloss: 0.116805\tvalid_1's auc: 0.833433\tvalid_1's binary_logloss: 0.132021\n",
            "[24]\ttraining's auc: 0.900283\ttraining's binary_logloss: 0.116183\tvalid_1's auc: 0.833267\tvalid_1's binary_logloss: 0.132053\n",
            "[25]\ttraining's auc: 0.902331\ttraining's binary_logloss: 0.115607\tvalid_1's auc: 0.832827\tvalid_1's binary_logloss: 0.132111\n",
            "[26]\ttraining's auc: 0.903265\ttraining's binary_logloss: 0.115128\tvalid_1's auc: 0.833003\tvalid_1's binary_logloss: 0.132076\n",
            "[27]\ttraining's auc: 0.905349\ttraining's binary_logloss: 0.114546\tvalid_1's auc: 0.832637\tvalid_1's binary_logloss: 0.132133\n",
            "[28]\ttraining's auc: 0.906925\ttraining's binary_logloss: 0.114023\tvalid_1's auc: 0.832538\tvalid_1's binary_logloss: 0.132199\n",
            "[29]\ttraining's auc: 0.908252\ttraining's binary_logloss: 0.113574\tvalid_1's auc: 0.832287\tvalid_1's binary_logloss: 0.132201\n",
            "[30]\ttraining's auc: 0.909248\ttraining's binary_logloss: 0.113173\tvalid_1's auc: 0.832153\tvalid_1's binary_logloss: 0.132196\n",
            "[31]\ttraining's auc: 0.910246\ttraining's binary_logloss: 0.112652\tvalid_1's auc: 0.832397\tvalid_1's binary_logloss: 0.132156\n",
            "[32]\ttraining's auc: 0.911242\ttraining's binary_logloss: 0.112142\tvalid_1's auc: 0.832476\tvalid_1's binary_logloss: 0.132167\n",
            "[33]\ttraining's auc: 0.911982\ttraining's binary_logloss: 0.111733\tvalid_1's auc: 0.832618\tvalid_1's binary_logloss: 0.132155\n",
            "[34]\ttraining's auc: 0.912711\ttraining's binary_logloss: 0.111375\tvalid_1's auc: 0.832501\tvalid_1's binary_logloss: 0.132176\n",
            "[35]\ttraining's auc: 0.914071\ttraining's binary_logloss: 0.110978\tvalid_1's auc: 0.832815\tvalid_1's binary_logloss: 0.132201\n",
            "[36]\ttraining's auc: 0.914842\ttraining's binary_logloss: 0.110696\tvalid_1's auc: 0.832076\tvalid_1's binary_logloss: 0.132334\n",
            "[37]\ttraining's auc: 0.915428\ttraining's binary_logloss: 0.110369\tvalid_1's auc: 0.831999\tvalid_1's binary_logloss: 0.132329\n",
            "[38]\ttraining's auc: 0.916631\ttraining's binary_logloss: 0.109863\tvalid_1's auc: 0.831572\tvalid_1's binary_logloss: 0.132446\n",
            "[39]\ttraining's auc: 0.918989\ttraining's binary_logloss: 0.109203\tvalid_1's auc: 0.832106\tvalid_1's binary_logloss: 0.13236\n",
            "[40]\ttraining's auc: 0.919411\ttraining's binary_logloss: 0.108916\tvalid_1's auc: 0.832352\tvalid_1's binary_logloss: 0.13234\n",
            "[41]\ttraining's auc: 0.920556\ttraining's binary_logloss: 0.108495\tvalid_1's auc: 0.83238\tvalid_1's binary_logloss: 0.132382\n",
            "[42]\ttraining's auc: 0.920846\ttraining's binary_logloss: 0.108245\tvalid_1's auc: 0.832096\tvalid_1's binary_logloss: 0.132445\n",
            "[43]\ttraining's auc: 0.921472\ttraining's binary_logloss: 0.107876\tvalid_1's auc: 0.831515\tvalid_1's binary_logloss: 0.132561\n",
            "[44]\ttraining's auc: 0.922064\ttraining's binary_logloss: 0.107574\tvalid_1's auc: 0.831519\tvalid_1's binary_logloss: 0.132582\n",
            "[45]\ttraining's auc: 0.923064\ttraining's binary_logloss: 0.107186\tvalid_1's auc: 0.831039\tvalid_1's binary_logloss: 0.132682\n",
            "[46]\ttraining's auc: 0.92387\ttraining's binary_logloss: 0.106874\tvalid_1's auc: 0.830818\tvalid_1's binary_logloss: 0.132685\n",
            "[47]\ttraining's auc: 0.924779\ttraining's binary_logloss: 0.106487\tvalid_1's auc: 0.830339\tvalid_1's binary_logloss: 0.132761\n",
            "[48]\ttraining's auc: 0.925764\ttraining's binary_logloss: 0.106126\tvalid_1's auc: 0.830207\tvalid_1's binary_logloss: 0.132808\n",
            "[49]\ttraining's auc: 0.92638\ttraining's binary_logloss: 0.105841\tvalid_1's auc: 0.829869\tvalid_1's binary_logloss: 0.132886\n",
            "[50]\ttraining's auc: 0.926815\ttraining's binary_logloss: 0.105565\tvalid_1's auc: 0.829695\tvalid_1's binary_logloss: 0.132901\n",
            "[51]\ttraining's auc: 0.928087\ttraining's binary_logloss: 0.105075\tvalid_1's auc: 0.829304\tvalid_1's binary_logloss: 0.133027\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 90%|█████████ | 45/50 [23:51<03:55, 47.14s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.1504\tvalid_1's auc: 0.810131\tvalid_1's binary_logloss: 0.15718\n",
            "[2]\ttraining's auc: 0.836057\ttraining's binary_logloss: 0.144091\tvalid_1's auc: 0.817762\tvalid_1's binary_logloss: 0.151548\n",
            "[3]\ttraining's auc: 0.845133\ttraining's binary_logloss: 0.139529\tvalid_1's auc: 0.823969\tvalid_1's binary_logloss: 0.148014\n",
            "[4]\ttraining's auc: 0.849831\ttraining's binary_logloss: 0.136163\tvalid_1's auc: 0.826202\tvalid_1's binary_logloss: 0.145548\n",
            "[5]\ttraining's auc: 0.854159\ttraining's binary_logloss: 0.133496\tvalid_1's auc: 0.827313\tvalid_1's binary_logloss: 0.143697\n",
            "[6]\ttraining's auc: 0.858637\ttraining's binary_logloss: 0.131243\tvalid_1's auc: 0.828293\tvalid_1's binary_logloss: 0.142224\n",
            "[7]\ttraining's auc: 0.862777\ttraining's binary_logloss: 0.129358\tvalid_1's auc: 0.829098\tvalid_1's binary_logloss: 0.141028\n",
            "[8]\ttraining's auc: 0.86775\ttraining's binary_logloss: 0.127719\tvalid_1's auc: 0.82932\tvalid_1's binary_logloss: 0.140171\n",
            "[9]\ttraining's auc: 0.870834\ttraining's binary_logloss: 0.126376\tvalid_1's auc: 0.831951\tvalid_1's binary_logloss: 0.139533\n",
            "[10]\ttraining's auc: 0.873656\ttraining's binary_logloss: 0.125115\tvalid_1's auc: 0.833171\tvalid_1's binary_logloss: 0.138938\n",
            "[11]\ttraining's auc: 0.876553\ttraining's binary_logloss: 0.123851\tvalid_1's auc: 0.833519\tvalid_1's binary_logloss: 0.138458\n",
            "[12]\ttraining's auc: 0.879312\ttraining's binary_logloss: 0.122853\tvalid_1's auc: 0.833217\tvalid_1's binary_logloss: 0.138246\n",
            "[13]\ttraining's auc: 0.88265\ttraining's binary_logloss: 0.121869\tvalid_1's auc: 0.833113\tvalid_1's binary_logloss: 0.137995\n",
            "[14]\ttraining's auc: 0.884901\ttraining's binary_logloss: 0.120866\tvalid_1's auc: 0.833769\tvalid_1's binary_logloss: 0.137784\n",
            "[15]\ttraining's auc: 0.886915\ttraining's binary_logloss: 0.120025\tvalid_1's auc: 0.833003\tvalid_1's binary_logloss: 0.137753\n",
            "[16]\ttraining's auc: 0.888593\ttraining's binary_logloss: 0.119199\tvalid_1's auc: 0.832913\tvalid_1's binary_logloss: 0.137644\n",
            "[17]\ttraining's auc: 0.8906\ttraining's binary_logloss: 0.11848\tvalid_1's auc: 0.832927\tvalid_1's binary_logloss: 0.137589\n",
            "[18]\ttraining's auc: 0.893262\ttraining's binary_logloss: 0.117712\tvalid_1's auc: 0.832529\tvalid_1's binary_logloss: 0.137545\n",
            "[19]\ttraining's auc: 0.894988\ttraining's binary_logloss: 0.117024\tvalid_1's auc: 0.832011\tvalid_1's binary_logloss: 0.137582\n",
            "[20]\ttraining's auc: 0.89622\ttraining's binary_logloss: 0.116471\tvalid_1's auc: 0.831608\tvalid_1's binary_logloss: 0.137575\n",
            "[21]\ttraining's auc: 0.897692\ttraining's binary_logloss: 0.115881\tvalid_1's auc: 0.831875\tvalid_1's binary_logloss: 0.137523\n",
            "[22]\ttraining's auc: 0.899856\ttraining's binary_logloss: 0.115179\tvalid_1's auc: 0.831317\tvalid_1's binary_logloss: 0.137612\n",
            "[23]\ttraining's auc: 0.901505\ttraining's binary_logloss: 0.114592\tvalid_1's auc: 0.831548\tvalid_1's binary_logloss: 0.137617\n",
            "[24]\ttraining's auc: 0.902892\ttraining's binary_logloss: 0.113919\tvalid_1's auc: 0.831444\tvalid_1's binary_logloss: 0.137638\n",
            "[25]\ttraining's auc: 0.904249\ttraining's binary_logloss: 0.113368\tvalid_1's auc: 0.831491\tvalid_1's binary_logloss: 0.137613\n",
            "[26]\ttraining's auc: 0.905578\ttraining's binary_logloss: 0.112793\tvalid_1's auc: 0.831772\tvalid_1's binary_logloss: 0.137624\n",
            "[27]\ttraining's auc: 0.906956\ttraining's binary_logloss: 0.112071\tvalid_1's auc: 0.831848\tvalid_1's binary_logloss: 0.137669\n",
            "[28]\ttraining's auc: 0.908498\ttraining's binary_logloss: 0.111498\tvalid_1's auc: 0.831592\tvalid_1's binary_logloss: 0.137745\n",
            "[29]\ttraining's auc: 0.909771\ttraining's binary_logloss: 0.11091\tvalid_1's auc: 0.831396\tvalid_1's binary_logloss: 0.137868\n",
            "[30]\ttraining's auc: 0.911342\ttraining's binary_logloss: 0.110482\tvalid_1's auc: 0.831964\tvalid_1's binary_logloss: 0.137766\n",
            "[31]\ttraining's auc: 0.911859\ttraining's binary_logloss: 0.110135\tvalid_1's auc: 0.831638\tvalid_1's binary_logloss: 0.137858\n",
            "[32]\ttraining's auc: 0.913476\ttraining's binary_logloss: 0.109603\tvalid_1's auc: 0.831227\tvalid_1's binary_logloss: 0.138008\n",
            "[33]\ttraining's auc: 0.915069\ttraining's binary_logloss: 0.109015\tvalid_1's auc: 0.831253\tvalid_1's binary_logloss: 0.13804\n",
            "[34]\ttraining's auc: 0.916138\ttraining's binary_logloss: 0.108678\tvalid_1's auc: 0.831387\tvalid_1's binary_logloss: 0.138056\n",
            "[35]\ttraining's auc: 0.917793\ttraining's binary_logloss: 0.107979\tvalid_1's auc: 0.831886\tvalid_1's binary_logloss: 0.137906\n",
            "[36]\ttraining's auc: 0.918647\ttraining's binary_logloss: 0.107579\tvalid_1's auc: 0.831706\tvalid_1's binary_logloss: 0.137967\n",
            "[37]\ttraining's auc: 0.919718\ttraining's binary_logloss: 0.107078\tvalid_1's auc: 0.831259\tvalid_1's binary_logloss: 0.138064\n",
            "[38]\ttraining's auc: 0.920732\ttraining's binary_logloss: 0.106581\tvalid_1's auc: 0.831071\tvalid_1's binary_logloss: 0.138097\n",
            "[39]\ttraining's auc: 0.921376\ttraining's binary_logloss: 0.106155\tvalid_1's auc: 0.831172\tvalid_1's binary_logloss: 0.13806\n",
            "[40]\ttraining's auc: 0.92189\ttraining's binary_logloss: 0.105828\tvalid_1's auc: 0.831004\tvalid_1's binary_logloss: 0.1381\n",
            "[41]\ttraining's auc: 0.922318\ttraining's binary_logloss: 0.105555\tvalid_1's auc: 0.831046\tvalid_1's binary_logloss: 0.138159\n",
            "[42]\ttraining's auc: 0.922806\ttraining's binary_logloss: 0.105229\tvalid_1's auc: 0.830903\tvalid_1's binary_logloss: 0.138145\n",
            "[43]\ttraining's auc: 0.923295\ttraining's binary_logloss: 0.104916\tvalid_1's auc: 0.831077\tvalid_1's binary_logloss: 0.138157\n",
            "[44]\ttraining's auc: 0.923951\ttraining's binary_logloss: 0.104518\tvalid_1's auc: 0.831153\tvalid_1's binary_logloss: 0.138115\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 92%|█████████▏| 46/50 [24:00<02:42, 40.55s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.155311\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.157795\n",
            "[2]\ttraining's auc: 0.833156\ttraining's binary_logloss: 0.149703\tvalid_1's auc: 0.806058\tvalid_1's binary_logloss: 0.153525\n",
            "[3]\ttraining's auc: 0.843039\ttraining's binary_logloss: 0.1456\tvalid_1's auc: 0.815016\tvalid_1's binary_logloss: 0.150378\n",
            "[4]\ttraining's auc: 0.846864\ttraining's binary_logloss: 0.142305\tvalid_1's auc: 0.816962\tvalid_1's binary_logloss: 0.147985\n",
            "[5]\ttraining's auc: 0.84967\ttraining's binary_logloss: 0.139653\tvalid_1's auc: 0.818815\tvalid_1's binary_logloss: 0.146178\n",
            "[6]\ttraining's auc: 0.85115\ttraining's binary_logloss: 0.137505\tvalid_1's auc: 0.819041\tvalid_1's binary_logloss: 0.144655\n",
            "[7]\ttraining's auc: 0.853653\ttraining's binary_logloss: 0.135576\tvalid_1's auc: 0.81996\tvalid_1's binary_logloss: 0.143345\n",
            "[8]\ttraining's auc: 0.855023\ttraining's binary_logloss: 0.133962\tvalid_1's auc: 0.820775\tvalid_1's binary_logloss: 0.142242\n",
            "[9]\ttraining's auc: 0.857541\ttraining's binary_logloss: 0.132558\tvalid_1's auc: 0.822274\tvalid_1's binary_logloss: 0.141285\n",
            "[10]\ttraining's auc: 0.860532\ttraining's binary_logloss: 0.131334\tvalid_1's auc: 0.823012\tvalid_1's binary_logloss: 0.140537\n",
            "[11]\ttraining's auc: 0.864364\ttraining's binary_logloss: 0.13015\tvalid_1's auc: 0.824508\tvalid_1's binary_logloss: 0.139957\n",
            "[12]\ttraining's auc: 0.867377\ttraining's binary_logloss: 0.128947\tvalid_1's auc: 0.826305\tvalid_1's binary_logloss: 0.139245\n",
            "[13]\ttraining's auc: 0.869479\ttraining's binary_logloss: 0.1279\tvalid_1's auc: 0.82674\tvalid_1's binary_logloss: 0.138788\n",
            "[14]\ttraining's auc: 0.871289\ttraining's binary_logloss: 0.126969\tvalid_1's auc: 0.826548\tvalid_1's binary_logloss: 0.138498\n",
            "[15]\ttraining's auc: 0.872861\ttraining's binary_logloss: 0.126165\tvalid_1's auc: 0.82635\tvalid_1's binary_logloss: 0.138221\n",
            "[16]\ttraining's auc: 0.874399\ttraining's binary_logloss: 0.125389\tvalid_1's auc: 0.825793\tvalid_1's binary_logloss: 0.138034\n",
            "[17]\ttraining's auc: 0.876614\ttraining's binary_logloss: 0.124642\tvalid_1's auc: 0.826809\tvalid_1's binary_logloss: 0.137748\n",
            "[18]\ttraining's auc: 0.878804\ttraining's binary_logloss: 0.1239\tvalid_1's auc: 0.826766\tvalid_1's binary_logloss: 0.13755\n",
            "[19]\ttraining's auc: 0.880744\ttraining's binary_logloss: 0.12324\tvalid_1's auc: 0.82615\tvalid_1's binary_logloss: 0.137422\n",
            "[20]\ttraining's auc: 0.883814\ttraining's binary_logloss: 0.122471\tvalid_1's auc: 0.82602\tvalid_1's binary_logloss: 0.137281\n",
            "[21]\ttraining's auc: 0.884695\ttraining's binary_logloss: 0.121898\tvalid_1's auc: 0.826005\tvalid_1's binary_logloss: 0.137201\n",
            "[22]\ttraining's auc: 0.885849\ttraining's binary_logloss: 0.121328\tvalid_1's auc: 0.825846\tvalid_1's binary_logloss: 0.137178\n",
            "[23]\ttraining's auc: 0.887432\ttraining's binary_logloss: 0.12065\tvalid_1's auc: 0.826094\tvalid_1's binary_logloss: 0.13714\n",
            "[24]\ttraining's auc: 0.889699\ttraining's binary_logloss: 0.119997\tvalid_1's auc: 0.826446\tvalid_1's binary_logloss: 0.136965\n",
            "[25]\ttraining's auc: 0.891233\ttraining's binary_logloss: 0.119477\tvalid_1's auc: 0.827198\tvalid_1's binary_logloss: 0.136854\n",
            "[26]\ttraining's auc: 0.892308\ttraining's binary_logloss: 0.118992\tvalid_1's auc: 0.827069\tvalid_1's binary_logloss: 0.13679\n",
            "[27]\ttraining's auc: 0.894894\ttraining's binary_logloss: 0.118365\tvalid_1's auc: 0.82802\tvalid_1's binary_logloss: 0.13653\n",
            "[28]\ttraining's auc: 0.8959\ttraining's binary_logloss: 0.117913\tvalid_1's auc: 0.828535\tvalid_1's binary_logloss: 0.136412\n",
            "[29]\ttraining's auc: 0.897209\ttraining's binary_logloss: 0.11744\tvalid_1's auc: 0.828797\tvalid_1's binary_logloss: 0.136342\n",
            "[30]\ttraining's auc: 0.898717\ttraining's binary_logloss: 0.116961\tvalid_1's auc: 0.82871\tvalid_1's binary_logloss: 0.136351\n",
            "[31]\ttraining's auc: 0.899235\ttraining's binary_logloss: 0.116585\tvalid_1's auc: 0.828759\tvalid_1's binary_logloss: 0.13634\n",
            "[32]\ttraining's auc: 0.900888\ttraining's binary_logloss: 0.116144\tvalid_1's auc: 0.829598\tvalid_1's binary_logloss: 0.136192\n",
            "[33]\ttraining's auc: 0.902094\ttraining's binary_logloss: 0.11578\tvalid_1's auc: 0.829473\tvalid_1's binary_logloss: 0.136209\n",
            "[34]\ttraining's auc: 0.903096\ttraining's binary_logloss: 0.115323\tvalid_1's auc: 0.829383\tvalid_1's binary_logloss: 0.136231\n",
            "[35]\ttraining's auc: 0.904003\ttraining's binary_logloss: 0.114957\tvalid_1's auc: 0.830043\tvalid_1's binary_logloss: 0.136152\n",
            "[36]\ttraining's auc: 0.904747\ttraining's binary_logloss: 0.114641\tvalid_1's auc: 0.830103\tvalid_1's binary_logloss: 0.136143\n",
            "[37]\ttraining's auc: 0.905828\ttraining's binary_logloss: 0.114223\tvalid_1's auc: 0.830254\tvalid_1's binary_logloss: 0.136128\n",
            "[38]\ttraining's auc: 0.906582\ttraining's binary_logloss: 0.113849\tvalid_1's auc: 0.830077\tvalid_1's binary_logloss: 0.136141\n",
            "[39]\ttraining's auc: 0.907321\ttraining's binary_logloss: 0.113483\tvalid_1's auc: 0.829681\tvalid_1's binary_logloss: 0.136237\n",
            "[40]\ttraining's auc: 0.908012\ttraining's binary_logloss: 0.113142\tvalid_1's auc: 0.829583\tvalid_1's binary_logloss: 0.136213\n",
            "[41]\ttraining's auc: 0.908821\ttraining's binary_logloss: 0.112787\tvalid_1's auc: 0.829601\tvalid_1's binary_logloss: 0.136225\n",
            "[42]\ttraining's auc: 0.909715\ttraining's binary_logloss: 0.11239\tvalid_1's auc: 0.829637\tvalid_1's binary_logloss: 0.136204\n",
            "[43]\ttraining's auc: 0.911291\ttraining's binary_logloss: 0.112031\tvalid_1's auc: 0.829417\tvalid_1's binary_logloss: 0.136243\n",
            "[44]\ttraining's auc: 0.911823\ttraining's binary_logloss: 0.111803\tvalid_1's auc: 0.829296\tvalid_1's binary_logloss: 0.136264\n",
            "[45]\ttraining's auc: 0.912627\ttraining's binary_logloss: 0.111449\tvalid_1's auc: 0.829006\tvalid_1's binary_logloss: 0.136343\n",
            "[46]\ttraining's auc: 0.913656\ttraining's binary_logloss: 0.111009\tvalid_1's auc: 0.828838\tvalid_1's binary_logloss: 0.136401\n",
            "[47]\ttraining's auc: 0.914549\ttraining's binary_logloss: 0.110654\tvalid_1's auc: 0.828575\tvalid_1's binary_logloss: 0.136469\n",
            "[48]\ttraining's auc: 0.91539\ttraining's binary_logloss: 0.110288\tvalid_1's auc: 0.828105\tvalid_1's binary_logloss: 0.136536\n",
            "[49]\ttraining's auc: 0.915809\ttraining's binary_logloss: 0.10999\tvalid_1's auc: 0.82819\tvalid_1's binary_logloss: 0.136536\n",
            "[50]\ttraining's auc: 0.916543\ttraining's binary_logloss: 0.109665\tvalid_1's auc: 0.827934\tvalid_1's binary_logloss: 0.136621\n",
            "[51]\ttraining's auc: 0.917479\ttraining's binary_logloss: 0.109282\tvalid_1's auc: 0.827954\tvalid_1's binary_logloss: 0.136583\n",
            "[52]\ttraining's auc: 0.918045\ttraining's binary_logloss: 0.108997\tvalid_1's auc: 0.827728\tvalid_1's binary_logloss: 0.136647\n",
            "[53]\ttraining's auc: 0.918304\ttraining's binary_logloss: 0.108805\tvalid_1's auc: 0.827419\tvalid_1's binary_logloss: 0.136714\n",
            "[54]\ttraining's auc: 0.918891\ttraining's binary_logloss: 0.108494\tvalid_1's auc: 0.827308\tvalid_1's binary_logloss: 0.136776\n",
            "[55]\ttraining's auc: 0.919726\ttraining's binary_logloss: 0.108167\tvalid_1's auc: 0.827393\tvalid_1's binary_logloss: 0.136793\n",
            "[56]\ttraining's auc: 0.920614\ttraining's binary_logloss: 0.107953\tvalid_1's auc: 0.827099\tvalid_1's binary_logloss: 0.136862\n",
            "[57]\ttraining's auc: 0.921062\ttraining's binary_logloss: 0.107753\tvalid_1's auc: 0.826911\tvalid_1's binary_logloss: 0.136905\n",
            "[58]\ttraining's auc: 0.921305\ttraining's binary_logloss: 0.107568\tvalid_1's auc: 0.826588\tvalid_1's binary_logloss: 0.136988\n",
            "[59]\ttraining's auc: 0.921888\ttraining's binary_logloss: 0.107315\tvalid_1's auc: 0.826288\tvalid_1's binary_logloss: 0.137071\n",
            "[60]\ttraining's auc: 0.923136\ttraining's binary_logloss: 0.106996\tvalid_1's auc: 0.826018\tvalid_1's binary_logloss: 0.13713\n",
            "[61]\ttraining's auc: 0.923505\ttraining's binary_logloss: 0.106796\tvalid_1's auc: 0.825839\tvalid_1's binary_logloss: 0.137187\n",
            "[62]\ttraining's auc: 0.923676\ttraining's binary_logloss: 0.106628\tvalid_1's auc: 0.825519\tvalid_1's binary_logloss: 0.137221\n",
            "[63]\ttraining's auc: 0.924509\ttraining's binary_logloss: 0.10628\tvalid_1's auc: 0.82527\tvalid_1's binary_logloss: 0.137268\n",
            "[64]\ttraining's auc: 0.925004\ttraining's binary_logloss: 0.106023\tvalid_1's auc: 0.82517\tvalid_1's binary_logloss: 0.137298\n",
            "[65]\ttraining's auc: 0.925279\ttraining's binary_logloss: 0.105826\tvalid_1's auc: 0.824918\tvalid_1's binary_logloss: 0.137361\n",
            "[66]\ttraining's auc: 0.925605\ttraining's binary_logloss: 0.105637\tvalid_1's auc: 0.824942\tvalid_1's binary_logloss: 0.13737\n",
            "[67]\ttraining's auc: 0.925982\ttraining's binary_logloss: 0.105404\tvalid_1's auc: 0.82471\tvalid_1's binary_logloss: 0.137427\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 92%|█████████▏| 46/50 [24:08<02:42, 40.55s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.157733\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.153721\n",
            "[2]\ttraining's auc: 0.829837\ttraining's binary_logloss: 0.152138\tvalid_1's auc: 0.814797\tvalid_1's binary_logloss: 0.149425\n",
            "[3]\ttraining's auc: 0.835507\ttraining's binary_logloss: 0.14802\tvalid_1's auc: 0.819012\tvalid_1's binary_logloss: 0.146105\n",
            "[4]\ttraining's auc: 0.842382\ttraining's binary_logloss: 0.1446\tvalid_1's auc: 0.82125\tvalid_1's binary_logloss: 0.143753\n",
            "[5]\ttraining's auc: 0.84698\ttraining's binary_logloss: 0.141915\tvalid_1's auc: 0.825568\tvalid_1's binary_logloss: 0.141717\n",
            "[6]\ttraining's auc: 0.850599\ttraining's binary_logloss: 0.1397\tvalid_1's auc: 0.828105\tvalid_1's binary_logloss: 0.140131\n",
            "[7]\ttraining's auc: 0.854711\ttraining's binary_logloss: 0.13766\tvalid_1's auc: 0.830011\tvalid_1's binary_logloss: 0.138838\n",
            "[8]\ttraining's auc: 0.85747\ttraining's binary_logloss: 0.135938\tvalid_1's auc: 0.8303\tvalid_1's binary_logloss: 0.137811\n",
            "[9]\ttraining's auc: 0.860168\ttraining's binary_logloss: 0.134425\tvalid_1's auc: 0.829954\tvalid_1's binary_logloss: 0.136904\n",
            "[10]\ttraining's auc: 0.865269\ttraining's binary_logloss: 0.132955\tvalid_1's auc: 0.831188\tvalid_1's binary_logloss: 0.136056\n",
            "[11]\ttraining's auc: 0.867609\ttraining's binary_logloss: 0.13169\tvalid_1's auc: 0.832238\tvalid_1's binary_logloss: 0.135369\n",
            "[12]\ttraining's auc: 0.870272\ttraining's binary_logloss: 0.130526\tvalid_1's auc: 0.831414\tvalid_1's binary_logloss: 0.134864\n",
            "[13]\ttraining's auc: 0.870972\ttraining's binary_logloss: 0.129553\tvalid_1's auc: 0.831374\tvalid_1's binary_logloss: 0.134498\n",
            "[14]\ttraining's auc: 0.873194\ttraining's binary_logloss: 0.128519\tvalid_1's auc: 0.831277\tvalid_1's binary_logloss: 0.134144\n",
            "[15]\ttraining's auc: 0.874236\ttraining's binary_logloss: 0.127633\tvalid_1's auc: 0.831959\tvalid_1's binary_logloss: 0.133739\n",
            "[16]\ttraining's auc: 0.876455\ttraining's binary_logloss: 0.126756\tvalid_1's auc: 0.832426\tvalid_1's binary_logloss: 0.133479\n",
            "[17]\ttraining's auc: 0.878212\ttraining's binary_logloss: 0.125949\tvalid_1's auc: 0.832546\tvalid_1's binary_logloss: 0.133206\n",
            "[18]\ttraining's auc: 0.879186\ttraining's binary_logloss: 0.125234\tvalid_1's auc: 0.832673\tvalid_1's binary_logloss: 0.132992\n",
            "[19]\ttraining's auc: 0.881213\ttraining's binary_logloss: 0.124495\tvalid_1's auc: 0.832611\tvalid_1's binary_logloss: 0.132803\n",
            "[20]\ttraining's auc: 0.883359\ttraining's binary_logloss: 0.123844\tvalid_1's auc: 0.83289\tvalid_1's binary_logloss: 0.132588\n",
            "[21]\ttraining's auc: 0.88523\ttraining's binary_logloss: 0.123204\tvalid_1's auc: 0.832714\tvalid_1's binary_logloss: 0.132461\n",
            "[22]\ttraining's auc: 0.886579\ttraining's binary_logloss: 0.122609\tvalid_1's auc: 0.833394\tvalid_1's binary_logloss: 0.132291\n",
            "[23]\ttraining's auc: 0.887961\ttraining's binary_logloss: 0.122055\tvalid_1's auc: 0.833576\tvalid_1's binary_logloss: 0.132192\n",
            "[24]\ttraining's auc: 0.889469\ttraining's binary_logloss: 0.121464\tvalid_1's auc: 0.833953\tvalid_1's binary_logloss: 0.132048\n",
            "[25]\ttraining's auc: 0.890698\ttraining's binary_logloss: 0.120953\tvalid_1's auc: 0.834104\tvalid_1's binary_logloss: 0.131962\n",
            "[26]\ttraining's auc: 0.891405\ttraining's binary_logloss: 0.120475\tvalid_1's auc: 0.834284\tvalid_1's binary_logloss: 0.131817\n",
            "[27]\ttraining's auc: 0.893315\ttraining's binary_logloss: 0.11996\tvalid_1's auc: 0.8341\tvalid_1's binary_logloss: 0.131778\n",
            "[28]\ttraining's auc: 0.894645\ttraining's binary_logloss: 0.11947\tvalid_1's auc: 0.833895\tvalid_1's binary_logloss: 0.131764\n",
            "[29]\ttraining's auc: 0.895658\ttraining's binary_logloss: 0.119052\tvalid_1's auc: 0.833892\tvalid_1's binary_logloss: 0.13172\n",
            "[30]\ttraining's auc: 0.897108\ttraining's binary_logloss: 0.118567\tvalid_1's auc: 0.834358\tvalid_1's binary_logloss: 0.131642\n",
            "[31]\ttraining's auc: 0.898182\ttraining's binary_logloss: 0.118125\tvalid_1's auc: 0.834216\tvalid_1's binary_logloss: 0.131607\n",
            "[32]\ttraining's auc: 0.899572\ttraining's binary_logloss: 0.117735\tvalid_1's auc: 0.833977\tvalid_1's binary_logloss: 0.131618\n",
            "[33]\ttraining's auc: 0.900398\ttraining's binary_logloss: 0.117392\tvalid_1's auc: 0.834144\tvalid_1's binary_logloss: 0.131583\n",
            "[34]\ttraining's auc: 0.9013\ttraining's binary_logloss: 0.116998\tvalid_1's auc: 0.834031\tvalid_1's binary_logloss: 0.131592\n",
            "[35]\ttraining's auc: 0.902063\ttraining's binary_logloss: 0.11672\tvalid_1's auc: 0.833945\tvalid_1's binary_logloss: 0.131601\n",
            "[36]\ttraining's auc: 0.902901\ttraining's binary_logloss: 0.116376\tvalid_1's auc: 0.833734\tvalid_1's binary_logloss: 0.131603\n",
            "[37]\ttraining's auc: 0.904326\ttraining's binary_logloss: 0.115996\tvalid_1's auc: 0.833542\tvalid_1's binary_logloss: 0.131647\n",
            "[38]\ttraining's auc: 0.905189\ttraining's binary_logloss: 0.115651\tvalid_1's auc: 0.833508\tvalid_1's binary_logloss: 0.131619\n",
            "[39]\ttraining's auc: 0.90615\ttraining's binary_logloss: 0.115276\tvalid_1's auc: 0.833513\tvalid_1's binary_logloss: 0.131632\n",
            "[40]\ttraining's auc: 0.907026\ttraining's binary_logloss: 0.114877\tvalid_1's auc: 0.833409\tvalid_1's binary_logloss: 0.131651\n",
            "[41]\ttraining's auc: 0.907722\ttraining's binary_logloss: 0.114504\tvalid_1's auc: 0.833297\tvalid_1's binary_logloss: 0.131665\n",
            "[42]\ttraining's auc: 0.908316\ttraining's binary_logloss: 0.114169\tvalid_1's auc: 0.833475\tvalid_1's binary_logloss: 0.131614\n",
            "[43]\ttraining's auc: 0.909005\ttraining's binary_logloss: 0.113864\tvalid_1's auc: 0.833613\tvalid_1's binary_logloss: 0.131588\n",
            "[44]\ttraining's auc: 0.909594\ttraining's binary_logloss: 0.113536\tvalid_1's auc: 0.833751\tvalid_1's binary_logloss: 0.13157\n",
            "[45]\ttraining's auc: 0.910155\ttraining's binary_logloss: 0.113314\tvalid_1's auc: 0.833873\tvalid_1's binary_logloss: 0.131539\n",
            "[46]\ttraining's auc: 0.91137\ttraining's binary_logloss: 0.112914\tvalid_1's auc: 0.833938\tvalid_1's binary_logloss: 0.131511\n",
            "[47]\ttraining's auc: 0.912041\ttraining's binary_logloss: 0.112559\tvalid_1's auc: 0.834048\tvalid_1's binary_logloss: 0.131487\n",
            "[48]\ttraining's auc: 0.912593\ttraining's binary_logloss: 0.1123\tvalid_1's auc: 0.833949\tvalid_1's binary_logloss: 0.131487\n",
            "[49]\ttraining's auc: 0.913224\ttraining's binary_logloss: 0.112007\tvalid_1's auc: 0.833898\tvalid_1's binary_logloss: 0.131482\n",
            "[50]\ttraining's auc: 0.914051\ttraining's binary_logloss: 0.11168\tvalid_1's auc: 0.833833\tvalid_1's binary_logloss: 0.131485\n",
            "[51]\ttraining's auc: 0.914567\ttraining's binary_logloss: 0.111425\tvalid_1's auc: 0.833852\tvalid_1's binary_logloss: 0.131489\n",
            "[52]\ttraining's auc: 0.915211\ttraining's binary_logloss: 0.11111\tvalid_1's auc: 0.833629\tvalid_1's binary_logloss: 0.13154\n",
            "[53]\ttraining's auc: 0.916113\ttraining's binary_logloss: 0.110738\tvalid_1's auc: 0.833806\tvalid_1's binary_logloss: 0.131515\n",
            "[54]\ttraining's auc: 0.916517\ttraining's binary_logloss: 0.110438\tvalid_1's auc: 0.833713\tvalid_1's binary_logloss: 0.131553\n",
            "[55]\ttraining's auc: 0.916963\ttraining's binary_logloss: 0.110211\tvalid_1's auc: 0.833527\tvalid_1's binary_logloss: 0.13159\n",
            "[56]\ttraining's auc: 0.91738\ttraining's binary_logloss: 0.109944\tvalid_1's auc: 0.833509\tvalid_1's binary_logloss: 0.131619\n",
            "[57]\ttraining's auc: 0.917844\ttraining's binary_logloss: 0.109767\tvalid_1's auc: 0.833299\tvalid_1's binary_logloss: 0.131665\n",
            "[58]\ttraining's auc: 0.918188\ttraining's binary_logloss: 0.109594\tvalid_1's auc: 0.833377\tvalid_1's binary_logloss: 0.131654\n",
            "[59]\ttraining's auc: 0.918501\ttraining's binary_logloss: 0.109379\tvalid_1's auc: 0.833079\tvalid_1's binary_logloss: 0.131711\n",
            "[60]\ttraining's auc: 0.918856\ttraining's binary_logloss: 0.109172\tvalid_1's auc: 0.832887\tvalid_1's binary_logloss: 0.131723\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 92%|█████████▏| 46/50 [24:19<02:42, 40.55s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.154434\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.160726\n",
            "[2]\ttraining's auc: 0.832658\ttraining's binary_logloss: 0.148941\tvalid_1's auc: 0.815472\tvalid_1's binary_logloss: 0.155788\n",
            "[3]\ttraining's auc: 0.841022\ttraining's binary_logloss: 0.144875\tvalid_1's auc: 0.821383\tvalid_1's binary_logloss: 0.152253\n",
            "[4]\ttraining's auc: 0.847467\ttraining's binary_logloss: 0.141466\tvalid_1's auc: 0.825812\tvalid_1's binary_logloss: 0.149619\n",
            "[5]\ttraining's auc: 0.850003\ttraining's binary_logloss: 0.138808\tvalid_1's auc: 0.827234\tvalid_1's binary_logloss: 0.147423\n",
            "[6]\ttraining's auc: 0.851936\ttraining's binary_logloss: 0.136487\tvalid_1's auc: 0.827789\tvalid_1's binary_logloss: 0.145781\n",
            "[7]\ttraining's auc: 0.855066\ttraining's binary_logloss: 0.134554\tvalid_1's auc: 0.830365\tvalid_1's binary_logloss: 0.144362\n",
            "[8]\ttraining's auc: 0.857375\ttraining's binary_logloss: 0.132933\tvalid_1's auc: 0.831823\tvalid_1's binary_logloss: 0.143082\n",
            "[9]\ttraining's auc: 0.859475\ttraining's binary_logloss: 0.131475\tvalid_1's auc: 0.831974\tvalid_1's binary_logloss: 0.142131\n",
            "[10]\ttraining's auc: 0.862558\ttraining's binary_logloss: 0.13014\tvalid_1's auc: 0.831603\tvalid_1's binary_logloss: 0.141403\n",
            "[11]\ttraining's auc: 0.866582\ttraining's binary_logloss: 0.128876\tvalid_1's auc: 0.831363\tvalid_1's binary_logloss: 0.140723\n",
            "[12]\ttraining's auc: 0.868553\ttraining's binary_logloss: 0.127833\tvalid_1's auc: 0.831453\tvalid_1's binary_logloss: 0.140129\n",
            "[13]\ttraining's auc: 0.871596\ttraining's binary_logloss: 0.126773\tvalid_1's auc: 0.83365\tvalid_1's binary_logloss: 0.139562\n",
            "[14]\ttraining's auc: 0.874556\ttraining's binary_logloss: 0.125838\tvalid_1's auc: 0.833724\tvalid_1's binary_logloss: 0.13919\n",
            "[15]\ttraining's auc: 0.875482\ttraining's binary_logloss: 0.124999\tvalid_1's auc: 0.833896\tvalid_1's binary_logloss: 0.138797\n",
            "[16]\ttraining's auc: 0.878024\ttraining's binary_logloss: 0.124184\tvalid_1's auc: 0.834373\tvalid_1's binary_logloss: 0.138407\n",
            "[17]\ttraining's auc: 0.880516\ttraining's binary_logloss: 0.123414\tvalid_1's auc: 0.834339\tvalid_1's binary_logloss: 0.138136\n",
            "[18]\ttraining's auc: 0.881925\ttraining's binary_logloss: 0.122729\tvalid_1's auc: 0.834829\tvalid_1's binary_logloss: 0.137859\n",
            "[19]\ttraining's auc: 0.88431\ttraining's binary_logloss: 0.122019\tvalid_1's auc: 0.83428\tvalid_1's binary_logloss: 0.137734\n",
            "[20]\ttraining's auc: 0.885273\ttraining's binary_logloss: 0.12144\tvalid_1's auc: 0.834639\tvalid_1's binary_logloss: 0.137465\n",
            "[21]\ttraining's auc: 0.886929\ttraining's binary_logloss: 0.120856\tvalid_1's auc: 0.835181\tvalid_1's binary_logloss: 0.137256\n",
            "[22]\ttraining's auc: 0.888236\ttraining's binary_logloss: 0.120278\tvalid_1's auc: 0.834814\tvalid_1's binary_logloss: 0.137151\n",
            "[23]\ttraining's auc: 0.890097\ttraining's binary_logloss: 0.11963\tvalid_1's auc: 0.835558\tvalid_1's binary_logloss: 0.136991\n",
            "[24]\ttraining's auc: 0.89153\ttraining's binary_logloss: 0.11908\tvalid_1's auc: 0.835294\tvalid_1's binary_logloss: 0.136947\n",
            "[25]\ttraining's auc: 0.892494\ttraining's binary_logloss: 0.118561\tvalid_1's auc: 0.835115\tvalid_1's binary_logloss: 0.136905\n",
            "[26]\ttraining's auc: 0.893594\ttraining's binary_logloss: 0.118125\tvalid_1's auc: 0.834873\tvalid_1's binary_logloss: 0.136847\n",
            "[27]\ttraining's auc: 0.89458\ttraining's binary_logloss: 0.117631\tvalid_1's auc: 0.834882\tvalid_1's binary_logloss: 0.136781\n",
            "[28]\ttraining's auc: 0.895914\ttraining's binary_logloss: 0.117173\tvalid_1's auc: 0.834762\tvalid_1's binary_logloss: 0.136767\n",
            "[29]\ttraining's auc: 0.896988\ttraining's binary_logloss: 0.116748\tvalid_1's auc: 0.834139\tvalid_1's binary_logloss: 0.136789\n",
            "[30]\ttraining's auc: 0.898078\ttraining's binary_logloss: 0.116335\tvalid_1's auc: 0.833935\tvalid_1's binary_logloss: 0.13679\n",
            "[31]\ttraining's auc: 0.899219\ttraining's binary_logloss: 0.115932\tvalid_1's auc: 0.833754\tvalid_1's binary_logloss: 0.136736\n",
            "[32]\ttraining's auc: 0.900007\ttraining's binary_logloss: 0.115539\tvalid_1's auc: 0.833362\tvalid_1's binary_logloss: 0.136755\n",
            "[33]\ttraining's auc: 0.901357\ttraining's binary_logloss: 0.115042\tvalid_1's auc: 0.83328\tvalid_1's binary_logloss: 0.136767\n",
            "[34]\ttraining's auc: 0.901932\ttraining's binary_logloss: 0.11472\tvalid_1's auc: 0.833687\tvalid_1's binary_logloss: 0.136656\n",
            "[35]\ttraining's auc: 0.903296\ttraining's binary_logloss: 0.114287\tvalid_1's auc: 0.833575\tvalid_1's binary_logloss: 0.13669\n",
            "[36]\ttraining's auc: 0.904353\ttraining's binary_logloss: 0.113952\tvalid_1's auc: 0.833408\tvalid_1's binary_logloss: 0.136714\n",
            "[37]\ttraining's auc: 0.905517\ttraining's binary_logloss: 0.113487\tvalid_1's auc: 0.833498\tvalid_1's binary_logloss: 0.136664\n",
            "[38]\ttraining's auc: 0.906491\ttraining's binary_logloss: 0.113037\tvalid_1's auc: 0.833419\tvalid_1's binary_logloss: 0.136682\n",
            "[39]\ttraining's auc: 0.907255\ttraining's binary_logloss: 0.112705\tvalid_1's auc: 0.833204\tvalid_1's binary_logloss: 0.136717\n",
            "[40]\ttraining's auc: 0.908202\ttraining's binary_logloss: 0.112349\tvalid_1's auc: 0.83282\tvalid_1's binary_logloss: 0.136838\n",
            "[41]\ttraining's auc: 0.909095\ttraining's binary_logloss: 0.111964\tvalid_1's auc: 0.832979\tvalid_1's binary_logloss: 0.136823\n",
            "[42]\ttraining's auc: 0.909836\ttraining's binary_logloss: 0.111682\tvalid_1's auc: 0.832958\tvalid_1's binary_logloss: 0.136828\n",
            "[43]\ttraining's auc: 0.910952\ttraining's binary_logloss: 0.111282\tvalid_1's auc: 0.833034\tvalid_1's binary_logloss: 0.136833\n",
            "[44]\ttraining's auc: 0.911512\ttraining's binary_logloss: 0.11102\tvalid_1's auc: 0.832894\tvalid_1's binary_logloss: 0.136844\n",
            "[45]\ttraining's auc: 0.912268\ttraining's binary_logloss: 0.1107\tvalid_1's auc: 0.832747\tvalid_1's binary_logloss: 0.136854\n",
            "[46]\ttraining's auc: 0.912758\ttraining's binary_logloss: 0.110475\tvalid_1's auc: 0.832678\tvalid_1's binary_logloss: 0.136862\n",
            "[47]\ttraining's auc: 0.913999\ttraining's binary_logloss: 0.11002\tvalid_1's auc: 0.832766\tvalid_1's binary_logloss: 0.136852\n",
            "[48]\ttraining's auc: 0.914586\ttraining's binary_logloss: 0.109743\tvalid_1's auc: 0.833011\tvalid_1's binary_logloss: 0.136831\n",
            "[49]\ttraining's auc: 0.914986\ttraining's binary_logloss: 0.1095\tvalid_1's auc: 0.832721\tvalid_1's binary_logloss: 0.13691\n",
            "[50]\ttraining's auc: 0.915541\ttraining's binary_logloss: 0.109233\tvalid_1's auc: 0.832502\tvalid_1's binary_logloss: 0.136995\n",
            "[51]\ttraining's auc: 0.916305\ttraining's binary_logloss: 0.108881\tvalid_1's auc: 0.832727\tvalid_1's binary_logloss: 0.136933\n",
            "[52]\ttraining's auc: 0.916959\ttraining's binary_logloss: 0.108628\tvalid_1's auc: 0.833099\tvalid_1's binary_logloss: 0.136911\n",
            "[53]\ttraining's auc: 0.917297\ttraining's binary_logloss: 0.108403\tvalid_1's auc: 0.83303\tvalid_1's binary_logloss: 0.136919\n",
            " 94%|█████████▍| 47/50 [24:27<01:49, 36.53s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.154558\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.157186\n",
            "[2]\ttraining's auc: 0.834595\ttraining's binary_logloss: 0.148708\tvalid_1's auc: 0.808895\tvalid_1's binary_logloss: 0.152568\n",
            "[3]\ttraining's auc: 0.84463\ttraining's binary_logloss: 0.144568\tvalid_1's auc: 0.814216\tvalid_1's binary_logloss: 0.149441\n",
            "[4]\ttraining's auc: 0.848606\ttraining's binary_logloss: 0.141281\tvalid_1's auc: 0.814494\tvalid_1's binary_logloss: 0.147252\n",
            "[5]\ttraining's auc: 0.851693\ttraining's binary_logloss: 0.138536\tvalid_1's auc: 0.815996\tvalid_1's binary_logloss: 0.145436\n",
            "[6]\ttraining's auc: 0.853955\ttraining's binary_logloss: 0.136211\tvalid_1's auc: 0.817246\tvalid_1's binary_logloss: 0.143887\n",
            "[7]\ttraining's auc: 0.855263\ttraining's binary_logloss: 0.13432\tvalid_1's auc: 0.819372\tvalid_1's binary_logloss: 0.142497\n",
            "[8]\ttraining's auc: 0.857828\ttraining's binary_logloss: 0.132558\tvalid_1's auc: 0.820995\tvalid_1's binary_logloss: 0.141357\n",
            "[9]\ttraining's auc: 0.862766\ttraining's binary_logloss: 0.131097\tvalid_1's auc: 0.822257\tvalid_1's binary_logloss: 0.14059\n",
            "[10]\ttraining's auc: 0.867432\ttraining's binary_logloss: 0.129757\tvalid_1's auc: 0.823589\tvalid_1's binary_logloss: 0.139902\n",
            "[11]\ttraining's auc: 0.870204\ttraining's binary_logloss: 0.128466\tvalid_1's auc: 0.824255\tvalid_1's binary_logloss: 0.139338\n",
            "[12]\ttraining's auc: 0.872007\ttraining's binary_logloss: 0.127258\tvalid_1's auc: 0.825221\tvalid_1's binary_logloss: 0.138737\n",
            "[13]\ttraining's auc: 0.874616\ttraining's binary_logloss: 0.126336\tvalid_1's auc: 0.825709\tvalid_1's binary_logloss: 0.138394\n",
            "[14]\ttraining's auc: 0.875975\ttraining's binary_logloss: 0.125428\tvalid_1's auc: 0.826229\tvalid_1's binary_logloss: 0.138033\n",
            "[15]\ttraining's auc: 0.87767\ttraining's binary_logloss: 0.124574\tvalid_1's auc: 0.826062\tvalid_1's binary_logloss: 0.137802\n",
            "[16]\ttraining's auc: 0.880052\ttraining's binary_logloss: 0.123703\tvalid_1's auc: 0.826395\tvalid_1's binary_logloss: 0.137559\n",
            "[17]\ttraining's auc: 0.882414\ttraining's binary_logloss: 0.12292\tvalid_1's auc: 0.826189\tvalid_1's binary_logloss: 0.137341\n",
            "[18]\ttraining's auc: 0.8837\ttraining's binary_logloss: 0.122256\tvalid_1's auc: 0.826581\tvalid_1's binary_logloss: 0.137197\n",
            "[19]\ttraining's auc: 0.886583\ttraining's binary_logloss: 0.121507\tvalid_1's auc: 0.826804\tvalid_1's binary_logloss: 0.13699\n",
            "[20]\ttraining's auc: 0.888986\ttraining's binary_logloss: 0.120783\tvalid_1's auc: 0.827265\tvalid_1's binary_logloss: 0.136834\n",
            "[21]\ttraining's auc: 0.889864\ttraining's binary_logloss: 0.12025\tvalid_1's auc: 0.826903\tvalid_1's binary_logloss: 0.136819\n",
            "[22]\ttraining's auc: 0.890719\ttraining's binary_logloss: 0.119703\tvalid_1's auc: 0.827069\tvalid_1's binary_logloss: 0.136724\n",
            "[23]\ttraining's auc: 0.892885\ttraining's binary_logloss: 0.119122\tvalid_1's auc: 0.828159\tvalid_1's binary_logloss: 0.136476\n",
            "[24]\ttraining's auc: 0.894101\ttraining's binary_logloss: 0.1186\tvalid_1's auc: 0.828382\tvalid_1's binary_logloss: 0.136455\n",
            "[25]\ttraining's auc: 0.895499\ttraining's binary_logloss: 0.118136\tvalid_1's auc: 0.828932\tvalid_1's binary_logloss: 0.136334\n",
            "[26]\ttraining's auc: 0.897189\ttraining's binary_logloss: 0.117601\tvalid_1's auc: 0.828603\tvalid_1's binary_logloss: 0.136281\n",
            "[27]\ttraining's auc: 0.898295\ttraining's binary_logloss: 0.117095\tvalid_1's auc: 0.828348\tvalid_1's binary_logloss: 0.136284\n",
            "[28]\ttraining's auc: 0.899249\ttraining's binary_logloss: 0.116623\tvalid_1's auc: 0.828612\tvalid_1's binary_logloss: 0.136257\n",
            "[29]\ttraining's auc: 0.900002\ttraining's binary_logloss: 0.116172\tvalid_1's auc: 0.828219\tvalid_1's binary_logloss: 0.136351\n",
            "[30]\ttraining's auc: 0.900939\ttraining's binary_logloss: 0.115753\tvalid_1's auc: 0.828516\tvalid_1's binary_logloss: 0.136328\n",
            "[31]\ttraining's auc: 0.901987\ttraining's binary_logloss: 0.115305\tvalid_1's auc: 0.828782\tvalid_1's binary_logloss: 0.136316\n",
            "[32]\ttraining's auc: 0.902717\ttraining's binary_logloss: 0.114924\tvalid_1's auc: 0.828957\tvalid_1's binary_logloss: 0.136329\n",
            "[33]\ttraining's auc: 0.903396\ttraining's binary_logloss: 0.114528\tvalid_1's auc: 0.829199\tvalid_1's binary_logloss: 0.136266\n",
            "[34]\ttraining's auc: 0.904533\ttraining's binary_logloss: 0.114108\tvalid_1's auc: 0.829148\tvalid_1's binary_logloss: 0.136306\n",
            "[35]\ttraining's auc: 0.905139\ttraining's binary_logloss: 0.113762\tvalid_1's auc: 0.828992\tvalid_1's binary_logloss: 0.136334\n",
            "[36]\ttraining's auc: 0.906205\ttraining's binary_logloss: 0.113405\tvalid_1's auc: 0.828677\tvalid_1's binary_logloss: 0.136376\n",
            "[37]\ttraining's auc: 0.907238\ttraining's binary_logloss: 0.11304\tvalid_1's auc: 0.828305\tvalid_1's binary_logloss: 0.136449\n",
            "[38]\ttraining's auc: 0.909032\ttraining's binary_logloss: 0.112658\tvalid_1's auc: 0.828299\tvalid_1's binary_logloss: 0.136458\n",
            "[39]\ttraining's auc: 0.910186\ttraining's binary_logloss: 0.11221\tvalid_1's auc: 0.827753\tvalid_1's binary_logloss: 0.136577\n",
            "[40]\ttraining's auc: 0.910838\ttraining's binary_logloss: 0.111861\tvalid_1's auc: 0.827741\tvalid_1's binary_logloss: 0.136616\n",
            "[41]\ttraining's auc: 0.911376\ttraining's binary_logloss: 0.111596\tvalid_1's auc: 0.827189\tvalid_1's binary_logloss: 0.136703\n",
            "[42]\ttraining's auc: 0.911983\ttraining's binary_logloss: 0.111321\tvalid_1's auc: 0.827047\tvalid_1's binary_logloss: 0.13676\n",
            "[43]\ttraining's auc: 0.913019\ttraining's binary_logloss: 0.111028\tvalid_1's auc: 0.827351\tvalid_1's binary_logloss: 0.13671\n",
            "[44]\ttraining's auc: 0.913707\ttraining's binary_logloss: 0.110726\tvalid_1's auc: 0.827168\tvalid_1's binary_logloss: 0.13676\n",
            "[45]\ttraining's auc: 0.914183\ttraining's binary_logloss: 0.110467\tvalid_1's auc: 0.826868\tvalid_1's binary_logloss: 0.136841\n",
            "[46]\ttraining's auc: 0.914935\ttraining's binary_logloss: 0.110099\tvalid_1's auc: 0.827056\tvalid_1's binary_logloss: 0.136798\n",
            "[47]\ttraining's auc: 0.915438\ttraining's binary_logloss: 0.109823\tvalid_1's auc: 0.826487\tvalid_1's binary_logloss: 0.136923\n",
            "[48]\ttraining's auc: 0.916102\ttraining's binary_logloss: 0.109492\tvalid_1's auc: 0.826019\tvalid_1's binary_logloss: 0.136991\n",
            "[49]\ttraining's auc: 0.916636\ttraining's binary_logloss: 0.109219\tvalid_1's auc: 0.826026\tvalid_1's binary_logloss: 0.136984\n",
            "[50]\ttraining's auc: 0.916899\ttraining's binary_logloss: 0.109047\tvalid_1's auc: 0.825922\tvalid_1's binary_logloss: 0.137035\n",
            "[51]\ttraining's auc: 0.917861\ttraining's binary_logloss: 0.108809\tvalid_1's auc: 0.826025\tvalid_1's binary_logloss: 0.137021\n",
            "[52]\ttraining's auc: 0.91886\ttraining's binary_logloss: 0.108423\tvalid_1's auc: 0.825922\tvalid_1's binary_logloss: 0.137067\n",
            "[53]\ttraining's auc: 0.919068\ttraining's binary_logloss: 0.108252\tvalid_1's auc: 0.825632\tvalid_1's binary_logloss: 0.13716\n",
            "[54]\ttraining's auc: 0.919466\ttraining's binary_logloss: 0.108015\tvalid_1's auc: 0.825475\tvalid_1's binary_logloss: 0.137182\n",
            "[55]\ttraining's auc: 0.920082\ttraining's binary_logloss: 0.107718\tvalid_1's auc: 0.825031\tvalid_1's binary_logloss: 0.137282\n",
            "[56]\ttraining's auc: 0.92054\ttraining's binary_logloss: 0.10747\tvalid_1's auc: 0.824861\tvalid_1's binary_logloss: 0.137314\n",
            "[57]\ttraining's auc: 0.921082\ttraining's binary_logloss: 0.107216\tvalid_1's auc: 0.824867\tvalid_1's binary_logloss: 0.137322\n",
            "[58]\ttraining's auc: 0.922219\ttraining's binary_logloss: 0.106901\tvalid_1's auc: 0.824607\tvalid_1's binary_logloss: 0.137364\n",
            " 94%|█████████▍| 47/50 [24:36<01:49, 36.53s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.156985\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.153167\n",
            "[2]\ttraining's auc: 0.831245\ttraining's binary_logloss: 0.151039\tvalid_1's auc: 0.816798\tvalid_1's binary_logloss: 0.148517\n",
            "[3]\ttraining's auc: 0.838666\ttraining's binary_logloss: 0.146761\tvalid_1's auc: 0.820584\tvalid_1's binary_logloss: 0.145287\n",
            "[4]\ttraining's auc: 0.844686\ttraining's binary_logloss: 0.143457\tvalid_1's auc: 0.825071\tvalid_1's binary_logloss: 0.142865\n",
            "[5]\ttraining's auc: 0.850439\ttraining's binary_logloss: 0.140666\tvalid_1's auc: 0.825689\tvalid_1's binary_logloss: 0.140983\n",
            "[6]\ttraining's auc: 0.853415\ttraining's binary_logloss: 0.138363\tvalid_1's auc: 0.82939\tvalid_1's binary_logloss: 0.13927\n",
            "[7]\ttraining's auc: 0.856349\ttraining's binary_logloss: 0.13638\tvalid_1's auc: 0.830586\tvalid_1's binary_logloss: 0.137971\n",
            "[8]\ttraining's auc: 0.859933\ttraining's binary_logloss: 0.134745\tvalid_1's auc: 0.831591\tvalid_1's binary_logloss: 0.137001\n",
            "[9]\ttraining's auc: 0.862205\ttraining's binary_logloss: 0.133267\tvalid_1's auc: 0.831985\tvalid_1's binary_logloss: 0.136058\n",
            "[10]\ttraining's auc: 0.865246\ttraining's binary_logloss: 0.131886\tvalid_1's auc: 0.831487\tvalid_1's binary_logloss: 0.13539\n",
            "[11]\ttraining's auc: 0.869314\ttraining's binary_logloss: 0.13057\tvalid_1's auc: 0.831932\tvalid_1's binary_logloss: 0.134884\n",
            "[12]\ttraining's auc: 0.871237\ttraining's binary_logloss: 0.129433\tvalid_1's auc: 0.833291\tvalid_1's binary_logloss: 0.134241\n",
            "[13]\ttraining's auc: 0.872735\ttraining's binary_logloss: 0.128482\tvalid_1's auc: 0.832697\tvalid_1's binary_logloss: 0.133855\n",
            "[14]\ttraining's auc: 0.874724\ttraining's binary_logloss: 0.127549\tvalid_1's auc: 0.832905\tvalid_1's binary_logloss: 0.133494\n",
            "[15]\ttraining's auc: 0.875989\ttraining's binary_logloss: 0.126688\tvalid_1's auc: 0.832782\tvalid_1's binary_logloss: 0.133241\n",
            "[16]\ttraining's auc: 0.877254\ttraining's binary_logloss: 0.125868\tvalid_1's auc: 0.832554\tvalid_1's binary_logloss: 0.132992\n",
            "[17]\ttraining's auc: 0.879313\ttraining's binary_logloss: 0.125078\tvalid_1's auc: 0.832294\tvalid_1's binary_logloss: 0.132758\n",
            "[18]\ttraining's auc: 0.881218\ttraining's binary_logloss: 0.124281\tvalid_1's auc: 0.831835\tvalid_1's binary_logloss: 0.132619\n",
            "[19]\ttraining's auc: 0.883322\ttraining's binary_logloss: 0.123599\tvalid_1's auc: 0.832355\tvalid_1's binary_logloss: 0.132389\n",
            "[20]\ttraining's auc: 0.884978\ttraining's binary_logloss: 0.122917\tvalid_1's auc: 0.832522\tvalid_1's binary_logloss: 0.132253\n",
            "[21]\ttraining's auc: 0.886924\ttraining's binary_logloss: 0.122333\tvalid_1's auc: 0.832265\tvalid_1's binary_logloss: 0.132162\n",
            "[22]\ttraining's auc: 0.888368\ttraining's binary_logloss: 0.121777\tvalid_1's auc: 0.832761\tvalid_1's binary_logloss: 0.132104\n",
            "[23]\ttraining's auc: 0.889681\ttraining's binary_logloss: 0.121171\tvalid_1's auc: 0.833025\tvalid_1's binary_logloss: 0.131974\n",
            "[24]\ttraining's auc: 0.890892\ttraining's binary_logloss: 0.120611\tvalid_1's auc: 0.832962\tvalid_1's binary_logloss: 0.131916\n",
            "[25]\ttraining's auc: 0.891936\ttraining's binary_logloss: 0.120053\tvalid_1's auc: 0.833546\tvalid_1's binary_logloss: 0.131752\n",
            "[26]\ttraining's auc: 0.892875\ttraining's binary_logloss: 0.119573\tvalid_1's auc: 0.834013\tvalid_1's binary_logloss: 0.131647\n",
            "[27]\ttraining's auc: 0.894231\ttraining's binary_logloss: 0.119067\tvalid_1's auc: 0.834608\tvalid_1's binary_logloss: 0.131532\n",
            "[28]\ttraining's auc: 0.895706\ttraining's binary_logloss: 0.118608\tvalid_1's auc: 0.834905\tvalid_1's binary_logloss: 0.131446\n",
            "[29]\ttraining's auc: 0.897372\ttraining's binary_logloss: 0.118129\tvalid_1's auc: 0.835043\tvalid_1's binary_logloss: 0.131372\n",
            "[30]\ttraining's auc: 0.898414\ttraining's binary_logloss: 0.117677\tvalid_1's auc: 0.834933\tvalid_1's binary_logloss: 0.131367\n",
            "[31]\ttraining's auc: 0.899249\ttraining's binary_logloss: 0.117283\tvalid_1's auc: 0.834721\tvalid_1's binary_logloss: 0.131388\n",
            "[32]\ttraining's auc: 0.901337\ttraining's binary_logloss: 0.116788\tvalid_1's auc: 0.83416\tvalid_1's binary_logloss: 0.131449\n",
            "[33]\ttraining's auc: 0.902701\ttraining's binary_logloss: 0.116401\tvalid_1's auc: 0.833744\tvalid_1's binary_logloss: 0.131492\n",
            "[34]\ttraining's auc: 0.903409\ttraining's binary_logloss: 0.116058\tvalid_1's auc: 0.834003\tvalid_1's binary_logloss: 0.131471\n",
            "[35]\ttraining's auc: 0.904204\ttraining's binary_logloss: 0.115761\tvalid_1's auc: 0.834192\tvalid_1's binary_logloss: 0.131438\n",
            "[36]\ttraining's auc: 0.904814\ttraining's binary_logloss: 0.115348\tvalid_1's auc: 0.834535\tvalid_1's binary_logloss: 0.13135\n",
            "[37]\ttraining's auc: 0.905916\ttraining's binary_logloss: 0.114995\tvalid_1's auc: 0.834459\tvalid_1's binary_logloss: 0.131379\n",
            "[38]\ttraining's auc: 0.907207\ttraining's binary_logloss: 0.114495\tvalid_1's auc: 0.833742\tvalid_1's binary_logloss: 0.131509\n",
            "[39]\ttraining's auc: 0.908147\ttraining's binary_logloss: 0.114105\tvalid_1's auc: 0.833755\tvalid_1's binary_logloss: 0.131489\n",
            "[40]\ttraining's auc: 0.908845\ttraining's binary_logloss: 0.113764\tvalid_1's auc: 0.83397\tvalid_1's binary_logloss: 0.131453\n",
            "[41]\ttraining's auc: 0.909245\ttraining's binary_logloss: 0.113509\tvalid_1's auc: 0.833762\tvalid_1's binary_logloss: 0.131508\n",
            "[42]\ttraining's auc: 0.910375\ttraining's binary_logloss: 0.113082\tvalid_1's auc: 0.833503\tvalid_1's binary_logloss: 0.131564\n",
            "[43]\ttraining's auc: 0.911027\ttraining's binary_logloss: 0.112747\tvalid_1's auc: 0.833407\tvalid_1's binary_logloss: 0.131594\n",
            "[44]\ttraining's auc: 0.911811\ttraining's binary_logloss: 0.112351\tvalid_1's auc: 0.833147\tvalid_1's binary_logloss: 0.131633\n",
            "[45]\ttraining's auc: 0.912304\ttraining's binary_logloss: 0.112056\tvalid_1's auc: 0.833204\tvalid_1's binary_logloss: 0.131628\n",
            "[46]\ttraining's auc: 0.912875\ttraining's binary_logloss: 0.111747\tvalid_1's auc: 0.832792\tvalid_1's binary_logloss: 0.131685\n",
            "[47]\ttraining's auc: 0.915064\ttraining's binary_logloss: 0.111138\tvalid_1's auc: 0.833142\tvalid_1's binary_logloss: 0.131666\n",
            "[48]\ttraining's auc: 0.915561\ttraining's binary_logloss: 0.11082\tvalid_1's auc: 0.833465\tvalid_1's binary_logloss: 0.131569\n",
            "[49]\ttraining's auc: 0.915826\ttraining's binary_logloss: 0.110567\tvalid_1's auc: 0.83346\tvalid_1's binary_logloss: 0.131584\n",
            "[50]\ttraining's auc: 0.916483\ttraining's binary_logloss: 0.110286\tvalid_1's auc: 0.83322\tvalid_1's binary_logloss: 0.131647\n",
            "[51]\ttraining's auc: 0.916701\ttraining's binary_logloss: 0.11008\tvalid_1's auc: 0.833201\tvalid_1's binary_logloss: 0.131658\n",
            "[52]\ttraining's auc: 0.917284\ttraining's binary_logloss: 0.109761\tvalid_1's auc: 0.833149\tvalid_1's binary_logloss: 0.13167\n",
            "[53]\ttraining's auc: 0.91805\ttraining's binary_logloss: 0.109475\tvalid_1's auc: 0.833332\tvalid_1's binary_logloss: 0.131639\n",
            "[54]\ttraining's auc: 0.918607\ttraining's binary_logloss: 0.109222\tvalid_1's auc: 0.833154\tvalid_1's binary_logloss: 0.131685\n",
            "[55]\ttraining's auc: 0.918918\ttraining's binary_logloss: 0.109043\tvalid_1's auc: 0.83331\tvalid_1's binary_logloss: 0.131653\n",
            "[56]\ttraining's auc: 0.919202\ttraining's binary_logloss: 0.108845\tvalid_1's auc: 0.833281\tvalid_1's binary_logloss: 0.131671\n",
            "[57]\ttraining's auc: 0.919397\ttraining's binary_logloss: 0.108689\tvalid_1's auc: 0.83319\tvalid_1's binary_logloss: 0.13169\n",
            "[58]\ttraining's auc: 0.919865\ttraining's binary_logloss: 0.108464\tvalid_1's auc: 0.833059\tvalid_1's binary_logloss: 0.131725\n",
            "[59]\ttraining's auc: 0.920919\ttraining's binary_logloss: 0.108091\tvalid_1's auc: 0.832913\tvalid_1's binary_logloss: 0.131777\n",
            " 94%|█████████▍| 47/50 [24:44<01:49, 36.53s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.153728\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.160101\n",
            "[2]\ttraining's auc: 0.832666\ttraining's binary_logloss: 0.148015\tvalid_1's auc: 0.81524\tvalid_1's binary_logloss: 0.154999\n",
            "[3]\ttraining's auc: 0.841825\ttraining's binary_logloss: 0.143748\tvalid_1's auc: 0.820449\tvalid_1's binary_logloss: 0.151482\n",
            "[4]\ttraining's auc: 0.847637\ttraining's binary_logloss: 0.140452\tvalid_1's auc: 0.82379\tvalid_1's binary_logloss: 0.148906\n",
            "[5]\ttraining's auc: 0.849719\ttraining's binary_logloss: 0.137695\tvalid_1's auc: 0.82559\tvalid_1's binary_logloss: 0.146749\n",
            "[6]\ttraining's auc: 0.853951\ttraining's binary_logloss: 0.135523\tvalid_1's auc: 0.827509\tvalid_1's binary_logloss: 0.145013\n",
            "[7]\ttraining's auc: 0.855339\ttraining's binary_logloss: 0.133616\tvalid_1's auc: 0.829143\tvalid_1's binary_logloss: 0.143626\n",
            "[8]\ttraining's auc: 0.857916\ttraining's binary_logloss: 0.131952\tvalid_1's auc: 0.829361\tvalid_1's binary_logloss: 0.142562\n",
            "[9]\ttraining's auc: 0.860381\ttraining's binary_logloss: 0.130538\tvalid_1's auc: 0.830004\tvalid_1's binary_logloss: 0.141632\n",
            "[10]\ttraining's auc: 0.86412\ttraining's binary_logloss: 0.129271\tvalid_1's auc: 0.830382\tvalid_1's binary_logloss: 0.140849\n",
            "[11]\ttraining's auc: 0.867573\ttraining's binary_logloss: 0.128073\tvalid_1's auc: 0.831267\tvalid_1's binary_logloss: 0.140155\n",
            "[12]\ttraining's auc: 0.869912\ttraining's binary_logloss: 0.127013\tvalid_1's auc: 0.832254\tvalid_1's binary_logloss: 0.139695\n",
            "[13]\ttraining's auc: 0.872926\ttraining's binary_logloss: 0.125952\tvalid_1's auc: 0.832958\tvalid_1's binary_logloss: 0.139246\n",
            "[14]\ttraining's auc: 0.874368\ttraining's binary_logloss: 0.125091\tvalid_1's auc: 0.832607\tvalid_1's binary_logloss: 0.138891\n",
            "[15]\ttraining's auc: 0.877017\ttraining's binary_logloss: 0.124168\tvalid_1's auc: 0.833405\tvalid_1's binary_logloss: 0.138532\n",
            "[16]\ttraining's auc: 0.878538\ttraining's binary_logloss: 0.123444\tvalid_1's auc: 0.83386\tvalid_1's binary_logloss: 0.138226\n",
            "[17]\ttraining's auc: 0.880905\ttraining's binary_logloss: 0.122574\tvalid_1's auc: 0.833569\tvalid_1's binary_logloss: 0.138036\n",
            "[18]\ttraining's auc: 0.883958\ttraining's binary_logloss: 0.121694\tvalid_1's auc: 0.832537\tvalid_1's binary_logloss: 0.137921\n",
            "[19]\ttraining's auc: 0.885773\ttraining's binary_logloss: 0.120975\tvalid_1's auc: 0.832469\tvalid_1's binary_logloss: 0.137786\n",
            "[20]\ttraining's auc: 0.887333\ttraining's binary_logloss: 0.120349\tvalid_1's auc: 0.832787\tvalid_1's binary_logloss: 0.137651\n",
            "[21]\ttraining's auc: 0.88929\ttraining's binary_logloss: 0.119719\tvalid_1's auc: 0.832865\tvalid_1's binary_logloss: 0.1375\n",
            "[22]\ttraining's auc: 0.890441\ttraining's binary_logloss: 0.11912\tvalid_1's auc: 0.833895\tvalid_1's binary_logloss: 0.137252\n",
            "[23]\ttraining's auc: 0.891825\ttraining's binary_logloss: 0.118556\tvalid_1's auc: 0.834235\tvalid_1's binary_logloss: 0.137122\n",
            "[24]\ttraining's auc: 0.892622\ttraining's binary_logloss: 0.118106\tvalid_1's auc: 0.834337\tvalid_1's binary_logloss: 0.137023\n",
            "[25]\ttraining's auc: 0.89377\ttraining's binary_logloss: 0.117677\tvalid_1's auc: 0.834326\tvalid_1's binary_logloss: 0.136978\n",
            "[26]\ttraining's auc: 0.895023\ttraining's binary_logloss: 0.117178\tvalid_1's auc: 0.8341\tvalid_1's binary_logloss: 0.136969\n",
            "[27]\ttraining's auc: 0.896184\ttraining's binary_logloss: 0.11672\tvalid_1's auc: 0.833693\tvalid_1's binary_logloss: 0.136988\n",
            "[28]\ttraining's auc: 0.896925\ttraining's binary_logloss: 0.116318\tvalid_1's auc: 0.833696\tvalid_1's binary_logloss: 0.136954\n",
            "[29]\ttraining's auc: 0.898411\ttraining's binary_logloss: 0.115852\tvalid_1's auc: 0.833765\tvalid_1's binary_logloss: 0.136877\n",
            "[30]\ttraining's auc: 0.899785\ttraining's binary_logloss: 0.115446\tvalid_1's auc: 0.833506\tvalid_1's binary_logloss: 0.136857\n",
            "[31]\ttraining's auc: 0.900931\ttraining's binary_logloss: 0.11507\tvalid_1's auc: 0.833312\tvalid_1's binary_logloss: 0.136863\n",
            "[32]\ttraining's auc: 0.901919\ttraining's binary_logloss: 0.114683\tvalid_1's auc: 0.832977\tvalid_1's binary_logloss: 0.136894\n",
            "[33]\ttraining's auc: 0.903083\ttraining's binary_logloss: 0.114154\tvalid_1's auc: 0.832857\tvalid_1's binary_logloss: 0.136972\n",
            "[34]\ttraining's auc: 0.904233\ttraining's binary_logloss: 0.113696\tvalid_1's auc: 0.832879\tvalid_1's binary_logloss: 0.137009\n",
            "[35]\ttraining's auc: 0.905174\ttraining's binary_logloss: 0.113271\tvalid_1's auc: 0.832788\tvalid_1's binary_logloss: 0.137086\n",
            "[36]\ttraining's auc: 0.906379\ttraining's binary_logloss: 0.112927\tvalid_1's auc: 0.832838\tvalid_1's binary_logloss: 0.13709\n",
            "[37]\ttraining's auc: 0.907258\ttraining's binary_logloss: 0.112538\tvalid_1's auc: 0.832986\tvalid_1's binary_logloss: 0.137066\n",
            "[38]\ttraining's auc: 0.908265\ttraining's binary_logloss: 0.112083\tvalid_1's auc: 0.833536\tvalid_1's binary_logloss: 0.137021\n",
            "[39]\ttraining's auc: 0.909121\ttraining's binary_logloss: 0.111689\tvalid_1's auc: 0.833423\tvalid_1's binary_logloss: 0.137071\n",
            "[40]\ttraining's auc: 0.910017\ttraining's binary_logloss: 0.111345\tvalid_1's auc: 0.833499\tvalid_1's binary_logloss: 0.137062\n",
            "[41]\ttraining's auc: 0.911094\ttraining's binary_logloss: 0.11088\tvalid_1's auc: 0.833468\tvalid_1's binary_logloss: 0.137052\n",
            "[42]\ttraining's auc: 0.911861\ttraining's binary_logloss: 0.11052\tvalid_1's auc: 0.83327\tvalid_1's binary_logloss: 0.137113\n",
            "[43]\ttraining's auc: 0.912508\ttraining's binary_logloss: 0.110171\tvalid_1's auc: 0.833777\tvalid_1's binary_logloss: 0.137061\n",
            "[44]\ttraining's auc: 0.913171\ttraining's binary_logloss: 0.109838\tvalid_1's auc: 0.833265\tvalid_1's binary_logloss: 0.137183\n",
            "[45]\ttraining's auc: 0.913632\ttraining's binary_logloss: 0.109605\tvalid_1's auc: 0.833396\tvalid_1's binary_logloss: 0.137147\n",
            "[46]\ttraining's auc: 0.915909\ttraining's binary_logloss: 0.109158\tvalid_1's auc: 0.833217\tvalid_1's binary_logloss: 0.137188\n",
            "[47]\ttraining's auc: 0.916647\ttraining's binary_logloss: 0.108781\tvalid_1's auc: 0.833018\tvalid_1's binary_logloss: 0.137236\n",
            "[48]\ttraining's auc: 0.916989\ttraining's binary_logloss: 0.108565\tvalid_1's auc: 0.833065\tvalid_1's binary_logloss: 0.137228\n",
            "[49]\ttraining's auc: 0.917601\ttraining's binary_logloss: 0.108243\tvalid_1's auc: 0.832899\tvalid_1's binary_logloss: 0.137289\n",
            "[50]\ttraining's auc: 0.91836\ttraining's binary_logloss: 0.1079\tvalid_1's auc: 0.832914\tvalid_1's binary_logloss: 0.13729\n",
            "[51]\ttraining's auc: 0.918762\ttraining's binary_logloss: 0.107662\tvalid_1's auc: 0.832873\tvalid_1's binary_logloss: 0.137313\n",
            "[52]\ttraining's auc: 0.919139\ttraining's binary_logloss: 0.107386\tvalid_1's auc: 0.832912\tvalid_1's binary_logloss: 0.137329\n",
            "[53]\ttraining's auc: 0.91959\ttraining's binary_logloss: 0.107166\tvalid_1's auc: 0.832793\tvalid_1's binary_logloss: 0.137368\n",
            "[54]\ttraining's auc: 0.920556\ttraining's binary_logloss: 0.106788\tvalid_1's auc: 0.832369\tvalid_1's binary_logloss: 0.137438\n",
            " 96%|█████████▌| 48/50 [24:54<01:07, 33.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.15942\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.161159\n",
            "[2]\ttraining's auc: 0.832641\ttraining's binary_logloss: 0.155514\tvalid_1's auc: 0.80536\tvalid_1's binary_logloss: 0.158181\n",
            "[3]\ttraining's auc: 0.833672\ttraining's binary_logloss: 0.152367\tvalid_1's auc: 0.805878\tvalid_1's binary_logloss: 0.155767\n",
            "[4]\ttraining's auc: 0.838287\ttraining's binary_logloss: 0.149663\tvalid_1's auc: 0.811114\tvalid_1's binary_logloss: 0.153548\n",
            "[5]\ttraining's auc: 0.842059\ttraining's binary_logloss: 0.147366\tvalid_1's auc: 0.812676\tvalid_1's binary_logloss: 0.151762\n",
            "[6]\ttraining's auc: 0.846474\ttraining's binary_logloss: 0.145378\tvalid_1's auc: 0.816255\tvalid_1's binary_logloss: 0.150283\n",
            "[7]\ttraining's auc: 0.848189\ttraining's binary_logloss: 0.143579\tvalid_1's auc: 0.817341\tvalid_1's binary_logloss: 0.148938\n",
            "[8]\ttraining's auc: 0.850722\ttraining's binary_logloss: 0.141938\tvalid_1's auc: 0.820305\tvalid_1's binary_logloss: 0.147739\n",
            "[9]\ttraining's auc: 0.852571\ttraining's binary_logloss: 0.140463\tvalid_1's auc: 0.820962\tvalid_1's binary_logloss: 0.146694\n",
            "[10]\ttraining's auc: 0.85446\ttraining's binary_logloss: 0.139085\tvalid_1's auc: 0.821695\tvalid_1's binary_logloss: 0.14582\n",
            "[11]\ttraining's auc: 0.855411\ttraining's binary_logloss: 0.137856\tvalid_1's auc: 0.821659\tvalid_1's binary_logloss: 0.144959\n",
            "[12]\ttraining's auc: 0.856532\ttraining's binary_logloss: 0.136697\tvalid_1's auc: 0.821841\tvalid_1's binary_logloss: 0.144199\n",
            "[13]\ttraining's auc: 0.85886\ttraining's binary_logloss: 0.135664\tvalid_1's auc: 0.822644\tvalid_1's binary_logloss: 0.143502\n",
            "[14]\ttraining's auc: 0.859763\ttraining's binary_logloss: 0.13477\tvalid_1's auc: 0.82311\tvalid_1's binary_logloss: 0.142829\n",
            "[15]\ttraining's auc: 0.86244\ttraining's binary_logloss: 0.133814\tvalid_1's auc: 0.823885\tvalid_1's binary_logloss: 0.142227\n",
            "[16]\ttraining's auc: 0.862742\ttraining's binary_logloss: 0.132996\tvalid_1's auc: 0.823803\tvalid_1's binary_logloss: 0.141714\n",
            "[17]\ttraining's auc: 0.864818\ttraining's binary_logloss: 0.132254\tvalid_1's auc: 0.824899\tvalid_1's binary_logloss: 0.141168\n",
            "[18]\ttraining's auc: 0.865713\ttraining's binary_logloss: 0.131455\tvalid_1's auc: 0.824891\tvalid_1's binary_logloss: 0.140777\n",
            "[19]\ttraining's auc: 0.867021\ttraining's binary_logloss: 0.130759\tvalid_1's auc: 0.825155\tvalid_1's binary_logloss: 0.140392\n",
            "[20]\ttraining's auc: 0.868357\ttraining's binary_logloss: 0.130119\tvalid_1's auc: 0.826039\tvalid_1's binary_logloss: 0.140005\n",
            "[21]\ttraining's auc: 0.869703\ttraining's binary_logloss: 0.129469\tvalid_1's auc: 0.826342\tvalid_1's binary_logloss: 0.139651\n",
            "[22]\ttraining's auc: 0.870556\ttraining's binary_logloss: 0.128872\tvalid_1's auc: 0.82664\tvalid_1's binary_logloss: 0.139341\n",
            "[23]\ttraining's auc: 0.871178\ttraining's binary_logloss: 0.128332\tvalid_1's auc: 0.826689\tvalid_1's binary_logloss: 0.139069\n",
            "[24]\ttraining's auc: 0.872399\ttraining's binary_logloss: 0.127754\tvalid_1's auc: 0.82756\tvalid_1's binary_logloss: 0.138731\n",
            "[25]\ttraining's auc: 0.873031\ttraining's binary_logloss: 0.127294\tvalid_1's auc: 0.827294\tvalid_1's binary_logloss: 0.138512\n",
            "[26]\ttraining's auc: 0.874133\ttraining's binary_logloss: 0.126768\tvalid_1's auc: 0.827331\tvalid_1's binary_logloss: 0.138285\n",
            "[27]\ttraining's auc: 0.875647\ttraining's binary_logloss: 0.126242\tvalid_1's auc: 0.827566\tvalid_1's binary_logloss: 0.138065\n",
            "[28]\ttraining's auc: 0.876653\ttraining's binary_logloss: 0.125797\tvalid_1's auc: 0.827545\tvalid_1's binary_logloss: 0.137912\n",
            "[29]\ttraining's auc: 0.877542\ttraining's binary_logloss: 0.125337\tvalid_1's auc: 0.827608\tvalid_1's binary_logloss: 0.137736\n",
            "[30]\ttraining's auc: 0.878456\ttraining's binary_logloss: 0.124893\tvalid_1's auc: 0.827752\tvalid_1's binary_logloss: 0.137562\n",
            "[31]\ttraining's auc: 0.879072\ttraining's binary_logloss: 0.124487\tvalid_1's auc: 0.828721\tvalid_1's binary_logloss: 0.137423\n",
            "[32]\ttraining's auc: 0.879967\ttraining's binary_logloss: 0.124087\tvalid_1's auc: 0.828833\tvalid_1's binary_logloss: 0.137276\n",
            "[33]\ttraining's auc: 0.881246\ttraining's binary_logloss: 0.123651\tvalid_1's auc: 0.828991\tvalid_1's binary_logloss: 0.137132\n",
            "[34]\ttraining's auc: 0.882045\ttraining's binary_logloss: 0.123284\tvalid_1's auc: 0.829119\tvalid_1's binary_logloss: 0.137014\n",
            "[35]\ttraining's auc: 0.883155\ttraining's binary_logloss: 0.122934\tvalid_1's auc: 0.82936\tvalid_1's binary_logloss: 0.136902\n",
            "[36]\ttraining's auc: 0.88421\ttraining's binary_logloss: 0.122566\tvalid_1's auc: 0.829226\tvalid_1's binary_logloss: 0.136817\n",
            "[37]\ttraining's auc: 0.884993\ttraining's binary_logloss: 0.122234\tvalid_1's auc: 0.829154\tvalid_1's binary_logloss: 0.136764\n",
            "[38]\ttraining's auc: 0.886001\ttraining's binary_logloss: 0.121873\tvalid_1's auc: 0.829073\tvalid_1's binary_logloss: 0.13674\n",
            "[39]\ttraining's auc: 0.887067\ttraining's binary_logloss: 0.121489\tvalid_1's auc: 0.829065\tvalid_1's binary_logloss: 0.136694\n",
            "[40]\ttraining's auc: 0.887862\ttraining's binary_logloss: 0.121163\tvalid_1's auc: 0.828981\tvalid_1's binary_logloss: 0.136627\n",
            "[41]\ttraining's auc: 0.888865\ttraining's binary_logloss: 0.120822\tvalid_1's auc: 0.829831\tvalid_1's binary_logloss: 0.136494\n",
            "[42]\ttraining's auc: 0.889533\ttraining's binary_logloss: 0.120507\tvalid_1's auc: 0.829716\tvalid_1's binary_logloss: 0.13647\n",
            "[43]\ttraining's auc: 0.890125\ttraining's binary_logloss: 0.120228\tvalid_1's auc: 0.829793\tvalid_1's binary_logloss: 0.136421\n",
            "[44]\ttraining's auc: 0.891346\ttraining's binary_logloss: 0.119905\tvalid_1's auc: 0.830054\tvalid_1's binary_logloss: 0.136322\n",
            "[45]\ttraining's auc: 0.891652\ttraining's binary_logloss: 0.119644\tvalid_1's auc: 0.829901\tvalid_1's binary_logloss: 0.136296\n",
            "[46]\ttraining's auc: 0.892183\ttraining's binary_logloss: 0.119395\tvalid_1's auc: 0.829677\tvalid_1's binary_logloss: 0.136296\n",
            "[47]\ttraining's auc: 0.893312\ttraining's binary_logloss: 0.119069\tvalid_1's auc: 0.83009\tvalid_1's binary_logloss: 0.136179\n",
            "[48]\ttraining's auc: 0.893884\ttraining's binary_logloss: 0.118824\tvalid_1's auc: 0.830123\tvalid_1's binary_logloss: 0.13614\n",
            "[49]\ttraining's auc: 0.8944\ttraining's binary_logloss: 0.118587\tvalid_1's auc: 0.830176\tvalid_1's binary_logloss: 0.136112\n",
            "[50]\ttraining's auc: 0.895044\ttraining's binary_logloss: 0.118342\tvalid_1's auc: 0.830423\tvalid_1's binary_logloss: 0.136063\n",
            "[51]\ttraining's auc: 0.895525\ttraining's binary_logloss: 0.118099\tvalid_1's auc: 0.830332\tvalid_1's binary_logloss: 0.136052\n",
            "[52]\ttraining's auc: 0.896196\ttraining's binary_logloss: 0.117838\tvalid_1's auc: 0.830275\tvalid_1's binary_logloss: 0.136043\n",
            "[53]\ttraining's auc: 0.896898\ttraining's binary_logloss: 0.117596\tvalid_1's auc: 0.830788\tvalid_1's binary_logloss: 0.135964\n",
            "[54]\ttraining's auc: 0.897612\ttraining's binary_logloss: 0.117345\tvalid_1's auc: 0.830744\tvalid_1's binary_logloss: 0.135943\n",
            "[55]\ttraining's auc: 0.898206\ttraining's binary_logloss: 0.117121\tvalid_1's auc: 0.830779\tvalid_1's binary_logloss: 0.135919\n",
            "[56]\ttraining's auc: 0.898738\ttraining's binary_logloss: 0.116851\tvalid_1's auc: 0.830663\tvalid_1's binary_logloss: 0.135934\n",
            "[57]\ttraining's auc: 0.899145\ttraining's binary_logloss: 0.116634\tvalid_1's auc: 0.830426\tvalid_1's binary_logloss: 0.135971\n",
            "[58]\ttraining's auc: 0.899965\ttraining's binary_logloss: 0.116402\tvalid_1's auc: 0.830297\tvalid_1's binary_logloss: 0.135974\n",
            "[59]\ttraining's auc: 0.900389\ttraining's binary_logloss: 0.116182\tvalid_1's auc: 0.83016\tvalid_1's binary_logloss: 0.135983\n",
            "[60]\ttraining's auc: 0.901747\ttraining's binary_logloss: 0.115907\tvalid_1's auc: 0.830702\tvalid_1's binary_logloss: 0.135903\n",
            "[61]\ttraining's auc: 0.902317\ttraining's binary_logloss: 0.115686\tvalid_1's auc: 0.830654\tvalid_1's binary_logloss: 0.135879\n",
            "[62]\ttraining's auc: 0.903018\ttraining's binary_logloss: 0.115479\tvalid_1's auc: 0.830817\tvalid_1's binary_logloss: 0.135843\n",
            "[63]\ttraining's auc: 0.90344\ttraining's binary_logloss: 0.11528\tvalid_1's auc: 0.83065\tvalid_1's binary_logloss: 0.135889\n",
            "[64]\ttraining's auc: 0.90373\ttraining's binary_logloss: 0.115101\tvalid_1's auc: 0.830581\tvalid_1's binary_logloss: 0.135898\n",
            "[65]\ttraining's auc: 0.904581\ttraining's binary_logloss: 0.114878\tvalid_1's auc: 0.830896\tvalid_1's binary_logloss: 0.13584\n",
            "[66]\ttraining's auc: 0.90501\ttraining's binary_logloss: 0.114666\tvalid_1's auc: 0.830793\tvalid_1's binary_logloss: 0.13585\n",
            "[67]\ttraining's auc: 0.905508\ttraining's binary_logloss: 0.114448\tvalid_1's auc: 0.830784\tvalid_1's binary_logloss: 0.135839\n",
            "[68]\ttraining's auc: 0.905993\ttraining's binary_logloss: 0.11424\tvalid_1's auc: 0.830727\tvalid_1's binary_logloss: 0.135867\n",
            "[69]\ttraining's auc: 0.906475\ttraining's binary_logloss: 0.114008\tvalid_1's auc: 0.830966\tvalid_1's binary_logloss: 0.135839\n",
            "[70]\ttraining's auc: 0.906813\ttraining's binary_logloss: 0.11382\tvalid_1's auc: 0.830826\tvalid_1's binary_logloss: 0.135862\n",
            "[71]\ttraining's auc: 0.907513\ttraining's binary_logloss: 0.11361\tvalid_1's auc: 0.830688\tvalid_1's binary_logloss: 0.135894\n",
            "[72]\ttraining's auc: 0.907795\ttraining's binary_logloss: 0.11344\tvalid_1's auc: 0.830818\tvalid_1's binary_logloss: 0.135878\n",
            "[73]\ttraining's auc: 0.90827\ttraining's binary_logloss: 0.113218\tvalid_1's auc: 0.830818\tvalid_1's binary_logloss: 0.135889\n",
            "[74]\ttraining's auc: 0.908935\ttraining's binary_logloss: 0.113008\tvalid_1's auc: 0.830569\tvalid_1's binary_logloss: 0.135922\n",
            "[75]\ttraining's auc: 0.909261\ttraining's binary_logloss: 0.112855\tvalid_1's auc: 0.830379\tvalid_1's binary_logloss: 0.135968\n",
            "[76]\ttraining's auc: 0.909699\ttraining's binary_logloss: 0.112692\tvalid_1's auc: 0.830505\tvalid_1's binary_logloss: 0.13595\n",
            "[77]\ttraining's auc: 0.910444\ttraining's binary_logloss: 0.112508\tvalid_1's auc: 0.830398\tvalid_1's binary_logloss: 0.135957\n",
            "[78]\ttraining's auc: 0.911209\ttraining's binary_logloss: 0.112268\tvalid_1's auc: 0.830364\tvalid_1's binary_logloss: 0.135983\n",
            "[79]\ttraining's auc: 0.911688\ttraining's binary_logloss: 0.112062\tvalid_1's auc: 0.830414\tvalid_1's binary_logloss: 0.135976\n",
            "[80]\ttraining's auc: 0.912022\ttraining's binary_logloss: 0.111903\tvalid_1's auc: 0.830167\tvalid_1's binary_logloss: 0.136015\n",
            "[81]\ttraining's auc: 0.912518\ttraining's binary_logloss: 0.111701\tvalid_1's auc: 0.830003\tvalid_1's binary_logloss: 0.136054\n",
            "[82]\ttraining's auc: 0.912771\ttraining's binary_logloss: 0.11156\tvalid_1's auc: 0.82995\tvalid_1's binary_logloss: 0.136049\n",
            "[83]\ttraining's auc: 0.913301\ttraining's binary_logloss: 0.111374\tvalid_1's auc: 0.829876\tvalid_1's binary_logloss: 0.136075\n",
            "[84]\ttraining's auc: 0.91364\ttraining's binary_logloss: 0.111211\tvalid_1's auc: 0.829756\tvalid_1's binary_logloss: 0.136089\n",
            "[85]\ttraining's auc: 0.914001\ttraining's binary_logloss: 0.111041\tvalid_1's auc: 0.829477\tvalid_1's binary_logloss: 0.13615\n",
            "[86]\ttraining's auc: 0.914323\ttraining's binary_logloss: 0.11089\tvalid_1's auc: 0.829365\tvalid_1's binary_logloss: 0.136189\n",
            "[87]\ttraining's auc: 0.914993\ttraining's binary_logloss: 0.110742\tvalid_1's auc: 0.829268\tvalid_1's binary_logloss: 0.136209\n",
            "[88]\ttraining's auc: 0.915252\ttraining's binary_logloss: 0.110591\tvalid_1's auc: 0.829114\tvalid_1's binary_logloss: 0.136244\n",
            "[89]\ttraining's auc: 0.915576\ttraining's binary_logloss: 0.110436\tvalid_1's auc: 0.828901\tvalid_1's binary_logloss: 0.136298\n",
            "[90]\ttraining's auc: 0.915922\ttraining's binary_logloss: 0.110261\tvalid_1's auc: 0.828686\tvalid_1's binary_logloss: 0.13634\n",
            "[91]\ttraining's auc: 0.916198\ttraining's binary_logloss: 0.11013\tvalid_1's auc: 0.828798\tvalid_1's binary_logloss: 0.136326\n",
            "[92]\ttraining's auc: 0.916485\ttraining's binary_logloss: 0.109985\tvalid_1's auc: 0.828712\tvalid_1's binary_logloss: 0.136336\n",
            "[93]\ttraining's auc: 0.917237\ttraining's binary_logloss: 0.109838\tvalid_1's auc: 0.828662\tvalid_1's binary_logloss: 0.136347\n",
            "[94]\ttraining's auc: 0.917509\ttraining's binary_logloss: 0.109704\tvalid_1's auc: 0.828539\tvalid_1's binary_logloss: 0.136387\n",
            "[95]\ttraining's auc: 0.917694\ttraining's binary_logloss: 0.109589\tvalid_1's auc: 0.828396\tvalid_1's binary_logloss: 0.13645\n",
            "[96]\ttraining's auc: 0.918471\ttraining's binary_logloss: 0.109423\tvalid_1's auc: 0.828457\tvalid_1's binary_logloss: 0.136458\n",
            "[97]\ttraining's auc: 0.918692\ttraining's binary_logloss: 0.109303\tvalid_1's auc: 0.82844\tvalid_1's binary_logloss: 0.136486\n",
            "[98]\ttraining's auc: 0.918952\ttraining's binary_logloss: 0.109144\tvalid_1's auc: 0.828308\tvalid_1's binary_logloss: 0.13653\n",
            "[99]\ttraining's auc: 0.919175\ttraining's binary_logloss: 0.109\tvalid_1's auc: 0.828262\tvalid_1's binary_logloss: 0.136537\n",
            " 96%|█████████▌| 48/50 [25:12<01:07, 33.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.161816\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156792\n",
            "[2]\ttraining's auc: 0.823429\ttraining's binary_logloss: 0.157964\tvalid_1's auc: 0.804276\tvalid_1's binary_logloss: 0.153714\n",
            "[3]\ttraining's auc: 0.831518\ttraining's binary_logloss: 0.154725\tvalid_1's auc: 0.815674\tvalid_1's binary_logloss: 0.151151\n",
            "[4]\ttraining's auc: 0.834981\ttraining's binary_logloss: 0.151982\tvalid_1's auc: 0.817722\tvalid_1's binary_logloss: 0.149138\n",
            "[5]\ttraining's auc: 0.837772\ttraining's binary_logloss: 0.149671\tvalid_1's auc: 0.819061\tvalid_1's binary_logloss: 0.14739\n",
            "[6]\ttraining's auc: 0.841542\ttraining's binary_logloss: 0.147685\tvalid_1's auc: 0.822294\tvalid_1's binary_logloss: 0.14589\n",
            "[7]\ttraining's auc: 0.844718\ttraining's binary_logloss: 0.145878\tvalid_1's auc: 0.824055\tvalid_1's binary_logloss: 0.144558\n",
            "[8]\ttraining's auc: 0.84882\ttraining's binary_logloss: 0.144258\tvalid_1's auc: 0.827617\tvalid_1's binary_logloss: 0.143357\n",
            "[9]\ttraining's auc: 0.851381\ttraining's binary_logloss: 0.142707\tvalid_1's auc: 0.828281\tvalid_1's binary_logloss: 0.14226\n",
            "[10]\ttraining's auc: 0.852035\ttraining's binary_logloss: 0.141398\tvalid_1's auc: 0.828903\tvalid_1's binary_logloss: 0.141297\n",
            "[11]\ttraining's auc: 0.854115\ttraining's binary_logloss: 0.140171\tvalid_1's auc: 0.829124\tvalid_1's binary_logloss: 0.140386\n",
            "[12]\ttraining's auc: 0.856211\ttraining's binary_logloss: 0.139056\tvalid_1's auc: 0.830713\tvalid_1's binary_logloss: 0.139542\n",
            "[13]\ttraining's auc: 0.857668\ttraining's binary_logloss: 0.138006\tvalid_1's auc: 0.832286\tvalid_1's binary_logloss: 0.138849\n",
            "[14]\ttraining's auc: 0.858778\ttraining's binary_logloss: 0.137023\tvalid_1's auc: 0.831809\tvalid_1's binary_logloss: 0.138218\n",
            "[15]\ttraining's auc: 0.859562\ttraining's binary_logloss: 0.136131\tvalid_1's auc: 0.831611\tvalid_1's binary_logloss: 0.137652\n",
            "[16]\ttraining's auc: 0.861466\ttraining's binary_logloss: 0.135295\tvalid_1's auc: 0.832452\tvalid_1's binary_logloss: 0.137148\n",
            "[17]\ttraining's auc: 0.862313\ttraining's binary_logloss: 0.134507\tvalid_1's auc: 0.832422\tvalid_1's binary_logloss: 0.136654\n",
            "[18]\ttraining's auc: 0.865235\ttraining's binary_logloss: 0.133705\tvalid_1's auc: 0.832984\tvalid_1's binary_logloss: 0.136229\n",
            "[19]\ttraining's auc: 0.867048\ttraining's binary_logloss: 0.132958\tvalid_1's auc: 0.832728\tvalid_1's binary_logloss: 0.135855\n",
            "[20]\ttraining's auc: 0.868555\ttraining's binary_logloss: 0.132278\tvalid_1's auc: 0.833122\tvalid_1's binary_logloss: 0.135466\n",
            "[21]\ttraining's auc: 0.870454\ttraining's binary_logloss: 0.131617\tvalid_1's auc: 0.83344\tvalid_1's binary_logloss: 0.135168\n",
            "[22]\ttraining's auc: 0.871595\ttraining's binary_logloss: 0.131024\tvalid_1's auc: 0.832967\tvalid_1's binary_logloss: 0.13484\n",
            "[23]\ttraining's auc: 0.872326\ttraining's binary_logloss: 0.130454\tvalid_1's auc: 0.833196\tvalid_1's binary_logloss: 0.13453\n",
            "[24]\ttraining's auc: 0.872859\ttraining's binary_logloss: 0.12991\tvalid_1's auc: 0.832945\tvalid_1's binary_logloss: 0.134311\n",
            "[25]\ttraining's auc: 0.873372\ttraining's binary_logloss: 0.129392\tvalid_1's auc: 0.833196\tvalid_1's binary_logloss: 0.134041\n",
            "[26]\ttraining's auc: 0.874143\ttraining's binary_logloss: 0.128889\tvalid_1's auc: 0.832734\tvalid_1's binary_logloss: 0.133868\n",
            "[27]\ttraining's auc: 0.874833\ttraining's binary_logloss: 0.1284\tvalid_1's auc: 0.832769\tvalid_1's binary_logloss: 0.133656\n",
            "[28]\ttraining's auc: 0.875305\ttraining's binary_logloss: 0.127943\tvalid_1's auc: 0.833023\tvalid_1's binary_logloss: 0.133445\n",
            "[29]\ttraining's auc: 0.875853\ttraining's binary_logloss: 0.127507\tvalid_1's auc: 0.833189\tvalid_1's binary_logloss: 0.133262\n",
            "[30]\ttraining's auc: 0.876711\ttraining's binary_logloss: 0.127074\tvalid_1's auc: 0.83328\tvalid_1's binary_logloss: 0.133083\n",
            "[31]\ttraining's auc: 0.877523\ttraining's binary_logloss: 0.126662\tvalid_1's auc: 0.83306\tvalid_1's binary_logloss: 0.132926\n",
            "[32]\ttraining's auc: 0.87851\ttraining's binary_logloss: 0.126244\tvalid_1's auc: 0.833209\tvalid_1's binary_logloss: 0.132771\n",
            "[33]\ttraining's auc: 0.878879\ttraining's binary_logloss: 0.125851\tvalid_1's auc: 0.83326\tvalid_1's binary_logloss: 0.132645\n",
            "[34]\ttraining's auc: 0.879268\ttraining's binary_logloss: 0.125496\tvalid_1's auc: 0.833243\tvalid_1's binary_logloss: 0.132546\n",
            "[35]\ttraining's auc: 0.880047\ttraining's binary_logloss: 0.12511\tvalid_1's auc: 0.832948\tvalid_1's binary_logloss: 0.132463\n",
            "[36]\ttraining's auc: 0.881462\ttraining's binary_logloss: 0.124724\tvalid_1's auc: 0.832926\tvalid_1's binary_logloss: 0.13238\n",
            "[37]\ttraining's auc: 0.882359\ttraining's binary_logloss: 0.124365\tvalid_1's auc: 0.832848\tvalid_1's binary_logloss: 0.132296\n",
            "[38]\ttraining's auc: 0.883143\ttraining's binary_logloss: 0.124057\tvalid_1's auc: 0.83269\tvalid_1's binary_logloss: 0.132225\n",
            "[39]\ttraining's auc: 0.88385\ttraining's binary_logloss: 0.123739\tvalid_1's auc: 0.832661\tvalid_1's binary_logloss: 0.132157\n",
            "[40]\ttraining's auc: 0.884699\ttraining's binary_logloss: 0.123411\tvalid_1's auc: 0.832886\tvalid_1's binary_logloss: 0.132094\n",
            "[41]\ttraining's auc: 0.885512\ttraining's binary_logloss: 0.123115\tvalid_1's auc: 0.833077\tvalid_1's binary_logloss: 0.13204\n",
            "[42]\ttraining's auc: 0.886006\ttraining's binary_logloss: 0.122813\tvalid_1's auc: 0.832853\tvalid_1's binary_logloss: 0.131987\n",
            "[43]\ttraining's auc: 0.886634\ttraining's binary_logloss: 0.122499\tvalid_1's auc: 0.832773\tvalid_1's binary_logloss: 0.131952\n",
            "[44]\ttraining's auc: 0.887345\ttraining's binary_logloss: 0.122186\tvalid_1's auc: 0.832925\tvalid_1's binary_logloss: 0.131858\n",
            "[45]\ttraining's auc: 0.888559\ttraining's binary_logloss: 0.121859\tvalid_1's auc: 0.833207\tvalid_1's binary_logloss: 0.131787\n",
            "[46]\ttraining's auc: 0.889571\ttraining's binary_logloss: 0.121547\tvalid_1's auc: 0.833126\tvalid_1's binary_logloss: 0.131736\n",
            "[47]\ttraining's auc: 0.890968\ttraining's binary_logloss: 0.121222\tvalid_1's auc: 0.83296\tvalid_1's binary_logloss: 0.131703\n",
            "[48]\ttraining's auc: 0.891436\ttraining's binary_logloss: 0.120948\tvalid_1's auc: 0.833022\tvalid_1's binary_logloss: 0.131653\n",
            "[49]\ttraining's auc: 0.891944\ttraining's binary_logloss: 0.120721\tvalid_1's auc: 0.832756\tvalid_1's binary_logloss: 0.131658\n",
            "[50]\ttraining's auc: 0.892315\ttraining's binary_logloss: 0.120499\tvalid_1's auc: 0.832718\tvalid_1's binary_logloss: 0.131621\n",
            "[51]\ttraining's auc: 0.893175\ttraining's binary_logloss: 0.120235\tvalid_1's auc: 0.833266\tvalid_1's binary_logloss: 0.131552\n",
            " 96%|█████████▌| 48/50 [25:22<01:07, 33.68s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.15827\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.164147\n",
            "[2]\ttraining's auc: 0.831485\ttraining's binary_logloss: 0.154501\tvalid_1's auc: 0.81448\tvalid_1's binary_logloss: 0.160758\n",
            "[3]\ttraining's auc: 0.834311\ttraining's binary_logloss: 0.151469\tvalid_1's auc: 0.815799\tvalid_1's binary_logloss: 0.158134\n",
            "[4]\ttraining's auc: 0.838287\ttraining's binary_logloss: 0.148857\tvalid_1's auc: 0.81812\tvalid_1's binary_logloss: 0.155872\n",
            "[5]\ttraining's auc: 0.839928\ttraining's binary_logloss: 0.146663\tvalid_1's auc: 0.818787\tvalid_1's binary_logloss: 0.153956\n",
            "[6]\ttraining's auc: 0.846347\ttraining's binary_logloss: 0.144527\tvalid_1's auc: 0.822991\tvalid_1's binary_logloss: 0.152327\n",
            "[7]\ttraining's auc: 0.849006\ttraining's binary_logloss: 0.142761\tvalid_1's auc: 0.824528\tvalid_1's binary_logloss: 0.150856\n",
            "[8]\ttraining's auc: 0.850149\ttraining's binary_logloss: 0.141172\tvalid_1's auc: 0.825427\tvalid_1's binary_logloss: 0.149584\n",
            "[9]\ttraining's auc: 0.851852\ttraining's binary_logloss: 0.139686\tvalid_1's auc: 0.826538\tvalid_1's binary_logloss: 0.148366\n",
            "[10]\ttraining's auc: 0.852673\ttraining's binary_logloss: 0.138374\tvalid_1's auc: 0.826841\tvalid_1's binary_logloss: 0.147323\n",
            "[11]\ttraining's auc: 0.853605\ttraining's binary_logloss: 0.137193\tvalid_1's auc: 0.827531\tvalid_1's binary_logloss: 0.146389\n",
            "[12]\ttraining's auc: 0.855416\ttraining's binary_logloss: 0.136069\tvalid_1's auc: 0.828361\tvalid_1's binary_logloss: 0.145563\n",
            "[13]\ttraining's auc: 0.85682\ttraining's binary_logloss: 0.135082\tvalid_1's auc: 0.829347\tvalid_1's binary_logloss: 0.144789\n",
            "[14]\ttraining's auc: 0.857998\ttraining's binary_logloss: 0.134156\tvalid_1's auc: 0.829421\tvalid_1's binary_logloss: 0.144086\n",
            "[15]\ttraining's auc: 0.858452\ttraining's binary_logloss: 0.133267\tvalid_1's auc: 0.829841\tvalid_1's binary_logloss: 0.143434\n",
            "[16]\ttraining's auc: 0.860347\ttraining's binary_logloss: 0.132439\tvalid_1's auc: 0.830421\tvalid_1's binary_logloss: 0.142823\n",
            "[17]\ttraining's auc: 0.862314\ttraining's binary_logloss: 0.131653\tvalid_1's auc: 0.83049\tvalid_1's binary_logloss: 0.142289\n",
            "[18]\ttraining's auc: 0.863464\ttraining's binary_logloss: 0.130956\tvalid_1's auc: 0.830828\tvalid_1's binary_logloss: 0.141794\n",
            "[19]\ttraining's auc: 0.864195\ttraining's binary_logloss: 0.130265\tvalid_1's auc: 0.830931\tvalid_1's binary_logloss: 0.141389\n",
            "[20]\ttraining's auc: 0.867064\ttraining's binary_logloss: 0.129581\tvalid_1's auc: 0.831749\tvalid_1's binary_logloss: 0.140967\n",
            "[21]\ttraining's auc: 0.868009\ttraining's binary_logloss: 0.128982\tvalid_1's auc: 0.83188\tvalid_1's binary_logloss: 0.140644\n",
            "[22]\ttraining's auc: 0.869393\ttraining's binary_logloss: 0.128365\tvalid_1's auc: 0.831775\tvalid_1's binary_logloss: 0.140332\n",
            "[23]\ttraining's auc: 0.87094\ttraining's binary_logloss: 0.127796\tvalid_1's auc: 0.833486\tvalid_1's binary_logloss: 0.140037\n",
            "[24]\ttraining's auc: 0.872481\ttraining's binary_logloss: 0.127238\tvalid_1's auc: 0.833856\tvalid_1's binary_logloss: 0.13975\n",
            "[25]\ttraining's auc: 0.873969\ttraining's binary_logloss: 0.126739\tvalid_1's auc: 0.834443\tvalid_1's binary_logloss: 0.139456\n",
            "[26]\ttraining's auc: 0.875246\ttraining's binary_logloss: 0.126222\tvalid_1's auc: 0.834624\tvalid_1's binary_logloss: 0.13925\n",
            "[27]\ttraining's auc: 0.875717\ttraining's binary_logloss: 0.125792\tvalid_1's auc: 0.835162\tvalid_1's binary_logloss: 0.138988\n",
            "[28]\ttraining's auc: 0.876388\ttraining's binary_logloss: 0.125341\tvalid_1's auc: 0.83489\tvalid_1's binary_logloss: 0.138776\n",
            "[29]\ttraining's auc: 0.877819\ttraining's binary_logloss: 0.124862\tvalid_1's auc: 0.834788\tvalid_1's binary_logloss: 0.138613\n",
            "[30]\ttraining's auc: 0.879417\ttraining's binary_logloss: 0.124373\tvalid_1's auc: 0.835011\tvalid_1's binary_logloss: 0.138415\n",
            "[31]\ttraining's auc: 0.88017\ttraining's binary_logloss: 0.123973\tvalid_1's auc: 0.835476\tvalid_1's binary_logloss: 0.138225\n",
            "[32]\ttraining's auc: 0.881969\ttraining's binary_logloss: 0.123505\tvalid_1's auc: 0.835736\tvalid_1's binary_logloss: 0.138061\n",
            "[33]\ttraining's auc: 0.882742\ttraining's binary_logloss: 0.1231\tvalid_1's auc: 0.835709\tvalid_1's binary_logloss: 0.137919\n",
            "[34]\ttraining's auc: 0.883627\ttraining's binary_logloss: 0.122705\tvalid_1's auc: 0.835711\tvalid_1's binary_logloss: 0.137795\n",
            "[35]\ttraining's auc: 0.884146\ttraining's binary_logloss: 0.122361\tvalid_1's auc: 0.835867\tvalid_1's binary_logloss: 0.137685\n",
            "[36]\ttraining's auc: 0.885181\ttraining's binary_logloss: 0.121991\tvalid_1's auc: 0.835716\tvalid_1's binary_logloss: 0.137588\n",
            "[37]\ttraining's auc: 0.885907\ttraining's binary_logloss: 0.121662\tvalid_1's auc: 0.836063\tvalid_1's binary_logloss: 0.137455\n",
            "[38]\ttraining's auc: 0.886684\ttraining's binary_logloss: 0.121348\tvalid_1's auc: 0.836179\tvalid_1's binary_logloss: 0.137352\n",
            "[39]\ttraining's auc: 0.887433\ttraining's binary_logloss: 0.121038\tvalid_1's auc: 0.836492\tvalid_1's binary_logloss: 0.137218\n",
            "[40]\ttraining's auc: 0.888293\ttraining's binary_logloss: 0.120716\tvalid_1's auc: 0.836367\tvalid_1's binary_logloss: 0.137118\n",
            "[41]\ttraining's auc: 0.889102\ttraining's binary_logloss: 0.12039\tvalid_1's auc: 0.836276\tvalid_1's binary_logloss: 0.137071\n",
            "[42]\ttraining's auc: 0.889862\ttraining's binary_logloss: 0.120093\tvalid_1's auc: 0.83605\tvalid_1's binary_logloss: 0.137016\n",
            "[43]\ttraining's auc: 0.890675\ttraining's binary_logloss: 0.119752\tvalid_1's auc: 0.836347\tvalid_1's binary_logloss: 0.136936\n",
            "[44]\ttraining's auc: 0.891421\ttraining's binary_logloss: 0.119472\tvalid_1's auc: 0.836534\tvalid_1's binary_logloss: 0.136862\n",
            "[45]\ttraining's auc: 0.891981\ttraining's binary_logloss: 0.119218\tvalid_1's auc: 0.836311\tvalid_1's binary_logloss: 0.136844\n",
            "[46]\ttraining's auc: 0.892522\ttraining's binary_logloss: 0.118972\tvalid_1's auc: 0.836462\tvalid_1's binary_logloss: 0.136781\n",
            "[47]\ttraining's auc: 0.893253\ttraining's binary_logloss: 0.118676\tvalid_1's auc: 0.836402\tvalid_1's binary_logloss: 0.136753\n",
            "[48]\ttraining's auc: 0.894343\ttraining's binary_logloss: 0.118346\tvalid_1's auc: 0.836222\tvalid_1's binary_logloss: 0.136751\n",
            "[49]\ttraining's auc: 0.895202\ttraining's binary_logloss: 0.118073\tvalid_1's auc: 0.836153\tvalid_1's binary_logloss: 0.136713\n",
            "[50]\ttraining's auc: 0.895685\ttraining's binary_logloss: 0.117836\tvalid_1's auc: 0.836566\tvalid_1's binary_logloss: 0.136656\n",
            "[51]\ttraining's auc: 0.896248\ttraining's binary_logloss: 0.11758\tvalid_1's auc: 0.83665\tvalid_1's binary_logloss: 0.136597\n",
            "[52]\ttraining's auc: 0.896917\ttraining's binary_logloss: 0.117336\tvalid_1's auc: 0.836474\tvalid_1's binary_logloss: 0.136559\n",
            "[53]\ttraining's auc: 0.897556\ttraining's binary_logloss: 0.117089\tvalid_1's auc: 0.83618\tvalid_1's binary_logloss: 0.13658\n",
            "[54]\ttraining's auc: 0.897996\ttraining's binary_logloss: 0.11687\tvalid_1's auc: 0.835988\tvalid_1's binary_logloss: 0.136593\n",
            "[55]\ttraining's auc: 0.898672\ttraining's binary_logloss: 0.116641\tvalid_1's auc: 0.836092\tvalid_1's binary_logloss: 0.136559\n",
            "[56]\ttraining's auc: 0.899265\ttraining's binary_logloss: 0.116439\tvalid_1's auc: 0.835941\tvalid_1's binary_logloss: 0.136544\n",
            "[57]\ttraining's auc: 0.900111\ttraining's binary_logloss: 0.116161\tvalid_1's auc: 0.835753\tvalid_1's binary_logloss: 0.136555\n",
            "[58]\ttraining's auc: 0.900837\ttraining's binary_logloss: 0.115937\tvalid_1's auc: 0.83565\tvalid_1's binary_logloss: 0.136553\n",
            "[59]\ttraining's auc: 0.901088\ttraining's binary_logloss: 0.115766\tvalid_1's auc: 0.835703\tvalid_1's binary_logloss: 0.136536\n",
            "[60]\ttraining's auc: 0.901805\ttraining's binary_logloss: 0.11553\tvalid_1's auc: 0.835395\tvalid_1's binary_logloss: 0.136521\n",
            "[61]\ttraining's auc: 0.902232\ttraining's binary_logloss: 0.115336\tvalid_1's auc: 0.835471\tvalid_1's binary_logloss: 0.136491\n",
            "[62]\ttraining's auc: 0.902481\ttraining's binary_logloss: 0.115132\tvalid_1's auc: 0.835553\tvalid_1's binary_logloss: 0.136478\n",
            "[63]\ttraining's auc: 0.903012\ttraining's binary_logloss: 0.114955\tvalid_1's auc: 0.835421\tvalid_1's binary_logloss: 0.136468\n",
            "[64]\ttraining's auc: 0.903949\ttraining's binary_logloss: 0.114656\tvalid_1's auc: 0.83582\tvalid_1's binary_logloss: 0.136402\n",
            "[65]\ttraining's auc: 0.90448\ttraining's binary_logloss: 0.114484\tvalid_1's auc: 0.835856\tvalid_1's binary_logloss: 0.136403\n",
            "[66]\ttraining's auc: 0.905322\ttraining's binary_logloss: 0.114218\tvalid_1's auc: 0.835775\tvalid_1's binary_logloss: 0.136405\n",
            "[67]\ttraining's auc: 0.905931\ttraining's binary_logloss: 0.113966\tvalid_1's auc: 0.835975\tvalid_1's binary_logloss: 0.136383\n",
            "[68]\ttraining's auc: 0.906358\ttraining's binary_logloss: 0.113813\tvalid_1's auc: 0.835984\tvalid_1's binary_logloss: 0.136383\n",
            "[69]\ttraining's auc: 0.906798\ttraining's binary_logloss: 0.11358\tvalid_1's auc: 0.835917\tvalid_1's binary_logloss: 0.136383\n",
            "[70]\ttraining's auc: 0.907215\ttraining's binary_logloss: 0.113386\tvalid_1's auc: 0.835827\tvalid_1's binary_logloss: 0.136423\n",
            "[71]\ttraining's auc: 0.90747\ttraining's binary_logloss: 0.113248\tvalid_1's auc: 0.835915\tvalid_1's binary_logloss: 0.136405\n",
            "[72]\ttraining's auc: 0.907982\ttraining's binary_logloss: 0.113007\tvalid_1's auc: 0.835833\tvalid_1's binary_logloss: 0.136431\n",
            "[73]\ttraining's auc: 0.908399\ttraining's binary_logloss: 0.112792\tvalid_1's auc: 0.836077\tvalid_1's binary_logloss: 0.13642\n",
            "[74]\ttraining's auc: 0.908763\ttraining's binary_logloss: 0.112603\tvalid_1's auc: 0.835996\tvalid_1's binary_logloss: 0.136449\n",
            "[75]\ttraining's auc: 0.909223\ttraining's binary_logloss: 0.112411\tvalid_1's auc: 0.835957\tvalid_1's binary_logloss: 0.136468\n",
            "[76]\ttraining's auc: 0.909821\ttraining's binary_logloss: 0.112237\tvalid_1's auc: 0.83601\tvalid_1's binary_logloss: 0.136458\n",
            "[77]\ttraining's auc: 0.910473\ttraining's binary_logloss: 0.112018\tvalid_1's auc: 0.835911\tvalid_1's binary_logloss: 0.136476\n",
            "[78]\ttraining's auc: 0.910738\ttraining's binary_logloss: 0.111845\tvalid_1's auc: 0.836033\tvalid_1's binary_logloss: 0.136476\n",
            "[79]\ttraining's auc: 0.911141\ttraining's binary_logloss: 0.111702\tvalid_1's auc: 0.836167\tvalid_1's binary_logloss: 0.136462\n",
            "[80]\ttraining's auc: 0.911491\ttraining's binary_logloss: 0.11152\tvalid_1's auc: 0.836176\tvalid_1's binary_logloss: 0.136453\n",
            "[81]\ttraining's auc: 0.911943\ttraining's binary_logloss: 0.111352\tvalid_1's auc: 0.836162\tvalid_1's binary_logloss: 0.136447\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 98%|█████████▊| 49/50 [25:36<00:36, 36.16s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.82489\ttraining's binary_logloss: 0.158489\tvalid_1's auc: 0.803742\tvalid_1's binary_logloss: 0.160391\n",
            "[2]\ttraining's auc: 0.832843\ttraining's binary_logloss: 0.154119\tvalid_1's auc: 0.806024\tvalid_1's binary_logloss: 0.156954\n",
            "[3]\ttraining's auc: 0.83452\ttraining's binary_logloss: 0.150699\tvalid_1's auc: 0.806743\tvalid_1's binary_logloss: 0.154395\n",
            "[4]\ttraining's auc: 0.842181\ttraining's binary_logloss: 0.147877\tvalid_1's auc: 0.813879\tvalid_1's binary_logloss: 0.152165\n",
            "[5]\ttraining's auc: 0.846269\ttraining's binary_logloss: 0.145448\tvalid_1's auc: 0.815737\tvalid_1's binary_logloss: 0.150387\n",
            "[6]\ttraining's auc: 0.848138\ttraining's binary_logloss: 0.143376\tvalid_1's auc: 0.81484\tvalid_1's binary_logloss: 0.148894\n",
            "[7]\ttraining's auc: 0.850609\ttraining's binary_logloss: 0.141467\tvalid_1's auc: 0.81748\tvalid_1's binary_logloss: 0.147485\n",
            "[8]\ttraining's auc: 0.85244\ttraining's binary_logloss: 0.139802\tvalid_1's auc: 0.819033\tvalid_1's binary_logloss: 0.146269\n",
            "[9]\ttraining's auc: 0.853268\ttraining's binary_logloss: 0.138341\tvalid_1's auc: 0.81972\tvalid_1's binary_logloss: 0.145245\n",
            "[10]\ttraining's auc: 0.854423\ttraining's binary_logloss: 0.13698\tvalid_1's auc: 0.82041\tvalid_1's binary_logloss: 0.144305\n",
            "[11]\ttraining's auc: 0.855361\ttraining's binary_logloss: 0.135731\tvalid_1's auc: 0.820807\tvalid_1's binary_logloss: 0.143502\n",
            "[12]\ttraining's auc: 0.857518\ttraining's binary_logloss: 0.134623\tvalid_1's auc: 0.82151\tvalid_1's binary_logloss: 0.142741\n",
            "[13]\ttraining's auc: 0.858314\ttraining's binary_logloss: 0.133653\tvalid_1's auc: 0.821789\tvalid_1's binary_logloss: 0.142022\n",
            "[14]\ttraining's auc: 0.860933\ttraining's binary_logloss: 0.132593\tvalid_1's auc: 0.821868\tvalid_1's binary_logloss: 0.141466\n",
            "[15]\ttraining's auc: 0.863036\ttraining's binary_logloss: 0.131673\tvalid_1's auc: 0.823467\tvalid_1's binary_logloss: 0.140953\n",
            "[16]\ttraining's auc: 0.864579\ttraining's binary_logloss: 0.130781\tvalid_1's auc: 0.823904\tvalid_1's binary_logloss: 0.140449\n",
            "[17]\ttraining's auc: 0.867207\ttraining's binary_logloss: 0.129993\tvalid_1's auc: 0.825126\tvalid_1's binary_logloss: 0.140001\n",
            "[18]\ttraining's auc: 0.869326\ttraining's binary_logloss: 0.129241\tvalid_1's auc: 0.825611\tvalid_1's binary_logloss: 0.139691\n",
            "[19]\ttraining's auc: 0.870185\ttraining's binary_logloss: 0.128603\tvalid_1's auc: 0.825908\tvalid_1's binary_logloss: 0.139378\n",
            "[20]\ttraining's auc: 0.871813\ttraining's binary_logloss: 0.127939\tvalid_1's auc: 0.826181\tvalid_1's binary_logloss: 0.139061\n",
            "[21]\ttraining's auc: 0.872634\ttraining's binary_logloss: 0.127299\tvalid_1's auc: 0.826503\tvalid_1's binary_logloss: 0.138765\n",
            "[22]\ttraining's auc: 0.873267\ttraining's binary_logloss: 0.126766\tvalid_1's auc: 0.826252\tvalid_1's binary_logloss: 0.138541\n",
            "[23]\ttraining's auc: 0.874313\ttraining's binary_logloss: 0.126196\tvalid_1's auc: 0.826083\tvalid_1's binary_logloss: 0.138342\n",
            "[24]\ttraining's auc: 0.875383\ttraining's binary_logloss: 0.125665\tvalid_1's auc: 0.82612\tvalid_1's binary_logloss: 0.138161\n",
            "[25]\ttraining's auc: 0.876214\ttraining's binary_logloss: 0.125193\tvalid_1's auc: 0.826779\tvalid_1's binary_logloss: 0.137921\n",
            "[26]\ttraining's auc: 0.877785\ttraining's binary_logloss: 0.124712\tvalid_1's auc: 0.827657\tvalid_1's binary_logloss: 0.137728\n",
            "[27]\ttraining's auc: 0.878619\ttraining's binary_logloss: 0.124274\tvalid_1's auc: 0.828258\tvalid_1's binary_logloss: 0.137495\n",
            "[28]\ttraining's auc: 0.87957\ttraining's binary_logloss: 0.123814\tvalid_1's auc: 0.828548\tvalid_1's binary_logloss: 0.137363\n",
            "[29]\ttraining's auc: 0.882515\ttraining's binary_logloss: 0.123246\tvalid_1's auc: 0.828738\tvalid_1's binary_logloss: 0.137223\n",
            "[30]\ttraining's auc: 0.883334\ttraining's binary_logloss: 0.122843\tvalid_1's auc: 0.829259\tvalid_1's binary_logloss: 0.137017\n",
            "[31]\ttraining's auc: 0.884684\ttraining's binary_logloss: 0.122416\tvalid_1's auc: 0.829237\tvalid_1's binary_logloss: 0.136892\n",
            "[32]\ttraining's auc: 0.88558\ttraining's binary_logloss: 0.122028\tvalid_1's auc: 0.829278\tvalid_1's binary_logloss: 0.136822\n",
            "[33]\ttraining's auc: 0.886339\ttraining's binary_logloss: 0.121657\tvalid_1's auc: 0.828962\tvalid_1's binary_logloss: 0.136758\n",
            "[34]\ttraining's auc: 0.887243\ttraining's binary_logloss: 0.121287\tvalid_1's auc: 0.828855\tvalid_1's binary_logloss: 0.136692\n",
            "[35]\ttraining's auc: 0.887584\ttraining's binary_logloss: 0.120959\tvalid_1's auc: 0.828973\tvalid_1's binary_logloss: 0.136597\n",
            "[36]\ttraining's auc: 0.889035\ttraining's binary_logloss: 0.120607\tvalid_1's auc: 0.828723\tvalid_1's binary_logloss: 0.136574\n",
            "[37]\ttraining's auc: 0.890558\ttraining's binary_logloss: 0.120199\tvalid_1's auc: 0.829177\tvalid_1's binary_logloss: 0.136457\n",
            "[38]\ttraining's auc: 0.891755\ttraining's binary_logloss: 0.11979\tvalid_1's auc: 0.829021\tvalid_1's binary_logloss: 0.136454\n",
            "[39]\ttraining's auc: 0.892329\ttraining's binary_logloss: 0.11947\tvalid_1's auc: 0.829264\tvalid_1's binary_logloss: 0.136405\n",
            "[40]\ttraining's auc: 0.89302\ttraining's binary_logloss: 0.119157\tvalid_1's auc: 0.829465\tvalid_1's binary_logloss: 0.136341\n",
            "[41]\ttraining's auc: 0.893807\ttraining's binary_logloss: 0.118856\tvalid_1's auc: 0.829419\tvalid_1's binary_logloss: 0.136347\n",
            "[42]\ttraining's auc: 0.894544\ttraining's binary_logloss: 0.118516\tvalid_1's auc: 0.829186\tvalid_1's binary_logloss: 0.136346\n",
            "[43]\ttraining's auc: 0.895915\ttraining's binary_logloss: 0.118152\tvalid_1's auc: 0.829792\tvalid_1's binary_logloss: 0.136211\n",
            "[44]\ttraining's auc: 0.896851\ttraining's binary_logloss: 0.117848\tvalid_1's auc: 0.829564\tvalid_1's binary_logloss: 0.136209\n",
            "[45]\ttraining's auc: 0.897674\ttraining's binary_logloss: 0.11756\tvalid_1's auc: 0.829922\tvalid_1's binary_logloss: 0.13611\n",
            "[46]\ttraining's auc: 0.898198\ttraining's binary_logloss: 0.117283\tvalid_1's auc: 0.829869\tvalid_1's binary_logloss: 0.136088\n",
            "[47]\ttraining's auc: 0.898769\ttraining's binary_logloss: 0.117011\tvalid_1's auc: 0.829915\tvalid_1's binary_logloss: 0.13605\n",
            "[48]\ttraining's auc: 0.899394\ttraining's binary_logloss: 0.116698\tvalid_1's auc: 0.829795\tvalid_1's binary_logloss: 0.136063\n",
            "[49]\ttraining's auc: 0.899978\ttraining's binary_logloss: 0.116439\tvalid_1's auc: 0.829818\tvalid_1's binary_logloss: 0.136063\n",
            "[50]\ttraining's auc: 0.901089\ttraining's binary_logloss: 0.116147\tvalid_1's auc: 0.83035\tvalid_1's binary_logloss: 0.135969\n",
            "[51]\ttraining's auc: 0.901986\ttraining's binary_logloss: 0.115895\tvalid_1's auc: 0.830576\tvalid_1's binary_logloss: 0.135917\n",
            "[52]\ttraining's auc: 0.902557\ttraining's binary_logloss: 0.115662\tvalid_1's auc: 0.830484\tvalid_1's binary_logloss: 0.135931\n",
            "[53]\ttraining's auc: 0.903084\ttraining's binary_logloss: 0.115418\tvalid_1's auc: 0.830387\tvalid_1's binary_logloss: 0.135946\n",
            "[54]\ttraining's auc: 0.90388\ttraining's binary_logloss: 0.115185\tvalid_1's auc: 0.830605\tvalid_1's binary_logloss: 0.135924\n",
            "[55]\ttraining's auc: 0.905037\ttraining's binary_logloss: 0.114853\tvalid_1's auc: 0.830561\tvalid_1's binary_logloss: 0.135937\n",
            "[56]\ttraining's auc: 0.905317\ttraining's binary_logloss: 0.114637\tvalid_1's auc: 0.830545\tvalid_1's binary_logloss: 0.135991\n",
            "[57]\ttraining's auc: 0.90583\ttraining's binary_logloss: 0.114421\tvalid_1's auc: 0.830482\tvalid_1's binary_logloss: 0.136\n",
            "[58]\ttraining's auc: 0.906415\ttraining's binary_logloss: 0.114151\tvalid_1's auc: 0.830341\tvalid_1's binary_logloss: 0.136014\n",
            "[59]\ttraining's auc: 0.907194\ttraining's binary_logloss: 0.113918\tvalid_1's auc: 0.830325\tvalid_1's binary_logloss: 0.136035\n",
            "[60]\ttraining's auc: 0.907596\ttraining's binary_logloss: 0.113705\tvalid_1's auc: 0.829965\tvalid_1's binary_logloss: 0.136087\n",
            "[61]\ttraining's auc: 0.907771\ttraining's binary_logloss: 0.113507\tvalid_1's auc: 0.829932\tvalid_1's binary_logloss: 0.136083\n",
            "[62]\ttraining's auc: 0.908728\ttraining's binary_logloss: 0.113259\tvalid_1's auc: 0.829639\tvalid_1's binary_logloss: 0.136138\n",
            "[63]\ttraining's auc: 0.909177\ttraining's binary_logloss: 0.113044\tvalid_1's auc: 0.829492\tvalid_1's binary_logloss: 0.136166\n",
            "[64]\ttraining's auc: 0.909606\ttraining's binary_logloss: 0.112836\tvalid_1's auc: 0.829666\tvalid_1's binary_logloss: 0.136125\n",
            "[65]\ttraining's auc: 0.910057\ttraining's binary_logloss: 0.112623\tvalid_1's auc: 0.829426\tvalid_1's binary_logloss: 0.136162\n",
            "[66]\ttraining's auc: 0.910572\ttraining's binary_logloss: 0.112413\tvalid_1's auc: 0.829364\tvalid_1's binary_logloss: 0.136179\n",
            "[67]\ttraining's auc: 0.910828\ttraining's binary_logloss: 0.112229\tvalid_1's auc: 0.829215\tvalid_1's binary_logloss: 0.136201\n",
            "[68]\ttraining's auc: 0.911219\ttraining's binary_logloss: 0.112031\tvalid_1's auc: 0.829094\tvalid_1's binary_logloss: 0.136208\n",
            "[69]\ttraining's auc: 0.911812\ttraining's binary_logloss: 0.11185\tvalid_1's auc: 0.829086\tvalid_1's binary_logloss: 0.136202\n",
            "[70]\ttraining's auc: 0.912046\ttraining's binary_logloss: 0.111708\tvalid_1's auc: 0.828852\tvalid_1's binary_logloss: 0.136238\n",
            "[71]\ttraining's auc: 0.912312\ttraining's binary_logloss: 0.11156\tvalid_1's auc: 0.828799\tvalid_1's binary_logloss: 0.136255\n",
            "[72]\ttraining's auc: 0.912758\ttraining's binary_logloss: 0.111376\tvalid_1's auc: 0.82862\tvalid_1's binary_logloss: 0.1363\n",
            "[73]\ttraining's auc: 0.914436\ttraining's binary_logloss: 0.111062\tvalid_1's auc: 0.828456\tvalid_1's binary_logloss: 0.136339\n",
            "[74]\ttraining's auc: 0.914856\ttraining's binary_logloss: 0.110879\tvalid_1's auc: 0.828419\tvalid_1's binary_logloss: 0.136351\n",
            "[75]\ttraining's auc: 0.915035\ttraining's binary_logloss: 0.110735\tvalid_1's auc: 0.828497\tvalid_1's binary_logloss: 0.13635\n",
            "[76]\ttraining's auc: 0.915356\ttraining's binary_logloss: 0.110564\tvalid_1's auc: 0.828305\tvalid_1's binary_logloss: 0.136408\n",
            "[77]\ttraining's auc: 0.916326\ttraining's binary_logloss: 0.110342\tvalid_1's auc: 0.828324\tvalid_1's binary_logloss: 0.136419\n",
            "[78]\ttraining's auc: 0.917077\ttraining's binary_logloss: 0.110165\tvalid_1's auc: 0.828223\tvalid_1's binary_logloss: 0.136436\n",
            "[79]\ttraining's auc: 0.917673\ttraining's binary_logloss: 0.109945\tvalid_1's auc: 0.828175\tvalid_1's binary_logloss: 0.13643\n",
            "[80]\ttraining's auc: 0.918036\ttraining's binary_logloss: 0.109766\tvalid_1's auc: 0.828237\tvalid_1's binary_logloss: 0.136431\n",
            "[81]\ttraining's auc: 0.918358\ttraining's binary_logloss: 0.109611\tvalid_1's auc: 0.82813\tvalid_1's binary_logloss: 0.136455\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 98%|█████████▊| 49/50 [25:49<00:36, 36.16s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.816897\ttraining's binary_logloss: 0.16089\tvalid_1's auc: 0.80215\tvalid_1's binary_logloss: 0.156089\n",
            "[2]\ttraining's auc: 0.82636\ttraining's binary_logloss: 0.156461\tvalid_1's auc: 0.81602\tvalid_1's binary_logloss: 0.152664\n",
            "[3]\ttraining's auc: 0.832599\ttraining's binary_logloss: 0.152887\tvalid_1's auc: 0.817747\tvalid_1's binary_logloss: 0.149926\n",
            "[4]\ttraining's auc: 0.834833\ttraining's binary_logloss: 0.150031\tvalid_1's auc: 0.819926\tvalid_1's binary_logloss: 0.147641\n",
            "[5]\ttraining's auc: 0.840337\ttraining's binary_logloss: 0.147592\tvalid_1's auc: 0.823207\tvalid_1's binary_logloss: 0.145803\n",
            "[6]\ttraining's auc: 0.845639\ttraining's binary_logloss: 0.145497\tvalid_1's auc: 0.826218\tvalid_1's binary_logloss: 0.144194\n",
            "[7]\ttraining's auc: 0.850039\ttraining's binary_logloss: 0.14357\tvalid_1's auc: 0.82794\tvalid_1's binary_logloss: 0.1428\n",
            "[8]\ttraining's auc: 0.851847\ttraining's binary_logloss: 0.141932\tvalid_1's auc: 0.828997\tvalid_1's binary_logloss: 0.141546\n",
            "[9]\ttraining's auc: 0.85338\ttraining's binary_logloss: 0.140463\tvalid_1's auc: 0.829798\tvalid_1's binary_logloss: 0.140514\n",
            "[10]\ttraining's auc: 0.855415\ttraining's binary_logloss: 0.13911\tvalid_1's auc: 0.832832\tvalid_1's binary_logloss: 0.139477\n",
            "[11]\ttraining's auc: 0.857581\ttraining's binary_logloss: 0.137868\tvalid_1's auc: 0.833768\tvalid_1's binary_logloss: 0.138607\n",
            "[12]\ttraining's auc: 0.85881\ttraining's binary_logloss: 0.136734\tvalid_1's auc: 0.833325\tvalid_1's binary_logloss: 0.137858\n",
            "[13]\ttraining's auc: 0.860031\ttraining's binary_logloss: 0.135727\tvalid_1's auc: 0.833337\tvalid_1's binary_logloss: 0.13715\n",
            "[14]\ttraining's auc: 0.862092\ttraining's binary_logloss: 0.134815\tvalid_1's auc: 0.834391\tvalid_1's binary_logloss: 0.136541\n",
            "[15]\ttraining's auc: 0.863139\ttraining's binary_logloss: 0.133855\tvalid_1's auc: 0.834511\tvalid_1's binary_logloss: 0.135973\n",
            "[16]\ttraining's auc: 0.865734\ttraining's binary_logloss: 0.132991\tvalid_1's auc: 0.834828\tvalid_1's binary_logloss: 0.135519\n",
            "[17]\ttraining's auc: 0.868279\ttraining's binary_logloss: 0.13219\tvalid_1's auc: 0.835035\tvalid_1's binary_logloss: 0.135107\n",
            "[18]\ttraining's auc: 0.869523\ttraining's binary_logloss: 0.131424\tvalid_1's auc: 0.835269\tvalid_1's binary_logloss: 0.134738\n",
            "[19]\ttraining's auc: 0.870698\ttraining's binary_logloss: 0.130698\tvalid_1's auc: 0.835275\tvalid_1's binary_logloss: 0.134345\n",
            "[20]\ttraining's auc: 0.872226\ttraining's binary_logloss: 0.130014\tvalid_1's auc: 0.834937\tvalid_1's binary_logloss: 0.134051\n",
            "[21]\ttraining's auc: 0.872981\ttraining's binary_logloss: 0.129373\tvalid_1's auc: 0.834456\tvalid_1's binary_logloss: 0.133829\n",
            "[22]\ttraining's auc: 0.87385\ttraining's binary_logloss: 0.128696\tvalid_1's auc: 0.834634\tvalid_1's binary_logloss: 0.133564\n",
            "[23]\ttraining's auc: 0.874734\ttraining's binary_logloss: 0.128126\tvalid_1's auc: 0.834415\tvalid_1's binary_logloss: 0.133357\n",
            "[24]\ttraining's auc: 0.87542\ttraining's binary_logloss: 0.127575\tvalid_1's auc: 0.834293\tvalid_1's binary_logloss: 0.133184\n",
            "[25]\ttraining's auc: 0.876547\ttraining's binary_logloss: 0.127024\tvalid_1's auc: 0.834333\tvalid_1's binary_logloss: 0.132991\n",
            "[26]\ttraining's auc: 0.877455\ttraining's binary_logloss: 0.126544\tvalid_1's auc: 0.83455\tvalid_1's binary_logloss: 0.132794\n",
            "[27]\ttraining's auc: 0.878452\ttraining's binary_logloss: 0.126028\tvalid_1's auc: 0.83504\tvalid_1's binary_logloss: 0.132606\n",
            "[28]\ttraining's auc: 0.878927\ttraining's binary_logloss: 0.125588\tvalid_1's auc: 0.835055\tvalid_1's binary_logloss: 0.132459\n",
            "[29]\ttraining's auc: 0.879863\ttraining's binary_logloss: 0.125097\tvalid_1's auc: 0.834678\tvalid_1's binary_logloss: 0.132351\n",
            "[30]\ttraining's auc: 0.880768\ttraining's binary_logloss: 0.124667\tvalid_1's auc: 0.834761\tvalid_1's binary_logloss: 0.132202\n",
            "[31]\ttraining's auc: 0.881964\ttraining's binary_logloss: 0.124266\tvalid_1's auc: 0.834583\tvalid_1's binary_logloss: 0.132124\n",
            "[32]\ttraining's auc: 0.882986\ttraining's binary_logloss: 0.123859\tvalid_1's auc: 0.834428\tvalid_1's binary_logloss: 0.132023\n",
            "[33]\ttraining's auc: 0.884122\ttraining's binary_logloss: 0.123497\tvalid_1's auc: 0.834262\tvalid_1's binary_logloss: 0.131894\n",
            "[34]\ttraining's auc: 0.884881\ttraining's binary_logloss: 0.123151\tvalid_1's auc: 0.834625\tvalid_1's binary_logloss: 0.131805\n",
            "[35]\ttraining's auc: 0.886037\ttraining's binary_logloss: 0.122723\tvalid_1's auc: 0.834669\tvalid_1's binary_logloss: 0.131719\n",
            "[36]\ttraining's auc: 0.886879\ttraining's binary_logloss: 0.122387\tvalid_1's auc: 0.83451\tvalid_1's binary_logloss: 0.131683\n",
            "[37]\ttraining's auc: 0.888684\ttraining's binary_logloss: 0.12195\tvalid_1's auc: 0.835067\tvalid_1's binary_logloss: 0.131589\n",
            "[38]\ttraining's auc: 0.889273\ttraining's binary_logloss: 0.12163\tvalid_1's auc: 0.834931\tvalid_1's binary_logloss: 0.131568\n",
            "[39]\ttraining's auc: 0.890338\ttraining's binary_logloss: 0.121271\tvalid_1's auc: 0.834644\tvalid_1's binary_logloss: 0.131552\n",
            "[40]\ttraining's auc: 0.891027\ttraining's binary_logloss: 0.120967\tvalid_1's auc: 0.835177\tvalid_1's binary_logloss: 0.131462\n",
            "[41]\ttraining's auc: 0.891493\ttraining's binary_logloss: 0.120665\tvalid_1's auc: 0.835254\tvalid_1's binary_logloss: 0.131383\n",
            "[42]\ttraining's auc: 0.892123\ttraining's binary_logloss: 0.120345\tvalid_1's auc: 0.835407\tvalid_1's binary_logloss: 0.131328\n",
            "[43]\ttraining's auc: 0.892961\ttraining's binary_logloss: 0.12001\tvalid_1's auc: 0.835545\tvalid_1's binary_logloss: 0.131276\n",
            "[44]\ttraining's auc: 0.89365\ttraining's binary_logloss: 0.119753\tvalid_1's auc: 0.835762\tvalid_1's binary_logloss: 0.131218\n",
            "[45]\ttraining's auc: 0.894421\ttraining's binary_logloss: 0.119438\tvalid_1's auc: 0.835377\tvalid_1's binary_logloss: 0.131208\n",
            "[46]\ttraining's auc: 0.895074\ttraining's binary_logloss: 0.119172\tvalid_1's auc: 0.835755\tvalid_1's binary_logloss: 0.131139\n",
            "[47]\ttraining's auc: 0.896162\ttraining's binary_logloss: 0.118887\tvalid_1's auc: 0.835508\tvalid_1's binary_logloss: 0.131143\n",
            "[48]\ttraining's auc: 0.896953\ttraining's binary_logloss: 0.118588\tvalid_1's auc: 0.835746\tvalid_1's binary_logloss: 0.131084\n",
            "[49]\ttraining's auc: 0.897445\ttraining's binary_logloss: 0.118332\tvalid_1's auc: 0.835863\tvalid_1's binary_logloss: 0.131034\n",
            "[50]\ttraining's auc: 0.898173\ttraining's binary_logloss: 0.118084\tvalid_1's auc: 0.835802\tvalid_1's binary_logloss: 0.131019\n",
            "[51]\ttraining's auc: 0.899062\ttraining's binary_logloss: 0.117786\tvalid_1's auc: 0.835623\tvalid_1's binary_logloss: 0.131037\n",
            "[52]\ttraining's auc: 0.900317\ttraining's binary_logloss: 0.117502\tvalid_1's auc: 0.835466\tvalid_1's binary_logloss: 0.131033\n",
            "[53]\ttraining's auc: 0.900802\ttraining's binary_logloss: 0.117248\tvalid_1's auc: 0.835403\tvalid_1's binary_logloss: 0.131022\n",
            "[54]\ttraining's auc: 0.901652\ttraining's binary_logloss: 0.116985\tvalid_1's auc: 0.835497\tvalid_1's binary_logloss: 0.131005\n",
            "[55]\ttraining's auc: 0.902173\ttraining's binary_logloss: 0.116795\tvalid_1's auc: 0.835554\tvalid_1's binary_logloss: 0.130986\n",
            "[56]\ttraining's auc: 0.90294\ttraining's binary_logloss: 0.11652\tvalid_1's auc: 0.835516\tvalid_1's binary_logloss: 0.131002\n",
            "[57]\ttraining's auc: 0.903991\ttraining's binary_logloss: 0.116288\tvalid_1's auc: 0.835431\tvalid_1's binary_logloss: 0.131012\n",
            "[58]\ttraining's auc: 0.90477\ttraining's binary_logloss: 0.115984\tvalid_1's auc: 0.83555\tvalid_1's binary_logloss: 0.13102\n",
            "[59]\ttraining's auc: 0.905204\ttraining's binary_logloss: 0.115758\tvalid_1's auc: 0.835427\tvalid_1's binary_logloss: 0.131036\n",
            "[60]\ttraining's auc: 0.905975\ttraining's binary_logloss: 0.115512\tvalid_1's auc: 0.83558\tvalid_1's binary_logloss: 0.131012\n",
            "[61]\ttraining's auc: 0.906614\ttraining's binary_logloss: 0.115332\tvalid_1's auc: 0.835577\tvalid_1's binary_logloss: 0.131008\n",
            "[62]\ttraining's auc: 0.907157\ttraining's binary_logloss: 0.115063\tvalid_1's auc: 0.835688\tvalid_1's binary_logloss: 0.130998\n",
            "[63]\ttraining's auc: 0.907905\ttraining's binary_logloss: 0.114819\tvalid_1's auc: 0.83567\tvalid_1's binary_logloss: 0.131012\n",
            "[64]\ttraining's auc: 0.908674\ttraining's binary_logloss: 0.114562\tvalid_1's auc: 0.835736\tvalid_1's binary_logloss: 0.131005\n",
            "[65]\ttraining's auc: 0.908975\ttraining's binary_logloss: 0.114378\tvalid_1's auc: 0.835728\tvalid_1's binary_logloss: 0.130993\n",
            "[66]\ttraining's auc: 0.909957\ttraining's binary_logloss: 0.114144\tvalid_1's auc: 0.83578\tvalid_1's binary_logloss: 0.130982\n",
            "[67]\ttraining's auc: 0.910499\ttraining's binary_logloss: 0.113896\tvalid_1's auc: 0.835868\tvalid_1's binary_logloss: 0.130976\n",
            "[68]\ttraining's auc: 0.911194\ttraining's binary_logloss: 0.113653\tvalid_1's auc: 0.835834\tvalid_1's binary_logloss: 0.130982\n",
            "[69]\ttraining's auc: 0.911744\ttraining's binary_logloss: 0.113406\tvalid_1's auc: 0.835854\tvalid_1's binary_logloss: 0.130965\n",
            "[70]\ttraining's auc: 0.912313\ttraining's binary_logloss: 0.113179\tvalid_1's auc: 0.835871\tvalid_1's binary_logloss: 0.130959\n",
            "[71]\ttraining's auc: 0.912667\ttraining's binary_logloss: 0.113028\tvalid_1's auc: 0.836\tvalid_1's binary_logloss: 0.130942\n",
            "[72]\ttraining's auc: 0.91302\ttraining's binary_logloss: 0.112825\tvalid_1's auc: 0.835868\tvalid_1's binary_logloss: 0.130938\n",
            "[73]\ttraining's auc: 0.913385\ttraining's binary_logloss: 0.112635\tvalid_1's auc: 0.835759\tvalid_1's binary_logloss: 0.130948\n",
            "[74]\ttraining's auc: 0.913694\ttraining's binary_logloss: 0.112457\tvalid_1's auc: 0.835625\tvalid_1's binary_logloss: 0.130973\n",
            "[75]\ttraining's auc: 0.914373\ttraining's binary_logloss: 0.112216\tvalid_1's auc: 0.835925\tvalid_1's binary_logloss: 0.130938\n",
            "[76]\ttraining's auc: 0.914743\ttraining's binary_logloss: 0.112031\tvalid_1's auc: 0.83601\tvalid_1's binary_logloss: 0.130932\n",
            "[77]\ttraining's auc: 0.915136\ttraining's binary_logloss: 0.111883\tvalid_1's auc: 0.835967\tvalid_1's binary_logloss: 0.130942\n",
            "[78]\ttraining's auc: 0.91547\ttraining's binary_logloss: 0.111704\tvalid_1's auc: 0.835765\tvalid_1's binary_logloss: 0.130971\n",
            "[79]\ttraining's auc: 0.915815\ttraining's binary_logloss: 0.111517\tvalid_1's auc: 0.83572\tvalid_1's binary_logloss: 0.13095\n",
            "[80]\ttraining's auc: 0.91633\ttraining's binary_logloss: 0.111345\tvalid_1's auc: 0.835591\tvalid_1's binary_logloss: 0.130982\n",
            "[81]\ttraining's auc: 0.916676\ttraining's binary_logloss: 0.1112\tvalid_1's auc: 0.835391\tvalid_1's binary_logloss: 0.131011\n",
            "[82]\ttraining's auc: 0.916933\ttraining's binary_logloss: 0.111039\tvalid_1's auc: 0.835265\tvalid_1's binary_logloss: 0.131025\n",
            "[83]\ttraining's auc: 0.917336\ttraining's binary_logloss: 0.110841\tvalid_1's auc: 0.835153\tvalid_1's binary_logloss: 0.131039\n",
            "[84]\ttraining's auc: 0.917671\ttraining's binary_logloss: 0.110665\tvalid_1's auc: 0.835252\tvalid_1's binary_logloss: 0.131022\n",
            "[85]\ttraining's auc: 0.917896\ttraining's binary_logloss: 0.110508\tvalid_1's auc: 0.835116\tvalid_1's binary_logloss: 0.131047\n",
            "[86]\ttraining's auc: 0.918253\ttraining's binary_logloss: 0.110331\tvalid_1's auc: 0.835177\tvalid_1's binary_logloss: 0.131043\n",
            "[87]\ttraining's auc: 0.918638\ttraining's binary_logloss: 0.11018\tvalid_1's auc: 0.835259\tvalid_1's binary_logloss: 0.131026\n",
            "[88]\ttraining's auc: 0.918826\ttraining's binary_logloss: 0.110041\tvalid_1's auc: 0.835076\tvalid_1's binary_logloss: 0.131066\n",
            "[89]\ttraining's auc: 0.918981\ttraining's binary_logloss: 0.109918\tvalid_1's auc: 0.834956\tvalid_1's binary_logloss: 0.131101\n",
            "[90]\ttraining's auc: 0.919409\ttraining's binary_logloss: 0.10973\tvalid_1's auc: 0.834845\tvalid_1's binary_logloss: 0.131133\n",
            "[91]\ttraining's auc: 0.919591\ttraining's binary_logloss: 0.109612\tvalid_1's auc: 0.83479\tvalid_1's binary_logloss: 0.131143\n",
            "[92]\ttraining's auc: 0.920628\ttraining's binary_logloss: 0.109325\tvalid_1's auc: 0.834626\tvalid_1's binary_logloss: 0.131178\n",
            "[93]\ttraining's auc: 0.92118\ttraining's binary_logloss: 0.109143\tvalid_1's auc: 0.834495\tvalid_1's binary_logloss: 0.131183\n",
            "[94]\ttraining's auc: 0.921313\ttraining's binary_logloss: 0.109042\tvalid_1's auc: 0.834635\tvalid_1's binary_logloss: 0.13115\n",
            "[95]\ttraining's auc: 0.921781\ttraining's binary_logloss: 0.108882\tvalid_1's auc: 0.834535\tvalid_1's binary_logloss: 0.131145\n",
            "[96]\ttraining's auc: 0.922332\ttraining's binary_logloss: 0.108668\tvalid_1's auc: 0.834255\tvalid_1's binary_logloss: 0.131199\n",
            "[97]\ttraining's auc: 0.922638\ttraining's binary_logloss: 0.108516\tvalid_1's auc: 0.834352\tvalid_1's binary_logloss: 0.131193\n",
            "[98]\ttraining's auc: 0.922915\ttraining's binary_logloss: 0.108362\tvalid_1's auc: 0.834505\tvalid_1's binary_logloss: 0.131157\n",
            "[99]\ttraining's auc: 0.923394\ttraining's binary_logloss: 0.10817\tvalid_1's auc: 0.834516\tvalid_1's binary_logloss: 0.131157\n",
            "[100]\ttraining's auc: 0.923846\ttraining's binary_logloss: 0.108012\tvalid_1's auc: 0.834396\tvalid_1's binary_logloss: 0.131173\n",
            "[101]\ttraining's auc: 0.9244\ttraining's binary_logloss: 0.10786\tvalid_1's auc: 0.834463\tvalid_1's binary_logloss: 0.13116\n",
            "[102]\ttraining's auc: 0.92453\ttraining's binary_logloss: 0.10776\tvalid_1's auc: 0.834517\tvalid_1's binary_logloss: 0.131164\n",
            "[103]\ttraining's auc: 0.924678\ttraining's binary_logloss: 0.107644\tvalid_1's auc: 0.834411\tvalid_1's binary_logloss: 0.13119\n",
            "[104]\ttraining's auc: 0.924911\ttraining's binary_logloss: 0.10749\tvalid_1's auc: 0.834432\tvalid_1's binary_logloss: 0.131193\n",
            "[105]\ttraining's auc: 0.92529\ttraining's binary_logloss: 0.10736\tvalid_1's auc: 0.834215\tvalid_1's binary_logloss: 0.13123\n",
            "[106]\ttraining's auc: 0.925413\ttraining's binary_logloss: 0.107263\tvalid_1's auc: 0.834101\tvalid_1's binary_logloss: 0.131254\n",
            "[LightGBM] [Warning] Unknown parameter: min_child_sample\n",
            " 98%|█████████▊| 49/50 [26:05<00:36, 36.16s/trial, best loss: -0.8354636347928764]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\ttraining's auc: 0.826594\ttraining's binary_logloss: 0.157402\tvalid_1's auc: 0.810132\tvalid_1's binary_logloss: 0.163369\n",
            "[2]\ttraining's auc: 0.831489\ttraining's binary_logloss: 0.153172\tvalid_1's auc: 0.814459\tvalid_1's binary_logloss: 0.159577\n",
            "[3]\ttraining's auc: 0.835985\ttraining's binary_logloss: 0.149777\tvalid_1's auc: 0.817084\tvalid_1's binary_logloss: 0.156687\n",
            "[4]\ttraining's auc: 0.838097\ttraining's binary_logloss: 0.147041\tvalid_1's auc: 0.818544\tvalid_1's binary_logloss: 0.154293\n",
            "[5]\ttraining's auc: 0.844291\ttraining's binary_logloss: 0.144573\tvalid_1's auc: 0.823356\tvalid_1's binary_logloss: 0.152215\n",
            "[6]\ttraining's auc: 0.847638\ttraining's binary_logloss: 0.142457\tvalid_1's auc: 0.824573\tvalid_1's binary_logloss: 0.150501\n",
            "[7]\ttraining's auc: 0.850388\ttraining's binary_logloss: 0.140644\tvalid_1's auc: 0.82655\tvalid_1's binary_logloss: 0.148935\n",
            "[8]\ttraining's auc: 0.851662\ttraining's binary_logloss: 0.13893\tvalid_1's auc: 0.827512\tvalid_1's binary_logloss: 0.147655\n",
            "[9]\ttraining's auc: 0.852478\ttraining's binary_logloss: 0.137445\tvalid_1's auc: 0.827913\tvalid_1's binary_logloss: 0.146457\n",
            "[10]\ttraining's auc: 0.854255\ttraining's binary_logloss: 0.136112\tvalid_1's auc: 0.828676\tvalid_1's binary_logloss: 0.145479\n",
            "[11]\ttraining's auc: 0.856379\ttraining's binary_logloss: 0.134918\tvalid_1's auc: 0.829611\tvalid_1's binary_logloss: 0.144548\n",
            "[12]\ttraining's auc: 0.857288\ttraining's binary_logloss: 0.13384\tvalid_1's auc: 0.829961\tvalid_1's binary_logloss: 0.14369\n",
            "[13]\ttraining's auc: 0.858846\ttraining's binary_logloss: 0.132821\tvalid_1's auc: 0.830365\tvalid_1's binary_logloss: 0.142932\n",
            "[14]\ttraining's auc: 0.860915\ttraining's binary_logloss: 0.131881\tvalid_1's auc: 0.830548\tvalid_1's binary_logloss: 0.142289\n",
            "[15]\ttraining's auc: 0.863634\ttraining's binary_logloss: 0.131021\tvalid_1's auc: 0.830516\tvalid_1's binary_logloss: 0.141716\n",
            "[16]\ttraining's auc: 0.8644\ttraining's binary_logloss: 0.130228\tvalid_1's auc: 0.830604\tvalid_1's binary_logloss: 0.141224\n",
            "[17]\ttraining's auc: 0.866818\ttraining's binary_logloss: 0.129439\tvalid_1's auc: 0.830944\tvalid_1's binary_logloss: 0.140752\n",
            "[18]\ttraining's auc: 0.868556\ttraining's binary_logloss: 0.128709\tvalid_1's auc: 0.831024\tvalid_1's binary_logloss: 0.140309\n",
            "[19]\ttraining's auc: 0.87002\ttraining's binary_logloss: 0.128032\tvalid_1's auc: 0.830901\tvalid_1's binary_logloss: 0.139979\n",
            "[20]\ttraining's auc: 0.872472\ttraining's binary_logloss: 0.127334\tvalid_1's auc: 0.833002\tvalid_1's binary_logloss: 0.139626\n",
            "[21]\ttraining's auc: 0.873075\ttraining's binary_logloss: 0.126742\tvalid_1's auc: 0.833269\tvalid_1's binary_logloss: 0.139307\n",
            "[22]\ttraining's auc: 0.874779\ttraining's binary_logloss: 0.126125\tvalid_1's auc: 0.833959\tvalid_1's binary_logloss: 0.13903\n",
            "[23]\ttraining's auc: 0.875992\ttraining's binary_logloss: 0.125563\tvalid_1's auc: 0.83425\tvalid_1's binary_logloss: 0.138751\n",
            "[24]\ttraining's auc: 0.878032\ttraining's binary_logloss: 0.125004\tvalid_1's auc: 0.834832\tvalid_1's binary_logloss: 0.138457\n",
            "[25]\ttraining's auc: 0.878968\ttraining's binary_logloss: 0.124479\tvalid_1's auc: 0.834611\tvalid_1's binary_logloss: 0.138252\n",
            "[26]\ttraining's auc: 0.880192\ttraining's binary_logloss: 0.123967\tvalid_1's auc: 0.834881\tvalid_1's binary_logloss: 0.138027\n",
            "[27]\ttraining's auc: 0.881563\ttraining's binary_logloss: 0.12347\tvalid_1's auc: 0.83506\tvalid_1's binary_logloss: 0.13786\n",
            "[28]\ttraining's auc: 0.883071\ttraining's binary_logloss: 0.122998\tvalid_1's auc: 0.835335\tvalid_1's binary_logloss: 0.13768\n",
            "[29]\ttraining's auc: 0.8837\ttraining's binary_logloss: 0.122578\tvalid_1's auc: 0.835413\tvalid_1's binary_logloss: 0.137527\n",
            "[30]\ttraining's auc: 0.885093\ttraining's binary_logloss: 0.122126\tvalid_1's auc: 0.834991\tvalid_1's binary_logloss: 0.137445\n",
            "[31]\ttraining's auc: 0.885853\ttraining's binary_logloss: 0.121742\tvalid_1's auc: 0.835335\tvalid_1's binary_logloss: 0.137282\n",
            "[32]\ttraining's auc: 0.887263\ttraining's binary_logloss: 0.121314\tvalid_1's auc: 0.835442\tvalid_1's binary_logloss: 0.137181\n",
            "[33]\ttraining's auc: 0.88851\ttraining's binary_logloss: 0.120877\tvalid_1's auc: 0.835797\tvalid_1's binary_logloss: 0.137069\n",
            "[34]\ttraining's auc: 0.889185\ttraining's binary_logloss: 0.120515\tvalid_1's auc: 0.835704\tvalid_1's binary_logloss: 0.136981\n",
            "[35]\ttraining's auc: 0.889831\ttraining's binary_logloss: 0.120181\tvalid_1's auc: 0.835424\tvalid_1's binary_logloss: 0.136937\n",
            "[36]\ttraining's auc: 0.89061\ttraining's binary_logloss: 0.119845\tvalid_1's auc: 0.835454\tvalid_1's binary_logloss: 0.136845\n",
            "[37]\ttraining's auc: 0.89139\ttraining's binary_logloss: 0.119511\tvalid_1's auc: 0.83515\tvalid_1's binary_logloss: 0.136819\n",
            "[38]\ttraining's auc: 0.892412\ttraining's binary_logloss: 0.119128\tvalid_1's auc: 0.835307\tvalid_1's binary_logloss: 0.13677\n",
            "[39]\ttraining's auc: 0.893005\ttraining's binary_logloss: 0.118799\tvalid_1's auc: 0.835177\tvalid_1's binary_logloss: 0.136771\n",
            "[40]\ttraining's auc: 0.893751\ttraining's binary_logloss: 0.118501\tvalid_1's auc: 0.83528\tvalid_1's binary_logloss: 0.136713\n",
            "[41]\ttraining's auc: 0.894228\ttraining's binary_logloss: 0.118234\tvalid_1's auc: 0.835399\tvalid_1's binary_logloss: 0.136637\n",
            "[42]\ttraining's auc: 0.894875\ttraining's binary_logloss: 0.117934\tvalid_1's auc: 0.83547\tvalid_1's binary_logloss: 0.136556\n",
            "[43]\ttraining's auc: 0.895932\ttraining's binary_logloss: 0.117612\tvalid_1's auc: 0.835439\tvalid_1's binary_logloss: 0.136516\n",
            "[44]\ttraining's auc: 0.896725\ttraining's binary_logloss: 0.117283\tvalid_1's auc: 0.835351\tvalid_1's binary_logloss: 0.136476\n",
            "[45]\ttraining's auc: 0.898124\ttraining's binary_logloss: 0.116925\tvalid_1's auc: 0.83522\tvalid_1's binary_logloss: 0.136475\n",
            "[46]\ttraining's auc: 0.898662\ttraining's binary_logloss: 0.11665\tvalid_1's auc: 0.835384\tvalid_1's binary_logloss: 0.136422\n",
            "[47]\ttraining's auc: 0.899406\ttraining's binary_logloss: 0.116373\tvalid_1's auc: 0.835283\tvalid_1's binary_logloss: 0.136399\n",
            "[48]\ttraining's auc: 0.900092\ttraining's binary_logloss: 0.116137\tvalid_1's auc: 0.835196\tvalid_1's binary_logloss: 0.13639\n",
            "[49]\ttraining's auc: 0.900828\ttraining's binary_logloss: 0.115855\tvalid_1's auc: 0.834827\tvalid_1's binary_logloss: 0.136427\n",
            "[50]\ttraining's auc: 0.901605\ttraining's binary_logloss: 0.1156\tvalid_1's auc: 0.834844\tvalid_1's binary_logloss: 0.136394\n",
            "[51]\ttraining's auc: 0.9023\ttraining's binary_logloss: 0.115256\tvalid_1's auc: 0.834826\tvalid_1's binary_logloss: 0.136364\n",
            "[52]\ttraining's auc: 0.902708\ttraining's binary_logloss: 0.115023\tvalid_1's auc: 0.834978\tvalid_1's binary_logloss: 0.136362\n",
            "[53]\ttraining's auc: 0.903295\ttraining's binary_logloss: 0.114733\tvalid_1's auc: 0.835028\tvalid_1's binary_logloss: 0.136315\n",
            "[54]\ttraining's auc: 0.903865\ttraining's binary_logloss: 0.114515\tvalid_1's auc: 0.835057\tvalid_1's binary_logloss: 0.136306\n",
            "[55]\ttraining's auc: 0.904396\ttraining's binary_logloss: 0.114249\tvalid_1's auc: 0.834966\tvalid_1's binary_logloss: 0.136348\n",
            "[56]\ttraining's auc: 0.904919\ttraining's binary_logloss: 0.11398\tvalid_1's auc: 0.8349\tvalid_1's binary_logloss: 0.136353\n",
            "[57]\ttraining's auc: 0.905475\ttraining's binary_logloss: 0.113741\tvalid_1's auc: 0.834801\tvalid_1's binary_logloss: 0.136385\n",
            "[58]\ttraining's auc: 0.906151\ttraining's binary_logloss: 0.113443\tvalid_1's auc: 0.834663\tvalid_1's binary_logloss: 0.136415\n",
            "[59]\ttraining's auc: 0.90664\ttraining's binary_logloss: 0.113199\tvalid_1's auc: 0.834688\tvalid_1's binary_logloss: 0.13642\n",
            "[60]\ttraining's auc: 0.907196\ttraining's binary_logloss: 0.112965\tvalid_1's auc: 0.83472\tvalid_1's binary_logloss: 0.136427\n",
            "[61]\ttraining's auc: 0.90767\ttraining's binary_logloss: 0.112743\tvalid_1's auc: 0.834818\tvalid_1's binary_logloss: 0.136437\n",
            "[62]\ttraining's auc: 0.908131\ttraining's binary_logloss: 0.112492\tvalid_1's auc: 0.834992\tvalid_1's binary_logloss: 0.136368\n",
            "[63]\ttraining's auc: 0.908773\ttraining's binary_logloss: 0.112205\tvalid_1's auc: 0.835326\tvalid_1's binary_logloss: 0.136307\n",
            "100%|██████████| 50/50 [26:13<00:00, 31.48s/trial, best loss: -0.8354636347928764]\n",
            "best: {'learning_rate': 0.07211160995639987, 'max_depth': 131.0, 'min_child_samples': 60.0, 'num_leaves': 47.0, 'subsample': 0.830574749612011}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf = LGBMClassifier(n_estimator=500, num_leaves=int(best['num_leaves']), subsample=round(best['subsample']),\n",
        "                          min_child_samples=int(best['min_child_samples']), learning_rate=round(best['learning_rate']),\n",
        "                          max_depth=(best['max_depth']))\n",
        "\n",
        "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
        "lgbm_clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=evals,\n",
        "             verbose=0)\n",
        "\n",
        "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1])\n",
        "print('ROC AUC: {0:.4f}'.format(lgbm_roc_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "3ageq3d_pt1m",
        "outputId": "67a4df30-5e03-4411-e1d0-a1bcbba22076"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: n_estimator\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LightGBMError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-684d035c4a58>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mevals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m lgbm_clf.fit(X_train, y_train, early_stopping_rounds=100, eval_metric=\"auc\", eval_set=evals,\n\u001b[0m\u001b[1;32m      7\u001b[0m              verbose=0)\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    965\u001b[0m                     \u001b[0mvalid_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_le\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,\n\u001b[0m\u001b[1;32m    968\u001b[0m                     \u001b[0meval_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                     \u001b[0meval_class_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_init_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m    749\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2603\u001b[0m                 )\n\u001b[1;32m   2604\u001b[0m             \u001b[0;31m# construct booster object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2605\u001b[0;31m             \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2606\u001b[0m             \u001b[0;31m# copy the parameters from train_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2607\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1813\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m                 \u001b[0;31m# create train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1815\u001b[0;31m                 self._lazy_init(self.data, label=self.label,\n\u001b[0m\u001b[1;32m   1816\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1817\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_from_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init_from_np2d\u001b[0;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0mptr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ptr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m         _safe_call(_LIB.LGBM_DatasetCreateFromMat(\n\u001b[0m\u001b[1;32m   1660\u001b[0m             \u001b[0mptr_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_ptr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \"\"\"\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLightGBMError\u001b[0m: Check failed: (learning_rate) > (0.0) at /__w/1/s/python-package/compile/src/io/config_auto.cpp, line 331 .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10**"
      ],
      "metadata": {
        "id": "meGh4eGwQY88"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wnERvdsQUBP"
      },
      "outputs": [],
      "source": [
        "# conda install -c conda-forge imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline\n",
        "\n",
        "card_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Datasets/creditcard.csv')\n",
        "card_df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "htKBzW1NSbEx",
        "outputId": "acbbd1ab-71b9-419e-9983-5a45f92d95ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "\n",
              "[3 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-62240945-f894-47bd-94e2-0592e66c4d23\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 31 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62240945-f894-47bd-94e2-0592e66c4d23')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-62240945-f894-47bd-94e2-0592e66c4d23 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-62240945-f894-47bd-94e2-0592e66c4d23');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8d33a59-83c8-44bd-b36f-abbd50d2cde0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8d33a59-83c8-44bd-b36f-abbd50d2cde0')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8d33a59-83c8-44bd-b36f-abbd50d2cde0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "  df_copy = df.copy()\n",
        "  df_copy.drop('Time', axis=1, inplace=True)\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "Qsgvads4SgJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_train_test_dataset(df=None):\n",
        "# Time열 드롭\n",
        "  df_copy = get_preprocessed_df(df)\n",
        "\n",
        "  X_features = df_copy.iloc[:, :-1]\n",
        "  y_target = df_copy.iloc[:, -1]\n",
        "\n",
        "  X_train, X_test, y_train, y_test = \\\n",
        "  train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)"
      ],
      "metadata": {
        "id": "61Pon2s5ShPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('학습 데이터 레이블 값 비율')\n",
        "print(y_train.value_counts()/y_train.shape[0]*100)\n",
        "\n",
        "print('테스트 데이터 레이블 값 비율')\n",
        "print(y_test.value_counts()/y_test.shape[0]*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWcuZxI3SirT",
        "outputId": "1f9071d1-0bb5-47f8-9f1a-d7dc7fa7458f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 레이블 값 비율\n",
            "0    99.827451\n",
            "1     0.172549\n",
            "Name: Class, dtype: float64\n",
            "테스트 데이터 레이블 값 비율\n",
            "0    99.826785\n",
            "1     0.173215\n",
            "Name: Class, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "  confusion = confusion_matrix( y_test, pred)\n",
        "  accuracy = accuracy_score(y_test, pred)\n",
        "  precision = precision_score(y_test, pred)\n",
        "  recall = recall_score(y_test, pred)\n",
        "\n",
        "  f1 = f1_score(y_test, pred)\n",
        "\n",
        "  # ROC_AUC 추가\n",
        "  roc_auc = roc_auc_score(y_test, pred_proba)\n",
        "\n",
        "  print('오차행렬')\n",
        "  print(confusion)\n",
        "\n",
        "  # ROC-AUC print 추가\n",
        "\n",
        "  print('accuracy: {0:.4f}, precision:{1:.4f}, recall: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'\n",
        "        .format(accuracy, precision, recall,f1,roc_auc))"
      ],
      "metadata": {
        "id": "U2EOzKKsSx5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_pred = lr_clf.predict(X_test)\n",
        "lr_pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "get_clf_eval(y_test, lr_pred, lr_pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7DRscRqS8as",
        "outputId": "5e4ade02-e5e2-46c6-bbd5-222df24894c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차행렬\n",
            "[[85283    12]\n",
            " [   60    88]]\n",
            "accuracy: 0.9992, precision:0.8800, recall: 0.5946, F1: 0.7097, AUC: 0.9593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
        "  model.fit(ftr_train, tgt_train)\n",
        "  pred = model.predict(ftr_test)\n",
        "  pred_proba = model.predict_proba(ftr_test)[:, 1]\n",
        "  get_clf_eval(tgt_test, pred, pred_proba)"
      ],
      "metadata": {
        "id": "1A6iPCt6TDQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leavers=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV909cdMTE_U",
        "outputId": "25a9d38c-d42a-44d6-f35b-677a663ce90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Unknown parameter: num_leavers\n",
            "[LightGBM] [Warning] Unknown parameter: num_leavers\n",
            "[LightGBM] [Info] Number of positive: 344, number of negative: 199020\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.199969 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 199364, number of used features: 29\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Unknown parameter: num_leavers\n",
            "[LightGBM] [Warning] Unknown parameter: num_leavers\n",
            "오차행렬\n",
            "[[85291     4]\n",
            " [   36   112]]\n",
            "accuracy: 0.9995, precision:0.9655, recall: 0.7568, F1: 0.8485, AUC: 0.9802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.xticks(range(0, 30000, 1000), rotation=60)\n",
        "sns.distplot(card_df['Amount'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "JTLfysU6TL8b",
        "outputId": "14d44e15-ac9d-4208-fe2e-14fb46829b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='Amount', ylabel='Density'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "  df_copy = df.copy()\n",
        "  scaler = StandardScaler()\n",
        "  amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1, 1))\n",
        "\n",
        "  df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "\n",
        "  df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "0IW-ByJdTOfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Amount 정규 분포 형태로 변환 후 로지스틱, LightBGM수\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train,\n",
        "                     tgt_test=y_test)\n",
        "\n",
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqVlHDJCTRD6",
        "outputId": "d38fee07-aa17-462a-ab1f-18fe1490e115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차행렬\n",
            "[[85281    14]\n",
            " [   58    90]]\n",
            "accuracy: 0.9992, precision:0.8654, recall: 0.6081, F1: 0.7143, AUC: 0.9702\n",
            "[LightGBM] [Info] Number of positive: 344, number of negative: 199020\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064506 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 199364, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001725 -> initscore=-6.360519\n",
            "[LightGBM] [Info] Start training from score -6.360519\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "오차행렬\n",
            "[[85191   104]\n",
            " [  101    47]]\n",
            "accuracy: 0.9976, precision:0.3113, recall: 0.3176, F1: 0.3144, AUC: 0.6578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessed_df(df=None):\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    amount_n = np.log1p(df_copy['Amount'])\n",
        "    df_copy.insert(0, 'Amount_scaled', amount_n)\n",
        "    df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "    return df_copy"
      ],
      "metadata": {
        "id": "lwybuVsITmsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
        "\n",
        "print('###로지스틱 회귀 예측 성능###')\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train,\n",
        "                     tgt_test=y_test)\n",
        "\n",
        "print('###LightGBM 예측 성능###')\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train,\n",
        "                     tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwQfk7l7Tntl",
        "outputId": "39a3c19b-ec3f-4312-b258-b5489a4def2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###로지스틱 회귀 예측 성능###\n",
            "오차행렬\n",
            "[[85283    12]\n",
            " [   59    89]]\n",
            "accuracy: 0.9992, precision:0.8812, recall: 0.6014, F1: 0.7149, AUC: 0.9727\n",
            "###LightGBM 예측 성능###\n",
            "[LightGBM] [Info] Number of positive: 344, number of negative: 199020\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066615 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 199364, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001725 -> initscore=-6.360519\n",
            "[LightGBM] [Info] Start training from score -6.360519\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
            "오차행렬\n",
            "[[85268    27]\n",
            " [   65    83]]\n",
            "accuracy: 0.9989, precision:0.7545, recall: 0.5608, F1: 0.6434, AUC: 0.7802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "corr=card_df.corr()\n",
        "sns.heatmap(corr, cmap='RdBu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "ZLvIY_7pTrfe",
        "outputId": "31a25c92-595d-4856-f701-42d56d99f85a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 900x900 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_outlier(df=None, column=None, weight=1.5):\n",
        "  fraud = df[df['Class']==1][column]\n",
        "  # froad 만\n",
        "  # 25%, 75%지점\n",
        "  quantile_25 = np.percentile(fraud.values, 25)\n",
        "  quantile_75 = np.percentile(fraud.values, 75)\n",
        "\n",
        "  iqr = quantile_75 - quantile_25\n",
        "\n",
        "  iqr_weight = iqr*weight\n",
        "  lowest_val = quantile_25 - iqr_weight\n",
        "  highest_val = quantile_75 + iqr_weight\n",
        "\n",
        "  outlier_index = fraud[(fraud<lowest_val)|(fraud>highest_val)].index\n",
        "  return outlier_index"
      ],
      "metadata": {
        "id": "31CeMKO1TsmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_index = get_outlier(df=card_df, column='V14', weight=1.5)\n",
        "print('outlier data index', outlier_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rSvAjKPT842",
        "outputId": "eaaaa9d7-a637-4e49-ea79-906e8773f3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outlier data index Int64Index([8296, 8615, 9035, 9252], dtype='int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preprocessed_df(df=None):\n",
        "  df_copy = df.copy()\n",
        "  amount_n = np.log1p(df_copy['Amount'])\n",
        "  df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "  df_copy.drop(['Time', 'Amount'], axis = 1, inplace = True)\n",
        "  # 이상치 삭제\n",
        "  outlier_index = get_outlier(df=card_df, column='V14', weight=1.5)\n",
        "  df_copy.drop(outlier_index, axis = 0, inplace = True)\n",
        "\n",
        "  return df_copy\n",
        "\n",
        "X_train, X_test, y_train, y_test = get_train_test_dataset(card_df)\n",
        "print('Logistic Reg 성능')\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test = X_test, tgt_train = y_train,\n",
        "                     tgt_test = y_test)\n",
        "print('LightGBM 성능')\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test = X_test, tgt_train = y_train,\n",
        "                     tgt_test = y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdOZdjSxT9bc",
        "outputId": "270a777e-8eff-4068-d59f-dd2fcbaee67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Reg 성능\n",
            "오차행렬\n",
            "[[85281    14]\n",
            " [   48    98]]\n",
            "accuracy: 0.9993, precision:0.8750, recall: 0.6712, F1: 0.7597, AUC: 0.9743\n",
            "LightGBM 성능\n",
            "[LightGBM] [Info] Number of positive: 342, number of negative: 199020\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062384 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 199362, number of used features: 29\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.001715 -> initscore=-6.366350\n",
            "[LightGBM] [Info] Start training from score -6.366350\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "오차행렬\n",
            "[[85268    27]\n",
            " [   36   110]]\n",
            "accuracy: 0.9993, precision:0.8029, recall: 0.7534, F1: 0.7774, AUC: 0.9218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=0)\n",
        "\n",
        "# fit_sample > fit_resample??\n",
        "\n",
        "X_train_over, y_train_over = smote.fit_resample(X_train, y_train)\n",
        "print('SMOTE 적용 후')\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_train_over.shape, y_train_over.shape)\n",
        "print(pd.Series(y_train_over).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc7RveOHUPUk",
        "outputId": "461f0bc1-2db2-409a-b048-b220f474ae73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SMOTE 적용 후\n",
            "(199362, 29) (199362,)\n",
            "(398040, 29) (398040,)\n",
            "0    199020\n",
            "1    199020\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf = LogisticRegression()\n",
        "\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train_over, ftr_test = X_test, tgt_train = y_train_over,\n",
        "                     tgt_test = y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99AIRT_FUesQ",
        "outputId": "d3cacddb-e5ca-423b-8e0d-462c55159932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차행렬\n",
            "[[82937  2358]\n",
            " [   11   135]]\n",
            "accuracy: 0.9723, precision:0.0542, recall: 0.9247, F1: 0.1023, AUC: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import increment_lineno\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def precision_recall_curve_plot(y_test, pred_proba_c1):\n",
        "  # threshold ndarray와 이 임계점에 따른 정밀도, 재현율 ndarray 추출\n",
        "  precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)\n",
        "\n",
        "  # X축을 threshold값으로, Y축은 정밀도,재현율 값으로 각각 plot수행. 정밀도는 점선\n",
        "  plt.figure(figsize=(8,6))\n",
        "  threshold_boundary = thresholds.shape[0]\n",
        "  plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
        "  plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')\n",
        "\n",
        "  # threshold 값 X축의 Scale을 0.1단위로 변경\n",
        "  start, end = plt.xlim()\n",
        "  plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
        "\n",
        "  # x축, y축 label, legend, grid 설정\n",
        "  plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
        "  plt.legend(); plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "jAqN0b3pUgk3",
        "outputId": "a97be820-0951-47d6-82fc-8234b4b8da3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "TbmREJB4Uja2",
        "outputId": "478fb8b2-a838-43af-a08f-cb7ea5bebbbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train_over, ftr_test=X_test,\n",
        "                     tgt_train=y_train_over, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpY4SGHAUkZj",
        "outputId": "5c4fab92-871f-4251-e089-908d5e9f5d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 199020, number of negative: 199020\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.117747 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 7395\n",
            "[LightGBM] [Info] Number of data points in the train set: 398040, number of used features: 29\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "오차행렬\n",
            "[[85283    12]\n",
            " [   22   124]]\n",
            "accuracy: 0.9996, precision:0.9118, recall: 0.8493, F1: 0.8794, AUC: 0.9814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11**"
      ],
      "metadata": {
        "id": "jQ29KFY5UnoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "\n",
        "X_data = cancer_data.data\n",
        "y_label = cancer_data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2, random_state=0)\n"
      ],
      "metadata": {
        "id": "ctp8gzWdUnNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 모델 생성/학습/예측/정확도 측정\n",
        "\n",
        "knn_clf = KNeighborsClassifier(n_neighbors=4)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state = 0)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "lr_final = LogisticRegression(C=10)\n",
        "\n",
        "knn_clf.fit(X_train, y_train)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "ada_clf.fit(X_train, y_train)\n",
        "\n",
        "knn_pred = knn_clf.predict(X_test)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "ada_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print(accuracy_score(y_test, knn_pred))\n",
        "print(accuracy_score(y_test, rf_pred))\n",
        "print(accuracy_score(y_test, dt_pred))\n",
        "print(accuracy_score(y_test, ada_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9cYU6HjUrga",
        "outputId": "e5dbd776-b2d7-4b5e-cd47-101133a05e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9210526315789473\n",
            "0.9649122807017544\n",
            "0.9035087719298246\n",
            "0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = np.array([knn_pred,rf_pred,dt_pred,ada_pred])\n",
        "\n",
        "print(pred.shape)\n",
        "\n",
        "# transpose>열단위의 예측결과로 피처 생\n",
        "\n",
        "pred = np.transpose(pred)\n",
        "print(pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vxMSHIVUz4G",
        "outputId": "c50107e9-a120-46a6-cebd-7d9255488bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 114)\n",
            "(114, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_final.fit(pred, y_test)\n",
        "final = lr_final.predict(pred)\n",
        "\n",
        "print('최종 메타 모델의 정확도: ')\n",
        "print(accuracy_score(y_test, final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQb6GTYRVF5T",
        "outputId": "dc3695e1-f47a-43e8-9f90-24d4801a22ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 메타 모델의 정확도: \n",
            "0.9736842105263158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
        "  kf = KFold(n_splits=n_folds, shuffle=False)\n",
        "\n",
        "  train_fold_pred = np.zeros((X_train_n.shape[0], 1))\n",
        "  test_pred = np.zeros((X_test_n.shape[0], n_folds))\n",
        "  print(model.__class__.__name__)\n",
        "\n",
        "  for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
        "    print(folder_counter)\n",
        "    X_tr = X_train_n[train_index]\n",
        "    y_tr = y_train_n[train_index]\n",
        "    X_te = X_train_n[valid_index]\n",
        "\n",
        "    #폴드 세트 내부에서 생성된 데이터로 기반모델 학습/검증>예측\n",
        "    model.fit(X_tr, y_tr)\n",
        "    train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
        "    # 원본 데이터로 예측\n",
        "    test_pred[:,folder_counter] = model.predict(X_test_n)\n",
        "\n",
        "  test_pred_mean = np.mean(test_pred, axis = 1).reshape(-1,1)\n",
        "\n",
        "  # 최종 메타 모델이 사용할 데이터\n",
        "  return train_fold_pred, test_pred_mean\n",
        "\n",
        "# 각 기반 모델로 최종 모델이 사용할 데이터 생성\n",
        "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
        "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
        "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
        "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)\n",
        "\n",
        "# 결과 합치기_스태\n",
        "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
        "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
        "\n",
        "print('original train data:', X_train.shape,'original test data', X_test.shape)\n",
        "print('Stacking train data:', Stack_final_X_train.shape,'Stacking test data', Stack_final_X_test.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbwL3_e9VO1p",
        "outputId": "e7d8633c-e017-40c3-c525-098039388c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighborsClassifier\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "RandomForestClassifier\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "DecisionTreeClassifier\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "AdaBoostClassifier\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "original train data: (455, 30) original test data (114, 30)\n",
            "Stacking train data: (455, 4) Stacking test data (114, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_final.fit(Stack_final_X_train, y_train)\n",
        "stack_final = lr_final.predict(Stack_final_X_test)\n",
        "\n",
        "print('최종 메타 모델 정확도:{0:.4f}'.format(accuracy_score(y_test, stack_final)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATGTVqj4WAXT",
        "outputId": "ba7c179c-0972-41e8-99dd-3d846b19d0b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 메타 모델 정확도:0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YnVWDrzYzA4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}